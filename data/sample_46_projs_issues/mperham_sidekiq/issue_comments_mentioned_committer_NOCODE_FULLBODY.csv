issue_num,datetime,body,login,mention_login
3410,2017-03-26 04:55:47,"@mperham - Yes,  and I was following along https://github.com/mperham/sidekiq/wiki/Batches.

I hope hope's it helpful but here's the error log I received:

    {
    context: Job raised exception, 
    job: {
    args: [
    complete, 
    gq8vqsqi6PGezw, 
    default
    ], 
    class: Sidekiq::Batch::Callback, 
    created_at: 1490499153.6902235, 
    enqueued_at: 1490499328.2866085, 
    error_class: NameError, 
    error_message: wrong constant name , 
    failed_at: 1490499153.6977885, 
    jid: 4eb294b68fa801de808828b4, 
    queue: default, 
    retried_at: 1490499328.2948356, 
    retry: True, 
    retry_count: 3
    }, 
    jobstr: {""class"":""Sidekiq::Batch::Callback"",""queue"":""default"",""args"":[""complete"",""gq8vqsqi6PGezw"",""default""],""retry"":true,""jid"":""4eb294b68fa801de808828b4"",""created_at"":1490499153.6902235,""enqueued_at"":1490499328.2866085,""error_message"":""wrong constant name "",""error_class"":""NameError"",""failed_at"":1490499153.6977885,""retry_count"":2,""retried_at"":1490499231.4071321}
    }",ACPK,mperham
3410,2017-03-26 05:00:10,"@mperham  - I've removed the complete line and edited the code to include ""self.step2"" but receive the error:

    {
    context: Job raised exception, 
    job: {
    args: [
    success, 
    u_KxxOWaFiuKrQ, 
    default
    ], 
    class: Sidekiq::Batch::Callback, 
    created_at: 1490503659.5103257, 
    enqueued_at: 1490503678.3210003, 
    error_class: NameError, 
    error_message: wrong constant name DailyWorkflowJob.step2, 
    failed_at: 1490503659.5157926, 
    jid: 8976694c6a4ee7b2fc0e340f, 
    queue: default, 
    retried_at: 1490503678.3260722, 
    retry: True, 
    retry_count: 1
    }, 
    jobstr: {""class"":""Sidekiq::Batch::Callback"",""queue"":""default"",""args"":[""success"",""u_KxxOWaFiuKrQ"",""default""],""retry"":true,""jid"":""8976694c6a4ee7b2fc0e340f"",""created_at"":1490503659.5103257,""enqueued_at"":1490503678.3210003,""error_message"":""wrong constant name DailyWorkflowJob.step2"",""error_class"":""NameError"",""failed_at"":1490503659.5157926,""retry_count"":0}
    }
",ACPK,mperham
3410,2017-03-26 06:21:26,"@mperham When I removed the .self, I still get ""wrong constant name DailyWorkflowJob.step2"".",ACPK,mperham
3410,2017-03-27 01:52:20,"@mperham @myfitment - I got it working by changing "".on(:complete, self)"" to "".on(:complete, self.class)"". Let me know if that works for you @myfitment.",ACPK,mperham
3409,2017-03-27 16:23:32,"Thanks @myfitment @mperham for sharing sample code.

While implementing the same we found an issue with the queue of jobs.

Let's say  `ChildWorker` has `base` queue and `ProductWorker` has `notifications` queue. 
But using above sample code, jobs of `ProductWorker` use `default` queue instead of `notifications`.
",ronakjangir47,mperham
3399,2017-03-22 15:31:13,@mperham done!,novito,mperham
3399,2017-03-23 08:29:28,"@mperham thanks for feedback. I will see if I can reproduce with update, but is hard because I've not even been able to reproduce with my current versions. It happens unexpectedly.",novito,mperham
3393,2017-03-19 08:25:55,"Thanks so much for the speedy response, @mperham !

Ah! Of course!! It now seems so obvious, no clue how I didn't think of it...

So there was a ""lost"" sidekiq process that obviously didn't get the USR2 signal ...

We're on 14.04, so I think systemd isn't available yet, but I've had some not-so-great experience with upstart (although it was a few years ago now), and the next upgrade we'll probably be on systemd. I'll meanwhile just make sure we don't lose any sidekiq processes with a temporary hack or some manual check in the init.d script.

Thanks so much again Mike!",gingerlime,mperham
3392,2017-03-18 15:51:15,💥 thanks for the quick turn-around @mperham!,agrobbin,mperham
3390,2017-03-16 18:16:43,Thanks @mperham ! <3,bobber205,mperham
3381,2017-03-12 05:17:39,"@mperham this look correct.
good job",seuros,mperham
3381,2017-03-13 19:05:07,"@seuros I've pushed an rtl branch which contains my initial work.  You are welcome to add an Arabic locale, update the `rtl?` method and let us know the results.",mperham,seuros
3379,2017-03-10 23:05:44,"@mm580486 can you should a screenshot of the dashboard ?
",seuros,mm580486
3377,2017-03-09 17:22:36,"@badosu this worked, thanks:

Was wondering if this could be detected in Sidekiq, from the :domain option that I pass in session_store.rb",heaven,badosu
3371,2017-03-06 21:04:37,"@mperham 
Executed same tests again but this time without `unique_for`. Most of batches were not completed.
",raivil,mperham
3370,2017-03-05 00:37:50,"@mperham updated to go with RAILS_MAX_THREADS, not sure why you closed.
",nateberkopec,mperham
3370,2017-03-05 01:33:07,"@mperham I want to make sure client pool sizes aren't unneccessarily large on, say, single-threaded apps (RAILS_MAX_THREADS=1). AFAICT in that case right now you'd set the pool size to 5, even though the client will only ever use 1. Server-side concurrency and pool sizes are not affected (they look good right now).",nateberkopec,mperham
3366,2017-03-08 10:32:36,"Hi @mperham,

Thank you for providing clear feedback around the usage of namespaces. We will look to move our usage away from namespaces towards separate databases/instances.

Cheers,

Phil",plcstevens,mperham
3366,2017-03-16 00:50:20,"@mperham can you please then give me a recommendation how to separate db for development and test db correctly? I tried to use such code:

**config/initializers/sidekiq.rb**


But that requested me to use `redis-namespace` which also shows deprecation message + you mentioned here that this is hack. Is there a proper way to separate redis dbs for test and development then? I don't want my tests to influence development database.",Loremaster,mperham
3366,2017-03-16 18:53:07,@mperham thank you very much for that!!,Loremaster,mperham
3365,2017-03-13 14:01:54,"Lol @mperham, are you saying there is a particular issue with the versions we're running, or are you just saying it's generally good to stay updated?",henrebotha,mperham
3365,2017-03-13 14:08:00,"@mperham I've been able to trace the issue to a worker getting stuck in IO wait because of a broken NFS descriptor.  However, I am at a loss as to why that's causing the supervisor to drop out of the Busy queue in the UI.

",emerson-h,mperham
3359,2017-02-17 17:49:05,@ryansch I'm using redis-mutex in my app but wanted to simplify the example.  The issue persists with any mutex system I've tried.,chrisyuska,ryansch
3359,2017-02-18 00:20:19,"@mperham, @ryansch  Thanks for the quick responses.  I really appreciate it.

If there's a database lock happening, I wouldn't expect it to occur until the worker is within the mutex lock, as that's the only ActiveRecord reference I have, which *shouldn't* deadlock the first worker.  Would ActiveRecord really lock the table for a simple `*.count` query too?

Note that I can run create two threads to process the jobs in the rails console and there's no deadlock issue (like so):



How much does the above really differ from how Sidekiq workers process the jobs?

I just tried something else to attempt to narrow this down.  If I start a second job while the first job is within the mutexed method but past the ActiveRecord query (using `sleep(30)` after the ActiveRecord query), the mutex behaves properly and no deadlock occurs.  Putting a `sleep(30)` within the mutexed method before the ActiveRecord query and starting the second job while the first job is sleeping (~25s before the ActiveRecord query) still results in deadlock though.

So Deadlock occurs if two Sidekiq workers perform mutexed jobs when the first job still has an ActiveRecord query coming up.  I think I'm even more confused now.",chrisyuska,ryansch
3359,2017-02-18 00:20:19,"@mperham, @ryansch  Thanks for the quick responses.  I really appreciate it.

If there's a database lock happening, I wouldn't expect it to occur until the worker is within the mutex lock, as that's the only ActiveRecord reference I have, which *shouldn't* deadlock the first worker.  Would ActiveRecord really lock the table for a simple `*.count` query too?

Note that I can run create two threads to process the jobs in the rails console and there's no deadlock issue (like so):



How much does the above really differ from how Sidekiq workers process the jobs?

I just tried something else to attempt to narrow this down.  If I start a second job while the first job is within the mutexed method but past the ActiveRecord query (using `sleep(30)` after the ActiveRecord query), the mutex behaves properly and no deadlock occurs.  Putting a `sleep(30)` within the mutexed method before the ActiveRecord query and starting the second job while the first job is sleeping (~25s before the ActiveRecord query) still results in deadlock though.

So Deadlock occurs if two Sidekiq workers perform mutexed jobs when the first job still has an ActiveRecord query coming up.  I think I'm even more confused now.",chrisyuska,mperham
3355,2017-02-15 15:34:41,"@mikegee aha, thank you",AlexWiles,mikegee
3344,2017-02-06 19:32:31,"I have no other application server than Puma.
It is a rails application, I noticed this issue in development and I thought it may propagate in production. What would you suggest to do @shaneog ? I suppose the existing root_path named route is considered as referred to my application's root_path, and there is not a sidekiq directory in my application root path. ",knzudgt,shaneog
3344,2017-02-07 16:10:51,"@shaneog @mperham I am pretty sure this is an issue with Vivaldi browser.
No issues with Firefox and SeaMonkey.",knzudgt,shaneog
3344,2017-02-07 16:10:51,"@shaneog @mperham I am pretty sure this is an issue with Vivaldi browser.
No issues with Firefox and SeaMonkey.",knzudgt,mperham
3341,2017-02-02 23:40:44,"Yup, that's my guess too @mperham; any suggestions on what to look at to try and isolate the cause?",azach,mperham
3340,2017-02-02 23:44:13,@mperham thanks for the fix but should I just add `'enqueued_at' => Time.now.to_f` to the push we are doing now?,bdmac,mperham
3335,2017-01-30 18:51:33,"@mperham Ok, I'll see if I can figure it out before someone else bestows documentation :)",bf4,mperham
3335,2017-01-31 23:13:18,"@mperham I think with the pagination helper it would be as below, though my code actually uses a 'hash' type, so I can't use it :(



as long as `""myapp-rediskey""` is a list or sorted set.

I tried adding a hash condition to the Paginator just for funsies, even though there's obvious performance implications

",bf4,mperham
3334,2017-01-30 17:58:24,"@mperham Thanks for the quick reply. 

So, we can rely on `chain.add SidekiqMiddleware, option1: 1, option2: 2` being passed to `SidekiqMiddleware.new` as a hash, so that the signature should be `def initialize(options = {})`? And that we should moreover not test the state of an already initialized middleware?

And you are strongly discouraging storing middleware configuration in `Sidekiq.options`, which means also discouraging getting them from sidekiq.yml.  That's very helpful, thanks! :)",bf4,mperham
3330,2017-01-27 17:39:09,@mikegee it could an option then?,Dorian,mikegee
3321,2017-01-18 22:32:37,@mperham Can the fact that the batch was invalidated be detected in the callback?,petergoldstein,mperham
3321,2017-01-19 01:41:05,@mperham Ok.  Would love to see that as a feature.  Can we get it on the road map?  I can't really implement batch cancellation until I can block the execution of the logic in my success callback.,petergoldstein,mperham
3316,2017-01-16 01:01:19,"@mperham I've pushed a commit for PERCY_ENABLE=0 preventing the gem being required and Percy code from being executed.  Is that what you had in mind?

This is executed by already by 3 of the 4 configurations in Travis too.",timhaines,mperham
3316,2017-01-18 23:18:04,"@mperham Apologies for missing the PhantomJS note.  PhantomJS is used by Capybara & Poltergeist for the UI tests now, even when Percy's snapshots are disabled.

Are you seeing 9 seconds with the snapshots enabled or disabled?   On my 2 year old macbook, these tests moved from 0.75 seconds to 3.5 seconds with the snapshots disabled in the dev environment.  It's intended that you'd only run snapshots in CI, so this was the comparison I was paying attention to.  

With snapshots enabled, the test suite was taking 15 - 25 seconds for me.",timhaines,mperham
3312,2017-01-31 00:38:41,"@raivil, @mperham we are seeing this issue as well. We are on:

sidekiq (4.2.4)
sidekiq-ent (1.3.2)
sidekiq-pro (3.3.2)

We have a long-running job (10-20 minutes) that we _think_ is getting killed and restarts in duplicate (2-3 jobs, 1 sharing the jid of the job that stopped). It is enqueued approximately every 15 mintues. The job has `sidekiq_options retry: false, unique_for: 20.minutes` but we end up sometimes having 10+ running at once.

Our current theory is that sidekiqswarm is killing the jobs due to memory and retrying them in duplicate but we are only able to observe this happening in production so we have been unable to validate the theory.",kroehre,mperham
3312,2017-01-31 21:47:26,"@mperham that's fair, and we are evaluating breaking up the job or finding a different solution. Just wanted to chime in on the issue since we appear to be observing the same or a very similar problem. ",kroehre,mperham
3312,2017-02-09 21:31:44,"@mperham 

Our jobs process both large and small files and we've seen this issue happening with both kinds of file.
Having several repeated jobs with same jid/class/parameters after a failure or restart suggests a possible issue with re-enqueueing jobs that should be unique for an amount of time as defined on `unique_for`.

Furthermore, today I was able to get some more evidences as this issue occurred again.

This is what happened:

- Batch with 5 jobs.
- 3 jobs successfully executed.
- New Deployment
- Batch Failures go from 0 to 2. Reason: `Sidekiq::Shutdown`
- Workers restart (`2017-02-09T19:42:00Z`)
- 2 Pending jobs start again. Start time `2017-02-09T19:42:00Z`.
- 2 pending jobs running for 1 hour. 
- 2 _new_ jobs enqueue and running, with same JID/params/class of executing jobs. No exceptions, no errors. 
- These 2 duplicated jobs were not enqueued by app.
- New duplicated jobs were enqueue exactly 1 hour after. Duplicated jobs started at `2017-02-09T20:42:00Z` 
- Log showing new jobs start:


- Workers still running. No restarts.

Update:
- 2 duplicating jobs were enqueued again, totaling 6 jobs. Enqueue time: `2017-02-09T21:42:00Z`
- One of the jobs finished. Job count 5. Batch  pending count updated to 1.
- 1 new job was re-enqueued. Duplicate of  the job pending in the batch. Start time: `2017-02-09T22:42:00Z`",raivil,mperham
3312,2017-02-13 14:22:26,"@mperham 
Foreman is used to export upstart scripts that will handle starts/stops.
Upstart will kill main sidekiq process with `sigterm`.



My biggest concern is why the jobs were re-enqueued in one hour intervals (`2017-02-09T20:42:00Z`, `2017-02-09T21:42:00Z`, `2017-02-09T22:42:00Z`) while original job was still executing.
",raivil,mperham
3311,2017-01-11 07:51:01,"@mperham 
Thanks! Setting `reconnect_attempts` fixed it for us just as you expected.

As for the connection closing, I found the following in the [Heroku blog (from July 28, 2016)](https://blog.heroku.com/real-world-redis-tips):
> ### Set an Appropriate Connection Timeout
> 
> By default, Redis will never close idle connections, which means that if you don't close your Redis connections explicitly, you will lock yourself out of your instance.
> 
> **To ensure this doesn't happen, Heroku Redis sets a default connection timeout of 300 seconds. This timeout doesn’t apply to non-publish/subscribe clients, and other blocking operations.**
> 
> Ensuring that your clients close connections properly, and that your timeout value is appropriate for your application will mean you never run out of connections.",trautwein,mperham
3311,2017-01-20 17:57:19,"@mperham By the way, thanks for reverting/fixing this!",trautwein,mperham
3310,2017-01-08 18:57:37,"Thanks for the quick response @mperham . Looks like this doesn't work for the latest Sidekiq:
Ruby version: 2.3.3
Sidekiq v4.2.7

Not sure if it's a Pro only feature. I can see it work on the Sidekiq at work:
Sidekiq v3.3.4 / Sidekiq Pro v2.0.1",desheikh,mperham
3310,2017-01-08 18:59:56,"It's not a Pro feature, likely regressed.

> On Jan 8, 2017, at 10:57, Zulfiqar Ali <notifications@github.com> wrote:
> 
> Thanks for the quick response @mperham . Looks like this doesn't work for the latest Sidekiq:
> Ruby version: 2.3.3
> Sidekiq v4.2.7
> 
> Not sure if it's a Pro only feature. I can see it work on the Sidekiq at work:
> Sidekiq v3.3.4 / Sidekiq Pro v2.0.1
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",mperham,mperham
3303,2017-01-02 19:07:22,"Thanks for the quick response @mperham!

We've rolled out the workaround I mentioned earlier today — I'll monitor and report here whether we see this problem again (we were seeing this quite infrequently, so it might take a little while before I can confirm whether the issue is indeed resolved).",krallin,mperham
3303,2017-01-12 09:58:36,"Hey @mperham,

Sure.

I suspect the issue here (and we're investigating this on our end as well — more on that below)  is that — as you observed in #3311 —, Redis connections aren't as robust as we'd want them to be (they may break over time due to timeouts, or due to the process forking and holding on to old connections).

Here is where my understanding of the problem is so far:

When Sidekiq tries to reuse an existing connection from the pool, that connection may or may not be still be alive. If it is, then the request goes through and everything is fine. If it's not, then you get an error, whereas before this fix, you'd have had a transparent reconnect, and everything would have been fine.

Now, if the connection is alive, you can still get a timeout when writing the push to Redis (that's the problem I brought up in this issue). What happens then is pretty much undetermined (as the push may or may not have gone through to Redis, and we can't know that), but it's related to `reconnect_attempts`: with transparent reconnects (`reconnect_attempts: 1`), we may push the job once or twice, and without them (`reconnect_attempts: 0`), we may zero times or once.

Note that in either case, [redis-rb will ""fix"" the connection before it attempts to use it again](https://github.com/redis/redis-rb/blob/37ab9045e0fed202e42e49ccc11d41cc64de1759/lib/redis/client.rb#L348-L380) (admittedly that would be a pretty major problem here): it'll disconnect if it gets an error, or if we attempt reusing a connection that was waiting on some data.

---

Now; as I mentioned, we're investigating this as well...

It does appear making this change replaced some cases where we had jobs running twice concurrently (these cause major problems for us right now, so given a choice we'll always err on the side of caution) with cases where jobs are not being enqueued at all (which isn't as problematic for our use case, but still something we'd like to minimize). I haven't looked closely at whether the rate is similar (I suspect it might be), largely because it's not as big a problem anymore

At least for our use case, I think a clear improvement would be to retry when we know for sure that it's safe to do so (and not in other cases), which would be a good middle ground between the two options we have right now (which are respectively retry never with `reconnect_attempts: 0` and retry always with `reconnect_attempts: 1`).

For now, I'm planning to try and `PING` Redis before trying to use the connection (for our use case, hitting the roundtrip latency there does not matter at all). That doesn't guarantee that the connection is going to stay healthy, but it might ensure we don't use a connection that died hours ago. In other words, it gives us one reconnect attempt (since redis-rb will auto-reconnect if that `PING` fails) before we attempt to send the real traffic through.

Here's the implementation I have for now. I have confirmed that this recovers from killing all clients in Redis (`CLIENT KILL TYPE normal`) then attempting to push from Sidekiq, whereas the standard `ConnectionPool` does not (it'll attempt to reuse the dead connection, fail with `Redis::ConnectionError: Connection lost (ECONNRESET)`, and then not retry).



Looking at #3311, there's also at least `Redis::InheritedError` that is most definitely an exception that could be retried: at that point, redis-rb hasn't even tried to talk to Redis yet. 

That being said, I suspect a more generally applicable (pinging before using the connection most likely isn't the right option for everyone) and robust solution here might be for Sidekiq's job push to be idempotent as far as Redis is concerned (in which case it's always safe to retry)... but I imagine this might represent quite a bit of work!

---

Finally, to answer your questions about our setup: we basically have a lot of Redis servers (several hundreds as of right now) that Sidekiq pushes jobs to. Most of these aren't particularly busy, and right now we don't enforce any connection timeouts on them (except for one exception..!).

Finally, currently, we use version 3.3.1 of the redis-rb gem.

I'm happy to continue trying out some things here (with the caveat that we're still on Sidekiq 3.x); just let me know if I can help provide more information 😄.",krallin,mperham
3303,2017-01-13 08:16:00,That's fair; thanks for the heads up @mperham!,krallin,mperham
3296,2017-01-01 08:20:26,@mperham Any workaround for the time being?,motymichaely,mperham
3296,2017-01-01 19:06:05,"You can test and verify the quality of the data by converting it to and from JSON before sending it to Sidekiq. Aside from that there's no workaround. 

> On Jan 1, 2017, at 00:20, Moty Michaely <notifications@github.com> wrote:
> 
> @mperham Any workaround for the time being?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",mperham,mperham
3294,2016-12-29 08:14:10,"@mperham Interesting. I wasn't thinking that the job was stuck due to parse error of Sidekiq itself :).

An example Hash that is passed as an argument to Sidekiq:



I like your idea of moving the ""poising pills"" into the dead queue! This will definitely solve the issue on one hand and give us the ability to track these down and handle manually.",motymichaely,mperham
3294,2017-01-05 07:26:58,"@mperham Thanks! 

In my case I don't do the JSON serializations but pass a Hash to Sidekiq's worker perform_async call:



This reproduces the infinite job retries with reliable fetch.",motymichaely,mperham
3294,2017-01-05 18:14:58,"@mperham - Thanks again. I found the culprit. Seems like the hash was wrapped with Rails' (3.2) HashWithIndifferentAccess.



This will cause Sidekiq to enqueue the job serializing the object as Json that will fail to parse. ",motymichaely,mperham
3294,2017-01-16 18:05:06,"@mperham - Sorry for my late reply, had busy days (who doesn't?).

Seems like the issue is with ActiveSupport 3.2. You can follow [this gist](https://gist.github.com/motymichaely/c54b488ac42c7b57b8a29c153c5c2c96) to reproduce it.",motymichaely,mperham
3294,2017-01-17 13:56:10,"@mperham it's not an issue with Rails 3.2 but with ActiveSupport::HashWithIndifferentAccess JSON generation. So deprecating support for Rails 3.2 doesn't make sense to me.

For instance, the way I was able to get the exact culprit was by using tracer:


I looked for `to_json` within the trace and found which gem was causing the exception.

In my case, I would love to get an easier way to remove the poison pill rather than trying to handle the JSON generation. (Actually, I wasn't able to remove the bad message yet :().",motymichaely,mperham
3290,2017-01-30 13:17:36,"I really think this has to do with the latency in our environment.  Maybe the hop between our workers and Redis is fine, but then when you add another hop to the DB then it starts to show.  When we queue longer running jobs (a min or 2 to complete) we don't experience this problem.  Thanks for your help @mperham ",nick-desteffen,mperham
3287,2016-12-21 20:42:31,"@mperham Thank you for the quick response! I ended out trying that, so my config.ru file now looks like:



However, when I start up the server (using either `foreman start` or just `rackup config.ru` I'm still seeing the bottom of the screen show that is connected to my localhost: `redis://127.0.0.1:6379/0`.

Any other ideas I can try? It's like it's just ignoring the redis_pool that I'm trying to use to connect to the remote apps. Unfortunately there's nothing really useful in the logging to help guide me in why this might be happening.",ToniRib,mperham
3287,2016-12-21 21:36:04,"Thanks! I really appreciate your help @mperham! If I can help in any way, please let me know.",ToniRib,mperham
3287,2017-01-06 19:43:03,"@mperham I'd like to reopen this with a further question. What we previously discussed in this thread got my Sinatra app connected to the correct redis instances, but while I see the correct redis data (version, uptime, connections, etc...) I don't see any information on workers, even though I know they are running and processing correctly. The workers in both apps are namespaced under 'workers' which I thought might be the issue, but adding a namespace didn't seem to help.

Here's an example of one of the Rail's app's config files:


Attached is a screenshot of what I am seeing.
![screen shot 2017-01-06 at 12 41 14 pm](https://cloud.githubusercontent.com/assets/10429574/21730579/973e47e6-d40d-11e6-8874-7ac4e13641f0.png)

Any ideas on what to try to get the worker information flowing to this UI?
",ToniRib,mperham
3287,2017-01-07 18:43:08,"Could you supply a simple app which reproduces the problem?  It works for me. 

> On Jan 6, 2017, at 11:43, Toni Rib <notifications@github.com> wrote:
> 
> @mperham I'd like to reopen this with a further question. What we previously discussed in this thread got my Sinatra app connected to the correct redis instances, but while I see the correct redis data (version, uptime, connections, etc...) I don't see any information on workers, even though I know they are running and processing correctly. The workers in both apps are namespaced under 'workers' which I thought might be the issue, but adding a namespace didn't seem to help.
> 
> Here's an example of one of the app's config files:
> 
> unless Rails.env.development?
>   Sidekiq.configure_server do |config|
>     config.options[:concurrency] = 5
>     config.redis = {url: ENV['REDISCLOUD_URL'], namespace: 'workers', size: 7}
>     config.options[:queues] = %w(default)
> 
>     database_url = ENV['DATABASE_URL']
>     if database_url
>       ENV['DATABASE_URL'] = ""#{database_url}?pool=10""
>       ActiveRecord::Base.establish_connection
>     end
>   end
> 
>   Sidekiq.configure_client do |config|
>     config.redis = {url: ENV['REDISCLOUD_URL'], namespace: 'workers', size: 1}
>   end
> end
> 
> # Start sidekiq locally 'bundle exec sidekiq'
> if Rails.env.development?
>   Sidekiq.configure_server do |config|
>     config.options[:concurrency] = 2
>     config.redis = {url: 'redis://127.0.0.1:6379/0', size: 3}
>     config.options[:queues] = %w(default)
>   end
> 
>   Sidekiq.configure_client do |config|
>     config.redis = {url: 'redis://127.0.0.1:6379/0', size: 1}
>   end
> end
> Attached is a screenshot of what I am seeing.
> 
> 
> Any ideas on what to try to get the worker information flowing to this UI?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",mperham,mperham
3280,2016-12-15 16:28:16,"@mperham my model has 4 instances of carrierwave imageUploader, and I think that is what causing this issue and making the object passed to devise and sidekiq bigger than it should, do you have any idea on how to hide certain attributes from `self`, or reduce the object passed in the method I added in my models to make it work?
",alaouy,mperham
3277,2016-12-13 07:22:10,"@mperham   when i only use grape framework, there is no anything about rails.  RAILS.root will return nil",houdl,mperham
3277,2016-12-14 05:56:14,@mperham   i think that it should have a default tag even if it is not used in rails framwork. default meaning a value for all framwork if it is nil.,houdl,mperham
3277,2016-12-14 07:57:51,"@mperham  bacause we always not set tag for sidekiq a lot of time.  in capistrano-sidekiq , the tag also is nil , so when we not use rails, there alway have a error message, something like 

i think sidekiq should have a default tag not only for rails.",houdl,mperham
3277,2016-12-15 06:40:39,"@mperham  thanks for your answer patiently. i have know what your mean. options[:require] directory only for rails, other framwork must appoint enviroment file.",houdl,mperham
3275,2016-12-13 05:43:53,"@mperham Well, here is the configuration of my `Gemfile` related to Sidekiq:



As you can see that I am using Sidekiq in `production` group, and in my routes, I have this line:



Since `Rails.application.queuing_enabled?` is `false`, I think Sidekiq should not have loaded in `development` mode at all. This config worked perfectly till Rails v4.2.7.1, but broke as soon as I switched to Rails v5.0.0.1.

BTW, using `master` solved this problem. :+1: ",31piy,mperham
3275,2016-12-19 06:30:22,@mperham When can I expect the next release with this fix?,31piy,mperham
3275,2017-01-06 23:00:14,@Nowaker 4.2.8 will be out Monday.,mperham,Nowaker
3275,2017-01-06 23:01:01,@mperham Great to hear! Have a good weekend.,Nowaker,mperham
3272,2016-12-08 18:05:10,@mperham thanks for clarifying. closing now,mtyeh411,mperham
3265,2016-11-30 22:06:19,"**Final update** After re-scaling the web and worker dynos with the Heroku CLI (and apparently not the Web UI), my sidekiq jobs continue, hours later, to be performing correctly.

Thanks again for your time @mperham I recognize and appreciate that you had no responsibility for this issue. Let me know if I can make it up to you in some way. Cheers.",joemsak,mperham
3265,2016-12-01 23:54:40,"Hey @mperham  --

I was helping Joe on this today and observed the issue, while the underlying server time returned fine (both in Ruby and Bash). We also checked the underlying instance for NTP drift, but found no evidence of that.

I was able to enqueue a job (both through ActiveJob and directly through Sidekiq), which resulted in a ""2168"" year in the web console. Here's one sitting in the retry queue:

![image](https://www.dropbox.com/s/wrbqfpjbufm55bh/Screenshot%202016-12-01%2015.51.15.png?dl=1)

Ever seen this before?",jmccartie,mperham
3265,2016-12-02 00:21:45,"Nope, I've never seen that before. What does the job payload look like in Redis?

> On Dec 1, 2016, at 15:54, Jon McCartie <notifications@github.com> wrote:
> 
> Hey @mperham --
> 
> I was helping Joe on this today and observed the issue, while the underlying server time returned fine (both in Ruby and Bash). We also checked the underlying instance for NTP drift, but found no evidence of that.
> 
> I was able to enqueue a job (both through ActiveJob and directly through Sidekiq), which resulted in a ""2168"" year in the web console. Here's one sitting in the retry queue:
> 
> 
> 
> Ever seen this before?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",mperham,mperham
3265,2016-12-02 00:47:25,"@mperham 

I just saw this happen again.  Job was enqueued ok.  Timestamp looked fine under ""Busy"".  Here was payload:



Job failed.  Now in the retry queue (not sure where to get the payload here):



Now, job is in Retry queue with a retry of `2640-08-01 08:00:20 UTC`.  I'm having @joemsak update Sidekiq to latest (4.2.7) to make sure it's nothing that was fixed in the earlier version (he's on 4.1.1)",jmccartie,mperham
3265,2016-12-02 02:09:15,"@mperham Relevant bits:




![image](https://www.dropbox.com/s/uodzxtzdptzok3f/Screenshot%202016-12-01%2018.12.01.png?dl=1)",jmccartie,mperham
3265,2016-12-02 02:34:07,"Confirmed:



@mperham So your guess is that @joemsak monkey-patched `Float#to_s` somewhere?",jmccartie,mperham
3265,2016-12-02 15:01:24,"Man, @jmccartie and @mperham both I really appreciate all of this investigation. You'll find the only sidekiq config I'm working with is here https://github.com/mperham/sidekiq/issues/3265#issuecomment-263965449

and my Procfile as @jmccartie can see is

",joemsak,mperham
3265,2016-12-02 16:15:19,Thanks @mperham ,jmccartie,mperham
3263,2016-11-30 03:23:16,"@ryansch By any chance have you tried running sidekiqswarm directly?  It implements the minimal `wait` loop required to reap child processes so should be able to run as PID 1 (I should probably document it better as ""container-friendly"" in that regard).",mperham,ryansch
3261,2016-11-30 07:50:08,"@mperham upgraded to 4.2.7 from 4.2.6, will post if that did the trick",dbenjamin57,mperham
3249,2016-11-22 13:14:04,"@mperham After digging further into Sidekiq Pro source code for ReliableFetch, looks like the Retriever singleton thread is not terminated when the Sidekiq process becomes quiet. Adding these 3 lines in `Retriever::start` seems to fix the problem:



Do you mind merging this patch? This is critical for our production system since we need to be able to quiet Sidekiq processes to manage our server resources.",9diov,mperham
3249,2016-11-22 18:28:43,"@mperham First of all, super_fetch uses the exact same code for Retriever class so it suffers from the same issue. The good thing is that the exact same fix I proposed earlier would work.

Second of all, you are arguing the wrong point here. The issue has nothing to do with TERM. It is about the expectation of quieting the Sidekiq process. When I quiet a process, I don't expect it to keep accepting new jobs without executing it. **It is clearly a bug, regardless of how critical it is.** Jobs can't be executed in a timely manner when they are stuck in the process's private queue. Both current reliable_fetch and super_fetch suffers from the same issue and can be fixed very easily by adding the callback for quiet in the Retriever class as I mentioned above.

Third of all, you argue that the issue doesn't matter. It DOES matter for our workload. For us, we are running jobs with diverse execution time ranging from a few seconds up to more than one hour. Re-starting a job is something we try to avoid as much as possible since it causes issues downstream for our customers. In order to conserve memory yet avoiding restarting a running job, we need to quiet a Sidekiq process after a certain memory threshold, wait for all the jobs to finish then restart the process. As a result, this period when a Sidekiq process is in quiet mode can last up to more than one hour. For us, **it is critical** that the quiet process doesn't hog the jobs that were sent to Sidekiq during this period. Our business requirements dictate that we need the jobs to execute as soon as they are sent.

Hope you understand our situation and the issue we are facing.",9diov,mperham
3249,2017-02-09 04:52:21,"This is awesome. Thank you so much @mperham !

When do you think 3.4.4 will be released?",nvquanghuy,mperham
3249,2017-03-03 03:23:09,"@mperham Circling back to this, do you have a timeline on when 3.4.4 will be released? And any suggestions/workaround we can do until then?

Regards,",nvquanghuy,mperham
3242,2016-11-17 18:49:50,"@mperham Thanks! much appreciated!
",richessler,mperham
3221,2016-11-12 02:32:20,"@mperham what do you think of making a final release in the 4.2.x series that uses this approach, and then removing it in 4.3.0? While https://github.com/mperham/sidekiq/pull/3235 is a more thorough fix, it's also a much bigger change.

Sidekiq 4.1.4 was the last version that worked properly with Rails 5 - 4.2.0 to 4.2.2 could lose jobs, and 4.2.3 to 4.2.5 don't release connections. If someone with a Rails 5 app is waiting for a version without those problems, upgrading from 4.1 to 4.3 will involve dealing with the Sinatra removal, the reloader replacing the previous middleware approach, _and_ the overhauled retry mechanism at the same time. That's a lot of stuff changing at once...
",eugeneius,mperham
3214,2016-11-02 00:09:30,"Thanks @mikegee. Good to see some other implementations of a similar concept.
",joshuamcginnis,mikegee
3211,2016-10-30 13:01:19,"@mperham I will be extremely happy for input from you:)?
",nitzanav,mperham
3211,2016-10-30 14:29:24,"Input about what?

> On Oct 30, 2016, at 06:01, Nitzan Aviram notifications@github.com wrote:
> 
> @mperham I will be extremely happy for input from you:)?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",mperham,mperham
3207,2016-11-04 03:42:57,"@mperham Thank you. Unfortunately, this is still not working in my initial configuration.
I'd like to inform you though that this is not a problem for me anymore, as the issue seems to have vanished after a general update of the gems we're using (most noticeable is updating Rails from 4.0.13 to 4.2.7.1).
",davidstosik,mperham
3194,2016-10-18 08:53:59,"Thanks @mperham  
",benoittgt,mperham
3186,2016-10-12 02:07:31,"@mperham 

$ bundle exec rake db:migrate
rake aborted!
NameError: uninitialized constant Sidekiq::Sinatra
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/sidekiq-4.1.4/lib/sidekiq/web.rb:12:in `<module:Sidekiq>'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/sidekiq-4.1.4/lib/sidekiq/web.rb:11:in`<top (required)>'
/home/viggy/Documents/github/core/config/routes.rb:225:in `block in <top (required)>'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/actionpack-4.1.5/lib/action_dispatch/routing/route_set.rb:337:in`instance_exec'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/actionpack-4.1.5/lib/action_dispatch/routing/route_set.rb:337:in `eval_block'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/actionpack-4.1.5/lib/action_dispatch/routing/route_set.rb:315:in`draw'
/home/viggy/Documents/github/core/config/routes.rb:1:in `<top (required)>'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:40:in`block in load_paths'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:40:in `each'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:40:in`load_paths'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:16:in `reload!'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:26:in`block in updater'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/activesupport-4.1.5/lib/active_support/file_update_checker.rb:75:in `call'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/activesupport-4.1.5/lib/active_support/file_update_checker.rb:75:in`execute'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:27:in `updater'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/routes_reloader.rb:7:in`execute_if_updated'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application/finisher.rb:71:in `block in <module:Finisher>'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/initializable.rb:30:in`instance_exec'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/initializable.rb:30:in `run'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/initializable.rb:55:in`block in run_initializers'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/initializable.rb:54:in `run_initializers'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application.rb:300:in`initialize!'
/home/viggy/Documents/github/core/config/environment.rb:5:in `<top (required)>'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application.rb:276:in`require_environment!'
/home/viggy/.rvm/gems/ruby-2.1.2@core/gems/railties-4.1.5/lib/rails/application.rb:379:in `block in run_tasks_blocks'
/home/viggy/.rvm/gems/ruby-2.1.2@core/bin/ruby_executable_hooks:15:in`eval'
/home/viggy/.rvm/gems/ruby-2.1.2@core/bin/ruby_executable_hooks:15:in `<main>'
Tasks: TOP => db:migrate => environment
(See full trace by running task with --trace)
",JohnMerlino2,mperham
3183,2016-10-10 13:34:56,"@inkstak Let me know if you need any help
",badosu,inkstak
3183,2016-10-14 16:56:38,":tada: @inkstak Thanks!
",badosu,inkstak
3182,2016-10-07 23:15:03,"Closing issue, since @mperham stated that it will not be implemented.
",nitzanav,mperham
3180,2016-10-14 16:58:12,"@inkstak Fixed?
",badosu,inkstak
3179,2016-10-11 08:53:36,"Thanks for your help. I build a new app from scratch with quite similar gems and config as our app but was not able to reproduce the issue locally in production ENV and on Heroku. Things that are different are maybe caching because I didn't plug addons we use for our app on Heroku. 

I don't want to take too much of your time for this issue how seems related to our server configuration and other tools and gem we use. Will keep digging.

Thanks @mperham  🎉
",benoittgt,mperham
3175,2016-10-03 23:38:33,"@mperham Thanks Mike. That makes sense, and much appreciated.
",harukizaemon,mperham
3174,2016-11-22 18:52:08,"@mperham why the move away from Delay Extension (I know it was originally a part of migration from DalyedJob)? I really liked the ability to write everything as a service object and then decide on the fly to run it through Sidekiq versus running it on the web server. In your experience, are there some limitations I'm maybe not thinking of? What I liked avoiding was having a bunch workers that simply wrap around a service (like CreateSellOrderService and then CreateSellOrderWorker that simple calls the service object.)",thebucknerlife,mperham
3174,2016-11-22 23:01:22,thanks @mperham! ,thebucknerlife,mperham
3171,2016-11-17 03:55:45,"@mperham , I was experiencing the issue with not being able to use the delay extension using rails 4.2.6 and sidekiq 4.2.6.

From here: https://github.com/mperham/sidekiq/blob/v4.2.6/lib/sidekiq/cli.rb



An easy solution would be to modify the `::Rails::VERSION::MAJOR >= 4 && environment != 'development'` to `::Rails::VERSION::MAJOR == 4 || (::Rails::VERSION::MAJOR >= 5 && environment != 'development')`, if that was an original intention as per one of the comments in the code
",che-burashco,mperham
3166,2016-09-29 00:36:39,"@mperham that's what we're doing?

We're also raising in the middleware in case somebody has explicitly added the ActiveRecord middleware themselves outside of the default middleware stack.

Although I've just realised that initialize has already happened by the time the reloader gets set, so if the user customises their middleware stack which lazily resolves the default server midddleware then it will have included the ActiveRecord middleware anyway.

There's a chicken and egg. We need to change initialization based on the presence of the reloader, but the reloader can't be present until we've initialized. I'll investigate.
",sj26,mperham
3166,2016-09-29 00:54:45,"Yep, all this logic should go in sidekiq/rails.rb or cli.rb.

> On Sep 28, 2016, at 5:36 PM, Samuel Cochran notifications@github.com wrote:
> 
> @mperham that's what we're doing?
> 
> Although I've just realised that initialize has already happened by the time the reloader gets set, so if the user customises their middleware stack which lazily resolves the default server midddleware then it will have included the ActiveRecord middleware anyway.
> 
> There's a chicken and egg. We need to change initialization based on the presence of the reloader, but the reloader can't be present until we've initialized. I'll investigate.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",mperham,mperham
3157,2016-09-26 18:46:11,"@mperham maybe that should be mentioned in the Changelog or something?
",connorshea,mperham
3156,2016-09-22 01:00:52,"@mperham The following block recursively requires all the workers:


",tommybstitch,mperham
3155,2016-09-21 17:00:22,"@mperham thanks, I'll dig in then and report back if I find the answer.
",antstorm,mperham
3153,2016-09-20 14:35:59,"@mperham in that case would it make more sense to remove it from `options` and make it a part of `Sidekiq` class?
",antstorm,mperham
3149,2016-09-19 14:23:13,"@seuros 

Everything working good if not using sidekiq and redis, but when background jobs not getting mails
",NRamakrishna,seuros
3139,2016-09-16 08:01:21,"Thanks @mperham but the same error raises for setting `sessions` in `4.2.1`
https://github.com/mperham/sidekiq/issues/2910#issuecomment-206978212


",zoras,mperham
3139,2016-12-21 20:03:57,"@zoras & @mperham 
Is there a solution for setting `sessions` as mentioned above?
`Sidekiq::Web.set :sessions, domain: 'all'` 

We are seeing multiple sessions set and trying to limit to just one. 
Currently on Sidekiq 4.2.0

We've configured `Sidekiq::Web.session_secret = Rails.application.secrets[:secret_key_base]`, which works, but I think we still need a way to limit the number of sessions. 

thanks
",dladowitz,mperham
3139,2016-12-22 04:26:00,"@mperham Yep, after upgrading to 4.2.3 I'm able to use
`Sidekiq::Web.set :sessions, domain: 'all'`.

Thanks for the quick reply


.......hmmm looks like maybe we should be using `Sidekiq::Web.set :sessions, false` instead.",dladowitz,mperham
3138,2016-10-03 17:54:56,"@mperham Perfect.
",ryansch,mperham
3135,2016-09-13 16:27:21,"@mperham Thanks! 😄 
",sandstrom,mperham
3131,2016-09-12 18:26:09,"@seuros is right, you'll need to provide us with a minimal rails app which reproduces your problem.  It's most likely the problem is in the app code or configuration.
",mperham,seuros
3127,2016-09-13 02:17:13,"@mperham Where was this middleware being set up?
",badosu,mperham
3127,2016-09-13 02:24:15,"Rails

> On Sep 12, 2016, at 19:17, Amadeus Folego notifications@github.com wrote:
> 
> @mperham Where was this middleware being set up?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",mperham,mperham
3123,2016-09-05 13:10:36,"@mperham I could use the [navigator.language](https://developer.mozilla.org/en-US/docs/Web/API/NavigatorLanguage/language) API but I figured that it would be better to align fully with Rails/web app.
",shaneog,mperham
3117,2016-09-02 19:02:33,"@mperham If you switch to [moment.js](http://momentjs.com/), you can use a CDN with the locales 😄 

For example: https://cdnjs.com/libraries/moment.js/ (https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.14.1/moment-with-locales.min.js)

Sadly, I don't know of any CDN that provides the jQuery.timeago locales.
",shaneog,mperham
3117,2016-09-02 21:30:47,"@shaneog I'd rather not depend on a CDN - that's another dependency that might break N years from now.
",mperham,shaneog
3116,2016-08-30 18:36:33,"@mperham thanks, I was enqueuing the job in a custom queue instead of using the scheduled set. 
",BeRMaNyA,mperham
3115,2016-08-30 15:59:41,"None of the assets are particularly complex. The most complex is the logo, which I bet @mperham has in vector format somewhere. What about converting everything to inline SVGs?
",jelder,mperham
3115,2016-08-30 16:03:36,"@mperham What browsers does the web interface target?
",jelder,mperham
3112,2016-08-23 07:47:10,"@mperham No this is in development mode and it also happens in production mode.
",ckgagan,mperham
3105,2016-08-19 07:50:15,"@mperham thank you very much for the explanation! 
",tuanlv1206,mperham
3103,2016-08-15 21:24:54,"@mperham sounds good, looking forward to `super_fetch` then!
",sandstrom,mperham
3096,2016-08-22 20:07:43,"Though closed, following up on this in case someone else happens to run into a similar issue.

After bumping up native libs one-by-one and monitoring for several days, I can say with about 99% confidence the issue has resolved itself.  Thanks for the suggestions @mperham 
",dphase,mperham
3093,2016-08-07 16:32:56,"Awesome ! Thanks so much @mperham  for the assist. 

However, now Im getting taht forbidden error that you speak of. 

routes.rb



In my gem file I have `gen 'sinatra', require: false` and I am still getting that error. 

Any ideas?
",rjrobinson,mperham
3090,2016-08-04 03:11:50,"Thanks @ryansch and @mperham!
",zulhfreelancer,ryansch
3090,2016-08-04 03:11:50,"Thanks @ryansch and @mperham!
",zulhfreelancer,mperham
3090,2016-08-04 03:49:06,"I get this error when I try to run `bundle exec sidekiq`:

`concurrency: 0 is not a valid value`

I think that's because Heroku converts all config vars to string.



I tried to put `<%= ENV[""SIDEKIQ_CONCURRENCY""].to_i %>` inside the sidekiq.yml file, but still get the same error.

Any idea how to fix this issue?

Thanks.

@ryansch @mperham
",zulhfreelancer,ryansch
3090,2016-08-04 03:49:06,"I get this error when I try to run `bundle exec sidekiq`:

`concurrency: 0 is not a valid value`

I think that's because Heroku converts all config vars to string.



I tried to put `<%= ENV[""SIDEKIQ_CONCURRENCY""].to_i %>` inside the sidekiq.yml file, but still get the same error.

Any idea how to fix this issue?

Thanks.

@ryansch @mperham
",zulhfreelancer,mperham
3088,2016-08-08 14:07:03,"@mperham if the dyno isn't running anymore, my assumption would be that there is no way the process could still be running.  This is on the web ui busy tab.  My guess is some data got orphaned in redis that keeps track of which workers/processes are running and nothing can automatically clean it up?

Haven't dived too deep into Sidekiq code and how all of that is managed, but maybe you could point me in the right direction?
",jwg2s,mperham
3088,2016-08-08 17:05:06,"@mperham awesome thanks!
",jwg2s,mperham
3083,2016-08-02 12:15:02,"@mperham 

How I can set 



in `rails initializer` so I won't get



for now I did it like this



but imo it's semi optimal
",lefty313,mperham
3081,2016-07-31 09:53:32,"@mperham https://gist.github.com/unnitallman/944011

ActiveRecord can work entirely in memory and so can mock_redis. Sounds like the `sidekiq/testing` stubbing is incomplete. Maybe we should fix that?
",postmodern,mperham
3077,2016-09-26 16:30:31,"Hi @mperham, any idea about the release date of `super_fetch!`?
",inkstak,mperham
3075,2016-07-28 18:07:45,"@mperham After some time thinking about it, I`ve decided to make this change totally compatible with the previous sinatra implementation, these are the major points I've identified so far:
- The `redirect` call should not include the custom base path
- The `render` method should accept the same arguments as the previous impl.
-  Implement `halt`
- `params` should be an indifferent access hash and also include the params from the route

I'll take a look at this on this weekend. Feel free to push forward if you want as well.
",badosu,mperham
3075,2016-07-29 16:17:04,"@mperham I don't know of It'll be a great difference as there aren't any optimizations and also I've sacrificed performance in favour of compatibility with `sinatra` (see `#params` implementation)
",badosu,mperham
3075,2016-07-30 20:14:33,"@mperham This should go in the settings hash, to use the same interface as sinatra sessions.
",badosu,mperham
3075,2016-08-01 23:40:14,"@mperham I changed it so that the user may specify it's own Rack::Session options if the secret alone is not enough.

I don't understand how this is related to github oauth.

That section specifically should be updated to use https://github.com/atmos/warden-github directly instead of a sinatra extension.
",badosu,mperham
3075,2016-08-02 01:42:55,"@mperham Feel free to add this to the examples section or update the wiki page when you want https://gist.github.com/badosu/5a6bb42cc0c0a7ae6e9b01313c61a5b9
",badosu,mperham
3075,2016-08-02 18:46:51,"@mperham I am pretty confident on the status of this implementation.

Let me know if there are any pending issues.
",badosu,mperham
3075,2016-08-20 21:52:49,"@badosu Any comments on (2) above?
",mperham,badosu
3075,2016-08-22 15:35:52,"@mperham If you're asking about the ETag issue, I don't know how it can happen if we control all headers and we're not passing any ETag response headers at all.

Only if this is something being setup by Pro or a middleware customization.

On a side note, as soon as this PR lands in master I am gonna send a PR to to each plugin that relied on (now) unsupported Sinatra functionality.
",badosu,mperham
3075,2016-08-22 15:51:06,"Could this be part of the rails middleware stack when mounted in a rails app?

> On Aug 22, 2016, at 08:35, Amadeus Folego notifications@github.com wrote:
> 
> @mperham If you're asking about the ETag issue, I don't know how it can happen if we control all headers and we're not passing any ETag response headers at all.
> 
> Only if this is something being setup by Pro or a middleware customization.
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",mperham,mperham
3075,2016-08-24 16:42:23,"Thank you @badosu for your incredible work on this PR.  It's a huge change and you've put an amazing amount of work into polishing it.  I hope it proves stable!
",mperham,badosu
3075,2016-08-26 14:08:19,"@badosu These were the steps I ran. Along the way something would end up being cached by the browser and not display the expected results:
1. Go to Queues tab.
2. Queue one job.
3. Refresh page. Queues should show 1 job queued.
4. Click on queue to view job.
5. Delete job. Page should be refreshed and show job removed.
6. Go back to queues. Should say 0 jobs.
7. Delete queue. Page should be refreshed with queue removed.
",johnathanludwig,badosu
3073,2016-07-26 20:28:31,"@mperham Ok, so could you give me any idea how could I fix that in `ActiveJob::Base` side?
",Azzurrio,mperham
3073,2016-07-26 21:55:58,"@mperham I need to access it so I can use `Sidekiq::Status` [tracking-progress methods](https://github.com/utgarda/sidekiq-status#tracking-progress-saving-and-retrieving-data-associated-with-job). The basic idea behind these methods is to store the progress using the `jid` attribute within `Sidekiq::Worker`. So inside `ActiveJob` while we don't have access to that `jid`attribute, we can easily work around that by using a `before_perform` callback like that



So the problem now, is that `provider_job_id` always returns `nil` inside the job because of what I just explained in first comment.
",Azzurrio,mperham
3070,2016-07-26 20:48:06,"If you're tracking Sinatra from github (which, AFAIK, you have to do if you're running on Rails 5 right now), then Sinatra now adds CSP by default (see https://github.com/sinatra/sinatra/commit/7f013c91607cc867806b29b316f576e2bc6be75c).

Gross hacky workaround for now -



@mperham - PR incoming as soon as I figure out CSPs enough to recommend a good default that works.
",jamesdabbs,mperham
3070,2016-08-30 20:41:29,"@mperham no problem, just wondering if it sounded like something that would make sense. Will submit a PR if people are interested then. I may wait until Sidekiq 2.0 is out of beta.
",chrisnicola,mperham
3069,2016-07-27 05:20:52,"@badosu If you want committer access so you can polish these changes more, just let me know.
",mperham,badosu
3069,2016-07-27 14:31:45,"@mperham Could you give me that access? I'll continue on those points tonight.
",badosu,mperham
3069,2016-07-27 19:34:20,"@mperham I've made some improvements and the sidetiq page is already accessible. Some points though:
- It is not needed anymore to include explicitly `home_path` on redirect calls, as seen [here](https://github.com/tobiassvn/sidetiq/blob/master/lib/sidetiq/web.rb)
- I had to reinclude code to set local variables inside partials, however It is not compatible with ruby 2.0.0 and I can't see a way to do it without using `eval`. 
- `params` includes only the querystring parameters accessible via String keys instead of symbols
- `route_params` includes those that come from the route, accessible via symbols

We will have to decide what to deprecate and what not, fortunately it looks pretty straightforward to upgrade old extensions to the new model.
",badosu,mperham
3064,2016-08-04 05:04:55,"@mperham If I use TTIN signal, will it actually kill the hung threads? Or will it just dump thread backtraces and keep working threads untouched?
",nextofsearch,mperham
3064,2016-08-04 13:49:37,"@mperham  Thank you so much! I assumed ""Kill"" command will kill something. :)
",nextofsearch,mperham
3064,2016-08-04 14:02:17,"Of course, that makes perfect sense. 'Kill' is terribly named!

> On Aug 4, 2016, at 06:49, Dano Lee notifications@github.com wrote:
> 
> @mperham Thank you so much! I assumed ""Kill"" command will kill something. :)
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
",mperham,mperham
3062,2016-07-19 17:32:21,"@mperham Happy to put something together; can you point me in the right direction? Doesn't look like `redis_connection.rb` does any validating or handling of exceptions regarding the URL. Is this handled by `Redis`, or is something else afoot? 
",coreyward,mperham
3060,2016-07-15 00:03:52,"@mperham Why did you go with CBC over GCM?

Edit: GCM includes authentication so you don't have to compute a separate MAC.
",ryansch,mperham
3060,2016-07-15 02:35:02,"@ryansch OpenSSL didn't add GCM until 1.0.1 and I'm afraid we'll see compatibility issues with Rubies running on older Linux distros, like 12.04.  CBC seems like a reasonable tradeoff for maximum compatibility but please speak up if you think differently.

@mikegee I'd actually thought of the same pattern but wasn't sure it was a good idea.  If you folks use and like it, that's a strong push for me to implement it.  Any ideas to make the pattern as clear and foolproof as possible?  What if people just want to throw a Hash of data as a single arg and expect to see it all encrypted?  Should it blow up if the Worker takes less than two args?
",mperham,ryansch
3060,2016-07-15 02:35:02,"@ryansch OpenSSL didn't add GCM until 1.0.1 and I'm afraid we'll see compatibility issues with Rubies running on older Linux distros, like 12.04.  CBC seems like a reasonable tradeoff for maximum compatibility but please speak up if you think differently.

@mikegee I'd actually thought of the same pattern but wasn't sure it was a good idea.  If you folks use and like it, that's a strong push for me to implement it.  Any ideas to make the pattern as clear and foolproof as possible?  What if people just want to throw a Hash of data as a single arg and expect to see it all encrypted?  Should it blow up if the Worker takes less than two args?
",mperham,mikegee
3060,2016-07-15 16:05:31,"Associated wiki page with support for @mikegee's argument pattern https://github.com/mperham/sidekiq/wiki/Ent-Encryption
",mperham,mikegee
3060,2016-07-15 16:48:31,"We have definitely found it valuable to have some clear text parameters along with an encrypted payload.  If nothing else it makes understanding what messages are being displayed in the WebUI possible.  We have fallen into the pattern @mikegee mentioned above of just encrypting the last argument, but for the general framework maybe a scheme of whitelisting parameters to leave in cleartext as a worker option would make sense.  That way people could choose how they want to do it without much effort.

For the size bloat, we have taken to adding a compression step too.  Most of our gains came from the fact that the data getting encrypted frequently contained a JSON blob that compressed well anyway.  However, the side benefit is that the encoded message is significantly smaller even with the encryption and Base64 encoding.  We also haven't found that the overhead of compression/decompression has had any significant impact.

At a previous place we also went to the extent of using public/private key pairs to do the encryption.  That was significantly more complex and introduced the need to have a more sophisticated key management scheme.  The benefit was that we could encrypt the contents in such a way that if the website was hacked then the messages were still secure since the private keys were not there.  This may be overkill for most uses, but might be something to keep in mind when thinking about custom encryption scenarios.

Overall though, kudos for thinking about this as a core feature.  I think it will benefit a lot of people.
",meadoch1,mikegee
3060,2016-07-15 17:07:18,"@ryansch that's true, but there are a lot of potential problems still: you need to use an encrypt-then-MAC construction, make sure you're comparing the MAC in constant time, etc.

For these reasons an AEAD mode is a much safer choice.

> We have definitely found it valuable to have some clear text parameters along with an encrypted payload.

@meadoch1 Perhaps you could leverage the authenticated data portion of an AEAD mode like AES-GCM
",tarcieri,ryansch
3053,2016-07-07 13:50:10,"@mperham










",hotanlamvnn,mperham
3049,2016-07-04 18:27:25,"As promised: https://github.com/iMacTia/sidekiq-logstash
It's still a WIP and I would like to make it customisable based on input from other developers.
@mperham, I know you're a busy man, but your input would be really much appreciated :)
",iMacTia,mperham
3044,2016-07-08 15:54:10,"@mperham shall give it a go :) feel free to close this for now, and I will open it again when I get more info.
",scottrobertson,mperham
3044,2016-07-14 12:25:30,"@mperham got it. It's returning `303 See Other`
",scottrobertson,mperham
3042,2016-07-01 04:44:40,"@mperham Is this solved now? After the rack 2.0 bump?
",kgrz,mperham
3013,2016-06-12 22:11:57,"Hey @mperham. Thanks for the quick response. 

I can't exactly explain this one but `q.pause!` does not work for us in practice. It does change the UI indicator but the queue in question doesn't actually pause. What's more interesting is the UI behavior change completely. `q.pause!` actually changed our standalone monitor to have the flag whereas the in app flag never appears. First thing I did was ensure that both applications are pointing at the same Redis instance so I can confirm that isn't the issue we're experiencing. Do you have any other suggestions by any chance?
",dustinsgoodman,mperham
3007,2016-06-10 05:44:41,"@brandonhilkert here it is http://pastebin.com/yLexRZBF
",dyoganand,brandonhilkert
3005,2016-06-07 20:31:09,"@ryansch is having the same problem. so Im looking for a way to do this without the gem as is not working at the moment.  check my post again plis :) 
",Frank004,ryansch
3005,2016-06-07 20:49:31,"@mperham  Thank yes I'm just trying to find a way by doing this type of thing I'm learning some new stuff. I will read your link maybe get the apartement-sidekiq gem running again. will update this post with the progress or solución. thank you.  any other comment are very welcome. 
",Frank004,mperham
3005,2016-06-07 22:16:25,"@ryansch  Thanx for your time. I was looking some light on this matter. now I have some info. I will close this and update the post for future dev. in my shoes.
",Frank004,ryansch
2996,2016-06-01 16:15:51,"Thanks for the responses everyone.  We're currently testing an active/passive setup among data centers where the passive data center is comprised of read-only replicas using a slave-priority of zero to prevent unintended failovers.  This would require some manual failover (similar to changing a DNS pointer, but also more complicated). At this point, we depend highly on sentinel with many of our applications, so using DNS as a pointer to our master redis instance would take some major reconfiguration.

In talking with @mikegee, he noted that sidekiq may have problems with timeouts while writing/reading across network partitions, so that will be something we test heavily. 

I also appreciate the great reviews of the Redis Labs product. We'll have to look into that.
",everestx,mikegee
2990,2016-05-26 15:02:58,"@mperham Thanks for the help. It would be nice if it is described in the wiki, which could save me several hours. :)
",nextofsearch,mperham
2990,2016-05-27 01:08:59,"@mperham the link is not working.

I think the current description is a bit misleading since it doesn't work without namespace tweak.
""Sidekiq is compatible with Resque. It uses the exact same message format as Resque so it can integrate into an existing Resque processing farm. You can have Sidekiq and Resque run side-by-side at the same time and use the Resque client to enqueue jobs in Redis to be processed by Sidekiq.""

If you don't recommend namespaces, I think it should be stated that adding a sidekiq node to a resque processing farm would not work because of the difference in namespace somewhere in the doc.
",nextofsearch,mperham
2987,2016-07-27 18:45:24,"@mperham it is a signficant amount of work to fix this on 1.7.x (we did get this working on 9k).  So we would prefer to not put in work for something we plan on supporting for 5 more months.   This more than a simple parser fix too it digs into how we cope with symbols as well with how we register method names as Java Strings.
",enebo,mperham
2987,2016-08-29 17:04:25,"@mperham Sidekiq also appears to only support Ruby 2.0-compatible and higher, which would not include JRuby 1.7. I agree this is a bug in JRuby 1.7 but practically speaking should Sidekiq even be expected to run on that version anymore?
",headius,mperham
2985,2016-05-24 22:07:56,"I'm not sure about the procfile solution, it would require you re-deploy after every change, which is a bad experience.

Maybe something like this in `Procfile`:



Then you could change `SIDEKIQ_CONCURRENCY` at will. 

Ideally I would like this to work out of the box without a custom procfile.

@jeremyevans any thoughts on @nateberkopec's comment? Would be cool if Sequel could Just work (TM) with Rails 5 + Puma like Active Record. Happy to take that conversation to another thread if you want.
",schneems,nateberkopec
2983,2016-05-23 18:58:01,"@seuros _edit:_ sorry, mis-read the question. We did not do incremental upgrades.
",brrygrdn,seuros
2975,2016-05-17 17:44:40,"@mperham enqueueing and dequeueing with `Sidekiq::Testing.disable!` (i.e. in test environment) in test environment isn't returning right results for `Sidekiq::Queue.new.size`
",alexvbush,mperham
2975,2016-05-17 17:49:43,"@mperham when you schedule jobs in the future with `perform_at`
",alexvbush,mperham
2975,2016-09-23 04:29:50,"@mperham Just to clarify does ""the API does not have a testing mode"" translate to ""it's impossible to test that jobs are queued in the future""?
",jagthedrummer,mperham
2966,2016-05-10 20:50:17,"@mperham if you want, I can reverse this commit 
",davydovanton,mperham
2966,2016-05-10 20:52:23,"Please do. It was correct as is. 

> On May 10, 2016, at 15:50, Anton Davydov notifications@github.com wrote:
> 
> @mperham if you want, I can reverse this commit
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
",mperham,mperham
2966,2016-05-10 21:01:54,"@mperham done. Sorry for hastiness
",davydovanton,mperham
2963,2016-05-13 20:49:04,"@mperham Ok... I have Devise working fine in my Rails app with my other endpoints. This error only occurs when I'm trying to authenticate Sidekiq's Web UI access using your documented method. Is there some other setting or configuration that I could have missed? Or what in Sidekiq's Web UI would be triggering an error in Devise? Any high level insights of your architecture will be helpful to isolate the issue and fix it.
",hmistry,mperham
2960,2016-05-10 06:24:27,"@mperham Can we reopen this issue? I updated my Rails app to 5rc1 and all my gems to the latest ones bundler resolves to. However it's still failing with the same error.

I also tried creating a fresh new rails project with default settings, edited the Gemfile and added sidekiq and sinatra to it. Ran bundle and then add the `require 'sidekiq/web` and `mount Sidekiq::Web => '/sidekiq'` in routes and still same error. This is a clean fresh project with nothing inside. Rails works if I comment those 2 lines out.

I also noticed Sinatra v1.0 is being installed by bundler while the new version is 1.4.7. Is that causing the issue?
",hmistry,mperham
2960,2016-05-10 09:36:30,"This is because you aren't using the proper rack version.  You need 2.0.alpha. 

> On May 10, 2016, at 01:24, hmistry notifications@github.com wrote:
> 
> @mperham Can we reopen this issue? I updated my Rails app to 5rc1 and all my gems to the latest ones bundler resolves to. However it's still failing with the same error.
> 
> I also tried creating a fresh new rails project with default settings, edited the Gemfile and added sidekiq and sinatra to it. Ran bundle and then add the require 'sidekiq/web and mount Sidekiq::Web => '/sidekiq' in routes and still same error. This is a clean fresh project with nothing inside. Rails works if I comment those 2 lines out.
> 
> I also noticed Sinatra v1.0 is being installed by bundler while the new version is 1.4.7. Is that causing the issue?
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
",mperham,mperham
2960,2016-05-10 15:51:56,"@mperham I was using Rack 2.0.0.rc1, which I assume is ok. The correct answer is forcing Sinatra to use master. 

Thanks for your help and quick responses! 
",hmistry,mperham
2959,2016-05-17 17:15:44,"@jakemack I don't know why those entries appear but it's possible.  You see stale workers on 4.1.2?
",mperham,jakemack
2958,2016-05-05 20:13:38,"Sounds good. I'll do that and keep an eye on it. We have monitoring in place now to ensure we're notified of another occurrence of this. Thanks @mperham! 
",chaslemley,mperham
2949,2016-04-25 17:15:13,"@mperham Awesome. Many thanks
",gingermusketeer,mperham
2947,2016-04-24 17:36:28,"@mperham thank you very much!
",ch33foong,mperham
2942,2016-04-23 03:46:58,"wow! That'r right! It worked. I did't notice that uppercase letter. Should be a typo.

Thanks, @mikegee 
",evenluo,mikegee
2937,2016-04-19 14:01:45,"@mikegee I was not clear.
For example, sidekiq launches 20 threads after started up, and there are queues called: 'critical', 'normal', 'low'.
I want to allocate 10 threads of the 20 always to process queue 'critical', and the remaining 10 threads for queue 'normal' and 'low'.
",gihnius,mikegee
2936,2016-04-19 21:20:29,"That type of health check makes sense for a web service, where you want to ensure the port is open and requests are routing.  It makes less sense for Sidekiq: the workers could be locked up but the health check return 200 all day.  Your ps command is just as useful.  As @mikegee pointed out, really you want to monitor your queue sizes and ensure they aren't backing up.
",mperham,mikegee
2935,2016-04-17 17:25:42,"`redis-cli --latency and --latency-history` looks ok
regarding to redis initialization i can't find network_timeout property inside redis client is it should be `timeout` or `connect_timeout` ? (the default is 5.0 already) @mperham 

https://github.com/redis/redis-rb/blob/master/lib/redis/client.rb#L14
",frenkelor,mperham
2922,2016-04-12 21:16:49,"You can do this but @seuros is right, `logrotate` is the correct solution.


",mperham,seuros
2919,2016-05-27 08:53:05,"@mperham I am very sorry to write here again, but the problem with removing batch status from redis after a batch successfully done seems still exists. We have updated our sidekiq-pro version to 3.2.1. 

This is a code snippet from the gem source code:



As you can see, this code removes a batch info from redis and publish the notification to redis channel.  The problem here that we cannot use a polling feature to fetch batch status as described here - https://github.com/mperham/sidekiq/wiki/Batches#polling - when batch done, we'll receive `Sidekiq::Batch::NoSuchBatch` as it never exists before.

Can we keep the statistic in redis, since it has 30-days expiration anyway? 
",SamMolokanov,mperham
2916,2016-04-08 14:40:16,"@mperham Got it, thanks for clarifying! 

Perhaps a `configure_both do |config|` block would work? Would also make the duality more obvious — I didn't know.

Not trying to criticize, I like Sidekiq so I'm only spending time suggesting things because I'd like to help out.
",sandstrom,mperham
2914,2016-04-13 20:25:28,"@davydovanton Can you commit the same hack here so the Sidekiq build passes?
",mperham,davydovanton
2912,2016-04-07 16:57:53,"@jonhyman Do you have it published?  I'd be interested in looking at your changes.
",ryansch,jonhyman
2910,2016-04-12 16:59:48,"@mperham thanks for the consolidation. i really thought i put in a rather deep-dive on the closed issues. i didn't come up with such a concise answer. this seems to be working. again thank you for your help. 
",hobakill,mperham
2910,2016-04-15 21:32:52,"@epintos I am a dev that works with @hobakill. I was investigating this issue after he opened a pull request into our application to add the new sidekiq configuration for 4.1. I noticed that the monitoring documentation and the code provided by @mperham uses `Sidekiq::Web.set :session_secret, Rails.application.secrets[:secret_token]` which is not actually standard for a rails 4 application. 

Rails 3 used `secret_token` as a base to encrypt and verify session cookies but Rails 4 uses `secret_key_base` to encrypt session cookies. Essentially, the code will most likely be, in your case if you are running Rails 4.*, `Sidekiq::Web.set :session_secret, Rails.application.secrets[:secret_key_base]`

Interesting enough, using the above code for one of our applications actually solved our problem. It allowed us to stop receiving 403 errors when trying to cancel Sidekiq jobs from the monitoring client even though the `session_secret` was set to `nil` in `Sidekiq::Web`. I am interested to know if anyone else has encountered such an issue when upgrading.
",PFStein,mperham
2910,2016-05-13 21:04:24,"@mperham That's makes sense.

I'm still hopeful that someone on here can point me in a helpful direction. I thought my app was pretty standard, but maybe something in my middleware is a bit off. The app has been upgraded from Rails 2- > 3 -> 4.0- > 4.2.

Here are the values for my secret_key_base and session_options. I have obviously replaced the strings with A, B, or C. You can see that all the values are different. Is that normal?



(I have tried using both `secret_token` and `secret_key_base`, but I don't see any change.)

The values are the same for my development, staging, and production. I can't figure out why it's working on development (using Pow), but not in staging or production on AWS Elastic Beanstalk.
",mike-ball,mperham
2910,2016-05-20 17:19:04,"@mike-ball http://www.sourcediver.org/blog/2015/07/01/rack-protection-and-nginx/
Had your same problem, this fixed it!
@mperham Could be worth including it in the troubleshooting? I understand it's probably an edge-case, but I spent days before finding it.

In case the link stops working, just add the following to your nginx config:


",iMacTia,mperham
2909,2016-04-04 15:50:08,"@mperham Thanks for the information.  I'll see what I can do to make this work.  Clock_work gem should do it.  I'd like to get Sidekiq enterprise but being in the startup world and running lean it's hard to afford with 100+ app instances.  Closing :)
",nynhex,mperham
2908,2016-04-09 20:01:22,"@mperham I have a similar issue with sidekiq `4.1.1` and I am consistently able to replicate it.

I have a simple worker



In rails console,



Ideally the job needs to be run 2 times, this is working as expected in local where the redis-server is running in the local machine iteself. But in my staging (where the redis is a Elasticache cluster), the job is executed only one time.

I also tried downgrading to `3.5`. Still stays the same. My theory is that enqueuing two jobs at the same exact time along with the network delay in accessing the redis-server is causing something to break in sidekiq.

Rails `4.2.4`
Sidekiq `4.1.1`
Redis `2.8.21`



Thanks for the awesome gem and the great work :smile: 
",Charizard,mperham
2908,2016-04-11 23:15:41,"@mperham Thanks for pointing it out, I will check the `app` part of the URL. But, one more update is that when I change the queue of the worker from default to something else, it seems to work stably :cry: 

Also, I am not using any middleware, other than the default ones. Plus, I can see the redis logs that both the jobs are getting `lpush`ed.
",Charizard,mperham
2908,2016-07-12 20:31:23,"For anyone that comes across this thread later, updating to sidekiq 4.1.2 did not solve the our disappearing job problem but upgrading to sidekiq pro with `timed_fetch` did. I think it has to do with the network hop between our separate web and sidekiq worker clusters.

Happy hunting and big thanks to @mperham. 

🚬 🐟 
",DrMavenRebe,mperham
2907,2016-03-30 13:36:21,"thanks @mikegee , i guess my question was is there a way to notify the job to ""bail out"" to save wasted cpu computing power?
",nimashariatian,mikegee
2907,2016-03-30 16:03:23,"@mperham  after speaking with my lead engineer, we are not going to kill the thread as you suggested. 
so you are correct on that end. 
however, we would love to hear any ideas regarding how to implement this. 
would it make sense to store to ""job to cancel id"" in redis and poll for it inside the worker?
",nimashariatian,mperham
2902,2016-03-28 04:59:16,"Thanks @mperham for checking my problem. 
Can you tell me how to verify if redis is out of memory and how to check network is ok or not

And now if I upgrade redis to latest version, what should I notice so that it does not make any break to our system?

Thanks
",ancv1990,mperham
2902,2016-03-28 05:03:15,"Thanks @mperham 
",ancv1990,mperham
2899,2016-04-04 20:12:05,"After upgrading to 4.1.1 I have a very similar issue. I'm running passenger standalone. I can login fine but when I go to delete/retry/whatever jobs I get the `Forbidden` message. 

For reference my config.ru look similar to this: 



Would love your thoughts @mperham or @pbhogan if you were able to solve this. 
",hobakill,mperham
2888,2016-03-17 16:32:12,"It took some time to find the issue, but for posterity: if it looks like your server batch middleware isn't running, but `sidekiq -v` says that it is, make sure you're actually calling a worker in your batch.jobs loop.  I wasn't. 

Thanks so much for your help @mperham!
",thatmoodyguy,mperham
2876,2016-06-28 18:53:52,"Hi @mperham! We are running into some trouble with this. After doing a little source diving, it appears that `Sidekiq::Batch.new` is always choosing a random shard for the batch, regardless of `Sidekiq::Shards.on(...)`:



It does appear that all the jobs are getting enqueued in the right shard.
",djreimer,mperham
2869,2016-03-05 10:54:12,"@mperham I upgraded to 4.1.1.
More logs from production env on Heroku. I noticed this weird part:
`:error_handlers=>[#<Sidekiq::ExceptionHandler::Logger:0x007fe7a5d2c370>]`


",01010000101001100,mperham
2868,2016-03-04 11:51:31,"Thanks you for your contribution @dbachet :heart: 
",seuros,dbachet
2866,2016-03-05 10:45:00,"@mperham thanks for your efforts, appreciate it. Actually, in my case jobs don't even go to ""enqueued"", sidekiq doesn't even initiate them although he runs in idle. This happens when I restart heroku, means some configs with heroku are lost because if I push the initial code with clean database, everything works just fine.
",01010000101001100,mperham
2862,2016-03-03 18:52:57,"@mperham thanks - yeah I figured if this was default sidekiq behavior there'd be more people complaining. Thanks for the ttin tip - I'll try that and see what I can figure out.
",jeremyhaile,mperham
2862,2016-03-03 21:10:32,"@mperham so, I haven't been able to reproduce an increasing number of threads locally. When I run the TTIN, I see the following threads:
- 1 sidekiq/cli thread
- 4 celluloid mailbox threads
- 1 puma_worker_killer auto_reap thread
- 1 sidekiq/launcher thread
- 1 connection_pool/timed_stack thread from sidekiq/scheduled
- 5 redis/connection/ruby threads from sidekiq's brpop call

Of these, celluloid seems like the most likely culprit. I use a gem (pubnub) that uses celluloid (they used to use eventmachine but an upgrade switched to celluloid.  However, I tried using that gem a lot in jobs and I can't get it to increase the number of threads I'm seeing in the TTIN dump.

Let me know if any of this rings a bell of something that could leak threads when used within sidekiq. Thanks!
",jeremyhaile,mperham
2862,2016-03-03 21:47:56,"That sounds totally normal, except the puma killer, which is spinning up an
unnecessary thread.

On Thu, Mar 3, 2016 at 1:10 PM, Jeremy Haile notifications@github.com
wrote:

> @mperham https://github.com/mperham so, I haven't been able to
> reproduce an increasing number of threads locally. When I run the TTIN, I
> see the following threads:
> - 1 sidekiq/cli thread
> - 4 celluloid mailbox threads
> - 1 puma_worker_killer auto_reap thread
> - 1 sidekiq/launcher thread
> - 1 connection_pool/timed_stack thread from sidekiq/scheduled
> - 5 redis/connection/ruby threads from sidekiq's brpop call
> 
> Of these, celluloid seems like the most likely culprit. I use a gem
> (pubnub) that uses celluloid (they used to use eventmachine but an upgrade
> switched to celluloid. However, I tried using that gem a lot in jobs and I
> can't get it to increase the number of threads I'm seeing in the TTIN dump.
> 
> Let me know if any of this rings a bell of something that could leak
> threads when used within sidekiq. Thanks!
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/issues/2862#issuecomment-191964707.
",mperham,mperham
2857,2016-03-07 11:53:12,"@mperham  Thanks for getting back. Perhaps, I am misleading myself... How can I ensure that job history is preserved after application restart? What are the prescribed steps?
",vmatekole,mperham
2852,2016-02-27 03:27:00,"@mperham  thanks
",zxx1988328,mperham
2849,2016-02-27 22:26:06,"@jonhyman every EBS process must look identical so it can auto-scale them.  There's no way to give them different yml/env/etc afaik.
",mperham,jonhyman
2844,2016-02-25 09:16:21,"@ryansch 

> and keeps most of the duplicate jobs from being scheduled.

Do you mean you met cases where it was duplicated ? Can you elaborate on that ?
",Micka33,ryansch
2839,2016-03-03 09:59:27,"Hi @mperham, 
could you tell me how to use sinatra master ? 

Thanks a lot, 

Yan
",yanperron,mperham
2828,2016-02-11 22:31:57,"@mperham done :star2: 
",davydovanton,mperham
2817,2016-02-06 04:11:02,"@mperham, I don't entirely understand how the connection pools work. But, if my Redis.current is going to be used inside a 25 Sidekiq workers, wouldn't I want Redis.current to have 25 connections in the pool?

Also, I know that it's asynchronous, but assuming that I'm specifically enqueuing things for a test, is there no way to tell that there are currently no jobs enqueued or in progress (meaning Sidekiq is completely idle)? What would polling for that look like? I'm fine with waiting, but I haven't found a good way to poll with certainty.
",natematykiewicz,mperham
2815,2016-03-31 15:48:14,"Ah, I see now that `Statsd::Batch.new($statsd)` has to be used. @mperham time periods are not collected on the client? How?

@jcarlson Why not just do this?



Thats what I'm doing (at 10s intervals). Is there something wrong with this approach?
",jhoffner,mperham
2809,2016-02-05 20:53:03,"@seuros Any chance you can look into that broken JS, see comment above?
",mperham,seuros
2802,2016-01-29 23:21:07,"Awesome, thank you @mperham 
",zedtux,mperham
2799,2016-02-11 11:31:35,"@mperham thanks for response :) , by different redis server i actually meant a server which is running on a different machine.
",MajorMashin,mperham
2798,2016-01-28 16:59:56,"thank you @mperham 
",DzmitryNikitsin,mperham
2796,2016-01-27 18:16:20,"@mperham Right, I don't expect you to, I work at GitLab so that's actually my job :) 

This issue was reported to us as Sidekiq getting stuck, and from the symptoms (`25 of 25 busy`, not showing up under `Processes`, not responding to `TTIN`) it sounds to me like an issue in Sidekiq rather than in GitLab code. I would love some help with debugging as I'm not familiar enough with Sidekiq, Ruby threading internals or GDB to go any further from here.

Does the GDB output or the `rb_backtrace()` lead you to believe the issue lies with GitLab, specifically in the top frame from that stacktrace, or is that just the place where the Ruby thread got stuck for some external reason?
",DouweM,mperham
2796,2016-01-28 15:06:11,"Thanks @mperham, that helps tremendously. I will continue debugging from here.

It's a testament to Sidekiq's stability and robustness that we've never needed support until now. If we ever need help again we will gladly reach out to you via http://sidekiq.org/support and get a support contract. If I came off a little ""demanding"" with this issue, I didn't mean to. I understand that your time is valuable.

Sidekiq Pro looks great, but is currently not interesting to us since we would need an Appliance license and it would only be available to our GitLab Enterprise Edition customers. Sidekiq ""basic"" is currently serving our users more than adequately, whether they be on the community or the enterprise edition.
",DouweM,mperham
2796,2016-01-28 17:23:09,"@mperham Fair enough, I'll keep that in mind.
",DouweM,mperham
2789,2016-02-12 10:25:30,"@mperham production works ok.
",krzysiek1507,mperham
2773,2016-02-01 07:01:21,"@mperham sorry for delay in answer.
Can you still help with it? 
gdb output https://gist.github.com/antonzaytsev/a38b0b9827dee25ce521
",antonzaytsev,mperham
2773,2016-02-02 04:18:05,"@D-side @mperham thanks for investigate it!
I use `therubyracer` for `V8`, I have code to eval js and manipulate variables.
Is there any thread-safe replacement for `therubyracer` ?
",antonzaytsev,mperham
2773,2016-02-02 06:13:08,"You have to create your own global lock for it. Discourse has one somewhere. 

> On Feb 1, 2016, at 20:18, Anton notifications@github.com wrote:
> 
> @D-side @mperham thanks for investigate it!
> I use therubyracer for V8, I have code to eval js and manipulate variables.
> Is there any thread-safe replacement for therubyracer ?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2773,2016-02-02 07:06:24,"Thanks @mperham.
For now I use mutex.


",antonzaytsev,mperham
2772,2016-01-14 22:13:10,"@davydovanton you mean @ddrmanxbxfr ;)
",krzysiek1507,ddrmanxbxfr
2772,2016-01-14 22:13:10,"@davydovanton you mean @ddrmanxbxfr ;)
",krzysiek1507,davydovanton
2772,2016-01-14 22:14:36,"Both method we're patched in this PR. The one in #2771 and a new one in
sorted set class.
On 14 Jan 2016 17:13, ""Krzysztof Rybka"" notifications@github.com wrote:

> @davydovanton https://github.com/davydovanton you mean @ddrmanxbxfr
> https://github.com/ddrmanxbxfr ;)
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/pull/2772#issuecomment-171798372.
",ddrmanxbxfr,ddrmanxbxfr
2772,2016-01-14 22:14:36,"Both method we're patched in this PR. The one in #2771 and a new one in
sorted set class.
On 14 Jan 2016 17:13, ""Krzysztof Rybka"" notifications@github.com wrote:

> @davydovanton https://github.com/davydovanton you mean @ddrmanxbxfr
> https://github.com/ddrmanxbxfr ;)
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/pull/2772#issuecomment-171798372.
",ddrmanxbxfr,davydovanton
2767,2016-05-04 08:05:51,"Hi @mperham, 

you missed the template file:
`template = Tilt.new(""#{File.dirname(__FILE__)}/templates/email.html.erb"")`

Regards.
",ryanfox1985,mperham
2766,2016-01-13 20:58:20,"@mperham Ah, it's `Process.kill(:KILL, pid)` in version 3.5.3. In master branch of `3.x`, it's now using `kill -9`. I think it will be fixed next version. Am I right?
",larryzhao,mperham
2763,2016-01-12 09:05:49,"It's also linked in #2749 - I had not noticed since I generally don't look at closed issues for problems with a current version. @mperham Perhaps it would help to leave one of these issues open w/ another flag such as on hold so that it is potentially easier to locate for others?
",pik,mperham
2763,2016-01-12 17:43:22,"@mperham If this ends up being a bug in Ruby instead of sidekiq, it could still be helpful to have an open issue here for folks searching.  :+1: @plk
",b264,mperham
2763,2016-01-12 17:58:34,"I think you meant to CC @pik rather than ""plk"" ...
",plk,pik
2759,2016-01-12 01:35:27,"@mperham Could you add a word about why a mutex is bad there for causal issue readers like me? Is it because that is a frequently executed method that you don't want to add overhead to?
",mikegee,mperham
2759,2016-01-12 04:27:49,"@mikegee In this case I was mostly concerned about readability.  I already have a plan for building similar functionality which doesn't require hacking those core methods.

I was concerned about a Mutex in a performance critical method but he's right that his double checked locking mostly fixes that issue.
",mperham,mikegee
2756,2016-01-07 21:07:57,"@mperham Thanks Mike.  Sorry for opening this issue, just figured I'd check.  Looks like we need enterprise.  I have some questions so I'll ping you on Twitter. :+1: 
",nynhex,mperham
2755,2016-01-07 11:05:57,"@seuros , you mean REDIS_URL, right?

Just tried with REDIS_URL, and it goes boom in the same way. 
",HoneyryderChuck,seuros
2753,2016-01-06 18:05:34,"@mperham I added `before` and `after` blocks and if it solution is good for you - I can squash commits before a merge.
",davydovanton,mperham
2749,2016-01-05 22:29:00,"@mperham Just resolved the issue, was going to update/close this issue.

I _was_ using rbenv:



Then I blew away `rbenv`, installed `chruby` and built Ruby 2.3.0 from scratch and things worked fine:


",peteygao,mperham
2748,2016-01-04 22:48:40,"@seuros it will be really cool if you check it in windows and linux desktop. I checked it on android phone and it work correct :tada: 
",davydovanton,seuros
2747,2016-01-04 16:07:53,"Thanks for contribution, @mizoR! :+1: 
",davydovanton,mizoR
2741,2015-12-31 23:08:16,"@mperham You may want to wait on a formal release until Ruby 2.3.1 is out.

I know that there's at least one showstopper bug preventing us from moving to Ruby 2.3.0 that will be fixed in 2.3.1 - Resolv::IPv6.create is completely broken because of frozen string issues.  You can see details here - https://github.com/ruby/ruby/commit/a3b53cd9919ff01567ef04af4057b3dec3192471
",petergoldstein,mperham
2741,2015-12-31 23:12:05,"@petergoldstein I'm not sure I understand your concern.  How does a bug in Ruby's Resolv prevent us from using frozen strings?
",mperham,petergoldstein
2741,2016-01-01 00:23:23,"@mperham My concern is that I think 2.3.0 isn't quite ready for prime time.  The frozen string change was a big one that impacted most of the Ruby code base.  Significant bugs (e.g. the IPv6 one) that impact large swaths of functionality are being found just a few days after the 2.3.0 release.

So making 2.3.0 the 'recommended' Ruby for use with Sidekiq feels premature to me.  But it's a judgment call, which is why I suggested that you may want to wait until 2.3.1 is out (or you may not).
",petergoldstein,mperham
2739,2015-12-29 08:51:17,"@mperham thanks
",sandish2222,mperham
2735,2016-01-04 16:08:56,"@mperham this issue about sidekiq.org site or web part of sidekiq?
",davydovanton,mperham
2735,2016-01-04 16:09:39,"Sidekiq.org

> On Jan 4, 2016, at 08:08, Anton Davydov notifications@github.com wrote:
> 
> @mperham this issue about sidekiq.org site or web part of sidekiq?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2735,2016-01-04 16:57:35,"@mperham if you want I can create this responsive table
http://codepen.io/icutpeople/pen/pfHDj

This is look like normal for you?
",davydovanton,mperham
2735,2016-01-05 17:23:00,"@davydovanton Thank you so much for fixing this!  I feel pretty helpless trying to fix web styling problems, it's awesome to have better web people than me willing to help out.
",mperham,davydovanton
2735,2016-01-05 17:27:02,"@mperham I am always glad to help :blush: 
",davydovanton,mperham
2726,2015-12-17 18:41:46,"Thanks tons @mperham ! Fixing our config made it work correctly. 
",drogar,mperham
2725,2016-01-01 21:06:01,"@mperham, I was not able to get any better idea of the cause of the problem or solve it. Had to rebuild the app completely. 
",duboff,mperham
2724,2015-12-17 04:36:26,"@mperham Thanks for having a look. Unfortunately, we're pretty much locked into our current init (and monit) for the foreseeable future and would really appreciate this behavior being corrected.

It's particularly odd in that I don't see any feasible reason that the pid file would disappear within such a short time frame, given that both the CLI and the spawned worker remain.
",ess,mperham
2724,2015-12-17 18:19:51,"So, I believe I know what's happening, and I'll leave this here for anybody that might be running into a similar issue. Effectively, Sidekiq is just plain too fast for its own good in this respect.

So as to ensure that `monit` doesn't try to watch an old PID, before we run the canonical `sidekiq` executable, we `rm -f` the pid file that it uses. The very next step is to run `sidekiq`. The problem, however, is that we're hitting a race condition: the results of the `rm` are not necessarily synced before `sidekiq` writes to the still quasi-existing file location. So, what we end up with looks like this:
1. `rm -f /path/to/pid`
2. `sidekiq -P /path/to/pid`
3. Filesystem sync completes, nuking the on-disk descriptor for `/path/to/pid`

This was detected in the least intuitive way possible: I added `strace -ff -o /sidekiq_strace` to our `sidekiq` run to determine if something odd was happening in the interpreter. This slowed execution to the point that I was no longer able to reproduce the issue. I both love and hate serendipity.

@mperham You're welcome to re-close this, but it might be worth adding a pre-write existence check to `Sidekiq::CLI#write_pid` to either handle or work around this excessively frustrating edge case. Barring that, it might be worth a mention in the documentation ... something to the effect of ""if you rely on pid files and remove them before doing a restart, be sure to `sync` before starting sidekiq as well.""
",ess,mperham
2724,2015-12-17 21:44:25,"No worries, @mperham. I was a bit of a jerk in my response, and I regret having done so. To be fair, I do occasionally miss cargo culting until everything magically works ;)

At any rate, I'm playing around with an alternative solution. I'll hit you up privately if it works out well enough that you could, indeed, remove the pid file feature from core.
",ess,mperham
2723,2016-03-29 16:31:24,"@mperham Can this be re-opened?  I am also seeing this issue, but I am not manually enqueing:



Being enqueued via:


",pnomolos,mperham
2723,2016-03-29 16:32:54,"@mperham Actually, scratch that ... I think this is because I killed my workers partway through and set the retry options to zero - looks like some jobs were re-enqueued with their retry count and that is still respected?
",pnomolos,mperham
2717,2015-12-15 10:48:40,"@mperham nice catch and thanks for merge!
",davydovanton,mperham
2710,2015-12-13 15:09:31,"If it is an expected behavior, I have following thoughts 
- If /queues/:name is only meant for listing enqueued jobs (like to confirm this) then [CurrentMessagesInQueue](https://github.com/mperham/sidekiq/blob/master/web/locales/en.yml#L25) should be changed to `Current enqueued jobs in <span class='title'>%{queue}</span>`
- Also If there are no jobs to list on this page, Can we have alert message like `No enqeued jobs were found` or `No  jobs were found` to be consistent with other tabs ?

@mperham  - Let me know your thoughts, I would be happy to make these changes.
",pramodshinde,mperham
2709,2015-12-16 09:11:33,"@mperham you was right, thanks :)
(totally forgot to give feedback, sorry)
",tchncs,mperham
2707,2015-12-11 11:49:54,"I think it's this line that truncates huge error messages: 

https://github.com/mperham/sidekiq/blob/3_x/lib/sidekiq/middleware/server/retry_jobs.rb#L99



The particular error encountered by @Nowaker would be solved by a `#to_s`:



It would be nice to see that custom exception to be sure, though.
",mikegee,Nowaker
2700,2016-06-30 12:35:49,"@mperham 

> I believe it's a smell for tests to use it. I'll rework the wiki docs.

what about case where you want to test full integration of worker which is internally using batch.
",lefty313,mperham
2700,2016-07-01 16:34:23,"I don't have any links, just a hazy memory of someone mentioning it.  Maybe @ryansch.
",mperham,ryansch
2698,2015-12-08 16:35:18,"@mperham Sweet! Thanks for taking a look at this. :) I'll close this one then.
",Wildebeest,mperham
2688,2015-12-08 21:42:03,"@mperham FYI, right after deploying on heroku I encountered the issue again, and as soon as I was able to `heroku redis:cli` without getting `ERR max number of clients reached` I had the following result:



I'm running my (single) worker dyno with `-c 10` , and my logfiles show the following:



Does that mean that heroku launches the new dyno before waiting until all jobs of the old worker are killed? And/or that even though the old worker jobs are killed its redis connections remain open until they timeout?
",maia,mperham
2688,2015-12-08 21:57:46,"Heroku does not guarantee that old process will be dead before the new process starts. You can add a sleep(5) to your initializer and see if it helps/prevents the problem. 

> On Dec 8, 2015, at 13:42, maia notifications@github.com wrote:
> 
> @mperham FYI, right after deploying on heroku I encountered the issue again, and as soon as I was able to heroku redis:cli without getting ERR max number of clients reached I had the following result:
> 
> ec2-54-83-33-255.compute-1.amazonaws.com:13319> client list
> id=423147 addr=10.234.214.90:33124 fd=13 name=observatory age=75572 idle=2 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=ping
> id=426910 addr=10.93.204.241:60550 fd=7 name=Sidekiq_3 age=8161 idle=57 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=get
> id=426911 addr=10.93.204.241:60551 fd=8 name=Sidekiq_3 age=8161 idle=57 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=get
> id=426913 addr=10.93.204.241:60553 fd=10 name=Sidekiq_3 age=8161 idle=59 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=srem
> id=426914 addr=10.93.204.241:60554 fd=11 name=Sidekiq_3 age=8161 idle=57 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=srem
> id=426915 addr=10.93.204.241:60555 fd=12 name=Sidekiq_3 age=8161 idle=58 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=srem
> id=427094 addr=10.93.204.241:44247 fd=14 name=Sidekiq_3 age=5375 idle=58 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=srem
> id=427095 addr=10.93.204.241:44568 fd=17 name=Sidekiq_3 age=5361 idle=58 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=get
> id=427397 addr=10.225.168.45:58825 fd=18 name= age=113 idle=53 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=slowlog
> id=427402 addr=10.178.213.123:36645 fd=19 name=Sidekiq_3 age=57 idle=2 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=rpop
> id=427403 addr=10.178.213.123:36649 fd=20 name=Sidekiq_3 age=57 idle=57 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=brpop
> id=427404 addr=10.178.213.123:36650 fd=21 name=Sidekiq_3 age=57 idle=1 flags=b db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=brpop
> id=427405 addr=10.178.213.123:36652 fd=22 name=Sidekiq_3 age=57 idle=2 flags=b db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=brpop
> id=427406 addr=10.178.213.123:36653 fd=23 name=Sidekiq_3 age=57 idle=2 flags=b db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=brpop
> id=427407 addr=10.178.213.123:36654 fd=24 name=Sidekiq_3 age=57 idle=2 flags=b db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=brpop
> id=427408 addr=10.178.213.123:36651 fd=25 name=Sidekiq_3 age=57 idle=55 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=srem
> id=427420 addr=62.178.117.43:43196 fd=9 name= age=3 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client
> I'm running my (single) worker dyno with -c 10 , and my logfiles show the following:
> 
> 2015-12-08 20:55:35.777074+00:00 app worker.1 - - 3 TID-ort0pt8k8 INFO: Shutting down
> 2015-12-08 20:55:35.777139+00:00 app worker.1 - - 3 TID-ort0pt8k8 INFO: Terminating quiet workers
> 2015-12-08 20:55:35.777237+00:00 app worker.1 - - 3 TID-ort1qls2c INFO: Scheduler exiting...
> …
> 2015-12-08 20:55:36.359600+00:00 app worker.1 - - 3 TID-ort0pt8k8 INFO: Pausing to allow workers to finish...
> 2015-12-08 20:55:33.715222+00:00 heroku worker.1 - - Starting process with command `bundle exec sidekiq -c 10 -q high_priority,2 -q default -q mailers -q low_priority`
> 2015-12-08 20:55:34.208963+00:00 heroku worker.1 - - Stopping all processes with SIGTERM
> …
> 2015-12-08 20:55:33.715222+00:00 heroku worker.1 - - Starting process with command `bundle exec sidekiq -c 10 -q high_priority,2 -q default -q mailers -q low_priority`
> …
> 2015-12-08 20:55:39.749811+00:00 app worker.1 - - 3 TID-ox2clntec INFO: Booting Sidekiq 4.0.1 with redis options {:id=>""Sidekiq_3"", :url=>""redis://h:REDACTED@ec2-54-83-33-255.compute-1.amazonaws.com:13319""}
> …
> 2015-12-08 20:55:34.208963+00:00 heroku worker.1 - - Stopping all processes with SIGTERM
> 2015-12-08 20:55:41.218297+00:00 heroku worker.1 - - Stopping all processes with SIGTERM
> …
> 2015-12-08 20:55:41.395986+00:00 app worker.1 - - 3 TID-ox2clntec INFO: Starting processing, hit Ctrl-C to stop
> 2015-12-08 20:55:41.447219+00:00 app worker.1 - - 3 TID-ox2dgeg48 ERROR: Error fetching job: ERR max number of clients reached
> 2015-12-08 20:55:41.449068+00:00 app worker.1 - - 3 TID-ox2dmwptk ERROR: Error fetching job: ERR max number of clients reached
> …
> 2015-12-08 20:55:43.342325+00:00 app worker.1 - - 3 TID-ort0pt8k8 WARN: Work still in progress [#<struct Sidekiq::BasicFetch::UnitOfWork queue=""queue:default"", job=""{…}"">]
> 2015-12-08 20:55:43.340536+00:00 app worker.1 - - 3 TID-ort0pt8k8 WARN: Terminating 10 busy worker threads
> …
> 2015-12-08 20:55:44.421968+00:00 heroku worker.1 - - Error R12 (Exit timeout) -> At least one process failed to exit within 10 seconds of SIGTERM 
> 2015-12-08 20:55:44.421968+00:00 heroku worker.1 - - Stopping remaining processes with SIGKILL
> …
> 2015-12-08 20:55:44.498428+00:00 app worker.1 - - 3 TID-ox2d9g4fo WARN: Redis::CommandError: ERR max number of clients reached
> Does that mean that heroku launches the new dyno before waiting until all jobs of the old worker are killed? And/or that even though the old worker jobs are killed its redis connections remain open until they timeout?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2683,2015-12-03 01:59:27,"@jonhyman that just makes way too much sense. Didn't know that was possible. Thank you.
",fedenusy,jonhyman
2683,2015-12-03 03:05:06,"@jonhyman You can set the options: `Class.delay(queue: :low).method`
",mperham,jonhyman
2681,2015-12-01 14:02:54,"Thanks @mperham for the response. But this is running since 4 days now whereas it should not same job with different params runs in less than a second or two. Is there a way to kill this job?
",abhijitsinha,mperham
2681,2015-12-01 14:04:33,"Restart the process. 

> On Dec 1, 2015, at 06:02, Abhijit Sinha notifications@github.com wrote:
> 
> Thanks @mperham for the response. But this is running since 4 days now whereas it should not same job with different params runs in less than a second or two. Is there a way to kill this job?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2681,2015-12-01 14:30:00,"@mperham Sure, thanks. We tried restarting the process but it did not work. 

Let me try again and get back. Closing the issue for now.
",abhijitsinha,mperham
2681,2015-12-01 15:02:07,"Hello @mperham - we restarted the process.

The job is back again and running endlessly. This is very strange.

Any idea why this is happening? Appreciate your help!
",abhijitsinha,mperham
2681,2015-12-03 08:36:14,"Hello @mperham 

 Is the machine showing >= 100% CPU usage?

What will this lead to if the CPU usage is more than 100% - other jobs run normal though few get into an infinite loop. 
",abhijitsinha,mperham
2681,2015-12-04 08:32:26,"Thanks @mperham - we were able to remove that job from redis.

Couple of queries - 
1. Is there a way to monitor such jobs consuming large memory and stuck in infinite loop.
2. Can we kill/remove such jobs when memory consumption is high automatically.

Please let us know if you have any suggestion around this. Thanks
",abhijitsinha,mperham
2681,2016-02-04 11:21:30,"@mperham Thanks for the all the help. Yes, we have inspeqtor in place to monitor those aspects.

Sharing below note to help others  -

We are using the below code to identify the queue name on production redis machine.



Once you have queue_name - we can use the code below - please note - the logic to match the code can vary on how precisely you want to filter a job in case you have many jobs having similar parameters - 


",abhijitsinha,mperham
2679,2015-11-30 16:37:10,"@dlackty thanks for contribution!
",davydovanton,dlackty
2678,2015-11-28 23:17:31,"@jonhyman that won't work, heroku still kills the dyno after 10 seconds. If a job has to run for more 10 minutes, you can't just increase the timeout
",alex88,jonhyman
2678,2015-11-28 23:28:10,"@mperham increasing -t won't help, heroku will SIGKILL the process which maybe can also cause the job to not be re-enqueued 
",alex88,mperham
2678,2015-11-30 16:01:42,"@mikegee the problem in my case is that there is a global lock (based on the data I'm currently processing) that needs to be released after the last loop item is processed (that's harder to manage when each item is processed in a separate job), not mentioning that I also need an order of processing due so pre-requisites the items at the bottom have.
",alex88,mikegee
2678,2015-11-30 16:43:28,"@mperham how? if inside the worker code I can't know neither when it receives the TERM signal?
",alex88,mperham
2678,2015-12-03 22:03:47,"@mperham I've just tried to but that code in the worker but seems no signal is being sent to the worker
",alex88,mperham
2674,2015-11-21 19:54:23,"Upgrading to Rails 4.2 seems to have fixed it. Thanks @mperham for the hard work on sidekiq.
",penso,mperham
2670,2015-11-20 08:54:49,"Yes, thank you very much for your time and patience @mperham 
",syndbg,mperham
2663,2015-11-17 17:11:51,"@mperham oh have fun at RubyConf!

In my testing and exploration, it looks like RSpec is quietly moving away from the `change(thing, :method)` toward `change { }`. None of the documentation recommends that pattern anymore. While it hasn't been deprecated, I wonder if it would just be worth calling out in the changelog as a breaking change (it was a major version bump after all), and updating the wiki?
",sethvargo,mperham
2663,2015-11-25 14:41:42,"@brandonhilkert I refactored all our tests to use the other RSpec syntax when we were blocked by the original issue. So, yes, I can run them, but it won't be a good indicator if the problem is fixed :smile:. Sorry!
",sethvargo,brandonhilkert
2663,2015-11-25 14:47:12,"Hey @brandonhilkert  - I just changed one test back to the old syntax and it's still failing. The gemfile is pointing to the queue-api branch off mperham/sidekiq.
",sethvargo,brandonhilkert
2663,2015-11-25 14:56:09,"@brandonhilkert no problem. It might be worth just adding a test to sidekiq itself to verify the behavior doesn't regress
",sethvargo,brandonhilkert
2659,2015-11-14 13:10:48,"No worries @brandonhilkert I already fixed the problem for me in the related pull request but didn't spend any time investigating a failing example before I did. I saw the test using a symbol for name of the queue in the worker and then fetching by a string which seemed odd since I couldn't find any code that would change this. If you take a look at https://github.com/mperham/sidekiq/blob/master/test/test_testing_fake.rb#L289 it seems like it should be working I just couldn't find the implementation that actually changes the symbol to a string. The changes I made does just that but maybe I am overriding or missing something in `SidekiqUniqueJobs`?
",mhenrixon,brandonhilkert
2653,2015-11-11 22:35:30,"@mperham Sorry for the confusion, unicorn being restarted is irrelevant. I tried reliable fetch and the job was still not enqueued. It turns out that since we're using upstart to kill processes, the process group is killed with SIGTERM, which immediately kills the sidekiq job and the process it forked as well. What we are trying to do now to avoid this is essentially wrap the forked process in the bash script that can ignores the first SIGTERM to let the process time out, then it will hopefully get re-enqueued which doesn't work either. I think I'm going to have another look at reliable jobs since the last time I tried, it told me it was initialized then didn't re-enqueue the job after the failure. Any input is appreciated.
",onetwopunch,mperham
2653,2015-11-11 23:31:01,"@mperham Right, but if the SIGTERM makes the job finish, the job does not restart once sidekiq is restarted. Is there extra code I need to add to make this functionality happen?
",onetwopunch,mperham
2653,2015-11-12 00:52:24,"@mperham Thanks so much for the help, I took another look through the code and it turns out there was a case where it would fail without raising an error. Once I surfaced that error, it restarted just fine. Thanks :+1: 
",onetwopunch,mperham
2637,2015-11-02 21:49:40,"Thanks @ryansch! Unfortunately I am not entirely happy with that approach since I am doing all kinds of overrides on the overrides sidekiq::testing does. I want to verify that a certain scenario is always working the real deal so that users of the gem won't have to. I am more than happy to have a single slow test for that purpose. 
",mhenrixon,ryansch
2637,2015-11-07 21:32:51,"@mhenrixon That looks great and this comment makes me happy: https://github.com/mhenrixon/sidekiq-unique-jobs/blob/master/lib/sidekiq/simulator.rb#L41
",mperham,mhenrixon
2634,2015-10-30 06:26:31,"@mperham wierd, we are still getting the error, I think there might a problem in the redis server config, 

what is the command to get the current redis connection setting?

Sidekiq.redis.pool?
",sahin,mperham
2628,2015-11-04 23:07:53,"@jcavalieri `bundle update sidekiq-ent` to get a shorter version string.
",mperham,jcavalieri
2628,2015-11-04 23:21:10,"Oh got it. I had a deployment freeze set with bundler. Thanks @mperham!
",jcavalieri,mperham
2628,2015-11-05 21:52:14,"Hi @mperham, I think this will be more responsive:
https://github.com/mperham/sidekiq/pull/2645
",jcavalieri,mperham
2626,2015-10-27 10:45:20,"@seuros yes. But I want automatic tool for this :smiley:
",davydovanton,seuros
2626,2015-10-28 15:58:47,"@davydovanton I wrote a small gem (https://github.com/zzet/sidekiq-tip) that solves this problem.
",zzet,davydovanton
2625,2015-10-29 01:31:43,"/facepalm

I didn't realize sidekiq would push jobs back to redis on SIGTERM. It was a bug on our side. Signals weren't being forwarded to sidekiq because it was launched from a bash script directly without exec.

Thanks for your help @mperham!
",sanjayprabhu,mperham
2624,2017-02-09 16:28:54,@mperham Is this statement above by you still true today? I recalled there was a line in the Sidekiq code that closes ActiveRecord connections after the worker is done processing.,HenleyChiu,mperham
2623,2015-10-26 22:05:24,"@mperham fair enough. Thanks for the help.
",imackinn,mperham
2618,2015-10-23 14:55:17,"@mperham glad you like the name ;-)

Does the built-in ActionMailer retry automatically on these types of failures? If so, I can just ignore these errors.
",jeremyhaile,mperham
2612,2015-10-21 11:42:22,"@mperham 
just shared my test application on GitHub: https://github.com/iMacTia/sidekiq_retry_test

Having some tests, I noticed that the retry_in option also is somehow inaccurate.
Even if I set it to 5 secs (like you'll find in the project), I see random retries in my log file:



Anything wrong in my test app?
",iMacTia,mperham
2612,2015-10-27 09:31:07,"After deleting all configurations (we also tried to set retry_in from the setting yml file), Sidekiq took the option and is now retrying the number of times we specify.
I would assume it was a configuration conflict.
However I also learned about the `average_scheduled_poll_interval`, so thanks a lot @mperham for your support.

Case closed
",iMacTia,mperham
2600,2015-10-27 13:07:27,"@mperham that's only while upgrading across the version bump to 4.0, right?
",aprescott,mperham
2600,2015-10-27 17:05:51,"@aprescott Reliable fetch in Pro 3.0 continues to use a single thread to fetch, it can't be parallelized like fetch in Sidekiq 4.0.  Nothing will change in Pro 2.x.

Sidekiq 3.x -> Pro 2.x
Sidekiq 4.x -> Pro 3.x
",mperham,aprescott
2593,2015-10-09 17:22:30,"@mperham on JRuby at least, it's backed by a `java.util.concurrent.ThreadPoolExecutor` and should have both lower thread coordination and memory overhead than anything that can be done in pure Ruby
",tarcieri,mperham
2593,2015-10-12 18:31:00,"@mperham very great work here. :dancer: 
",halorgium,mperham
2593,2015-10-14 15:49:15,"@mperham What happens if the status updator/heartbeat thread dies?  Will it have status info about jobs that finished but it never sends that info back to Redis?  It seems like the buffering of stats creates a hole for data to get lost in a crash, resulting in even more double-run or stuck jobs.
",drewblas,mperham
2593,2015-10-14 16:26:10,"@mperham Glad to see that you are dropping Celluloid :) -- good move!
",nviennot,mperham
2593,2015-10-15 11:46:51,"@mperham 

> 8x less garbage generated!

Is it because of removed Celluloid? 
",Magicdream,mperham
2593,2015-10-29 18:35:06,"@mperham Can we start using v4.0 now?

Thank you for all this work!! :+1: 
",esbanarango,mperham
2592,2015-10-08 04:49:27,"@mperham In our cloud formation template to create opsworks environment we pass custom json as



and our sidekiq cookbook


",optimisticanshul,mperham
2592,2015-10-08 05:19:19,"@mperham the reason behind that was cloudformation sends it as a string to opsworks even if it's defined as integer.
",optimisticanshul,mperham
2591,2015-10-06 16:58:58,"@mperham That sounds great, thanks for all your hard work on this.

So am I correct to think that a bandaid would be to lower the timeout to 7, maybe even 6 seconds?
",smidwap,mperham
2591,2015-10-20 17:04:42,"@mperham Is there an issue or PR we can track (perhaps this one) w/r/t

> I'm rewriting the manager right now and making the shutdown timeout more strict

We're going to try setting our `-t` option to 6 or 7 seconds for now, but would like to have something to track to know if/when we can remove that workaround and go back to the defaults.
",stevenharman,mperham
2591,2015-12-23 21:18:36,"@mperham Really sorry, I think I'm still not clear at all. Correct me if I'm wrong, what I understand about sidekiq's behaviour on shutdown is the following : 

1 - On SIGTERM, stop polling for jobs
2 - Wait 'timeout' seconds (8 by default) for every running job to have a chance to finish gracefully.
3 - Send a Sidekiq::Shutdown interrupt to any remaining thread to 'kill' them, then call wait on each thread to ensure they have been terminated. This is the ""hard_shutdown"" of the manager that calls processor.kill for each processor. 
4 - Do the remaining cleanup (close connections & the like).

What I have seen on heroku is that quite often, I get a SIGKILL from heroku during 3), because small lags may appear here and there. So 4) is never executed and things may stay unclean (especially, leaking connections on PostGres side because Sidekiq could not close them). 

I think it's important to have that final cleanup executed in any case, that's why I was suggesting to lower the timeout _just a bit_, to let some time to Sidekiq to execute that cleanup. I did a few tests today and currently have set the timeout to 7 which seems to give better luck. But it's hard to tweak.
",BenTalagan,mperham
2586,2016-01-29 18:48:12,"@zedtux It's been done correctly.  You add the gem to your Gemfile, everything else just works.
",mperham,zedtux
2586,2016-01-29 19:01:23,"@mperham you're right there is a message explaining that the gem is missing and to install it in case he'd like to still use namespaces, but it could also suggest to review the configuration in order to remove the namespace parameter in case he don't care about it.
",zedtux,mperham
2583,2015-10-02 17:51:48,"@mperham All of our high-level abstractions support thread pool configuration via dependency injection. The patter of having one global thread pool for IO-intensive tasks and another for fast, non-blocking tasks is a patter we borrow from Clojure. Nothing more.
",jdantonio,mperham
2583,2015-10-02 17:53:58,"@mperham I'm not going to lie--I've looked at the source of Sidekiq and given _a lot_ of thought to how c-r could be used instead of Celluloid. I'm happy to spike something out for you to look at.
",jdantonio,mperham
2583,2015-10-02 18:00:23,"@jdantonio I see, so I could have a thread pool for one type of Actor so that Actor instances (e.g. Sidekiq::Processor) could perform blocking I/O without worry?  Rad.  Could I size the default thread pool size if I know how many Actors I'll have and that way every thread can do blocking I/O without issue?

Sidekiq has 3-4 singleton Actors (Manager, Fetcher, Scheduler, etc) + a set of Processors.  I prefer to pre-allocate a Thread for each because the system does not dynamically allocate Actors.  If you set Sidekiq concurrency to 20, you'll get about 25 Actor instances in the system.
",mperham,jdantonio
2583,2015-10-02 18:02:42,"@jdantonio Are you going to Rubyconf?  We could pair there one night and spike something if this doesn't happen before.
",mperham,jdantonio
2583,2015-10-02 18:06:04,"@mperham Yes to all the above. Not only can you configure the global thread pools, but we also have `SingleThreadExecutor` for when you want a single thread (another idea borrowed from Java). A STE is basically a pool of 1 with a queue. Internally it monitors the thread so should something happen to it, it will be restarted. So that's a very good option for those singleton instances.

I'm attending RubyConf (and speaking on Mon ""Everything You Know About the GIL is Wrong""). I'd love to pair with you. Another member of the team, @pitr-ch will be attending and speaking as well.
",jdantonio,mperham
2583,2015-10-02 18:10:03,"@jdantonio Sounds good, let's meet up at Rubyconf and see what needs to be done then.
",mperham,jdantonio
2583,2015-10-02 18:50:23,"Regarding making the actors to feel more OOP, see what @inecas did [here](https://github.com/Dynflow/dynflow/blob/95fa3872ddbfecc3e18e492bbc2a7822120ad07b/lib/dynflow/actor.rb#L3-L8). @mperham great news that you are considering c-r :) I would love to join the discussion on RubyConf. Most of the actor implementation is my contribution so I should be able to answer any questions you might have.
",pitr-ch,mperham
2583,2015-10-02 19:56:11,"@mperham the explosion in little gem means that celluloid team saw (finally) that they're providing too many features inside the celluloid ""framework-not-gem"" (what do futures have to do with the actor pattern?). I think that they're separating now and bundling all together for backwards compatibility, in the future you only add what you really need. Which in your case, means the basic celluloid (no extras, no fsm, no pool, no supervision), since sidekiq actors mainly set timer events and call async functions. 

Things you maybe should be using already: supervisor for your processor actors (you must have had your reasons not to though). 

Things you should guard against and (I think) c-r will not help you with: random use of the Timeout module. For that, I'd suggest https://github.com/celluloid/timeout-extensions and overwrite of Timeout::timeout and Kernel.sleep with the proper celluloid implementations. Been using this for over a year with my celluloid-io project without issues. 

Non-blocking IO support is interesting, but not really the main focus of sidekiq, right? Do you want your n workers to perform m tasks, in general? Sounds like unexpected behaviour. In the end, the libraries used in the job will define and will have to opt-in in this behaviour (celluloid-io solves this already. one could provide examples of setting one's non-blocking network fetcher inside a sidekiq worker, though). 

Celluloid has IMO three main drawbacks: method dispatching (awfully slow), time spent in futex syscalls (reason why celluloid-io doesn't match eventmachine in performance, even if the code is more maintainable) and byzantine backtraces. And these haven't changed in 0.17 . I don't know c-r actor implementation that well to know whether these issues are solved there, but the benchmarks do look good.
",HoneyryderChuck,mperham
2583,2015-10-02 20:13:31,"@mperham I agree with @jdantonio. I have switched some simple code away from Celluloid because the gains from the abstractions were outweighed by the hidden complexity. 
Sidekiq is a pretty static system, so having a few thread-pools and queues would be enough to achieve the same behaviour. 
I would love to see an prototype of Sidekiq on c-r. I have a feeling that the heavy weight associated with Celluloid and also the workarounds needed because of some abstraction issues may be eliminated by using lower-level primitives. 
Good luck!
",halorgium,jdantonio
2583,2015-10-02 20:13:31,"@mperham I agree with @jdantonio. I have switched some simple code away from Celluloid because the gains from the abstractions were outweighed by the hidden complexity. 
Sidekiq is a pretty static system, so having a few thread-pools and queues would be enough to achieve the same behaviour. 
I would love to see an prototype of Sidekiq on c-r. I have a feeling that the heavy weight associated with Celluloid and also the workarounds needed because of some abstraction issues may be eliminated by using lower-level primitives. 
Good luck!
",halorgium,mperham
2583,2015-10-02 20:41:44,"@halorgium I think you're right.  Sidekiq _should be_ simple enough to port to a simpler abstraction.  We'll see what if anything comes of it.
",mperham,halorgium
2581,2015-10-29 19:00:46,"Unfortunately I didn't got rid of it. Following @mperham advice I tuned up my settings but my Redis still gets a lot of brpop queries with a response time varying from 64ms to 3s with a cpm of 20.

Is this related to my Redis hosting service or to an improper configuration of Sidekiq, I don't know. I guessing there's something between the concurrency value and the number of queues...
",loto,mperham
2581,2016-03-18 20:59:22,"@L-Oto @randomm I'm having the same worrisome results in my newrelic dashboard: 



@mperham Does sidekiq block on brpop for the duration of the background job?  
",onomated,mperham
2581,2016-03-19 01:28:47,"Thanks for explaining @ryansch 
",onomated,ryansch
2581,2016-06-24 15:40:49,"@ryansch 

> You want that behavior. That's what sidekiq is doing while it's waiting for work. It's a long running blocking operation because redis can then tell sidekiq about work as soon as it arrives. The alternative would be polling which we certainly don't want.
> I see the same thing in my new relic dashboard. No worries.

Does that mean that using the same redis db for caching and sidekiq causes sidekiq to block or otherwise impact caching operations?
",bf4,ryansch
2561,2015-09-19 10:01:06,"@davydovanton Added missing translation.
",elrakita,davydovanton
2560,2015-10-07 22:49:27,"@juanibiapina Have you tried cloning the sidekiq repo, and running [myapp](https://github.com/mperham/sidekiq/tree/master/myapp)? Can you reproduce the `forbidden` response there? 

What kind of auth are you using?  Can you paste your sidekiq config?
",codebender,juanibiapina
2560,2015-10-20 17:29:39,"I'm also behind a haproxy, I guess that should be the problem @juanibiapina
",rikas,juanibiapina
2560,2015-12-03 08:48:58,"@codebender @mguentner @mperham I've [updated the wiki](https://github.com/mperham/sidekiq/wiki/Monitoring#rack-session-and-protection-against-web-attacks) and added a note about Rack::Protection and links to possible solution for `403 Forbidden` error (link to this issue and the article).
",907th,mperham
2555,2015-10-29 09:11:44,"+1 it's very very annoying bug, spent hours tracking it, using sidekiq 3.5.1

solution from @inkstak worked, but also curious about implications
",antulik,inkstak
2555,2016-01-20 01:00:34,"I am also having an issue with Sidekiq::Web's sessions using Sidekiq 3.5.4 and Rails 3.2.22, and I am using the DB session store.  Just upgraded from a pre 3.4.2 version, which did not have this issue.  The @inkstak fix worked for me as well.
",kgx,inkstak
2555,2016-02-17 21:56:19,"I also ran into some troubles related to Sidekiq::Web's sessions and was able to resolve them using...



My app is using sidekiq 4.1.0 on rails 3.2 and mounting `Sidekiq::Web` into the main Rails app in  `config/routes.rb` using:



(the constraint checks for an authenticated admin user)

The main Rails app uses



The problem I was running into was that, after authenticating as an admin user in the main app, when a Sidekiq route such as `/admin/sidekiq/javascripts/application.js` was requested, it loaded fine the first time, but at the conclusion of the request, it reset the session due to this warning:



such that the very next request to any Sidekiq route (such as `/admin/sidekiq/javascripts/application.js`) resulted in a 404 / routing error.

Indeed, the main Rails app's session data exceeds 4K, but since it _should_ be storing that data in an ActiveRecordStore, this _shouldn't_ be a problem.

**Expected behavior**: That it would share the same session as the main Rails app, out of the box.

**Observed behavior**: Sinatra's default `Rack::Session::Cookie` store somehow prevents that from happening.

It may not be worth chasing down this issue since it is with an old Rails, but I thought I'd post in case it helped future Googlers (as @inkstak's post-issue-close comment sure helped me out—thank you!)...
",TylerRick,inkstak
2552,2015-09-16 05:35:49,"@mperham do you recommend creating custom methods in the worker class?
",krzkrzkrz,mperham
2552,2015-09-16 12:33:16,"Workers are normal Ruby objects.  Treat them as such.

On Tue, Sep 15, 2015 at 10:35 PM, Christian Fazzini <
notifications@github.com> wrote:

> @mperham https://github.com/mperham do you recommend creating custom
> methods in the worker class?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/issues/2552#issuecomment-140631068.
",mperham,mperham
2546,2015-09-09 21:18:34,"@mperham you are welcome :)
",davydovanton,mperham
2541,2015-12-05 01:22:10,"@mperham I work with @sax..

One other artifact I am seeing is that when this error occurs the sidekiq_retries_exhausted block was getting called multiple times for the same class/args. We are using uniq extension as well as an fyi. Not sure if this is related but just something observed.



We will update the sidekiq-pro version and monitor it.
",mattcamuto,mperham
2541,2015-12-09 00:35:28,"@jonhyman ahah. Yeah, that might be a better solution for us. This could very well be causing our problem. Is your code in a sharable state? If not, I'll see if I can make something with less monkeying.
",sax,jonhyman
2541,2016-02-08 19:52:30,"@mperham Ok, I may have figured out how to ""reproduce"" this issue. It appears to happen if a batch ""succeeds"" and then has more added to it.

Here's the code that does it:



The ""DummyBatch"" is just a no-op. Essentially, the first job finishes but we still have reference to the batch and we start adding to it again.

This causes the batch to get ""broken"" and results in the batch saying it's from the unix epoch. Let me know if this helps you guys figure it out.
",kbacha,mperham
2541,2016-02-08 21:12:44,"@mperham Yea, I understand that it's expected behavior, I'm backing out the code that was resulting in these races.

I just thought I would point it out since it causes this exact error. Basically, we get the implicit type conversion error, and the batches are older than 46 years, and clicking on the batch results in a 500.

Maybe we should only let you call `batch.jobs` once? And after that the batch is completely immutable?
",kbacha,mperham
2541,2016-02-08 21:21:18,"@mperham I suppose the only thing it needs to do is to throw an exception if you initialize with a bid but that bid doesn't exist. Would that work?
",kbacha,mperham
2540,2015-10-12 03:30:59,"@mperham, I didn't see where the ""accesskey"" attribute was ever used. But, I did use it to define the bindings using unobtrusive javascript. That way, you don't have to maintain what constants get looped over to define bindings. You can just add the ""accesskey"" attribute to any nav link.

https://github.com/natematykiewicz/sidekiq/commit/3d0ff1712bb541b133dd7a1e788200aab93b1154
",natematykiewicz,mperham
2535,2015-09-05 12:03:46,"so, may be you're right. Thanks for catch @seuros 
",davydovanton,seuros
2535,2017-03-12 05:19:21,@davydovanton can we reopen this PR ?,seuros,davydovanton
2533,2015-09-04 20:38:23,"Yeah, I saw that issue and it prompted the investigation into memory. If this happens again I'll update the issue with logs and comments, but I think the main culprit's been identified. Thanks for the happy hour support earlier today, @mperham.
",geoffharcourt,mperham
2523,2015-08-31 19:17:47,"@jcarbo thanks for contribution! :+1: 
~~Your changes looks really cool, @mperham what do you think about this feature?~~ (I'm really slow writing :disappointed:)
",davydovanton,mperham
2523,2015-08-31 19:54:11,"@mperham makes sense - I didn't love this being a javascript-based solution, especially the part where it piggybacks the ajax request, but I wasn't exactly sure the best way to maintain state across polls server-side. FWIW I modeled it off of [this snippet](https://github.com/mperham/sidekiq/blob/master/web/assets/javascripts/dashboard.js#L92-L120) of `dashboard.js` which maintains the state on the client side javascript.
",jcarbo,mperham
2517,2015-08-29 21:36:47,"@seuros that's my understanding too, about `2.2` testing the latest `2.2.x` release.
",aprescott,seuros
2514,2015-09-01 01:50:50,"thanks @davydovanton 
",VoTaiTri,davydovanton
2507,2015-08-27 10:02:59,"@mperham and for others wondering - The issue was in our shards.yml, we did not mention pool size. By default it picks up 5 for shards.

This should even perhaps be considered as a small note in the sidekiq wiki for all postgres users, who are using octopus and sharding.
",pratik60,mperham
2503,2015-08-21 12:30:25,"@seuros yes, of course it will separate plugin for sidekiq like as [sidekiq-statistic](https://github.com/davydovanton/sidekiq-statistic) (or may be it will one part of this plugin).

In this thread I want discuss this feature and how I or we can create this. 
",davydovanton,seuros
2498,2015-08-18 01:02:16,"@mperham thanks :+1: 
",TangMonk,mperham
2487,2016-02-04 06:21:31,"I just wanted to add that we ran into the same issue. Key components:

`rails 4.2.5`
`sidekiq 4.0.1`
`sidekiq-pro 3.0.0`
`devise 3.5.2`

Sidekiq was mounted via `mount Sidekiq::Web => 'sidekiq'` in our Rails application. Submitting forms in the Sidekiq UI failed with the ""Forbidden"" message and no backtrace.

And the solution by @dalibor fixed it. We were on `rack-protection 1.5.0` and updating to `rack-protection 1.5.3` solved the issue for us.

Should I add this to the relevant wiki entry, @mperham?
",mrnugget,mperham
2487,2016-03-15 19:08:07,"@mrnugget where do I set 


",syedhassan,mrnugget
2487,2016-11-01 19:55:46,"Note that in Rails 4.2+ the token has changed to `secret_key_base` and can be accessed by `Rails.application.secrets.secret_key_base`.

That being said, @mrnugget's solution doesn't seem to be working for me.
",gabeodess,mrnugget
2483,2015-08-15 14:35:40,"@ryansch we are trying to avoid adding it to the `Dockerfile` because we use the same one to create two images that differ by the command you pass into it. And, both images do not require `tmp/pids/sidekiq.pid`. 
However, I think this is a problem that can be solved using [ansible files](http://docs.ansible.com/ansible/file_module.html) so I'm going to explore that now.
",soapy1,ryansch
2482,2015-12-17 17:51:41,"This issue still persists for me. @mperham any ideas what could be causing this?
",panmari,mperham
2475,2015-08-05 16:26:05,"@elia if you send PR, please fix `kill` in [this method](https://github.com/mperham/sidekiq/blob/5ffac099418d833934768d08c11d4ed436791323/bin/sidekiqctl#L66-L80) too :blush: 
",davydovanton,elia
2471,2015-07-31 21:30:35,"@mperham Is there any way for me to grab the jids in the success callback as well? I saw this issue https://github.com/mperham/sidekiq/issues/2458 and it seems like their problem was my solution.  Can I still grab all the JIDs in redis somewhere?
",scottchiang,mperham
2471,2015-08-03 16:47:33,"@jonhyman I actually use batches for a single job.  I'm using batches just for the callback functionality.  I have an table in my database that has `jid` as one of its columns.  Inside the callback, I need to query for that object using `jid`.  
",scottchiang,jonhyman
2462,2015-07-28 22:09:36,"http://www.sinatrarb.com/configuration.html

> :sessions - enable/disable cookie based sessions
> Support for encrypted, cookie-based sessions are included with Sinatra but are disabled by default. Enable them with:
> 
> set :sessions, true
> Sessions are implemented by inserting the Rack::Session::Cookie component into the application’s middleware pipeline.

@jc00ke, perhaps you want to re-open `Sidekiq::Web` if you're using the cookie store, and not do this in the base?
",jonhyman,jc00ke
2462,2015-07-28 22:39:42,"I can confirm that using the `enable-sessions-in-web-ui` branch does fix the problem @mperham 
",hbrysiewicz,mperham
2461,2015-07-28 21:30:29,"Hi @mperham I actually did consult the Padrino team before bringing this back to the Sidekiq team. https://github.com/padrino/padrino-framework/issues/1944 who seem to think it is a Sidekiq issue. The standalone doc you have referenced does not actually fix the issue. I realize both teams want to blame the other but would you mind just looking at the example repo or maybe talking to the Padrino team about where the issue lies?
",hbrysiewicz,mperham
2460,2015-07-28 18:13:53,"Looks like @jonhyman is shooting for vice president in my administration.
",mperham,jonhyman
2460,2015-07-28 19:39:10,"@jonhyman Thanks for the suggestion! I know basic auth is simple, but for many users of sidekiq I imagine that is good enough.

I have always used Sidekiq Web along side a rails app, but it seems with this latest change it must run in its own process because of the rails bug I mentioned above. It would be great for us to have an out of the box solution to this. 

So here is my question: Is it possible to hook Sidekiq Web onto an existing rails app using solely the sidekiq gem and basic auth?
",codebender,jonhyman
2460,2015-07-29 16:44:42,"@mperham I can confirm that with your monkey patch https://github.com/rails/rails/issues/15843#issuecomment-125784043 sidekiq web is working in my rails app...:see_no_evil:...:crying_cat_face:
",codebender,mperham
2459,2015-07-25 03:26:26,"@mperham Yes I've searched the issues.  You locked the other issue that I commented on immediately after I commented.

@jonhyman Yes, I have a session store.  Per my `session_store.rb` initializer:


",mhuggins,mperham
2459,2015-07-25 03:26:26,"@mperham Yes I've searched the issues.  You locked the other issue that I commented on immediately after I commented.

@jonhyman Yes, I have a session store.  Per my `session_store.rb` initializer:


",mhuggins,jonhyman
2459,2015-07-27 13:49:16,"@jasonneylon @jonhyman  There is a workaround to getting this to work in padrino posted by @ujifgc - https://github.com/padrino/padrino-framework/issues/1944
",pchaganti,jonhyman
2457,2016-07-05 15:37:32,"And we will be happy when the feature is merged, whenever that may be @mperham. Thanks for all your hard work!
",fusion2004,mperham
2449,2015-07-22 14:25:11,"@mperham  it made me confused  because it worked with previous versions. 
BTW, thanks for your quick response +1 +1 +1 +1 
",thomastran,mperham
2449,2015-08-10 20:37:59,"@mperham Hi, I am using ActiveJob with Sidekiq and I want to add some Sidekiq specific configuration (retries related).  In view that I can not include Sidekiq::Worker in an ActiveJob subclass. What would you recommend me to do?
",edipox,mperham
2438,2015-07-29 14:19:52,"@digitalextremist byebug don't work with these engines. Maybe you can use their respective debuggers.
",seuros,digitalextremist
2438,2015-07-30 00:37:43,"@seuros ah, well I will add `Gemfile` and `gemspec` conditions where appropriate then, because the gem is a dependency by default, regardless of which engine is in use.
",digitalextremist,seuros
2438,2015-08-13 18:34:08,"@mperham have you done any additional testing with 0.17.0? There are some memory leak fixes in there that we're interested in, so am keen on trying out 0.17.0 in the coming weeks.
",jonhyman,mperham
2438,2015-08-13 18:38:34,"I haven't done any testing; I was waiting for sign off before trying it out.  @digitalextremist You ok with this now?
",mperham,digitalextremist
2438,2015-08-13 19:03:51,"I'll retry removing `byebug` to be able to test `jruby` and `rbx` today .. otherwise I did `50,000` jobs with `mri-2.2.2` no problem @mperham.
",digitalextremist,mperham
2438,2015-08-13 19:52:36,"@mperham results:

`jruby-1.7.20` passed without event, like `mri-2.2.2`

`rbx-2.5.8` segfaulted, but when retested with a partial job queue it passed.
Refilled job queue and reran and reproduced segmentation fault.
Reran with partial job queue: segmentation fault.
Reran with even smaller job queue: segmentation fault.
Reran with even smaller even smaller job queue: segmentation fault.
Reran with even smaller even smaller even smaller job queue: finished.

This does not seem related to `Celluloid` at first glance. Will research and post accordingly.
",digitalextremist,mperham
2438,2015-08-14 02:15:22,"@mperham has anyone reported segfaults with `rbx`? That's the last thing I'm troubleshooting but I suspect it's not `Celluloid` doing that.
",digitalextremist,mperham
2438,2015-08-14 02:34:35,"I have customers that use MRI and JRuby, but I don't know of anyone using rubinius so I'm OK with the current state. 

> On Aug 13, 2015, at 19:15, Donovan Keme notifications@github.com wrote:
> 
> @mperham has anyone reported segfaults with rbx? That's the last thing I'm troubleshooting but I suspect it's not Celluloid doing that.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2438,2015-08-14 03:12:52,"@mperham isolated this to a thread issue in `Rubinius`, in associated ticket ( #2489 )

@brixen & team will need to diagnose and patch for complete `Rubinius` compatibility.

Moving to `rbx-2.5.2` introduces non-`segfault` error and process becomes a zombie.

Until I am shown otherwise, I believe this is not `Celluloid` related.

So... you are clear to ship it //
",digitalextremist,mperham
2438,2015-08-15 05:46:25,"@mperham that should be totally fine, too.
",digitalextremist,mperham
2435,2015-07-14 10:31:44,"Interesting. Thanks @seuros!
",davydovanton,seuros
2431,2015-07-15 15:58:22,"I'm curious if we should expose the ability to not use `brpoplpush` but rather an `rpoplpush` followed by a short `sleep` as @cainlevy suggested. Sidekiq-Pro could either detect this itself using `info` or have a config option.

We have a lot of connected clients as well. Taking a look at our `brpoplpush` in New Relic right now, that the standard deviation is more than 1 second (and the max is 5 seconds) indicates to me that we may be get better performance doing this. We use a custom Fetcher that subclasses `ReliableFetch` and we already make minimal use of `brpoplpush` in our Fetcher, but I'm thinking of changing it.

![image](https://cloud.githubusercontent.com/assets/832655/8702889/5c76fd94-2ae8-11e5-9c7b-7e007c370fd5.png)
",jonhyman,cainlevy
2431,2015-07-16 08:29:16,"First feedbacks:
1. Yes the timeout changes a lot depending on the number of clients. Tuning `hz` is useful since for each call the function will try to process at least 50 clients, so with HZ=100 it processes 50*100 clients each second. With 5000 clients the average delay in returning is 0.5 seconds. However this is not good, we need something more deterministic and I'm fixing it.
2. I don't understand this part of @cainlevy report:

> When ReliableFetch idles with a blocking operation, jobs may be pushed into the queue after the client has timed out but before the server has checked the connection. The blocking operation succeeds, but no one is listening

Even if the timeout can get longer, if the client is blocked and a message arrives into a list, the client is correctly unblocked and the message sent to the client. If you are seeing something different, maybe it's up to the library client implementation that when detecting the connection is broken does not care to deliver the last (received) reply to the caller? Otherwise if I'm wrong, please could you send me more details?

For now I'm fixing the non deterministic timeout behavior, that should not depend on HZ so much: it may make a small rounding error difference, but the return time should be the same, and HZ should only tune **how much work** it does per iteration, so that if you use an higher HZ, you get the same work per second, but more evenly distributed across the second. As it is today it dramatically changes the total work it does, which is bad.

News ASAP. Thanks.
",antirez,cainlevy
2431,2015-07-16 16:12:51,"Thanks @cainlevy, so it's the Ruby side that disconnects the client actively for client-side timeout. Now I understand. Probably (but it's just a far shot) what happens is that the socket waits for the Ruby garbage collector in order to be reclaimed (and actually closed)? If possible the Ruby client, on timeout, should call the appropriate method in order to close the underlying TCP socket ASAP, so that the connection closed if sensed by Redis (that does not need to check the client: an event will be raised in the event loop immediately). Messages can be still lost of course, there is no way to guarantee with TCP a reliable channel when disconnections happen (if not with resending & acknowledgement) but the window is greatly diminished.

Thanks for checking the commit, should go live tomorrow. Unfortunately I'm not fixing 2.8 as well since I can't just cherry pick and the details are different. Given that we started the process of abandoning the 2.8 release if not for critical issues, I'm not going to change it.

EDIT: to be clear, if Ruby closes the connection ASAP this is what _should_ happen:
- 0 seconds - client sends BRPOPLPUSH with 1-second timeout
- 1 sec - waiting
- 2 sec - waiting
- 3 sec - waiting
- 4 sec - waiting
- 5 sec - client raises timeout error **and closes the socket**
- 5.01 sec - Redis traps the socket error and disconnects the client, unregistering it from the clients waiting for list operations.
- 6 sec - message arrives on list, and gets accumulated for the next client.

As you can see there is still a window for race conditions but much shorter.
",antirez,cainlevy
2431,2015-07-16 16:53:46,"You are welcome @mperham. There is no problem of computational intensive task that adds latency, checking even 10k clients per second does not introduce any latency, even so if evenly computed in HZ different function calls in an incremental way. The problem is that currently we are _brute forcing_ the problem by rotating the list of clients searching for timed out ones. This is technically dumb, so I approached the problem when I tried to fix this issue thinking about ordering clients for timeout in a skiplist (or any other O(logN)-insert, O(1) query for MIN/MAX data structure). This way you just process clients that are _actually_ in timeout, and unblock/release them.

However for the rule ""try the simplest thing that works"" I tried if I could measure processing 300/400 clients per iteration (in the case of 3000/4000 clients connected) and was not able to measure any difference. So I went, at least for now, for the simplest solution not involving any skiplist.

It helps that it's just a matter of raising HZ in order to have just 300/400 clients processed per function call if there are much more clients, like 40k connected at the same time.

If I'll go for the skiplist, I'll also tune the event loop in order to exit at the right time when the next client is going to expire, to get a 10ms granularity on expires. Doing it with the current internals would make the code just more complex with just some noticeable gain in precision but not to the extend I would love to see.
",antirez,mperham
2431,2015-07-16 17:29:03,"@antirez I found a moment to try https://github.com/antirez/redis/commit/25e1cb3f040262deb13c9be6a07e19b6cac485f0, and it works beautifully. With 2040 connected clients, `time redis-cli blpop test 1` takes ~1.1s on Redis 3.1.999, compared to ~7s on Redis 3.0.2.

> Unfortunately I'm not fixing 2.8 as well since I can't just cherry pick and the details are different.

Works for me. We'll tune `hz` until we can upgrade.

@mperham Your call on when to close this issue. I'm happy!
",cainlevy,mperham
2428,2015-07-10 17:08:32,"@mperham I'd be curious to **learn** a little bit more about the reasoning behind this.

Is there anything in `Sidekiq::ScheduledSet` implementation or the Redis behaviour that can't easily be replicated in Sidekiq::Testing?
",vroy,mperham
2423,2015-07-07 14:31:03,"I did, found out I made a very rookie mistake. D:



Should have been 



Derp. Sorry @mperham !

Thank you for taking the time to reply, cheers!
",PDaily,mperham
2412,2015-06-29 14:36:26,"@mperham if you want use pure css I can add `overflow` for redis url. But this include some problems. For example you can check this PR #2393 where you can see what will happen for window users.
But anyway I think that long redis url it's big problem for web UI.
",davydovanton,mperham
2412,2015-06-29 19:34:49,"@mperham okay, I close it
",davydovanton,mperham
2411,2015-06-29 09:00:10,"@davydovanton 70 characters long. We use an Amazon AWS internal hostname to connect to Redis.

Addition: I can confirm that the issue is fixed when the host is shorter!
",edwinv,davydovanton
2400,2015-09-24 18:17:01,"@davydovanton  Thanks for the explanation. :)
",rshiva,davydovanton
2400,2015-10-09 17:02:04,"@davydovanton didn't want to open a new issue for this but was wondering the same as @inspire22, if I just include hiredis in my Gemfile, does sidekiq-pro switch to using that or do I need to specify a config option? Had trouble finding an answer to that.
",javierjulio,davydovanton
2400,2015-10-09 17:10:55,"@mperham thank you!
",javierjulio,mperham
2397,2015-06-19 16:50:57,"@mperham can you try installing `celluloid-essentials` first? It's currently at `0.20.0.pre17` ... but it'd be easier to just pin versions in your gemspec/Gemfile and `bundle update`
",digitalextremist,mperham
2397,2015-08-20 17:03:22,"@mperham Will you be releasing to RubyGems or bumping the version on this? I got stuck in limbo locked to Celluloid 0.16.1 (which is no longer on RubyGems?).
",dja,mperham
2397,2015-08-20 17:22:37,"Not for this. Bundle update sidekiq should update the gems. 

> On Aug 20, 2015, at 10:03, Daniel Jacob Archer notifications@github.com wrote:
> 
> @mperham Will you be releasing to RubyGems or bumping the version on this? I got stuck in limbo locked to Celluloid 0.16.1 (which is no longer on RubyGems?).
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2397,2015-08-20 20:00:39,"@mperham Will `bundle update sidekiq` update Sidekiq's dependencies? I'm in the same boat as @danieljacobarcher , have celluloid locked to Celluloid 0.16.1, and `bundle update sidekiq` is updating Sidekiq to the latest, but it's not touching Celluloid.
",dubilla,mperham
2397,2015-08-20 22:02:45,"@mperham Yeah, it didn't handle the yank gracefully, unfortunately.

Anyway, updating our Gemfile with your suggestion worked! Thanks a ton for the assistance.
",dubilla,mperham
2395,2015-06-18 23:09:27,"Rails.cache.write(""results:rates:#{job_id}"", rates)
But I just noticed that it's most likely another issue.
rates consists of
rates << Rate.new(
              :supplier_id  => candidate.supplier_id,
              :candidate_id => candidate.id,
              :total        => result.total,
              :catering     => result.catering,
              :arrival      => options['arrival'],
              :departure    => options['departure'],
              :nightly_rate => result.per_night,
              :breakfast    => result.breakfast_price
          )
but they don't get save to the db. So I assume that the Rate which got created and pushed to the array is having the Proc inside just because it has not been save yet?!

So it's not related to sidekiq, sorry for the inconveniences I am causing
@ismaelga anyhow, if you got a clue, help is appreciated :)
",dcdieci,ismaelga
2394,2015-06-18 19:28:36,"@aprescott, I'm going to take a look at this. Thank you very much for showing your code!
",geoffharcourt,aprescott
2387,2015-06-16 20:15:01,"@mperham, this happens a lot, CinemaWorker is in the workers folder actually. I have feeling it is a memory issue. Can it be?

For autoloading or require, do u have any suggestion to read. I can also add smth in sidekiq wiki for autoloading.  
",sahin,mperham
2383,2015-10-08 13:44:35,"@ryansch - What kind of service do you use for alerting? Can you I know some other options?
",VishalRam,ryansch
2375,2015-06-03 11:11:11,"@mrsimo please squash your commits :blush: 
",davydovanton,mrsimo
2375,2015-06-03 11:15:12,"@mrsimo thank you for contributing :tada:
",davydovanton,mrsimo
2356,2015-05-17 04:28:50,"@newdark if you turn on polling, the footer will update every two seconds.  The time is meant to represent when the page was rendered so you know how old the data is.

Sidekiq uses UTC everywhere (e.g. log output).  I don't want to show timezone-specific times in one place but not others.
",mperham,newdark
2348,2015-05-13 22:39:53,"Yes, that would be great @jonhyman.
",johnathanludwig,jonhyman
2344,2015-05-12 22:27:17,"Got to the bottom of this, but not sure how we'd prefer to get it fixed.

The issue isn't actually the middleware tracing itself, but the fact that we default to using New Relic's middleware from Sinatra. The code in question that injects the middlewares during building the app is at https://github.com/newrelic/rpm/blob/6b310a9428618d4b611806c83014cb6e5365adc2/lib/new_relic/agent/instrumentation/sinatra.rb#L95-L102.

The `Sharding` middleware in Sidekiq Pro assumes that it's `@app` will be `Sidekiq::Web`, but it gets our middlewares instead.

I see a couple ways around this:
- `Sharding` could call `Sidekiq::Web.settings` instead of `@app.settings`. Because of how Sinatra does things, those are equivalent, and then `Sharding` avoids ordering assumptions.
- New Relic's Sinatra instrumentation could check for a method on the app during `build_with_newrelic` to ask whether to add middlewares. `Sidekiq::Web` could define that method and opt out.
- Although I'm leery of it, New Relic's agent middlewares could add `method_missing`, under the assumption that any call we don't recognize was meant for some other middleware/app we've been unknowingly inserted around. :see_no_evil: 

Thoughts on those options @mperham?
",jasonrclark,mperham
2344,2015-05-12 22:35:18,"I'm not @mperham but calling `Sidekiq::Web.settings` seems far cleaner.
",aprescott,mperham
2344,2015-05-12 22:41:12,"@aprescott That wouldn't work because the app needs to have instance-specific data: the redis pool to use.  In effect I create ""instances"" by creating custom subclasses for each sharded instance of `Sidekiq::Pro::Web`.  Sinatra allows this because `settings` is per-class.
",mperham,aprescott
2344,2015-05-12 22:53:36,"All the agent's does here is add middlewares to Sinatra's list for startup. So `app` passed to `Sharding#initialize` is just the next callable thing in the middleware chain. Without the agent it's the Sinatra app, with the agent it happens to be one of our middlewares instead.

I see why the custom subclasses messes with accessing settings. Didn't have sharding configured on the test app, so I missed that.

Because we're just a standard middleware, though, `method_missing` doesn't seem right. I mean, you don't expect all middlewares to forward arbitrary method calls they receive, right? That's all that's happening here--the agent's put middlewares in that `Sharding` wasn't expecting.

Option 2 seems best to me--we provide an opt-out that `Sidekiq::Web` could tap into. I can get that in the next agent release if you're game @mperham.
",jasonrclark,mperham
2344,2015-05-12 23:07:38,"@mperham if you switch the `app.use` lines, does it still work?

With `Rack::Logger` followed by `Sharding`, `Rack::Logger` is called first, which asks `Sharding` for a response, which then goes to the app. So it's working because `Sharding`'s `@app` is the application itself.

If you flip the two, do you get the `NoMethodError` from `@app.settings`? My guess is yes, because `Sharding` is calling out to `Rack::Logger`, and asking it to set `@app.settings`, which `Rack::Logger` won't have.

> I mean, you don't expect all middlewares to forward arbitrary method calls they receive, right? That's all that's happening here--the agent's put middlewares in that `Sharding` wasn't expecting.

+1 to this.
",aprescott,mperham
2341,2015-05-10 12:25:13,"@mperham AR pool size is 60 and the Sidekiq concurrency is 2
",penso,mperham
2336,2015-05-07 15:58:46,"@mperham ok! Will do.
",mikz,mperham
2329,2015-04-28 23:23:52,"thanks @mperham 
",carlosbrb,mperham
2328,2015-04-28 18:39:56,"@newdark thanks! But could you display some screenshots with bug and your solution?
",davydovanton,newdark
2328,2015-04-28 18:43:08,"Sure @davydovanton, here is what I am seeing. I should of looked closer at this with the issue #2205  however I missed this when I tested out the changes.

![screen shot 2015-04-28 at 1 41 39 pm](https://cloud.githubusercontent.com/assets/13140/7377496/58b7eb7e-edac-11e4-8931-05bcc30af60d.png)
",newdark,davydovanton
2326,2015-10-28 09:32:16,"hi @davydovanton ! I have quite the same error but I don't have a `maxmemory`



[gist](https://gist.github.com/guinslym/ab877162f389660acceb)

my error (sidekiq.log; wich is now 1GB of logs)


",guinslym,davydovanton
2326,2015-10-28 15:52:20,"Ok thanks @mperham :+1: 
I followed the answer of this post
[stackoverflow](https://stackoverflow.com/questions/19581059/misconf-redis-is-configured-to-save-rdb-snapshots)
",guinslym,mperham
2325,2015-04-25 13:36:31,"@aprescott oh... you're damn right! I can just check if the worker need to skip itself at the very beginning!
Thanks a lot!
",lazywei,aprescott
2325,2015-04-25 13:38:35,"@mperham do you think it is okay if I follow @aprescott 's suggestion -- instead of remove from queue, we just check if the worker need to skip or not?
",lazywei,aprescott
2325,2015-04-25 13:38:35,"@mperham do you think it is okay if I follow @aprescott 's suggestion -- instead of remove from queue, we just check if the worker need to skip or not?
",lazywei,mperham
2325,2015-04-25 13:45:10,"Absolutely that's the best course of action. 

> On Apr 25, 2015, at 06:38, Chih-Wei (Bert) Chang notifications@github.com wrote:
> 
> @mperham do you think it is okay if I follow @aprescott 's suggestion -- instead of remove from queue, we just check if the worker need to skip or not?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,aprescott
2325,2015-04-25 13:45:10,"Absolutely that's the best course of action. 

> On Apr 25, 2015, at 06:38, Chih-Wei (Bert) Chang notifications@github.com wrote:
> 
> @mperham do you think it is okay if I follow @aprescott 's suggestion -- instead of remove from queue, we just check if the worker need to skip or not?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2317,2015-04-23 18:02:59,"@jonhyman Nice. Can you share what interval and number of pollers you're currently running?
",cainlevy,jonhyman
2317,2015-04-23 18:16:06,"@mperham Agreed that electing a single Poller is a lot of complexity for the problem. It sounds cool, but not pragmatic. That's why I'd be happy to elect one myself via an option to disable that actor on all but one or two processes.

We haven't rolled Sidekiq out to anything in production yet, so this is definitely theoretical. But unless we can use a static polling interval and trust Redis to handle it (something the library discourages but @jonhyman appears to have success with), the random delay jitter does sound less than ideal. Some of our scheduled jobs expect to run within seconds of the scheduled time, e.g. to match up with a public countdown on www.kickstarter.com. I know there will always be moments where that doesn't happen, but they're a nice thing to minimize.
",cainlevy,mperham
2317,2015-04-23 18:16:06,"@mperham Agreed that electing a single Poller is a lot of complexity for the problem. It sounds cool, but not pragmatic. That's why I'd be happy to elect one myself via an option to disable that actor on all but one or two processes.

We haven't rolled Sidekiq out to anything in production yet, so this is definitely theoretical. But unless we can use a static polling interval and trust Redis to handle it (something the library discourages but @jonhyman appears to have success with), the random delay jitter does sound less than ideal. Some of our scheduled jobs expect to run within seconds of the scheduled time, e.g. to match up with a public countdown on www.kickstarter.com. I know there will always be moments where that doesn't happen, but they're a nice thing to minimize.
",cainlevy,jonhyman
2309,2015-04-21 21:39:04,"@nolman thank you for contribution :thumbsup:
",davydovanton,nolman
2300,2015-04-16 14:49:09,"@davydovanton just checked -- and both contexts are 'development'
",avifoxi,davydovanton
2297,2015-04-20 19:01:50,"@substars what kind of affects do you mean? all travis jruby tests has passed :grimacing:
",davydovanton,substars
2297,2015-04-20 20:46:55,"@substars sorry, I found lost comment in my mail client :confused: 
",davydovanton,substars
2296,2015-04-09 22:31:46,"@mperham I fixed cache for `strings` method and add test case where I send three request with different locales
",davydovanton,mperham
2293,2015-04-14 21:10:06,"@mperham what do you think about @dmitry idea?
",davydovanton,mperham
2291,2015-04-07 19:09:21,"okay :)
_P.S.: @adisos please, in future, add `[skip ci]` text to commit message for doc and locale changes_
",davydovanton,adisos
2291,2015-04-07 19:10:16,"@adisos thanks :+1: 
",davydovanton,adisos
2290,2015-04-07 18:56:32,"So, I create simple prototype for scheduled page:
![download](https://cloud.githubusercontent.com/assets/1147484/7030924/cd61950c-dd70-11e4-93a3-490a3c17486b.png)

@seuros and @mperham what do you think? 
",davydovanton,seuros
2290,2015-04-07 18:56:32,"So, I create simple prototype for scheduled page:
![download](https://cloud.githubusercontent.com/assets/1147484/7030924/cd61950c-dd70-11e4-93a3-490a3c17486b.png)

@seuros and @mperham what do you think? 
",davydovanton,mperham
2290,2015-04-07 20:32:07,"yes, @mperham I agree with you - `750px`\+ isn't correct value.  But I have checked screen width for iphone 6+ in chrome mobile mode and this equal `414px`.
Also I think that center is great place for checkbox, @seuros what do you think?
",davydovanton,seuros
2290,2015-04-07 20:32:07,"yes, @mperham I agree with you - `750px`\+ isn't correct value.  But I have checked screen width for iphone 6+ in chrome mobile mode and this equal `414px`.
Also I think that center is great place for checkbox, @seuros what do you think?
",davydovanton,mperham
2290,2015-04-07 23:00:31,"@davydovanton center is fine too.
",seuros,davydovanton
2288,2015-04-06 20:57:19,"@mperham sorry, but I forgot to add this changes to `CHANGELOG` :sweat: 
May be I need update this?
",davydovanton,mperham
2283,2015-05-29 20:54:33,"@mperham No, that should not be the case. In my case, Sidekiq runs on a single Heroku Dyno that has been restarted after I flushed the Redis database.
",pixelate,mperham
2279,2015-04-01 14:15:25,"@mperham Thanks for merging :+1: 
",ferdinandrosario,mperham
2277,2015-03-31 22:17:25,"@mperham could you explain why do it [check](https://github.com/mperham/sidekiq/pull/2277/files#diff-7123f67bfb91cbf5f0f0b409724a8152L24) if `url == ''` ? It seems to me it's excess condition.

Also I changed navbar behaviour. Now if you have 2+ plugins you will see dropdown button, else you will see link to plugin page.
",davydovanton,mperham
2277,2015-03-31 22:22:00,"@davydovanton Which line of code?  Where?
",mperham,davydovanton
2277,2015-04-01 21:41:49,"@mperham good idea!
But I want to try write js code which will replace navbar links on dropdown button if screen width less than navbar `<ul>` block. That is why I changed PR status on **wip** :smiley: 
",davydovanton,mperham
2277,2015-04-02 22:13:01,"@mperham I completed this PR :tada: Also I updated PR description.
Please check this :grimacing:
",davydovanton,mperham
2276,2015-04-08 20:58:40,"@seuros if you do not mind, I can do it today :smiley_cat: 
",davydovanton,seuros
2272,2015-03-30 11:35:01,"Thanks @davydovanton !
",karlingen,davydovanton
2270,2015-03-27 23:42:32,"@mperham I changed helper. But rubinius test is failed in [this](https://github.com/mperham/sidekiq/blob/master/test/test_retry.rb#L165) and [this](https://github.com/mperham/sidekiq/blob/master/test/test_retry.rb#L186) tests. It's normal? %)
",davydovanton,mperham
2270,2015-03-28 00:06:19,"@mperham I'm sorry, but i don't understand you correctly :sweat:
What do you mean by multiple blocks? Something like this: 



?
",davydovanton,mperham
2270,2015-03-28 00:16:29,"Exactly. 

> On Mar 27, 2015, at 17:06, Anton Davydov notifications@github.com wrote:
> 
> @mperham I'm sorry, but i don't understand you correctly 
> What do you mean by multiple blocks? Something like this:
> 
> # in partial #1
> 
> <% add_to_head do %>
>   <link rel=""stylesheet"" href=""css1.css""/>
> <% end %>
> 
> # in partial #2
> 
> <% add_to_head do %>
>   <link rel=""stylesheet"" href=""css2.css""/>
> <% end %>
> 
> # in partial #3
> 
> <% add_to_head do %>
>   <link rel=""stylesheet"" href=""css3.css""/>
> <% end %>
> 
> # in layout partial
> 
> <%= display_custom_head %>
> 
> # => <link rel=""stylesheet"" href=""css1.css""/>
> 
> 
> 
> ?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2270,2015-03-28 12:59:07,"@mperham I have a little problem with procs in erb, that why I'll hold PR a little :worried: 
",davydovanton,mperham
2270,2015-03-30 00:42:35,"@mperham I solved my problem with erb :tada: and also I wrote a [post](https://medium.com/@anton_davydov/rendering-block-content-from-erb-619d761ed889) about solving this problem :smile: 
",davydovanton,mperham
2264,2015-03-29 06:04:33,"@mperham let me know if there's anything I can do to make this happen. I'd love to contribute.
",samuelreh,mperham
2258,2015-03-24 22:00:20,"@mperham okay, i will fix it :ok_hand:
",davydovanton,mperham
2256,2015-03-24 19:55:34,"@mperham that's clean enough for me :-)

But I forgot to mention that my use case (indeed very specific) implies not knowing a priori the available (as in _already downloaded_) files.

This is because I download them asynchronously but also notify their availability in sequential ordering.
So, for example, if I download log_a2.csv before log_a1.csv, I can't process it until I've finished downloading and processing log_a1.csv first.
",olistik,mperham
2256,2015-03-25 08:07:50,"@mperham yes, I could use a solution like this, but isn't the purpose of abstractions to keep away the lower details allowing the user to focus as much as possible on the highest details?
Don't you think that a DSL that wraps the execution of several jobs into a batch, customizable by concurrency level and execution ordering would allow a simpler user level code? :-)
",olistik,mperham
2256,2015-03-25 18:37:23,"@mperham fair enough :-)
That generic feature, if feasible, would probably deserve a bigger wrapper around Sidekiq instead of being embedded into it.
",olistik,mperham
2254,2015-03-24 17:20:42,"@seuros Let's not be rude please.  Issues can be frustrating for all involved.  He is using Sidekiq Pro so he is entitled to some amount of support, I just can't afford to chase after every reported memory leak.
",mperham,seuros
2254,2015-03-24 17:22:07,"@sdeframond @mperham Sorry.
",seuros,mperham
2254,2015-03-24 17:36:02,"@seuros oh, good to know. We are using ruby 2.2.0.

This is not really critical for us right now. Just something to keep watching. I definitely understand that chasing every single dependency's memory leak is close to impossible.

It is good to know that ruby itself may be the source of the issue though :smile: 

Still, this is an issue, for both you and me ;)
",sdeframond,seuros
2251,2016-02-15 16:52:14,"@mperham Processing queue in random order has practical use case:
I have got a queue of pages (URLs) to download. These URL points to several servers. Jobs for each of servers are enqueued almost consecutive to the queue.
That means:
- I may case load issues on the server (when several workers work in concurrent).
- If one of the server time-outs then whole queue is locked (even if I have several workers).

What is the right solution with Sidekiq? I hope that Sidekiq is the right choice and there exists some solution.
",lksv,mperham
2251,2016-02-16 07:20:40,"thanks @jonhyman , I though this way too:
- enqueue to more queues (lets say 10 for my case) which will be processed with the same sidekiq process.
- within the worker randomly re-enqueue some jobs to later instead of processing them (could be even used with perform_in with random time).

...but the easiest solution is yours (enqueue jobs directly at random time in the future). Thanks.
",lksv,jonhyman
2249,2015-03-24 16:04:33,"@mperham so made those adjustments to our deps yesterday and everything is locked up again this morning. :-(

Our worker dynos and AWS system are all still running and haven't restarted the process that I can tell. The sidekiq admin dashboard shows 12k jobs enqueued, 0 busy workers, and the Busy tab shows no processes or jobs executing. I'm going to tune the concurrency on the heroku dynos back down to 1 so things will hopefully run again but I'll leave the AWS system that you can SSH into stuck.
",bdmac,mperham
2244,2015-03-19 15:58:37,"@ncri, you could use globalid gem. But as @mperham said it better to have full control.
",seuros,mperham
2244,2015-03-19 17:59:07,"@seuros globalid looks useful, yes
",ncri,seuros
2237,2015-03-16 12:15:47,"Thanks @mperham!
",veverkap,mperham
2232,2015-04-11 17:47:16,"@seuros That looks to be a good solution too.
",ismaelga,seuros
2232,2015-04-11 21:40:45,"@ismaelga We've had this discussion before.  The UI is optional and Rubygems does not support optional dependencies so we're stuck with this behavior unless we add some sort of Sinatra version check.  I'd be ok with that.  We're not going to split it into a separate gem.
",mperham,ismaelga
2222,2015-03-12 10:02:03,"Hi @mperham 

I'm trying to get it working with upstart. I'm using Vagrant locally as my dev environment, and tried putting this into `/etc/init/sidekiq.conf`



I use this command and get this feedback:



That works, but...

When I try to run it as a service, I get this:



I get the same message when I do:



Is there something wrong with my config?
",npearson72,mperham
2209,2015-03-01 18:31:10,"@seuros jruby-19 refers to the current jruby used in 1.9 mode. 1.9 is the default since jruby 1.7. Both jruby and jruby-19mode refer to jruby 1.7.19 so I don't think it's necessary.
",PragTob,seuros
2207,2015-03-01 15:20:40,"@seuros, Thanks. It's works. Every change in my job file I need restart sidekiq :/ So boring. I'll close the issue.  
",marciovicente,seuros
2206,2015-03-20 21:19:22,"@mperham We have a couple folks on our team seeing this behavior. I use Bundler bin stubs in my project, so `sidekiq` should be the same as `bundle exec sidekiq`... right? Any further thoughts?
",jcarlson,mperham
2206,2015-05-31 23:11:12,"@mperham I found the culprit! We had this gem installed in our project: https://github.com/johnvoloski/spring-commands-sidekiq

For whatever reason, that gem defaults to the `test` environment when starting through Spring. Nuked that gem, all is well.
",jcarlson,mperham
2204,2015-02-27 06:44:02,"@newdark can you try #2205 ?
",seuros,newdark
2203,2015-02-25 09:56:59,"@seuros thanks! :star2: :tada: :collision:
",davydovanton,seuros
2201,2015-02-24 23:36:42,"This is almost certainly due to a recent change in connection_pool 2.1.1. https://github.com/mperham/connection_pool/pull/67 Your Redis connections are being discarded for some reason.

@ryansch Can you share your solution or link to your original issue?
",mperham,ryansch
2200,2015-02-22 19:01:01,"@jonhyman I could but that wouldn't solve the problem. The problem is the callbacks are already a job themselves and Sidekiq enqueues them in the same queue as the rest of the jobs.

@mperham So the jobs do not know what the batch class is when they create the callback job? How about making it a global setting that people could set in their Sidekiq initializer or config. Not as customizable but it would get around the performance issue.
",johnathanludwig,mperham
2200,2015-02-22 19:01:01,"@jonhyman I could but that wouldn't solve the problem. The problem is the callbacks are already a job themselves and Sidekiq enqueues them in the same queue as the rest of the jobs.

@mperham So the jobs do not know what the batch class is when they create the callback job? How about making it a global setting that people could set in their Sidekiq initializer or config. Not as customizable but it would get around the performance issue.
",johnathanludwig,jonhyman
2200,2015-03-12 16:17:06,"@mperham I assume that you thought about publishing the queue name to the batch and getting it back in the `multi` which adds successes/failures?
",jonhyman,mperham
2200,2016-02-24 18:18:41,"@mperham It took a bit of searching to find this.  Would it be possible to update the [wiki page](https://github.com/mperham/sidekiq/wiki/Batches) with this option?  Unless there is somewhere else to find it that I simply overlooked.  Thanks!
",mhuggins,mperham
2200,2016-02-24 18:28:58,"@mhuggins The wiki is publicly editable.  Added here: https://github.com/mperham/sidekiq/wiki/Batches#callback-details
",mperham,mhuggins
2199,2015-02-20 22:39:23,"@seuros I appreciate your response.  We are using bundler 1.8.2.  When running with the previous Gemfile, we would get a notice that having multiple sources is a problem.
",veverkap,seuros
2199,2015-02-20 22:49:01,"Okay, thanks @seuros!

And @mperham do you have any docs for existing customers that you can point me at?

Thanks!
",veverkap,seuros
2199,2015-02-20 22:49:01,"Okay, thanks @seuros!

And @mperham do you have any docs for existing customers that you can point me at?

Thanks!
",veverkap,mperham
2196,2015-02-19 16:46:28,"@mperham 


",sahin,mperham
2196,2015-02-19 18:11:13,"@mperham 

I know this very well. Even we had a yml and load in the init. 

recurring-jobs is very minimalist and good enough. We moved to sidetiq. 

because I feel sidetiq way of doing recurring is more sidekiq way :) like below, u create a class with perform , sidetiq has a UI ( which is a plus)


",sahin,mperham
2188,2015-02-12 21:45:57,"@mperham all tests passed :tada: 
",davydovanton,mperham
2186,2015-02-11 16:37:03,"@mperham what are my options here then? 
Should I keep on using the deprecated `.deliver(retry: false)` option until this is fixed? 
",karlingen,mperham
2186,2015-02-14 16:28:45,"@seuros thanks for taking the time to sort this one out!
",karlingen,seuros
2186,2015-02-17 14:57:43,"@mperham can we not keep this issue open?
",karlingen,mperham
2186,2015-02-26 17:32:34,"@seuros anything new regarding this issue?
",karlingen,seuros
2168,2015-01-29 18:42:23,"@mperham snap :)
",aprescott,mperham
2164,2015-01-28 18:28:20,"@mperham additional `a comment to the top of each file` + my commit? 
",davetoxa,mperham
2160,2015-01-27 21:21:13,"@mperham does this also include not using `app/workers/` for Sidekiq-only, ActiveJob-incompatible classes, as per https://github.com/mperham/sidekiq/pull/1909#issuecomment-53081866?
",aprescott,mperham
2159,2015-01-30 18:44:32,"I admit possessing perhaps 0.1% knowledge of Sidekiq :smile: 

Based on my brief exchange with @ryansch and this thread, I proposed you ensure all relevant keys are on the same shard and in the same slot. The quickest way to do it is with a hashtag (e.g. `{sidekiq}queue:$NAME`) and have all keys sit in the same place. That, of course, may turn that slot red hot with activity so a better way of partitioning the queue and script may be called for, but I'm not too savvy on the requirements here.

Re. the use of Redis Cluster, you're actually one of the best sources for that info. It is possible, of course, that the intersect between Sidekiq users and Cluster is an empty set for any number of reasons. I am, however, hearing more and more about Redis cluster users and with yesterday's release of RC3, the Cluster is happening :smile_cat: 
",itamarhaber,ryansch
2155,2015-01-26 17:53:14,"@mperham unfortunately this job will never be exhausted, Sidekiq will retry it after 2 hours... forever. :(
",dlibanori,mperham
2152,2015-01-24 19:40:57,"@mperham, what are your thoughts of an interface that's like this?



Could make this a bit easier for people to do things like update their code to dynamically use a different queue (e.g., high/med/low priority queues based on customer level). I'm happy to submit a pull if so.
",jonhyman,mperham
2145,2015-01-22 17:32:21,"We have millions of jobs in our `ScheduledSet` at any given time, and what @mperham is saying about looking up the job by JID rings very true to us. We used to search the set and even zscan it to find jobs when we needed to cancel them, but it was too inefficient.

We have a small set of jobs which are user-cancelable or reschedulable, maybe a few thousand of the millions. The way in which we handle that is by breaking the abstraction barrier somewhat. When we schedule those jobs at a given UNIX timestamp (e.g., 1421947789), we also generate six digits of random jitter to be used as microseconds, so it would actually get enqueued at something like 1421947789.489211. We then store the timestamp, the jitter as an integer (databases can be hard at getting the precision right), and the jid.

With those three pieces of information, we can use `ScheduledSet.new.fetch(score, jid)` which is `O(log(M)+N)`. `N` should by and large always be 1 because of the microsecond precision, and `O(log(M))` is not the fastest, but it's fine even at millions of elements. This way, we can access the job ourselves to delete it.

The solution proposed by @ryansch that's on the wiki also sounds pretty good, just add some middleware or pre-perform check for jobs that are canceled and return early.
",jonhyman,ryansch
2145,2015-01-22 17:32:21,"We have millions of jobs in our `ScheduledSet` at any given time, and what @mperham is saying about looking up the job by JID rings very true to us. We used to search the set and even zscan it to find jobs when we needed to cancel them, but it was too inefficient.

We have a small set of jobs which are user-cancelable or reschedulable, maybe a few thousand of the millions. The way in which we handle that is by breaking the abstraction barrier somewhat. When we schedule those jobs at a given UNIX timestamp (e.g., 1421947789), we also generate six digits of random jitter to be used as microseconds, so it would actually get enqueued at something like 1421947789.489211. We then store the timestamp, the jitter as an integer (databases can be hard at getting the precision right), and the jid.

With those three pieces of information, we can use `ScheduledSet.new.fetch(score, jid)` which is `O(log(M)+N)`. `N` should by and large always be 1 because of the microsecond precision, and `O(log(M))` is not the fastest, but it's fine even at millions of elements. This way, we can access the job ourselves to delete it.

The solution proposed by @ryansch that's on the wiki also sounds pretty good, just add some middleware or pre-perform check for jobs that are canceled and return early.
",jonhyman,mperham
2142,2015-01-16 23:37:10,"Fwiw I agree with @mperham here. Optimizing the network roundtrips is much
more important, especially for these calls which are really fast on Redis.

Sent from my mobile device
On Jan 16, 2015 6:30 PM, ""Mike Perham"" notifications@github.com wrote:

> I'm not clear what you are trying to optimize with the additional
> complexity. Are you trying to minimize Redis operations? I'd much rather
> avoid network round-trips and not make the developer worry about which mode
> they want to use.
> 
> ## 
> 
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/pull/2142#issuecomment-70339686.
",jonhyman,mperham
2142,2015-01-17 21:55:30,"Fantastic work, @ismaelga!  3x improvement!!
",mperham,ismaelga
2142,2015-01-28 16:10:41,"So, now it has a small transformation, of getting list of queues, is it? @ismaelga
`Sidekiq::Stats.new.queues` -> `Sidekiq::Stats::Queues.new.lengths`
",davetoxa,ismaelga
2142,2015-01-28 16:47:34,"@davetoxa ^^^
",mperham,davetoxa
2142,2015-01-28 17:08:23,"@mperham :smiley: :+1: 
",davetoxa,mperham
2139,2015-01-22 14:00:56,"@mperham : Could you give me any advice how to track this down? Cheers!
",fiedl,mperham
2139,2015-01-23 22:51:11,"@ryansch I've used the rails console to call `cached(:name)` directly.



[This is the **trace.txt produced by this code**](https://trello-attachments.s3.amazonaws.com/50006d110ad48e941e8496d2/54b319d8b888d9c7dbb43a2a/c32636249e39d89308fc0b8a4272d8da/successful-cached-name.trace.txt).

Thanks!
",fiedl,ryansch
2139,2015-01-23 23:46:48,"@mperham Thanks, looking for alias methods got me on the right track.

I've got some further testing to do, but I think this code has been responsible:



I'm using this code to rescue from cases where the class fetched from the cache isn't loaded, yet. 

I'll post my results here and then I'll close the issue.
",fiedl,mperham
2132,2015-01-11 21:44:44,"That's my prime suspect. I got another box spinning with the exact same setup on another provider and will keep an eye on things. I'm pretty sure it's nothing to do with sidekiq, but thought it's better to share this just in case... Thanks for the quick response and suggestions, @mperham. If you'd rather close this issue, then please do. Otherwise, I promise to keep you posted as soon as I find anything.
",gingerlime,mperham
2131,2015-01-09 23:46:58,"Thanks @mperham. Any insight into why it never seems to happen on the writes, just the reads?
",samuelreh,mperham
2130,2015-01-23 17:38:25,"@aprescott Good catch, fixing now.
",mperham,aprescott
2130,2015-01-26 17:44:34,"@aprescott beta2 is out.  I'm working on #2154 right now but your issues should be fixed.
",mperham,aprescott
2125,2015-01-09 16:45:22,"@mperham Perfect, thanks
",bnorton,mperham
2121,2015-01-07 21:04:19,"@jonhyman Yes, in Development I can get everything working and enqueue the workers without an issue. Simply changing rails to run in production mode causes workers to not enqueue for whatever reason.

@ryansch here is a copy of the Gemfile:
https://gist.github.com/zeknox/0694a76e9026da5d68cc
",zeknox,ryansch
2121,2015-01-07 21:04:19,"@jonhyman Yes, in Development I can get everything working and enqueue the workers without an issue. Simply changing rails to run in production mode causes workers to not enqueue for whatever reason.

@ryansch here is a copy of the Gemfile:
https://gist.github.com/zeknox/0694a76e9026da5d68cc
",zeknox,jonhyman
2121,2015-01-07 21:05:00,"@mperham Here is what my initializer looks like:

<pre>
Sidekiq.configure_server do |config|
  config.redis = { url: 'redis://127.0.0.1:6379/12' }
end
Sidekiq.configure_client do |config|
  config.redis = { url: 'redis://127.0.0.1:6379/12' }
end
</pre>
",zeknox,mperham
2121,2015-01-07 21:07:29,"@ryansch here is a copy of `Sidekiq::Testing.__test_mode`

<pre>
$ rails c -e production
Loading production environment (Rails 4.2.0)
2.1.1 :001 > Sidekiq::Testing.__test_mode
 => :inline 
</pre>
",zeknox,ryansch
2120,2015-01-07 17:39:12,"Wow. Thanks for reporting and thanks for fixing, @mperham!

Sent from my mobile device
On Jan 7, 2015 12:36 PM, ""Mike Perham"" notifications@github.com wrote:

> Closed #2120 https://github.com/mperham/sidekiq/issues/2120 via
> d1191ca3b3c62982f32d02c4c5b80ecf2269fb2c.
> 
> ## 
> 
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/issues/2120#event-215421187.
",jonhyman,mperham
2120,2015-02-13 00:18:35,"@mperham I appreciate this change! Since upgrading from `1.9.1` to `1.9.2` I have seen a significant performance regression. Do you have tests that can check this or would you like some diagnostic data?
",parhamr,mperham
2120,2015-02-13 00:27:26,"Can you give more versions: Ruby, sidekiq, sidekiq pro?  Ruby 1.9 support is pretty frozen at this point, any possibility of upgrading Ruby and sidekiq?

> On Feb 12, 2015, at 16:18, Reid Parham notifications@github.com wrote:
> 
> @mperham I appreciate this change! Since upgrading from 1.9.1 to 1.9.2 I have seen a significant performance regression. Do you have tests that can check this or would you like some diagnostic data?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2107,2014-12-30 02:39:54,"Oh, no! That's not good to hear, I guess... :fearful:

Thanks, @mperham! Hope @tarcieri can chime in.

I thought about filing this issue in Celluloid's repository, but couldn't get a working example using plain Celluloid, without Sidekiq.
",deborasetton,mperham
2103,2014-12-26 22:26:05,"Correct. Thanks @jc00ke !
I missed that bit when looking for the web UI docs (which i did not realize was under the heading ""Monitoring"").
",cpg,jc00ke
2099,2015-01-06 15:55:07,"@moserke Could you squash your commits ?
",seuros,moserke
2097,2014-12-24 23:13:34,"@jejacks0n are you suggesting removing the `execute_job` hook entirely? That will break any code that now depends on that hook, which I myself have written and presumably others have too, on the assumption that it would be a supported feature.
",aprescott,jejacks0n
2097,2014-12-24 23:18:02,"@aprescott not really, but I didn't like how the tests fail to utilize it, so if you do anything with it, you must also patch the test harness, which then got me thinking that that was probably a really bad approach -- I mean, if that's the case, someone can change the real implementation, but the tests happily pass. Deploy to production, and :boom:.

That's all I really want to solve here, is to unify that so it's a patch once and be done sort of thing. No additional understanding of how the test harness is wired up (or not wired up).
",jejacks0n,aprescott
2097,2014-12-24 23:29:41,"@aprescott no, I have a test that calls `MyWorker.perform_async`, if you follow what that does in the code, when you've configured `Sidekiq::Testing.inline!`, it goes through `Client#raw_push`, which then calls `MyWorker.perform_one`.. which then currently calls the `MyWorker#execute_job` method -- which is not the same as the desired path, which lives in `Processor#execute_job`.

So if you change one, you must also change the other, and then it makes it really easy to break one and not capture it in your specs. Does that make more sense?
",jejacks0n,aprescott
2097,2014-12-24 23:35:32,"@jejacks0n oh, hm. I'd only concerned myself with `MyWorker#execute_job` up to this point.
",aprescott,jejacks0n
2097,2014-12-24 23:47:15,"@aprescott it can be useful and clean though, and so that was my first attempt with this PR. @mperham had some valid feedback, so the only alternative I saw at a fix (current draft of this PR) is to extract it out to a higher level so it can be shared cleanly -- I'm unsure about how he'll feel about this though.

As a last resort I offer to remove it and still provide some of the cleanup around the `drain` method.
",jejacks0n,aprescott
2096,2014-12-23 15:51:12,"@mperham that works. It seems like this is something that Sidekiq Pro should always ignore for test environments, instead of pushing the responsibility into each app, what do you think?
",aprescott,mperham
2096,2014-12-23 18:03:11,"I don't know how to implement that. How do I know it's the test env?  Sidekiq can't require Rails and this is the client side so Sidekiq's env setting isn't relevant. 

> On Dec 23, 2014, at 07:51, Adam Prescott notifications@github.com wrote:
> 
> @mperham that works. It seems like this is something that Sidekiq Pro should always ignore for test environments, instead of pushing the responsibility into each app, what do you think?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2096,2014-12-23 22:26:50,"@mperham in a test environment, can Sidekiq not check if `require ""sidekiq/testing""` has happened and/or if `Sidekiq::Testing.enabled?`/`Sidekiq::Testing.inline?` is configured appropriately?
",aprescott,mperham
2093,2014-12-18 16:39:22,"@seuros but it works on staging machine with corresponding environment variable passed to sidekiq binary(in processes it shows 10 workers). Even if the problem was with the environment, you can see 37  busy workers on screenshot which is more than 35 which is set for production
",rustamagasanov,seuros
2093,2014-12-18 16:41:28,"@mperham thank you for quick reply and explanation! I guess, I can close this then.
",rustamagasanov,mperham
2088,2014-12-16 17:54:07,"@mperham it would be cool to have better profiling in ruby. Either way, it was a suggestion, I'll keep it in my version while I'am profiling the production environment and son revet back to Sidekiq's original gem.
",felipeclopes,mperham
2088,2015-01-23 09:20:04,"@mperham I stumbled across your `rb_profile_frames()` issue earlier today as I bumped up against the same problem. I was a bit too impatient to wait for the function to be added in Ruby 2.x, so I hacked support for it into a [fork](https://github.com/glassechidna/stackprofx) of `stackprof`. Emphasis on ""hack"". 

In any case, it allowed me to make a [middleware](https://github.com/glassechidna/stackprofiler-sidekiq) to profile Sidekiq jobs. Right now it's fairly rigid and expects to work with a [GUI tool](https://github.com/glassechidna/stackprofiler) I started last month to browse Stackprof profiles.

There's one (somewhat substantial) limitation with the middleware in that right now it can't profile multiple jobs concurrently. I don't think this is _too_ much of an issue at the moment as devs will probably be drilling down into issues with a given job and don't want to be flooded with data. In any case, it's an issue I'm working on.

This has gone really off-topic for this issue. I apologise for the rambling. The reason I brought it up in _this_ issue on the Sidekiq tracker is because the middleware may be of interest to @felipeclopes, even if it's very early state.
",aidansteele,mperham
2086,2015-01-13 23:09:54,"By popular [demand](https://github.com/taskrabbit/resque-bus/issues/10) @bleonard the author of resque-bus has gracefully supported a [refactoring](https://github.com/taskrabbit/resque-bus/pull/13) that will allow for other adapters and already includes a test Sidekiq adapter. I am quite impressed with this gem with its clean DSL, intelligent architecture and thorough test suite . It is being used by the author in production and it allows multiple application to subscribe to events without the publishing application needing to assign to specific workers. We are intending to try this out on a multi-service application and see how well it scales.

A question I have for @mperham is whether there are any other ways besides the command line or sidekiq.yml file to assign queues to a Sidekiq client? It seems that resque allows for an ENV['QUEUES'] setting which is how resque-bus currently communicates to resque.

Also would you be interested in doing a final review of the Sidekiq adapter implementation when it is ready to offer any suggestions and confirm that the implementation is sound?
",jonsgreen,mperham
2086,2015-01-13 23:16:31,"@jonsgreen YAY!! I have looked at `resque-bus` and is indeed very impressive work, `sidekiq` will be a welcomed integration. As always thanks @mperham @bleonard
",kapso,mperham
2086,2015-01-14 00:31:06,"By popular demand. ha!
I agree with the rename @mperham - suggestions welcome.

I was just thinking 99% of what we have now is called something (background-bus?)
resque-bus requires that and adds the resque adapter.
sidekiq-bus would do the same for sidekiq.
maybe delayed_job if anyone is still into that one.
",bleonard,mperham
2085,2014-12-10 22:20:15,"@substars can you squash your commits ?
",seuros,substars
2073,2014-12-04 20:09:33,"@halorgium How's that look?
",mperham,halorgium
2073,2014-12-18 17:24:43,"@halorgium What's the prognosis?  Do we want to use TaskThread or TaskNone (or whatever it's called)?
",mperham,halorgium
2073,2014-12-19 19:21:19,"@mperham `TaskThread` seems to be stable. I haven't made much more progress on `TaskInline`. 
There are edge cases and tests which requires suspending being possible. 
",halorgium,mperham
2072,2014-12-04 17:33:45,"That response and closing the issue actually feels like shoving something off the table. That feels arrogant.

Thanks @substars, I'll take a look.
",ollie,substars
2072,2015-01-08 18:37:03,"@mperham The Deserialization error happens because of a record not found exception. This typically happens when I queue a job to happen at a later time and meanwhile the object on which the job was set to run is deleted. An example scenario :

1- A new user registers to the application and a welcome email is set be delivered 1 day from now.
2- The user deletes his account.
3- A deserialization error is raised when the job runs because the record cannot be found (deleted).

I just saw that Active Job provides a `rescue_from` method. I will try to see if I can catch the exception with that method : http://edgeguides.rubyonrails.org/active_job_basics.html#exceptions
",pomartel,mperham
2072,2015-07-23 05:14:28,"I didn't really see anyone explaining the way I see this, so I'm trying now: Some exceptions just don't make sense to be retried at all - a cliche example is the `ActiveRecord::RecordNotFound`. Applications that interact with third-party services on behalf of users might face exceptions like `SomeService::ProfileNotFound` that don't make sense to be retried as well.

So, for cases like this, I feel error-prone to reimplement the same `rescue` block in multiple workers.
Also, in many cases that I could simply do `SomeClass.delay.method` and I want to skip a common exception from retry, I'll have to wrap in a custom worker class.

This behavior is used in gems such as Airbrake and Rollbar:
![](https://dl.dropboxusercontent.com/spa/9kycf4oxo6l3hcj/5xzka2ri.png)

_I don't think we should/need to have a default list of skipped exceptions like Airbrake. I like that Sidekiq won't be having a lot of Rails-specific code_

@mperham It would be a pleasure to write a PR if you think you can accept that. Thanks.
",rafaelsales,mperham
2072,2015-07-23 13:21:42,"@aprescott Thanks for your attention here.

Adding a global non-retry list with the scenarios I described doesn't really mean we would silently fail. I still implement the Sidekiq global exception handler to notify me on Rollbar properly when I know it's something I should be aware of.

My point is: I'm currently about to refactor fair amount of code to stop using `Model.delay.method` because when we have a RecordNotFound in this, it's really safe that I shouldn't retry. E.g:
![image](https://cloud.githubusercontent.com/assets/1196663/8851210/52beb1ce-3124-11e5-8e60-5c3e03927ca6.png)

As you can see in this image, the id was persisted because it had an id, but it couldn't be found - there's really no reason to retry this. It's quite awkward it happened though, so the simplest way I see to handle this is to not even retry a single time and notice the team via Rollbar (with the global exception handler) 
",rafaelsales,aprescott
2072,2015-07-23 16:34:04,"@aprescott Yes. There are really some cases where `ar_model.operation` would work but `ar_model.delay.operation` won't - you can see the image I posted above. If the job takes like 30 minutes to get executed and the record was removed meanwhile. There are other scenarios and exceptions that I had ignored in nearly every job and I would put in a global retry ignore list if possible
",rafaelsales,aprescott
2070,2014-12-03 18:01:53,"@mperham Thanks for the quick reply! I'm going to see if fiddling with `MALLOC_ARENA_MAX` alleviates the problem.
",silasjmatson,mperham
2069,2014-12-02 16:11:08,"@mperham nothing blocking here - but it adds a bit of ""what is happening here?"" when it's the first time you look at the batch UI. Thanks!
",thbar,mperham
2065,2015-03-30 08:13:11,"@ryansch can you have a look if I can give you ssh access to a debian test environment? This will help me update the sidekiq package in debian.
",pravi,ryansch
2065,2015-05-02 06:27:47,"@ryansch would it be possible to allow ~ and + in filenames?
",pravi,ryansch
2057,2014-11-26 15:57:03,"@seuros : thank 3.3.0 works
upd:


",dammer,seuros
2056,2014-11-19 18:17:58,"@mperham :thumbsup:
",tarcieri,mperham
2056,2014-11-20 05:44:56,"@mperham This appears to fix the Sidekiq shutdown issue we've run into. :+1:
",ezkl,mperham
2056,2014-11-20 21:09:07,"@mperham can we get a release?
",thommahoney,mperham
2056,2014-11-20 22:44:21,"Thank you @mperham 
",thommahoney,mperham
2055,2014-11-19 19:46:45,"I just realized that I wasn't properly setting the poll interval for the environment I was testing it in. I'm really sorry for making that bone head mistake.

I think part of what threw me off was that the default should have been 15 seconds, but the times seemed really random. Now with the setting marked properly I'm seeing zrangebyscore call come in about every 1-1.5 seconds. I'm still seeing some delay in the total completions of my task, but that could a variety of things which I'm going to dig deeper into.

@mperham were you seeing any variance in the times for zrangebyscore when you didn't set the poll_invterval?
",nicolo,mperham
2047,2014-11-11 17:28:43,"@mperham fair enough. I'll do that.
",bmarini,mperham
2046,2014-11-11 19:11:19,"@mperham: Pushed that change. Purely documentation and synching the two examples now.
",sorentwo,mperham
2044,2014-11-07 15:45:10,"@mperham: yes, likely thread safety issues but I don't see how it can corrupt something ""read-only"" like `ENV` (not that any of you confirmed that ruby backticks actually uses `ENV['PATH']`).

Here is some code:



Here is the curl call:



I'm aware that you probably want more code but I'd rather try to isolate it and get something reproducible so you have a testcase. That's why I'm asking about guidance for what debugging can be attempted (dump ENV in workers? can we get sidekiq to attach a debugger to some worker when some exception is thrown? etc).
",Silex,mperham
2044,2014-11-07 15:51:30,"@seuros: I never said ENV was read-only, I'm saying it doens't make sense for `ENV['PATH']` to suddenly return nil or an empty string (not that we even asserted this is what happens).
",Silex,seuros
2044,2014-11-07 16:54:40,"@mperham: alright, thanks for the idea.

I added some `ENV` dumping to the logs in the hope that it'll at least help us assert this is a PATH issue.

I now need for the bug to show up again, which didn't happen since I upgraded the gems, so I'll close this and reopen when/if I have more data.

Thanks guys for all the informations.
",Silex,mperham
2043,2014-11-05 19:02:34,"@seuros I'm not sure why loggers can't be initialized before?
",kenips,seuros
2043,2014-11-05 19:07:23,"Because we have to parse the arguments first to build the options.
I could refactor that to initialize the logger inside `setup_options` if @mperham has not objection.
",seuros,mperham
2041,2014-11-05 18:18:03,"@seuros go for it. If not I can come back to this tomorrow :) thanks!
",kenips,seuros
2039,2014-11-13 00:29:59,"@aprescott  Thanks!
",imWildCat,aprescott
2036,2014-11-12 22:19:41,"@mperham Any thoughts?

@seuros Yes, the Celluloid version should be relaxed if and when this is merged.
",petergoldstein,seuros
2036,2014-11-12 22:19:41,"@mperham Any thoughts?

@seuros Yes, the Celluloid version should be relaxed if and when this is merged.
",petergoldstein,mperham
2036,2014-11-13 18:43:45,"@petergoldstein could you please relax Celluloid version in this PR ? 
",seuros,petergoldstein
2036,2014-11-13 18:48:08,"@seuros Done.
",petergoldstein,seuros
2030,2015-02-27 05:57:45,"@seuros Can `default_worker_options` be configured in sidekiq.yml or must that happen in an initializer?
",ethagnawl,seuros
2030,2015-02-27 06:25:51,"@seuros Good to know. Thanks for the prompt response! 
",ethagnawl,seuros
2028,2014-10-28 15:01:20,"@mperham should we raise if an old version of redis is detected ?
",seuros,mperham
2028,2014-10-28 15:30:48,"@seuros Sure.  Here's how to fetch the version:


",mperham,seuros
2025,2014-11-01 21:35:16,"I think @jonhyman brings up a good point.  I think the need for using unique jobs are attempts at throttling solutions.  We want to do something repeatedly but prevent overlap: starting another same job when the first one is still going.  Like, ""download inventory for every merchant every 15 minutes, but if job is not finished don't enqueue this again"".  

Maybe I'm off topic a bit, but maybe instead of trying to limit what goes into the queue, Sidekiq could provide a way of throttling which jobs are fetched from the queue based on some criteria.  It would be very useful to have the simulation of a unique queue per user, or job type, where you could control the concurrency with the worker's `sidekiq_options`.  For example, say a user is importing a CSV file with 100K lines, and say I parse and batch each 100K lines to it's own worker, I might easily block all my workers from doing anything useful for anyone else.  Sure I can play around with priority weighted queues and shift the jobs into a low priority queue so other high priority jobs still go through: but it doesn't change the fact that this one user is disproportionally hogging the low queue.  It takes more architecting and careful layering of more workers but it's possible to paginate and batch jobs out so you get the benefits of serial executing with bursts of concurrency.  But it would be nice if we could limit by the perform arguments `CsvProcessLine.perform_async('user_id' => 23, 'data' => data)`, and provided some kind of `sidekiq_options :throttling => {:max_concurrency => 10, :within => 1.second, :unique_args => [:user_id]}`, so the workers only dequeue 10 of `user_id = 23`'s jobs at a time and save some capacity for other users.

Similarly it would be easier to architect workers that reflect the throttling needs of 3rd party api's, for example for an `AmazonMarketplaceWorker` you might want to limit to 10 simultaneous calls within a 2 second interval.  Whereas an `EtsyWorker` you might not want any concurrency at all, you might want the worker to dequeue this type of job in serial only 1 at a time.  
",homanchou,jonhyman
2022,2014-10-30 19:02:05,"@brandonhilkert , we are in rails 4.1.6,

we have hundreds of worke

1 example: 
      if cinema[:showtimes_updated_at][""day#{date.wday}""] == params[:date]
        logger.info(""Skiping #{params}"")
        next
      end
",sahin,brandonhilkert
2019,2014-10-21 14:56:16,"@seuros squashed! :+1: 
",dlackty,seuros
2012,2014-10-27 03:12:15,"@oleander @subelsky can you post an example sidekiq config using `resolv-replace`? Google doesn't render anything relevant at the moment

Is it only a matter of putting `require 'resolv-replace.rb'
` in an initializer (`config/initializers/require.rb`)?
",krzkrzkrz,subelsky
2012,2015-03-12 15:03:18,"Hi guys, I'm facing a similar issue. Once or twice a day sidekiq stops proccessing any new workers (though sidetiq stills enqueuing new jobs), it appears alive with `ps aux | grep sidekiq` with `[15 of 15 busy]`.

The output of `kill -TTIN <sidekiq_pid>` is https://gist.github.com/rapofran/83afa64161c20b0f9a8d

As you can see there are workers that talk to Rserve through rserve-client, and they seem to be locked in the `recv`call.

@mperham the TTIN output is normal? so this is an issue related to Rserve?

I'm using this stack:
sidekiq (2.17.3)
celluloid (0.15.2)
sidetiq (0.5.0)

(plus I figured they pass through `sidekiq/middleware/server/retry_jobs.rb` so recently I changed to `sidekiq_options retry: false` so they don't try to retry)

Thanks a lot for this spectacular gem!
",rapofran,mperham
2012,2015-03-12 15:42:33,"@mperham thanks! and sorry for hijack someone else's issue
",rapofran,mperham
2012,2015-12-01 20:22:06,"I've done some experimentation over the past 300M background jobs and found that the following setup works.
- sidekiq 3.3.0
- ruby 2.2.1
- rails 4.0.13

The sidekiq init file has the following line to ensure that `resolv-replace` is loaded.



@mperham Thanks for your help!
",oleander,mperham
2010,2014-10-17 14:03:11,"@jonhyman could you exemplify how can I use this batch feature to solve the problem? Many thanks!
",nicolasiensen,jonhyman
2010,2014-10-17 17:55:30,"@mperham, @seuros thanks for your reply
",nicolasiensen,seuros
2010,2014-10-17 17:55:30,"@mperham, @seuros thanks for your reply
",nicolasiensen,mperham
2006,2014-10-17 14:37:32,"@mperham Thanks for quick response. It turns out that I didn't get the difference between the `timeout` setting in `config/sidekiq.yml` and the argument that is passed to `sidekiqctl` by my Capistrano deployment.

As I understand now is that the setting in `config/sidekiq.yml` is for Sidekiq to complete the jobs itself before stopping itself. The number of seconds passed into `sidekiqctl` is the ""last chance grace period"" before the process is `kill -9`'ed. So now I've configured both and it seems to be working!
",michiels,mperham
2003,2014-10-15 04:18:34,"@mperham https://gist.github.com/4d2ad902c1813876f8d1 - Gemfile.lock
Unfortunately, I cannot give you SSH access, as this is our production environment
",krzkrzkrz,mperham
2003,2014-10-15 09:46:29,"Sorry @mperham its https://gist.github.com/09efa886d5a09e676da2
",krzkrzkrz,mperham
2003,2014-10-16 03:53:33,"@mperham I only see TID in the sidekiq.log which log are you referring to for the TTIN?
",krzkrzkrz,mperham
2003,2014-10-16 04:06:12,"See Signals wiki page.  `kill -TTIN $sidekiq_pid`

On Wed, Oct 15, 2014 at 8:53 PM, Christian Fazzini <notifications@github.com

> wrote:
> 
> @mperham https://github.com/mperham I only see TID in the sidekiq.log
> which log are you referring to for the TTIN?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/issues/2003#issuecomment-59310862.
",mperham,mperham
2003,2014-10-26 08:35:26,"Thanks @krzkrzkrz for posting this!! @mperham I'll gladly give you ssh access to my server when this happens to me(every day it happens sporadically, and I can't figure out the common factor). I have been trying to debug this problem for a couple of months now. It seem like sidekiq just falls asleep. 
",SirBertly,mperham
2003,2014-10-27 04:18:32,"@mperham https://gist.github.com/ccb74e6c91e69c5bb70f the sidkiq log when I issue the kill -TTIN command
",krzkrzkrz,mperham
2003,2014-10-27 06:25:03,"I am curious, when accessing Sidekiq's dashboard. Does Sidekiq check if the background process is running and if it isn't, attempts to run it? This certainly seems like the case. But would like to verify.

I suspect that the Sidekiq process stops (for whatever reason), and nothing is there to ""wake it up"" again. If so, perhaps monit/upstart could be the solution here. Your thoughts @mperham ?
",krzkrzkrz,mperham
2003,2014-10-27 16:53:10,"Hi @mperham I do have both those files on my server.
",SirBertly,mperham
2003,2014-10-28 03:01:13,"@sirBertly today the jobs were ""stuck"" again. 20k jobs or so. Going onto Sidekiq's dashboard, made Sidekiq start the jobs again.

@mperham it seems the Web UI (Sidekiq's dashboard) starts the job processing again though.

I'll have to wait until tomorrow to see if the sidekiq process is running or not, via `pa -aux`. If the process isn't running, then something must have made it crash, and if so, then a monitoring tool like monit, god or even inspeqtor _could_ be the solution.

I believe having a supervisor process is also mentioned somewhere in the wiki.
",krzkrzkrz,mperham
2003,2014-10-30 03:13:59,"Today the jobs were ""stuck"" again. `ps aux | grep sidekiq` returned:



Which means the process was running, never crashed, but ""stuck""! Going on the dashboard started working on the queue. i.e. the queue started to go down.

Frustrating, because the logs dont really indicate anything. @mperham any other ideas I should try?

@sirBertly how are things on your end?
",krzkrzkrz,mperham
2003,2014-11-01 07:28:53,"@oleander Yup! That works, thanks again! @krzkrzkrz I had noticed that sidekiq craps out when it loses connection to redis, for whatever reason. I solved this with a monitor. I'm using monit, sorry @mperham, I had it installed before I found out about inspector. I'll probably change this later..



and 


",SirBertly,mperham
2003,2014-11-01 07:45:05,"@seuros Yes! That's the plan. I had monit in place and I want to monitor this first and make sure that I actually fixed my issues before tinkering with new stuff.
",SirBertly,seuros
2003,2014-12-09 05:42:36,"@mperham `kill -TTIN $sidekiq_pid` on queued workers will kill the jobs permanently?
",krzkrzkrz,mperham
2003,2014-12-11 19:59:34,"@mperham My bad about the TTIN. Anyhow I figured out that the issue was celluloid @ version 16. Backed it to 15.2 and working fine again.
",sarmiena,mperham
2003,2014-12-11 20:10:32,"Upgrade sidekiq. 3.3.0 works great with 16. 

> On Dec 11, 2014, at 11:59, aldo sarmiento notifications@github.com wrote:
> 
> @mperham My bad about the TTIN. Anyhow I figured out that the issue was celluloid @ version 16. Backed it to 15.2 and working fine again.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2003,2016-03-18 02:56:59,"@mperham sorry for that. I will open a new issue. Thank you. 
",imgarylai,mperham
1999,2014-10-12 05:30:49,"Nice. Thanks @mperham 
",ChunAllen,mperham
1999,2015-08-06 05:52:14,"Hi @mperham,

`MyMailer.delay.my_new_mail` has async the mail through sidekiq 3.4.2, ruby 2.2.1 and rails 4.2.1 .

And, inside the mailer i want `jid` as like below:


",shreeramneupane,mperham
1999,2015-10-12 13:30:24,"Hi @mperham,

When I use delay for
job_id =MyWorker.delay_for(2.day).perform_async(self.id)

And, inside the worker jid get changed, is not same as which I get in job_id

---

But when I use perform at

job_id = MyWorker.perform_at(2.day.from_now, self.id)

And, inside the worker jid  remain same as we get in job_id

Can you please tell me this difference(delay_for and perform_at). I am unable to find this answer? 
",sumitisrani,mperham
1999,2015-10-23 07:07:56,"Hi @mperham,

I am using perform at to delay the job

job_id = MyWorker.perform_at(2.day.from_now, self.id)

But when my job run jid get change,  the jid is not same as which I get when I schedule the job.
I saved that jid in my DB and when my job run I find the records with jid, update the record in my DB.
But due jid get change I am unable to find out the record and my job get failed.

My sidekiq version is (3.3.4)
",sumitisrani,mperham
1999,2016-03-22 15:06:17,"@mperham - Could you expand on ""Don't use delay on a Worker?""  I'm converting a previous implemenation that used a worker (and some wonky `raise`s to implement a retry strategy) into a more pro-active retry that calls `.delay_for(5.minutes)` within the worker to schedule the next attempt, if needed.

Should I not be calling `delay_for` within a worker?  Can you point to an example of how a method can more cleanly re-invoke itself?
",dhempy,mperham
1999,2016-03-22 15:55:15,"Thanks, @mperham !  :-)  I'll give that a whirl!
",dhempy,mperham
1993,2014-10-13 21:33:03,"@mperham - only sidekiq-failures and we removed it to rule that out as an issue.
",anazar,mperham
1993,2014-12-18 17:04:56,"@subelsky That does require your Sidekiq process to be responding.  If all workers are ""stuck"", it won't work because the job will never be pulled from Redis.
",mperham,subelsky
1989,2014-10-07 17:28:59,"Bundler isn't required.  Sidekiq assumes that the first thing you do to use Sidekiq code is `require 'sidekiq'`.  Anything else can get into the load problems that @indirect is mentioning.
",mperham,indirect
1989,2014-10-07 18:11:36,"So I guess ultimately I don't care about this in real life, but it seems weird to deliberately create a situation where either a file doesn't require a thing before it calls that thing, since it means exceptions are easily possible. It also seems weird to create a circular dependency (and ruby or rubygems will call you out on that by printing a warning).

I required sidekiq/worker by itself because I wrote an extension (wanelo/sidekiq-dynamic) that extends it, and my tests fail unless I require sidekiq before I require sidekiq/worker, even though I only interact with the Sidekiq::Worker class.

Again, your gem, do whatever, but I think the low-cost ""correct"" thing would be to make sidekiq/worker and require a new file that adds the needed class methods to Sidekiq, and have sidekiq.rb require sidekiq/worker.

> On Oct 7, 2014, at 10:29 AM, Mike Perham notifications@github.com wrote:
> 
> Bundler isn't required. Sidekiq assumes that the first thing you do to use Sidekiq code is require 'sidekiq'. Anything else can get into the load problems that @indirect is mentioning.
> 
> \
> Reply to this email directly or view it on GitHub.
",indirect,indirect
1988,2014-10-06 18:30:48,"@seuros I agree in spirit but we do it elsewhere in the codebase so there is precedent.
",mperham,seuros
1987,2014-10-06 16:57:11,"@bensie Not AFAIK. We have set a ( generous ) database.yml pool size of 150 using the mysql adapter, to allow enough connections for workers, unicorn etc.
",joshmyers,bensie
1987,2015-05-14 14:18:21,"@mperham Do you have any idea what might be causing this? We are hitting this pretty regularly (several times a day) and cannot afford to reduce concurrency. Can I do anything to help debug this?

celluloid 0.16.0 and sidekiq 3.3.4
",kremso,mperham
1987,2015-05-14 14:35:22,"@kremso I need a backtrace or crash report of some type.
",mperham,kremso
1987,2015-08-17 10:10:31,"We are calling a (sometimes slow) http service from our workers. I noticed that at the time when sidekiq crashes we also observed increased response times from the service to the point that the http requests from workers timeout.

I put up a minimal setup that simulates this and it can reproduce the issue reliably; see here https://gist.github.com/kremso/ffee0659f40ea630825f

It takes around a minute or two, but eventually sidekiq will crash with the linking timeout. I also noticed that with http timeout length <= 2 seconds the issue goes away, with timeout larger than 2 seconds, sidekiq will crash.

@mperham Does this give you any idea what might be going on?
",kremso,mperham
1984,2014-10-08 18:00:29,"@mperham Super excited for this fix. Do you mind pushing it to ruby gems? It still shows the latest version as 3.2.5

Thanks!
",comjf,mperham
1975,2014-10-09 19:43:05,"@mperham I followed your advice here but now getting occasional errors like #1468 where a batch's pending count goes negative. This is what we're doing:



did I miss something, so that the new job gets officially added to the batch?
",subelsky,mperham
1974,2014-10-03 19:19:55,"@mperham Is there any way that the code that checks the number of processes to calculate the wait-time multiplier could clean out dead processes the way that ProcessSet does? As far as I remember it does a straight `redis.scard 'processes'` call and doesn't use the ProcessSet class. 

Maybe if that sounds like a decent idea I can take a stab at a PR implementing it.
",epchris,mperham
1974,2014-10-03 19:20:53,"@mskog @comjf @seuros yeah, I believe there was a regression in the underlying threading library that cause some issues with shutdown, look at the changelog for 3.2.5.
",epchris,seuros
1974,2014-10-03 19:22:52,"Sounds like a great pr. Love to see it. 

> On Oct 3, 2014, at 12:19, Chris TenHarmsel notifications@github.com wrote:
> 
> @mperham Is there any way that the code that checks the number of processes to calculate the wait-time multiplier could clean out dead processes the way that ProcessSet does? As far as I remember it does a straight redis.scard 'processes' call and doesn't use the ProcessSet class.
> 
> Maybe if that sounds like a decent idea I can take a stab at a PR implementing it.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1973,2014-09-29 21:30:25,"@mperham The second element of the array is the suffix of the class (e.g. label-primary => primary) - from any of the selection listed at http://getbootstrap.com/components/#labels.
",pgeraghty,mperham
1973,2014-09-29 21:56:40,"@mperham let keep this open and see if there is interest. wdyt ?
",seuros,mperham
1972,2014-09-29 15:50:00,"@Nowaker is right that AJ will be a major source of Sidekiq users.  We need a new wiki page which covers basic usage.  It might be very simple but it should be there just so people know how easy it is to use.
",mperham,Nowaker
1972,2014-09-29 23:08:16,"@seuros @mperham yes
https://github.com/mperham/sidekiq/wiki/Active-Job
",rselk,seuros
1972,2014-09-29 23:08:16,"@seuros @mperham yes
https://github.com/mperham/sidekiq/wiki/Active-Job
",rselk,mperham
1972,2014-09-29 23:22:21,"@rselk Awesome work.  I might fine tune the third sentence so it doesn't scare people as much but the rest of the content looks great.
",mperham,rselk
1972,2014-09-29 23:33:27,"@Nowaker , it a wiki. You can edit it too. :)
",seuros,Nowaker
1966,2014-09-23 22:03:32,"@seuros No plugins. Just installed sidekiq this morning.
",bobber205,seuros
1965,2014-09-22 15:55:27,"@aprescott good point. Reliable fetch doesn't respect the `retries` configuration option and #1493 does appear to touch on this, assuming that the ""easy win"" @mperham talks about isn't the final solution for #1493. I'll close out as a duplicate and watch that issue.
",jonhyman,aprescott
1963,2014-09-26 08:47:15,"@seuros it happens on 0.15.2 and 0.16.

We deployed it to production and it does not get stuck for 3 days so far (was stuck twice a day on staging). Don't have an idea why.
",jumski,seuros
1963,2014-10-30 03:31:33,"@jumski @seuros I am facing a similar issue (https://github.com/mperham/sidekiq/issues/2003) wondering if you managed to find a fix on your end?
",krzkrzkrz,seuros
1963,2014-10-30 16:02:46,"it started working on fresh production server, was failing on staging

dont really have any clues :(

2014-10-30 4:31 GMT+01:00 Christian Fazzini notifications@github.com:

> @jumski https://github.com/jumski @seuros https://github.com/seuros I
> am facing a similar issue (#2003
> https://github.com/mperham/sidekiq/issues/2003) wondering if you
> managed to find a fix on your end?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/issues/1963#issuecomment-61041342.
",jumski,seuros
1963,2014-11-23 12:21:04,"@mperham We have some networking issues occurring around 4am nightly on a recurring basis - hosting company seems incapable of fixing it alas. Due to this even with 3.2.5 we're seeing the system simply stop processing. Is it possible the timeouts are still too low for the Redis work around you introduced with 3.2.2? We'd preferably like it to just never stop trying :)
",lypanov,mperham
1963,2014-11-23 12:36:32,"@mperham Ignore that last one noticed there is a duplicate of this issue which provides various suggestions. I'll try 3.2.6 / TTIN / resolv-replace. If still broken will comment again.
",lypanov,mperham
1963,2016-11-15 13:23:58,"In case anyone ends up here with a similar problem, exit status 137 means your process was killed by Linux’s OOM (Out of Memory) killer.

@mperham: sorry for the trouble, but I think documenting this here might help others Googling this, and incidentally reduce the number of tickets being opened related to memory bloat issues.
",jdurand,mperham
1961,2015-10-26 11:53:14,"@mperham 
I tried to make your solution work on my machine. But I'm running through some issues. 
This is what I'm doing:
1. I have 2 app both on Rails, 1 is admin and the other one is frontend. 
2. I have about five workers in the admin which work great 
3. I have one worker in the frontend to clean all the caches. 
4. Both these apps use the same redis db but have different sidekiq processes 
5. Now, I have queues and namespaces to handle any conflicts between the jobs which is also fine. 
6. But, when I want the admin to queue a job for frontend which is `clear_cache` using the command



which works but then the same is queued forever and never gets processed by frontend sidekiq.
7. Also, I can see the job queued in the sidekiq web under the admin app but the sidekiq in frontend shows empty always. 

Here are some extra details
1. Admin sidekiq.yml


1. Admin sidekiq.rb
   
   
2. frontend sidekiq.yml 
   
   
3. frontend sidekiq.rb
   
   

Am I missing something here ? 

PS: I did start the sidekiq on the frontend app as mentioned by you 


",pamio,mperham
1961,2015-10-27 04:59:09,"@mperham, its now working with the suggested change. However, the very reason I brought namespace into the picture was that I read somewhere on stackoverflow to have namespaces to avoid conflicts with other sidekiq processes. So one sidekiq process with namespace 'A' would always consume jobs from namespace A and another process with namespace 'B' would consume respectively. 

Anyway, its working now and thanks for your support. 

Cheers! 
",pamio,mperham
1961,2015-10-27 05:01:31,"@mperham, Thanks for additional knowledge. 
",pamio,mperham
1959,2014-09-29 17:16:36,"@mperham I can get you a backtrace. There's also one in the gist linked from #1022: https://gist.github.com/yangchenyun/5849852
",aprescott,mperham
1959,2014-09-29 17:21:22,"@aprescott I suspect that logging is out of date.  I'm hoping to get something with Sidekiq 3.x and Celluloid 0.15.2 as I can't repro with current gem versions.
",mperham,aprescott
1956,2014-09-28 19:32:54,"@ryansch I need this today or you don't make the launch cutoff.
",mperham,ryansch
1953,2014-09-18 13:01:51,"thanks @mperham. Believe me I strictly adhere to the Sidekiq Way :tm: everywhere else, but in this app we're constrained by outside resources -- there's a limit to how many Sidekiq workers I can spin up before I run out of DB connections, so I see this as a way to avoid having to beef up my database for now, especially since I only intermittently need this capability. Also some of our jobs are long-running and don't let themselves to decomposition into smaller jobs.

A solution that's more with-the-grain-of-Sidekiq would be if I could configure batch lifecycle notifications to go on a separate queue. Then I could have a worker that I only turn on in surge situations like this.
",subelsky,mperham
1950,2014-09-18 09:28:00,"Oh found that: https://github.com/StatusPage/librato-sidekiq/issues/7

@mperham thanks for your help!
",thibaudgg,mperham
1949,2014-09-17 06:34:58,"No I'm not pushing jobs into Redis manually there, it seems to only happens on jobs that have a retry count > 1 so maybe the `""enqueued_at""` is wrongly set in the retry process somewhere... 

@seuros thanks for the quick fix!
",thibaudgg,seuros
1946,2014-09-29 09:49:31,"@kosh-jelly We are only running around 30 threads. The issue still persists unfortunately.

I posted a few more details here: http://stackoverflow.com/questions/26096939/ruby-http-not-threadsafe-hangs-at-tcpsocket - The problematic line is: https://github.com/ruby/ruby/blob/ruby_2_1/lib/net/http.rb#L879

Unfortunately this really exceeds my knowledge of ruby.  @mperham Have a you had somebody using ruby to crawl websites before? What did he/she use? Thanks!
",hendricius,kosh-jelly
1946,2014-09-29 09:49:31,"@kosh-jelly We are only running around 30 threads. The issue still persists unfortunately.

I posted a few more details here: http://stackoverflow.com/questions/26096939/ruby-http-not-threadsafe-hangs-at-tcpsocket - The problematic line is: https://github.com/ruby/ruby/blob/ruby_2_1/lib/net/http.rb#L879

Unfortunately this really exceeds my knowledge of ruby.  @mperham Have a you had somebody using ruby to crawl websites before? What did he/she use? Thanks!
",hendricius,mperham
1943,2014-09-10 22:31:33,"@ryansch that's a good point. That'd probably be a deal-breaker if Sidekiq intends to support parallel testing. If it is, perhaps it would be better to keep it similar to how it was before but simply use `klass.execute_job(worker, args)` instead of `worker.perform`. That should at least keep the consistency of `execute_job` and not lose thread-safety? (I have no idea if it's trivial or difficult to add thread-safety to an implementation that relies on `perform_one`.)
",aprescott,ryansch
1943,2014-12-18 18:09:18,"@mperham is this no longer being considered for merging?
",aprescott,mperham
1939,2014-09-10 17:59:22,"Will do, thank you @mperham !
",darkside,mperham
1938,2014-09-10 14:53:03,"Thanks @aprescott. But the objective here is not to support keyword args. That's my use case, but it's to provide an API that allows a relatively easy way to override how perform is called, for any use case.
",jejacks0n,aprescott
1938,2014-09-10 16:28:54,"@mperham two things, not part of a gem, but something I'll likely gist about -- and I'm fine making them protected or something else. Like I said, it's really more about allowing this by simply breaking out the code that determines worker, and builds args from the part that calls it.

I like `execute_job`, and will change this PR to reflect that, along with providing some tests. Would you merge it if I did this?
",jejacks0n,mperham
1938,2014-09-10 17:16:14,"@mperham thanks for your time, and the library!
",jejacks0n,mperham
1938,2014-09-10 19:31:16,"@aprescott awesome! that's basically what the intention is. =)

If there are smaller, more direct methods it'll make it easier to reopen/extend functionality. I only had this specific need, and there's some additional thought in how it can be abstracted so it's not part of the class methods (eg. a service object that knows how to deal _only_ with the worker), but that's something to discuss and formulate ideas about first.

I'd be happy to take the concept a bit further in a different pull request if @mperham has ideas of how to approach that in general, but am happy to leave it as is too. =)
",jejacks0n,mperham
1938,2014-09-10 19:31:16,"@aprescott awesome! that's basically what the intention is. =)

If there are smaller, more direct methods it'll make it easier to reopen/extend functionality. I only had this specific need, and there's some additional thought in how it can be abstracted so it's not part of the class methods (eg. a service object that knows how to deal _only_ with the worker), but that's something to discuss and formulate ideas about first.

I'd be happy to take the concept a bit further in a different pull request if @mperham has ideas of how to approach that in general, but am happy to leave it as is too. =)
",jejacks0n,aprescott
1938,2014-10-19 19:10:57,"@mperham wondering when this might get merged into sidekiq pro? Have been waiting on that before moving forward with a few internal adjustments.
",jejacks0n,mperham
1933,2014-09-09 15:21:00,"@seuros Absolutely right but I don't see any alternative in this case.  We need to use deliver_now in Rails 4.2 to avoid that warning.
",mperham,seuros
1931,2014-09-08 15:55:02,"@mperham Thanks for the answer, I took a better look on it, makes sense, sorry, my mistake. I wanted to use the same interface but with different connection, and that doesn't make sense at all. :(

I want to be able to use the connection pool connection to store and retrieve keys without using the default namespace of the connection (`sidekiq`), but I still want Sidekiq's to store it's data normally in the namespace. But I imagine it's not possible at this moment. 

@seuros Thanks, but I want to use a different namespace but only for specific cases inside my code.
",estevaoam,seuros
1931,2014-09-08 15:55:02,"@mperham Thanks for the answer, I took a better look on it, makes sense, sorry, my mistake. I wanted to use the same interface but with different connection, and that doesn't make sense at all. :(

I want to be able to use the connection pool connection to store and retrieve keys without using the default namespace of the connection (`sidekiq`), but I still want Sidekiq's to store it's data normally in the namespace. But I imagine it's not possible at this moment. 

@seuros Thanks, but I want to use a different namespace but only for specific cases inside my code.
",estevaoam,mperham
1930,2014-09-09 08:40:30,"@keithpitt thanks for pointing out. Should we better close this one, and track this problem on #1929 instead?
",samnang,keithpitt
1929,2014-09-08 07:53:31,"@mperham I've seen this today as well. I'm currently using this to restart sidekiq:



And in the log I just get this:



Is there something you'd like me to try? This is what I'm seeing when I run `ps aux` - I've got 2 rogue sidekiq processes there.



(Note, there are 2 sidekiq processes there from the 2 previous deploys I did)
",keithpitt,mperham
1929,2014-09-08 12:52:55,"+1

`sidekiq 2.17.7 xpto [0 of 25 busy] stopping`

@keithpitt same env here
",plentz,keithpitt
1929,2014-09-08 14:24:36,"@mperham maybe we should release 3.2.5 with a lock ? WDYT ?
",seuros,mperham
1929,2014-09-08 15:17:50,"@mperham any updates? any release? 
",sahin,mperham
1927,2014-09-05 16:43:13,"@mperham not sure what to tell you! The log shows no sign of any retries being attempted for that job, until the manual retry when `DEBUG: enqueued retry` shows up.
",aprescott,mperham
1927,2014-09-05 17:33:49,"@aprescott  : Same Timezone  ?
",seuros,aprescott
1927,2014-09-05 17:34:07,"@seuros same timezone, yes, although I'd have thought we'd be on UTC everywhere for Sidekiq purposes?
",aprescott,seuros
1927,2014-09-08 23:10:25,"@aprescott Can you repro with a trivial Rails app?
",mperham,aprescott
1923,2014-09-04 13:49:34,"@seuros Actually, I'm on Rails 4.1.5

Whatever change was made to break `__send__` affects 4.1 too. I just looked at edge to see how they were handling their own delivery jobs.
",pbhogan,seuros
1921,2014-09-08 16:16:41,"@mperham @seuros Sorry that I forgot to update the thread in time. After changing to 2.1.2, it had crashed once and running OK for the rest of days ( like 4 days ). So I think I could say it's all right for now.

I think I could close this thread for now, and maybe reopen it when the error comes back again.

Thanks you all for the help.

Larry
",larryzhao,seuros
1921,2014-09-08 16:16:41,"@mperham @seuros Sorry that I forgot to update the thread in time. After changing to 2.1.2, it had crashed once and running OK for the rest of days ( like 4 days ). So I think I could say it's all right for now.

I think I could close this thread for now, and maybe reopen it when the error comes back again.

Thanks you all for the help.

Larry
",larryzhao,mperham
1919,2014-09-01 03:16:18,"@aprescott It's an ""opt-in with foreknowledge"" vs ""let's hope it doesn't break"" approach.

@jonhyman Any chance you can test this week?  A successful real world smoke test would make me more comfortable with rolling it into `jobs` directly.
",mperham,aprescott
1919,2014-09-01 03:16:18,"@aprescott It's an ""opt-in with foreknowledge"" vs ""let's hope it doesn't break"" approach.

@jonhyman Any chance you can test this week?  A successful real world smoke test would make me more comfortable with rolling it into `jobs` directly.
",mperham,jonhyman
1919,2014-09-04 20:57:29,"@mperham We've created a few hundred batches since my last comment, I think we're good for 1.8.0 if you want to release it now.
",jonhyman,mperham
1917,2014-09-29 16:46:34,"@subelsky Brilliant. That's a great solution.
",mperham,subelsky
1916,2014-08-31 14:11:43,"@mperham thanks，we will upgrading。
",leyafo,mperham
1916,2014-09-10 07:28:46,"Hi @mperham. we upgrade to 2.17.7, which has the same problem.
",leyafo,mperham
1916,2014-09-10 13:16:05,"@mperham What's celluloid?
",leyafo,mperham
1916,2014-09-10 14:24:56,"@seuros  Ok，I will try it.

## 

Join
Sent with Sparrow (http://www.sparrowmailapp.com/?sig)

On Wednesday, September 10, 2014 at 9:23 PM, Abdelkader Boudih wrote:

> this : https://github.com/celluloid/celluloid
> in your gemfile
> gem 'celluloid', '0.15.2'
> 
> —
> Reply to this email directly or view it on GitHub (https://github.com/mperham/sidekiq/issues/1916#issuecomment-55113945).
",leyafo,seuros
1916,2014-09-29 07:19:34,"@mperham  Thanks
",leyafo,mperham
1914,2014-08-27 20:49:41,"@mperham 

I got your points. I think some people would love to have little cost of linear scanning etc etc to have a better UI while they are using the UI which is very low overhead in redis. 

I know(installed/use) all the extensions in the extension wiki page :). sidekiq_monitor is good but they have mysql dependency.

So I will go for a building a different gem, if people like it, I will bring into your reconsideration. 
",sahin,mperham
1913,2014-08-26 20:35:11,"@mperham can you share the steps to create application.js from its component libraries? Is it just normal concatenation or some other changes are made? What are the two libraries? Is it jquery and jquery-timeago? 

Also how about dashboard.js?
",pravi,mperham
1913,2014-09-09 16:13:30,"@seuros , I just used a simple cat during deb package build time (each min.js come from a package of its own and they are generated from their normal js file during their package build). 

cat /usr/share/javascript/jquery/jquery.min.js /usr/share/javascript/jquery-timeago/jquery.timeago.min.js > web/assets/javascripts/application.js

cat /usr/share/javascript/d3/d3.min.js /usr/share/javascript/rickshaw/rickshaw.min.js > web/assets/javascripts/dashboard.js

My requirements are satisfied (hopefully it is enough to satisfy debian ftpmasters too). Thanks for all the inputs.
",pravi,seuros
1912,2014-08-26 14:50:12,"I've tried it and it works:
https://github.com/cristianbica/test-aj-sidekiq.git







sidekiq.log



development.log



PS: @seuros I still like the autoloading stuff in rails and you should leave the PR there :)
",cristianbica,seuros
1910,2014-08-22 16:21:21,"@aprescott it won't affect non-Rails project. 

@mperham I think we can clean up a little more while still on 3.x without breaking anything. But i think we should turn off the monkeypatching by default. Something like we did in RSpec with the `.should` syntax. 
We should encourage users to create workers instead of using the delay. 
With the introduction of AJ in 4.2, we have deliver_now and deliver_later. So delay became obsolete in ActionMailer. 
",seuros,mperham
1910,2014-08-22 16:21:21,"@aprescott it won't affect non-Rails project. 

@mperham I think we can clean up a little more while still on 3.x without breaking anything. But i think we should turn off the monkeypatching by default. Something like we did in RSpec with the `.should` syntax. 
We should encourage users to create workers instead of using the delay. 
With the introduction of AJ in 4.2, we have deliver_now and deliver_later. So delay became obsolete in ActionMailer. 
",seuros,aprescott
1909,2014-08-22 15:56:03,"I'm reluctant to pull in features that no one is asking for.  The syntax for creating a worker is already so lightweight that this is really optimizing something which isn't painful in the first place.

@aprescott Worker is what we're stuck with now, for legacy reasons.  If I had to do it all over again, I'd seriously consider using Job instead.
",mperham,aprescott
1909,2014-08-22 15:57:55,"@mperham under the assumption that this generator would even exist (I've never needed one, personally), would it not make sense to push for the preferred naming convention of Job over Worker? I know the name doesn't actually matter to Sidekiq, but consistency between Sidekiq ""install""s on common naming patterns is good to have I think.
",aprescott,mperham
1909,2014-08-22 16:14:00,"@aprescott This is a WIP. I know it easy to create a worker, but the generator will generate/destroy the test file too.
I often create a worker and forget to add test for it. With this generator, i will have pending tests since the files will be present but empty.

@mperham I prefer if we keep worker since we could have /jobs for activejobs and /workers for sidekiq workers. The /jobs folder will be know to contain cross-backend jobs, while the worker folder will have sidekiq specific workers.
",seuros,mperham
1909,2014-08-22 16:14:00,"@aprescott This is a WIP. I know it easy to create a worker, but the generator will generate/destroy the test file too.
I often create a worker and forget to add test for it. With this generator, i will have pending tests since the files will be present but empty.

@mperham I prefer if we keep worker since we could have /jobs for activejobs and /workers for sidekiq workers. The /jobs folder will be know to contain cross-backend jobs, while the worker folder will have sidekiq specific workers.
",seuros,aprescott
1909,2014-08-22 17:15:54,"@mperham, can you review the new commit ? especially the minitest template. 
This implemetation is working, but we should later use `hook_for :test_framework` instead of these methods.
",seuros,mperham
1906,2014-08-25 14:21:31,"@seuros ,I use cliver (0.3.2) that's latest version.
",Keita-N,seuros
1906,2014-08-25 14:55:29,"@seuros , I tried cliver(0.3.1) and (0.2.1). but got the same result.
",Keita-N,seuros
1904,2014-08-19 14:47:27,"@seuros Having a different queue for each priority and using strict priorities could accomplish some of this, but anytime a new priority is needed it would require a code push to update the queues config. Is there a different way that you can see to accomplish this that I'm just missing?
",bobbrez,seuros
1903,2014-08-19 15:42:50,"@seuros Notice the first two look like spikes.  That's an increment by one.  The latest one is flat on top because it incremented by 1 twice.
",mperham,seuros
1903,2014-08-19 19:50:28,"@seuros I suppose I can make a video instead. During that last spike one job was processed but the count went from 19 to 21. I'm not using Sidekiq Pro. No callbacks the code that is running is:



It's the same as the previous jobs, but this one takes longer, however I should probably remove the long running external call of the job to test the same code, perhaps it isn't the length of time. That just seemed like a good first guess.
",chrisnicola,seuros
1900,2014-08-16 18:06:31,"Makes sense!  Thanks for the thoughts @mperham 
",shedd,mperham
1897,2014-08-13 12:14:50,"@seuros Yeah, looks awesome
So, I should repair tests first :) 
![53eb568838d387458063d5c3](https://cloud.githubusercontent.com/assets/417317/3905121/57d46960-22e3-11e4-983d-f41a17730601.png)

![53eb56260077911c01b4fee8](https://cloud.githubusercontent.com/assets/417317/3905111/285a23d2-22e3-11e4-8a22-afcf8c217a68.png)
",davetoxa,seuros
1897,2014-08-13 15:49:24,"Thanks!

@seuros If you merge a feature or bug fix, would you also be sure to add a note to Changes.md?  For example, this deserves a note but 1898 would not.
",mperham,seuros
1897,2014-08-13 15:51:44,"@mperham , i got distracted, sorry. I already did it , i can push it once i return to my computer.
",seuros,mperham
1894,2014-08-12 20:34:34,"Thanks @mperham, working fine.
I had already tested `retry: 0` but dead queue don't update in dashboard web monitor.
The stats request (/sidekiq/dashboard) don't return dead queue.


",rodolfospalenza,mperham
1892,2014-08-12 19:06:10,"@aprescott , I try to the best design possible... Let me see how it looks like. If we separate it, it will motivate people to update their gem for < 3.2

@seuros, you are right, but there is smth important here, even the list is open to contribute, it is under sidekiq or @mperham so It is some kind of reference. 

I remember that I downloaded so many of these gem, didnt work, lose workers's jobs, sidekiq didnt work etc etc. I am sure, I am not the only one. so it will be good have some kind of indication of the quality. maybe test coverage not code climate. 
",sahin,mperham
1892,2014-08-12 19:06:10,"@aprescott , I try to the best design possible... Let me see how it looks like. If we separate it, it will motivate people to update their gem for < 3.2

@seuros, you are right, but there is smth important here, even the list is open to contribute, it is under sidekiq or @mperham so It is some kind of reference. 

I remember that I downloaded so many of these gem, didnt work, lose workers's jobs, sidekiq didnt work etc etc. I am sure, I am not the only one. so it will be good have some kind of indication of the quality. maybe test coverage not code climate. 
",sahin,seuros
1892,2014-08-12 19:06:10,"@aprescott , I try to the best design possible... Let me see how it looks like. If we separate it, it will motivate people to update their gem for < 3.2

@seuros, you are right, but there is smth important here, even the list is open to contribute, it is under sidekiq or @mperham so It is some kind of reference. 

I remember that I downloaded so many of these gem, didnt work, lose workers's jobs, sidekiq didnt work etc etc. I am sure, I am not the only one. so it will be good have some kind of indication of the quality. maybe test coverage not code climate. 
",sahin,aprescott
1891,2014-08-15 12:29:05,"@mperham :+1: 
",davetoxa,mperham
1889,2014-08-10 20:30:31,"Thanks for the feedback!

@seuros I tried out a middleware solution ( https://gist.github.com/samsm/d05203adc8c4c89ca829 )
I don't think it would work without allowing one process to kill other processes, but maybe I'm being narrow-minded about that. The middleware is a cool feature.

@mperham I think what you are saying is correct about Heroku's treatment of workers defined in a Procfile and run through the `heroku scale worker=5` mechanism, but is incorrect about jobs run via `heroku run sidekiq ...` or `heroku run:detached sidekiq ...` or through the Heroku scheduler. Heroku just runs those one time and does not attempt to restart them if they stop for any reason. Whenever they exit, you stop paying for their resources.

Let me know if that changes your perspective at all. Also, I am far enough in that I probably will just go ahead and make a monkey-patched gem, so perhaps it's all a moot point. :-)
",samsm,seuros
1889,2014-08-10 20:30:31,"Thanks for the feedback!

@seuros I tried out a middleware solution ( https://gist.github.com/samsm/d05203adc8c4c89ca829 )
I don't think it would work without allowing one process to kill other processes, but maybe I'm being narrow-minded about that. The middleware is a cool feature.

@mperham I think what you are saying is correct about Heroku's treatment of workers defined in a Procfile and run through the `heroku scale worker=5` mechanism, but is incorrect about jobs run via `heroku run sidekiq ...` or `heroku run:detached sidekiq ...` or through the Heroku scheduler. Heroku just runs those one time and does not attempt to restart them if they stop for any reason. Whenever they exit, you stop paying for their resources.

Let me know if that changes your perspective at all. Also, I am far enough in that I probably will just go ahead and make a monkey-patched gem, so perhaps it's all a moot point. :-)
",samsm,mperham
1888,2014-08-12 16:36:23,"@ryansch How's this look?  The current behavior will create an empty batch if the bid is nil which is bad.  This will return nil instead.


",mperham,ryansch
1881,2014-08-06 18:37:24,"@mperham Thank you for your quick respond.  
",joshidhruv,mperham
1881,2014-08-06 18:41:19,"@mperham I have one more question about worker in heroku if you have any idea. is there any way to tell sidekiq process to restart/reopen/close after you reach some memory peak. heroku gives me R14 Error which is Exceed Memory. There is lot if question out there but not a single good solution.
",joshidhruv,mperham
1876,2014-08-05 18:10:50,"@mperham 

I've tried but no result. Process name didn't change.



![screen02](https://cloud.githubusercontent.com/assets/415928/3816092/85949c26-1ccb-11e4-9452-376bb67f0c29.png)
",targence,mperham
1876,2014-08-06 11:10:55,"@mperham, @seuros 

I've found a way how to use labels. I'ts ok for me.





![ewrwer](https://cloud.githubusercontent.com/assets/415928/3825909/00dac7aa-1d5a-11e4-9316-a0a62f53b56c.png)
",targence,seuros
1876,2014-08-06 11:10:55,"@mperham, @seuros 

I've found a way how to use labels. I'ts ok for me.





![ewrwer](https://cloud.githubusercontent.com/assets/415928/3825909/00dac7aa-1d5a-11e4-9316-a0a62f53b56c.png)
",targence,mperham
1867,2014-07-29 12:58:41,"wow, that was fast! thanks @seuros @mperham !
",subelsky,seuros
1867,2014-07-29 12:58:41,"wow, that was fast! thanks @seuros @mperham !
",subelsky,mperham
1857,2014-07-22 03:49:36,"@mperham , we dont use any extension or delayedjob... This is happening the web UI and 

we are getting this error in the retries tab or in dead jobs tab. 
in UI is says Internal Server Error ,

 the stacktrace I copied was from nginx's error log. 
",sahin,mperham
1856,2014-07-21 20:56:59,"@seuros yes, it was a fresh deploy, new branch and everything

Here's my initializer: 



REDIS_HOST gets written as ""localhost"" for these tests.

Here's my Gemfile:


",AndydeCleyre,seuros
1856,2014-07-21 21:10:50,"@seuros alright, I'll try to give that a shot if I can, but right now resque is part of our project.

Here's the error:


",AndydeCleyre,seuros
1856,2014-07-21 21:21:42,"@seuros It's probably not a good idea to tell people to remove gems from their app unless we have data that leads us to believe it's a possible cause.

@AndydeCleyre Can you pop into rails console and execute a delay or a sidekiq_delay or do you get the same error?


",mperham,seuros
1856,2015-02-28 03:40:50,"@mperham  is there any way by which delay instance method to get work with normal class objects(not active record)?
",sachin87,mperham
1856,2015-02-28 03:50:24,"Nope. Jobs should be simple arguments, not complex stateful Ruby objects. 

> On Feb 27, 2015, at 19:40, Sachin Singh notifications@github.com wrote:
> 
> @mperham is there any way by which delay instance method to get with normal class objects(not active record)?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1849,2014-07-17 16:51:23,"If you think you can do a better ui design, i think @mperham won't be against. But the logo should stay.
",seuros,mperham
1846,2014-09-08 13:11:26,"@mperham Without knowing how extensive implementation work would be, I'd argue this violates the principle of least surprise. 

When running Sidekiq tests inline or draining them, especially as client middleware is run, I'd expect server middleware to run. It's essentially already an integration test at the point of providing inline/drain, just with an important caveat that one of two types of middleware won't run. 

And this middleware can be very important to test as it often has impacts on guarantees you can make about your system (environment-dependent information, multi-tenancy, etc…).

I'd love to hear if I'm misunderstanding something.
",jpcody,mperham
1845,2014-07-15 06:15:05,"Agree with the api of `done?` not being *stable nor public.

Track progress as the job runs and sure when it is killed then we will have the latest checkpoint even in the case that 100 items takes more than `:timeout` number of seconds to process. Thanks @mperham
",bnorton,mperham
1843,2014-07-12 12:41:05,"Super!

Thanks for your help with this @seuros.  I'll rework the implementation and get some tests around it today or tomorrow.
",mikegee,seuros
1843,2014-07-14 01:13:28,"We just rely on our logs for this. Sidekiq's dashboard is helpful put it's useful to dig into the logs for a stack trace, surrounding info messages, etc. I'm with @mperham here, I don't think it should have a specialized config option for what is essentially log info. 
",jonhyman,mperham
1843,2014-07-14 01:18:47,"@mikegee ignore earlier comment. Didn't see full thread in my email. 
",jonhyman,mikegee
1843,2014-07-14 01:57:17,"@mikegee The point is to avoid lots of little flags for every possible edge case.  Sidekiq's mantra is ""simple, efficient"".  Simplicity is achieved not by adding features but by explicitly not adding them where possible.  Sometimes that means we don't handle rare edge cases perfectly.

Error messages shouldn't be megabytes in size.  The root error is elsewhere and I don't want to complicate Sidekiq mitigating it.
",mperham,mikegee
1839,2014-07-19 13:58:02,"@mperham 







(I didn't delete anything)
The unlisted repos, i'm not sure about their fate. 
",seuros,mperham
1832,2014-07-08 13:39:06,"@seuros not really :(

What can I say is that we have 432 models on it and a lot of subfolders. What exactly are you looking for?
",sobrinho,seuros
1831,2014-07-07 20:33:33,"@seuros yeah that's too much of a hack for my liking ;) also, it's not completely reliable, as there is a chance of losing the job between the Redis pop instruction and the saving of the params.

@jonhyman yeah man it looks great, but I use it in maybe 10 apps that are in production. I can't go drop $7,500 to cover them all, and then continue to up that by $750 every time I deploy something new.
",ryana,seuros
1831,2014-07-07 20:33:33,"@seuros yeah that's too much of a hack for my liking ;) also, it's not completely reliable, as there is a chance of losing the job between the Redis pop instruction and the saving of the params.

@jonhyman yeah man it looks great, but I use it in maybe 10 apps that are in production. I can't go drop $7,500 to cover them all, and then continue to up that by $750 every time I deploy something new.
",ryana,jonhyman
1831,2014-07-07 20:41:33,"@mperham good to know about the $750/company. I guess technically all but 1 of those apps fall under the umbrella of one LLC (not clients of that LLC).... Interesting. I'll consider that.

Thanks!
",ryana,mperham
1813,2014-06-30 05:25:14,"@mperham Will do!
",sentience,mperham
1813,2014-06-30 07:15:03,"How’s that look, @mperham? I’ve made the tests show up as pending on Ruby < 2.1.0, since they cannot pass without `Exception#cause`.
",sentience,mperham
1810,2014-06-30 22:56:02,"@seuros Thank you so much for your help.
",mperham,seuros
1809,2014-06-29 05:39:27,"@mperham my sidekiq in my deploy script looks like this:

set :sidekiq_cmd, ""bundle exec sidekiq""
set :sidekiqctl_cmd, ""bundle exec sidekiqctl""
set :sidekiq_timeout, 10
set :sidekiq_role, :app
set :sidekiq_pid, ""#{current_path}/tmp/pids/sidekiq.pid""
set :sidekiq_processes, 2 

So to answer your question, yes it appears so. How would that affect a spike in db connections?
",JohnMerlino1,mperham
1809,2014-06-29 05:48:17,"@mperham What I don't understand is if my rails application set pool size to 50 for the postgresql database. Then why are more connections being used than the limit specified? Shouldn't they just start to block once 50 connections have been made?
",JohnMerlino1,mperham
1809,2014-06-29 05:56:18,"@mperham ok I am using Phusion Passenger/apache. I am not using the preworker multi-threaded module. I am using the prefork module, which spawns a process with a single thread. Just to confirm, since you seem knowledgeable on the subject, for each tcp connection to my web server, does that spawn a single process which means 50 connections for each process? Or does the Ruby on Rails application itself use at most 50 connections?
",JohnMerlino1,mperham
1807,2014-06-28 23:23:20,"@mperham well, guess that's the good news...it should work

bad news, not for me

any suggestions on how to troubleshoot?

i should note that i can queue and run jobs async just fine from a worker dyno on heroku, but does not work in the web dyno
",cscairns,mperham
1807,2014-06-28 23:36:10,"Give me more info. Initializer, config file, worker code, etc. how do you know the job isn't getting to Redis?

> On Jun 28, 2014, at 16:23, Chris Cairns notifications@github.com wrote:
> 
> @mperham well, guess that's the good news...it should work
> 
> bad news, not for me
> 
> any suggestions on how to troubleshoot?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1806,2014-07-07 21:23:50,"@mperham I guess I am not sure at which point I should define the conditional Redis connection depending on the environment.

Let's say I am just using the por example: https://github.com/mperham/sidekiq/blob/master/examples/por.rb 

If I do the conditional `if environment` right before defining the worker class, I get an `undefined local variable or method `environment' for main:Object`

At which point should we define the configuration of Sidekiq depending on the environment so that the script knows what 'environment' is?
",novito,mperham
1804,2014-06-30 01:36:41,"Thank you very much @mperham  and @tarcieri. I got it. 
",arthurbryant,mperham
1798,2014-09-25 12:24:14,"@mperham It is NOT caused by Typhoeus, please be careful in future when to advice things or not. It is in fact a libcurl issue that typhoeus is making use of and has been fixed quite a time ago.
",mcb,mperham
1796,2015-04-30 08:13:26,"I've got the same issue that happens from time to time with 1 of the worker we developed.

@tonkapark Do you confirm the issue disappeared once you upgraded to Ruby 2.1.1 ?

@mperham Could you please elaborate a bit on the root cause of this issue when using Sidekiq 3.x with Ruby 1.9.3 if you know what it is ?
",lfarcy,mperham
1791,2014-07-04 21:13:16,"Right, I've realised that the solution I suggested is only compatible with Rails 4+, since `config.eager_load` was only added in Rails 4. Sorry about that. @mperham what do you want to do? I guess the options are:
1. Drop support for Rails 3.2
2. Add extra hacks to support both Rails 3.2 and Rails 4+
",jonleighton,mperham
1791,2014-07-04 21:33:18,"I can't really drop 3.2 without a major version bump. When does 3.2 go EOL?

> On Jul 4, 2014, at 14:13, Jon Leighton notifications@github.com wrote:
> 
> Right, I've realised that the solution I suggested is only compatible with Rails 4+, since config.eager_load was only added in Rails 4. Sorry about that. @mperham what do you want to do? I guess the options are:
> 
> Drop support for Rails 3.2
> Add extra hacks to support both Rails 3.2 and Rails 4+
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1791,2015-08-19 13:45:54,"Had a custom directory inside `app/models` (eg. `app/models/foo-bar/`) that was throwing errors when starting Sidekiq in development.



Doing exactly what @ryansch resolved it.
",shime,ryansch
1786,2016-09-08 00:35:08,"A small tweak to @timdorr's patch - this relies on `super` to help ensure you'll pick up future changes to Sidekiq's server logging. In this case including the ""BID"" in the logging.
https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/middleware/server/logging.rb


",Empact,timdorr
1784,2014-11-24 23:53:05,"@mperham I'm using the latest version of timers gem (4.0.1). Any ideas what else could be causing it? 
",e-fisher,mperham
1782,2014-06-16 17:17:40,"@tdantas That doesn't make a difference. What @aprescott says is correct. 
",etagwerker,aprescott
1782,2014-06-16 17:29:06,"@mperham Interesting! The code you pasted works for me. 

Does it use `ConnectionPool` automatically? The complexity in my code was so that Sidekiq used the `connection_pool` gem. 
",etagwerker,mperham
1782,2014-06-16 17:32:28,"@mperham Awesome. Thanks, Mike! 
",etagwerker,mperham
1778,2014-06-20 20:28:37,"@mperham I did some experimenting with a global method or as a configuration option, but there's definitely some friction. Consider the following, simplified example extracted from `test/test_extensions.rb`:



Ideally, we'd like to be able to put a call to `Sidekiq.disable_extensions!` at `Mark 2 which would then lead to a NoMethodError exception at Mark 3.

Since no other Sidekiq code executes between `Mark 2` and `Mark 3`, I see a limited number of options for how `Sidekiq.disable_extensions!` could work.

The simpliest, but potential very impactful, option I tried involved overriding `Object#method_missing` and then when `SomeClass.delay` is called, check if extensions are enabled. If they are, include them using the `Sidekiq.run_extension_load_hooks` method from this PR.
Here's the implementation: https://github.com/hundredwatt/sidekiq/commit/17d134b577121ceabea48f192e6f67688afecceb

One problem is the tests won't pass if run together. To get it to work, the two disabling extensions related tests must be run in a separate process since there's interaction with what code is loaded.

A couple other options for consideration:
1. Use meta-programming to undefine all the extension methods individually. This could be really messing and cause problems if other ancestors define, eg: `#delay`
2. When `SomeClass.delay` is called, check to see if extensions are enabled and then do the right thing. This is also complicated and my gut feel is that there are a number of edge-cases not covered. Here's an (untested) sample implementation:



(This could easily be extracted into its own macro to replace `alias_method`)

Any suggestions or feedback?
",hundredwatt,mperham
1778,2014-06-20 20:47:16,"@mperham What about https://github.com/hundredwatt/sidekiq/commit/17d134b577121ceabea48f192e6f67688afecceb, specifically: https://github.com/hundredwatt/sidekiq/blob/17d134b577121ceabea48f192e6f67688afecceb/lib/sidekiq/extensions/object.rb?

I decided to put the `Sidekiq.run_extension_load_hooks!` in Object#method_missing so it would work outside of Rails. This could easily be adapted to the approach you described with a `startup` event that includes the extensions as long as `disable!` hasn't been called.

Seems like the ideal approach might be:

For Rails applications: use your approach

For non-Rails applications: Don't load the extensions by default

Other than that, I don't see a way to have the extensions load by default AND be disable-able without meta-programming / doing what I did in my example.
",hundredwatt,mperham
1778,2014-06-28 22:22:18,"@mperham leveraging `remove_delay!`, this commit patches extension loading so we can prevent the extensions from ever being loaded in a Rails app: https://github.com/hundredwatt/sidekiq/commit/8cf0bf447c690e5681f4b25efa9dc17559f7968a

That would complete the approach we described above. Thoughts?
",hundredwatt,mperham
1778,2014-06-28 22:49:26,"@mperham wiki updated: https://github.com/mperham/sidekiq/wiki/Delayed-extensions. Thanks for your feedback, this was an interesting exploration!
",hundredwatt,mperham
1764,2014-06-05 18:31:54,"@mperham ahh makes sense. These are the only 2 workers running on heroku, have moved everything else to other platforms
",subelsky,mperham
1762,2014-07-01 04:09:12,"@mperham Awesome, thanks. Any plans of doing a release?
",kapso,mperham
1762,2014-07-01 04:10:45,"Sometime in the next week. 

> On Jun 30, 2014, at 21:09, Kapil notifications@github.com wrote:
> 
> @mperham Awesome, thanks. Any plans of doing a release?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1744,2014-06-01 11:56:05,"@mperham this change assumes that we have a worker monitoring the default queue. After upgrading to 1.7.2, I woke up this morning to a default queue full of `Sidekiq::Batch::Lifecycle` jobs, not sure how I can process them other than by adding `-q default` to my sidekiq initialization command
",subelsky,mperham
1744,2014-06-01 13:09:07,"Yep, I had a bad feeling about releasing this as a patchlevel. Sorry, i'll fix today. 

> On Jun 1, 2014, at 4:56, Mike Subelsky notifications@github.com wrote:
> 
> @mperham this change assumes that we have a worker monitoring the default queue. After upgrading to 1.7.2, I woke up this morning to a default queue full of Sidekiq::Batch::Lifecycle jobs, not sure how I can process them other than by adding -q default to my sidekiq initialization command
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1736,2014-05-27 12:39:23,"hey @mperham ,
have you ever try to set trim mode in the App ? maybe theses trim problems could be solved at all.   

@subelsky  try it yourself just to verify if it helps you.  
find your sidekiq gem



open in your editor the file in gem **sidekiq/web.rb** and insert this line   



as below


",tdantas,subelsky
1736,2014-05-27 12:39:23,"hey @mperham ,
have you ever try to set trim mode in the App ? maybe theses trim problems could be solved at all.   

@subelsky  try it yourself just to verify if it helps you.  
find your sidekiq gem



open in your editor the file in gem **sidekiq/web.rb** and insert this line   



as below


",tdantas,mperham
1736,2014-05-27 13:40:13,"Got it, I think it's something Rails configures globally: `ActionView::Base.erb_trim_mode='%<>-'` to activate all the trim options in ERB.  Notice that @subelsky isn't using Rails whereas my test suite does reference Rails.
",mperham,subelsky
1736,2014-05-27 13:44:52,"Hey ! @mperham  amazing. Using  **set :erb, { trim: '-' }** didn't not work ?  
Sinatra uses Tilt, and every render it will initialize the proper engine and pass options.   

Nice work !
",tdantas,mperham
1736,2014-05-27 14:00:58,":thumbsup:  yeah ! got it !
The ideia was just to prevent future PR with ERB trim configured in the views.
@subelsky could you try to verify if it works on your code ? setup the **set :erb, { trim: '-' }** on sidekiq/web.rb ?
",tdantas,subelsky
1709,2015-10-02 10:38:52,"@mperham Sorry to bother you with an already closed issue. 

I think this should be implemented even if you think it's a smell. There are a number of custom queues created by third party code there are out of user control. I was recently bitten by a typo in `config/sidekiq.yml`, I wrote `mailer` instead of `mailers` and all my messages remained in queue because of this.

There are lot of gems ([ActionMailer](https://github.com/rails/rails/blob/10d0c43c7937f65b2fc6fb87a87b1023bbd85674/actionmailer/lib/action_mailer/delivery_methods.rb#L20), [rollbar](https://github.com/rollbar/rollbar-gem#using-sidekiq), [searchkick](https://github.com/ankane/searchkick#stay-synced), [carrierwave_backgrounder](https://github.com/lardawge/carrierwave_backgrounder#installation-and-usage) to list some of them) that in their default configuration use named queues and if one doesn't list them (or make some errors) in sidekiq config their jobs won't be processed.
",fabn,mperham
1706,2014-05-15 21:02:41,"Thank you for the replies! :smiley:  
@aprescott I will try it. 
@mperham can you show me an example please? I don't understand what you mean with reusable Module.
",phlegx,mperham
1706,2014-05-15 21:02:41,"Thank you for the replies! :smiley:  
@aprescott I will try it. 
@mperham can you show me an example please? I don't understand what you mean with reusable Module.
",phlegx,aprescott
1706,2014-05-15 21:27:57,"Thank you @mperham! :smiley: 
",phlegx,mperham
1703,2014-05-14 06:08:03,"@mperham you should totally add this to the web UI. 
Also, would it make sense for redis get updated with the process state? If it is ""quiet"", it'd be nice to know that fact. 
",halorgium,mperham
1699,2014-05-20 14:35:11,"@mperham my first draft:
https://github.com/yelled3/sidekiq-activerecord

you're welcome to review it :-)
",yelled3,mperham
1699,2014-05-20 22:04:39,"@mperham i'm not 100% with the class names and some of the method names... WDYT?
",yelled3,mperham
1697,2014-05-13 16:35:00,"@mperham okdoki. Thank you!
",hendricius,mperham
1696,2014-05-12 13:51:34,"@jonhyman - Unfortunately I don't have the time in ms for those lines. The scenario you mentioned is possible. I will try to get higher resolution timestamp to prove it.
",motymichaely,jonhyman
1691,2014-05-09 23:37:20,"@mperham, thank you for your explanation. Sorry, yes, I realise I was confusing above by calling it the payload, when it is more metadata. I am glad to hear that Sidekiq is still compatible with Resque job payloads. I am a little disappointed that attempting to monitor Resque workers using the Sidekiq API or UI will no longer work; I am concerned that perhaps mixing Sidekiq with Resque might not be as straightforward if there is not an easy way to monitor both. However, it is, of course, your call. :)

I will give thought to which direction to take with regards to my own project, sidekiq-spy; up until now, I've been able to leverage the Sidekiq API. For this I am grateful :) , but I suspect I do consider being able to monitor both Resque and Sidekiq important for that project (and indeed I'd ideally like to be able to do so with the Sidekiq UI too—but that's already discussed :) ).
",tiredpixel,mperham
1679,2014-04-29 15:17:50,"@jonhyman thanks for the feedback, I'm just about done with a deployment that'll do the same.  I'll just close this issue as I can tell you from trying to use the Thread local for sidekiq_pool that the implementation would need to be totally changed especially to work with puma/jruby.
",dbelwood,jonhyman
1674,2014-04-25 05:34:30,"@mperham - you are right. I have tried ways to add a flag before extensions are added. 

BUT the gem loads into the stack before any flag / settings in initializers are called. So, for an end user to avoid those methods, he has to manually modify the gem and set the flag - Not possible.

Any thoughts / ideas? I will be happy to implement
",devaroop,mperham
1668,2014-04-23 13:34:58,"@mperham That was my original thought as well.  There is certainly some tension between the client/server domains and full stack testing.
",ryansch,mperham
1666,2014-04-25 00:56:51,"Hey @mperham the explanation is rather simple. If anybody anywhere defines a module called ActiveRecord in the codebase, then sidekiq will try to call .clear_active_connections! on Base, which may not even exist.

This patch may be overly pessimistic, but a good improvement would be to switch on the existence of ActiveRecord::Base, rather than ActiveRecord.
",Empact,mperham
1666,2014-04-25 03:11:23,"The correct thing to do is only inject the AR middleware upon AR initialization in the railtie. 

> On Apr 24, 2014, at 17:56, Ben Woosley notifications@github.com wrote:
> 
> Hey @mperham the explanation is rather simple. If anybody anywhere defines a module called ActiveRecord in the codebase, then sidekiq will try to call .clear_active_connections! on Base, which may not even exist.
> 
> This patch may be overly pessimistic, but a good improvement would be to switch on the existence of ActiveRecord::Base, rather than ActiveRecord.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1664,2014-04-22 03:15:34,"Got it. Thanks for the answer, @mperham.
",andrisetiawan,mperham
1660,2014-04-18 15:45:46,"@mperham oh, I hadn't even thought of that. I guess that's an argument for solving it in N places with ActiveSupport (or a gem with only the subset you want)? If most applications using Sidekiq also use Rails then for the majority of users it's not an added dependency. I obviously can't judge the downsides for non-Rails people though.

(Still want to throw a vote into getting batch support in testing though, all the same. :))
",aprescott,mperham
1660,2014-04-18 16:25:53,"@mperham since `perform_async` is caught by `inline!` testing, I guess I'm not too worried about that limitation. But consistency around `Hash#[]` with strings and symbols is probably preferable so that batches aren't a special case?
",aprescott,mperham
1660,2014-06-03 22:19:25,"As @aprescott stated in the issue #1757 that I opened, named parameters (a language implementation) have the same issue as regular-ole-symbol-hashes. 

So if it remains as no plans to implement, in my opinion, there also needs to be very clear documentation that ""Using named parameters is also not permitted for the N instances in the Sidekiq public API""
",chendrix,aprescott
1652,2014-04-14 18:10:48,"@mperham I think you can fix this with [`word-break: break-all`](http://css-tricks.com/almanac/properties/w/word-break/) on the `td`. You might need `word-break: break-word` for WebKit too.
",aprescott,mperham
1645,2014-04-13 23:47:09,"Thanks @seuros, this fixed my issue!
",marcqualie,seuros
1641,2014-04-14 07:40:50,"Hi @mperham 

Its not an application specific error. 
The reason for saying this is, I tried same code with same data at different places:
1. Linode Server
2. Production Env in local machine
3. Digital Ocean.

It works absolutely fine at 1 & 2. 
It doesn't work on digital ocean server. It works well sometimes and at times it produces above errors.
",nikunj0407,mperham
1640,2016-09-16 09:30:47,"@mperham is there any example file to completely setup sidekiq with `redis`, `rails 4`, `nginx`, `unicorn`.
",kaleemullah360,mperham
1639,2014-04-08 15:43:37,"@jonhyman Are you possibly sharing jobs between two different processes, i.e. the hostname, queue and index are all the same value so they share the same internal queue?
",mperham,jonhyman
1628,2014-04-18 04:07:16,"@subelsky Any word here?
",mperham,subelsky
1627,2014-09-12 18:48:38,"@mperham this doesn't work for me on Sidekiq 3.1.4 when I added it the following way:



I also dug into the source code and found a way to do it using the config object, but that didn't work either, and I forgot exactly what I did.
",wideopenspaces,mperham
1626,2015-05-05 06:10:39,"@mperham  Having the number of processed jobs per queue would also be very helpful - I don't think that is currently recorded/exposed; is it?
",Notalifeform,mperham
1624,2014-04-27 16:35:25,"I agree with @mperham...it's his library, he can use :heart: if he wants to :-) Maybe you can help fix the issue in Rubinius?
",headius,mperham
1619,2014-03-29 20:04:01,"@seuros https://github.com/mperham/sidekiq/wiki/Delayed-Extensions
",mperham,seuros
1614,2014-04-02 17:21:24,"@seuros will do.
",pawel2105,seuros
1612,2015-09-20 00:08:54,"@mperham just out of curiosity what library/tools would you suggest for really long running jobs (days or weeks, e.g. collecting twitter streaming data)?
",glampr,mperham
1603,2014-03-27 03:48:55,"@jonhyman I'm envisioning serious limitations with the sharding support.  Major features, like the API, will not support sharding and continue to work only with the global Redis pool.  You'll need to have a separate web process with the Sidekiq Web UI for each Redis server, the statistics will be completely separate, etc.  Reasonable?
",mperham,jonhyman
1603,2014-03-27 07:49:28,"@mperham yeah I know that I'll have to work around the global limitations (I already am working on separate rackup configs for the web UI here). I would hope eventually the global state could be removed and injected in for the API and everything else, though. Maybe for 4.0. ;)
",jonhyman,mperham
1597,2014-05-31 21:40:30,"@subelsky with ruby 2+, you can do 



Encoding.default_external is by default UTF8 if you ENV[""LANG""] has utf8
",seuros,subelsky
1597,2014-05-31 22:25:23,"To be clear, this is not something sidekiq can do for you. Gems should not be altering process-wide settings. That's what the application should do. 

> On May 31, 2014, at 14:40, Abdelkader Boudih notifications@github.com wrote:
> 
> @subelsky with ruby 2+, you can do
> 
> Encoding.default_internal = Encoding.default_external
> Encoding.default_external is by default UTF8
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,subelsky
1597,2014-06-01 08:55:18,"Sure, but this does not solve the issue with serialsation in redis. I think that's the core problem of this ticket, or? @mperham previously opened a ticket in the `redis-rb` repo. https://github.com/redis/redis-rb/issues/421
",hendricius,mperham
1594,2014-11-14 19:25:39,"@mperham I had the same question. It's not really specific to Heroku -- how do you wire up Sidekiq's stats to Librato? There's nothing in there docs I can see about how to directly send statsd info to them without using their REST API
",subelsky,mperham
1594,2014-11-14 19:43:54,"You'd need to run a custom Statsd process. Not sure if Heroku supports that or if you'd need something custom in ec2. 

> On Nov 14, 2014, at 11:25, Mike Subelsky notifications@github.com wrote:
> 
> @mperham I had the same question. It's not really specific to Heroku -- how do you wire up Sidekiq's stats to Librato? There's nothing in there docs I can see about how to directly send statsd info to them without using their REST API
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1589,2014-03-22 20:29:04,"@mperham yes, we run this as a standalone app. I can use this hack while awaiting 3.0.
",subelsky,mperham
1573,2014-03-21 14:41:59,"@mperham thank you! deploying this now!
",subelsky,mperham
1567,2014-03-16 11:04:46,"i think @godfat 's idea is good. We could make translation better within a context instead of looking simple word.
",weichienhung,godfat
1567,2014-03-16 11:59:50,"@mperham I think we probably shouldn't have two dialects for this, and I don't have strong opinions over my version, so it's ok to pick one over the other. If I knew there's one translation already, I wouldn't have tried to translate. So feel free to close this without merging.

@weichienhung Thanks for agreeing on that. Does this also mean you approved my translations? :P Or do you have any ideas on some of the specific items?
",godfat,mperham
1567,2014-03-16 11:59:50,"@mperham I think we probably shouldn't have two dialects for this, and I don't have strong opinions over my version, so it's ok to pick one over the other. If I knew there's one translation already, I wouldn't have tried to translate. So feel free to close this without merging.

@weichienhung Thanks for agreeing on that. Does this also mean you approved my translations? :P Or do you have any ideas on some of the specific items?
",godfat,weichienhung
1551,2014-03-20 18:23:50,"@mperham -- we're still trying to track down this issue.... we run a minimum of 1 heroku worker and scale up from there.  What we're seeing is that after running for a long time the main heroku worker `sidekiq_worker.1` seems to grind to a hault.  In the case of this morning the jobs were still in the busy queue but they had actually been processed... just not removed from the busy queue.  worker1 was no longer receiving any jobs.  Then after about 30-60mins it seemed to clean up itself and started receiving and processing like normal but quickly froze up again with jobs stuck in the busy queue.  We had to manually restart the worker.  The good news is that it does appear that no jobs are being lost... but just that the worker is dealing with some sort of crash or memory leak.

A list of our workers:



A tail of the sidekiq_worker.1 logs (note the super long processing times)



No errors are being raised.  We upgraded to `ruby 2.1.1` which seems to have fixed a number of issues were having before that seemed to cause net connections to randomly segfault.  It also seems to have fixed the random 5 second timeouts we were getting w/ active record.

Any ideas on why this might be happening?  @subelsky - have you seen this at all?
",anazar,mperham
1550,2014-03-12 23:55:59,"@mperham, this is great. how about also separating the web-ui , I am not sure about pro UI, but sidekiq come to the point ( fame and code size) that it might be logical to separate. 
",sahin,mperham
1550,2014-03-13 00:15:40,"I want to keep the UI integrated. 

> On Mar 12, 2014, at 16:55, sahinboydas notifications@github.com wrote:
> 
> @mperham, this is great. how about also separating the web-ui , I am not sure about pro UI, but sidekiq come to the point ( fame and code size) that it might be logical to separate.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1549,2014-03-12 15:42:05,"@jonhyman 

### redis-cli info

Server
redis_version:2.8.7
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:8a4b2cac15686a65
redis_mode:standalone
os:Linux 3.2.0-36-virtual x86_64
arch_bits:64
multiplexing_api:epoll
gcc_version:4.6.3
process_id:951
run_id:2ce417bcbdcd91983200e55872872da6dbd2aa84
tcp_port:6379
uptime_in_seconds:15287
uptime_in_days:0
hz:10
lru_clock:1051844
config_file:/etc/redis/6379.conf

Clients
connected_clients:28
client_longest_output_list:0
client_biggest_input_buf:0
blocked_clients:1

Memory
used_memory:3919228016
used_memory_human:3.65G
used_memory_rss:3946819584
used_memory_peak:3929465448
used_memory_peak_human:3.66G
used_memory_lua:33792
mem_fragmentation_ratio:1.01
mem_allocator:jemalloc-3.2.0

Persistence
loading:0
rdb_changes_since_last_save:241
rdb_bgsave_in_progress:0
rdb_last_save_time:1394638661
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:39
rdb_current_bgsave_time_sec:-1
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok

Stats
total_connections_received:608
total_commands_processed:150968
instantaneous_ops_per_sec:0
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
evicted_keys:0
keyspace_hits:17467
keyspace_misses:98665
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:1177791

Replication
role:master
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

CPU
used_cpu_sys:63.02
used_cpu_user:19.00
used_cpu_sys_children:69.00
used_cpu_user_children:614.22

Keyspace
db0:keys=99804,expires=156,avg_ttl=9435196149
",seyhunak,jonhyman
1549,2014-03-12 15:47:13,"@mperham Using for cache stuff, and for some counters.
",seyhunak,mperham
1527,2014-03-07 07:20:45,"@jonhyman - This is happening randomly... maybe once or twice a day... but when it does the jobs don't finish processing.  We know this because we adding logging around the jobs.

When it happens we are typically seeing a lot of these errors: 



There are a couple jobs where we have the establish a connection with a new database and I think this might be what's causing the issue.  It seems like calling establish_connection may be clearing out the existing connection pool.   I have yet to investigate or verify this.

When we establish another connection we are doing the following:



Any thoughts?
",anazar,jonhyman
1527,2014-03-07 13:19:32,"Sorry we don't use active record so I do not have experience with it.

Sent from my mobile device
On Mar 7, 2014 2:20 AM, ""Adam"" notifications@github.com wrote:

> @jonhyman https://github.com/jonhyman - This is happening randomly...
> maybe once or twice a day... but when it does the jobs don't finish
> processing. We know this because we adding logging around the jobs.
> 
> When it happens we are typically seeing a lot of these errors:
> 
> ActiveRecord::ConnectionTimeoutError: could not obtain a database connection within 5.000 seconds
> 
> There are a couple jobs where we have the establish a connection with a
> new database and I think this might be what's causing the issue. It seems
> like calling establish_connection may be clearing out the existing
> connection pool. I have yet to investigate or verify this.
> 
> When we establish another connection we are doing the following:
> 
>   establish_connection ENV['OTHER_DATABASE_URL']
>   config = Rails.application.config.database_configuration[Rails.env]
>   config['reaping_frequency'] = ENV['DB_REAP_FREQ'] || 10 # seconds
>   config['pool']            = ENV['DB_POOL'] || 30
>   config['checkout_timeout'] = 10
>   config['dead_connection_timeout'] = 600
>   config['timeout'] = 15
>   ActiveRecord::Base.establish_connection(config)
> 
> Any thoughts?
> 
> ## 
> 
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/1527#issuecomment-36973519
> .
",jonhyman,jonhyman
1527,2014-03-07 22:23:55,"@mperham - here is the basic worker that just uploads a file to s3.  I can try to monkeypatch AR but it does seem like it's setting the pool size correctly.

The strange this is that despite setting all the configs to increase timeout, pool, ect before establishing any connections I'm still randomly getting this.  There doesn't appear to be any reason why.



Here's an example of my worker.


",anazar,mperham
1527,2014-03-17 18:02:13,"@mperham I'm having the same problem. Right now we're chasing down a bug with Heroku's Ruby 2.0 installation where `Net::HTTP` can cause a segfault when connecting to certain SSL hosts. 

When this happens, Sidekiq crashes and any jobs being worked get stuck in the busy queue. When the dyno reboots, these jobs never get worked again but just stay in the queue forever. I played around with some code to detect these zombie jobs 'till I realized reliable fetch should be preventing it. 



sidekiq (2.17.7)
sidekiq-pro (1.4.3)
ruby 2.0.0p451 on heroku

if it helps, here's how I'm able to reproduce the segfault


",subelsky,mperham
1527,2014-03-17 18:19:55,"@subelsky when the dyno reboots, does its hostname change? If so, then I would expect the jobs to stay stuck in the queue.
",jonhyman,subelsky
1527,2014-03-17 20:54:52,"Glad to see this is not just me.  We're also still having the same issues as @subelsky as well... sounds like the exact same problem.  Also using the `sidekiq -i $DYNO` trick.  

@subelsky -- we're actually seeing the jobs eventually disappear from the busy queue (after an hour or so) but they often never get processed.
",anazar,subelsky
1527,2014-03-17 21:14:53,"@mperham a quick workaround would be to let them pass in the hostname via something like `-h` instead of using `Socket.gethostname`. Heroku users could then do something like `-i $DYNO -h heroku`. Though if you have a real solution in mind, I think that's preferable to a hack.
",jonhyman,mperham
1527,2014-03-18 00:01:52,"@mperham in sync, the more I thought about it, the more brittle it became.
",jonhyman,mperham
1527,2014-03-18 00:57:27,"@mperham I can write up some zombie job rescue code, but is there something missing from my code above? Seems like it was not copasetic with batches. Maybe I should push them without the original `jid` but I was trying to disturb the messages as little as possible
",subelsky,mperham
1527,2014-03-18 20:05:27,"@mperham per your request I made a new issue #1573 
",subelsky,mperham
1527,2014-04-21 18:31:59,"@mperham I'm not having this problem any more, the fix works great
",subelsky,mperham
1526,2014-03-02 23:03:16,"@daveharris I literally know nothing about the Mongo space.  I'll let @jonhyman speak for Sidekiq since he's an expert in both areas.
",mperham,jonhyman
1526,2014-03-02 23:08:50,"Hi @jonhyman,

Yes I have read your gist - I wanted to do that but was put off by the Monkey Patching. Would you suggest that we Monkey Patch until Mongoid v4 actually supports connection pooling?

My understand of your Monkey Patch is to store to Mongoid connection at the level of a Fiber, rather than a Thread - is that correct? I see [talk of running in production with the Ruby 1.9.3 version](http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/#comment-1026783827), I assume performance therefore isn't an issue? (what we are trying to address!) 

Also, what do you mean by ""Just be sure that you write your own middleware to clear the IdentityMap if you enable it in production."". You are saying I need a middleware for [just line 22 of Kiqstand](https://github.com/mongoid/kiqstand/blob/master/lib/kiqstand/middleware.rb#L22)?

Thanks
Dave

PS. Sorry to involve you int he conversation @mperham, there seems to be a lot of talk around the issue and trying to figure out what the best option is
",daveharris,mperham
1526,2014-03-02 23:08:50,"Hi @jonhyman,

Yes I have read your gist - I wanted to do that but was put off by the Monkey Patching. Would you suggest that we Monkey Patch until Mongoid v4 actually supports connection pooling?

My understand of your Monkey Patch is to store to Mongoid connection at the level of a Fiber, rather than a Thread - is that correct? I see [talk of running in production with the Ruby 1.9.3 version](http://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/#comment-1026783827), I assume performance therefore isn't an issue? (what we are trying to address!) 

Also, what do you mean by ""Just be sure that you write your own middleware to clear the IdentityMap if you enable it in production."". You are saying I need a middleware for [just line 22 of Kiqstand](https://github.com/mongoid/kiqstand/blob/master/lib/kiqstand/middleware.rb#L22)?

Thanks
Dave

PS. Sorry to involve you int he conversation @mperham, there seems to be a lot of talk around the issue and trying to figure out what the best option is
",daveharris,jonhyman
1526,2014-03-02 23:11:45,"@daveharris No problem.  I hope you and @jonhyman can figure out a solution; I'm sure there are others with the same issue.
",mperham,jonhyman
1526,2014-03-02 23:30:52,"Hey @daveharris, I'm on my phone so sorry that I might be brief and not
link to lines of code.

Moped and Mongoid store information about the session in Thread.current
thread-local variables which are local to Fibers (each Fiber has a
different variable stack not visible to each other). Celluloid uses fibers
around its threads, so when one terminates, the session also terminates.
Sidekiq never did ""not clean up its workers"", at least not with Ruby 2.0.
If you open up mongostat and run jobs without Kiqstand you'll the behavior
I'm talking about here. Connections will open as soon as the job starts and
close as soon as the job finishes.

What the gist does is move those sessions to thread local variables that
are shared across the fibers using new Ruby 2.0 thread features. Now
connections will stay open, one connection per concurrency set in Sidekiq.
Look again at mongostat, as many connections will be created for your
concurrency level, and they will not disconnect nor have any more
connections opened.

We run this in production with decently sized load. Eg last time I checked
the new relic graphs last week we had some peak load of about 150,000 jobs
per minute. That range is pretty regular for us. I don't know about 1.9.3
issues since we don't run it. You can't use the newer thread methods but
the original author of the gist used a hash so it doesn't seem required.

In terms of production performance things got better after this patch,
confirmed by our dbas at ObjectRocket. They definitely thought this as an
improvement over the health of mongodb and we saw job throughput increase
slightly.

I know that this is a monkey patch and in general I am very bearish on them
but if you understand the code I think this one is reasonable. My stance is
to do it until Mongoid 4. That's my current plan.

Sent from my mobile device

Hi @jonhyman https://github.com/jonhyman,

Yes I have read your gist - I wanted to do that but was put off by the
Monkey Patching. Would you suggest that we Monkey Patch until Mongoid v4
actually supports connection pooling?

My understand of your Monkey Patch is to store to Mongoid connection at the
level of a Fiber, rather than a Thread - is that correct? I see talk of
running in production with the Ruby 1.9.3
versionhttp://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/#comment-1026783827,
I assume performance therefore isn't an issue? (what we are trying to
address!)

Also, what do you mean by ""Just be sure that you write your own middleware
to clear the IdentityMap if you enable it in production."". You are saying I
need a middleware for just line 22 of
Kiqstandhttps://github.com/mongoid/kiqstand/blob/master/lib/kiqstand/middleware.rb#L22
?

Thanks
Dave

PS. Sorry to involve you int he conversation
@mperhamhttps://github.com/mperham,
there seems to be a lot of talk around the issue and trying to figure out
what the best option is

## 

Reply to this email directly or view it on
GitHubhttps://github.com/mperham/sidekiq/issues/1526#issuecomment-36471118
.
",jonhyman,jonhyman
1526,2014-03-02 23:31:12,"And yes, just write a quick Middleware to clear out the identity map. It
should be almost identical to kiqstand, just get rid of the disconnect
sessions line.

Sent from my mobile device
On Mar 2, 2014 6:29 PM, hyman.jon@gmail.com wrote:

> Hey @daveharris, I'm on my phone so sorry that I might be brief and not
> link to lines of code.
> 
> Moped and Mongoid store information about the session in Thread.current
> thread-local variables which are local to Fibers (each Fiber has a
> different variable stack not visible to each other). Celluloid uses fibers
> around its threads, so when one terminates, the session also terminates.
> Sidekiq never did ""not clean up its workers"", at least not with Ruby 2.0.
> If you open up mongostat and run jobs without Kiqstand you'll the behavior
> I'm talking about here. Connections will open as soon as the job starts and
> close as soon as the job finishes.
> 
> What the gist does is move those sessions to thread local variables that
> are shared across the fibers using new Ruby 2.0 thread features. Now
> connections will stay open, one connection per concurrency set in Sidekiq.
> Look again at mongostat, as many connections will be created for your
> concurrency level, and they will not disconnect nor have any more
> connections opened.
> 
> We run this in production with decently sized load. Eg last time I checked
> the new relic graphs last week we had some peak load of about 150,000 jobs
> per minute. That range is pretty regular for us. I don't know about 1.9.3
> issues since we don't run it. You can't use the newer thread methods but
> the original author of the gist used a hash so it doesn't seem required.
> 
> In terms of production performance things got better after this patch,
> confirmed by our dbas at ObjectRocket. They definitely thought this as an
> improvement over the health of mongodb and we saw job throughput increase
> slightly.
> 
> I know that this is a monkey patch and in general I am very bearish on
> them but if you understand the code I think this one is reasonable. My
> stance is to do it until Mongoid 4. That's my current plan.
> 
> Sent from my mobile device
> 
> Hi @jonhyman https://github.com/jonhyman,
> 
> Yes I have read your gist - I wanted to do that but was put off by the
> Monkey Patching. Would you suggest that we Monkey Patch until Mongoid v4
> actually supports connection pooling?
> 
> My understand of your Monkey Patch is to store to Mongoid connection at
> the level of a Fiber, rather than a Thread - is that correct? I see talk
> of running in production with the Ruby 1.9.3 versionhttp://avi.io/blog/2013/01/30/problems-with-mongoid-and-sidekiq-brainstorming/#comment-1026783827,
> I assume performance therefore isn't an issue? (what we are trying to
> address!)
> 
> Also, what do you mean by ""Just be sure that you write your own middleware
> to clear the IdentityMap if you enable it in production."". You are saying I
> need a middleware for just line 22 of Kiqstandhttps://github.com/mongoid/kiqstand/blob/master/lib/kiqstand/middleware.rb#L22
> ?
> 
> Thanks
> Dave
> 
> PS. Sorry to involve you int he conversation @mperhamhttps://github.com/mperham,
> there seems to be a lot of talk around the issue and trying to figure out
> what the best option is
> 
> ## 
> 
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/1526#issuecomment-36471118
> .
",jonhyman,jonhyman
1526,2014-03-03 00:00:46,"Hi @jonhyman,

Thank you so much for the explanation - I now understand. 

I've implemented in development and seems to work exactly as you say - I can see mongostat connections go up and down by 25 when I start and stop sidekiq.

Thanks again - it's was super confusing with so many technologies in play and so much talk about the issue.

Dave
",daveharris,jonhyman
1526,2014-03-03 00:05:04,"You're welcome! Best of luck in prod!

Sent from my mobile device
On Mar 2, 2014 7:00 PM, ""Dave Harris"" notifications@github.com wrote:

> Hi @jonhyman https://github.com/jonhyman,
> 
> Thank you so much for the explanation - I now understand.
> 
> I've implemented in development and seems to work exactly as you say - I
> can see mongostat connections go up and down by 25 when I start and stop
> sidekiq.
> 
> Thanks again - it's was super confusing with so many technologies in play
> and so much talk about the issue.
> 
> Dave
> 
> ## 
> 
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/1526#issuecomment-36472613
> .
",jonhyman,jonhyman
1526,2015-07-22 10:12:15,"The updated URL for the google group discussion is:
https://groups.google.com/forum/#!topic/mongoid/8rpSlgsRSSc

And the gist can be found here:
https://gist.github.com/markmeeus/6412088

And the one by @jonhyman (ruby 2.0) is here:
https://gist.github.com/jonhyman/7751687
",amitsaxena,jonhyman
1525,2014-03-07 07:51:49,"@mperham , I just had 1590 workers, but there should be 1200. I would love to test it. is it master? or which branch?
",sahin,mperham
1525,2014-03-07 13:17:51,"It's the heartbeat branch. 

> On Mar 6, 2014, at 23:51, sahinboydas notifications@github.com wrote:
> 
> @mperham , I just had 1590 workers, but there should be 1200. I would love to test it. is it master? or which branch?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1523,2014-03-01 21:00:55,"@justindowning That's a great start!  Thanks.

Now I want even more:
1. A full ANSI drawing
2. Animated kicker, like the sidekiq.org logo. Slide the kicker to the right and knock the logo at an angle.

Basically I really want to push the boundaries of what we could do in a modern terminal.  I wonder who could do this?  I'd be willing to pay money for a really impressive animation.
",mperham,justindowning
1518,2014-03-02 22:39:35,"@brainopia  I think , we are using the latest version. let me try again. sidekiq-limit is a cool plugin. we want to use it... 
",sahin,brainopia
1507,2014-02-23 01:19:31,"@mperham - Thanks for the answer!  Any suggestions on how to ensure that this doesn't happen?  We need to be able to ensure that 100% of jobs are retried and processed.  I can't tell (without writing more code to log everything) if these jobs are completing and then sidekiq is failing to remove the worker or if the jobs just are erroring and not retrying.
",anazar,mperham
1507,2014-02-23 01:35:01,"Sidekiq Pro's reliable fetching solves the segfault problem.

> On Feb 22, 2014, at 17:19, Adam notifications@github.com wrote:
> 
> @mperham - Thanks for the answer! Any suggestions on how to ensure that this doesn't happen? We need to be able to ensure that 100% of jobs are retried and processed. I can't tell (without writing more code to log everything) if these jobs are completing and then sidekiq is failing to remove the worker or if the jobs just are erroring and not retrying.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1505,2014-02-28 04:00:02,"@mperham I just want to note here that I've been seeing this half-crashed behavior, too.  My sidekiq.log includes a big segfault stacktrace, but the sidekiq process sticks around.

I don't have any reason to think sidekiq is doing something wrong.  (In my case tiny_tds is the culprit.)  I just thought you might like to know that a segfault doesn't always completely kill the process.  Not that this makes any sense.

When I notice jobs aren't being processed, I tell bluepill to restart sidekiq for me.
",mikegee,mperham
1485,2015-01-20 22:20:59,"@mperham I'd be down to test 2.0.
",aprescott,mperham
1485,2015-02-08 17:04:08,"@mperham thanks. Sorry for asking in two places... I realized after the Tweet that a code sample would help me better convey what I was trying to ask!

This all makes sense now -- I'll fire off another batch in the callback. 

Thanks for all the swift replies. We're refactoring a few of our long running jobs into batches and the results thus far are looking great!
",harlow,mperham
1484,2014-02-27 22:18:27,"@mperham have been running on ruby 2.0 for a while, no crashes. Seems like a Ruby VM issue.
",kapso,mperham
1480,2014-02-14 16:40:35,"@mperham It would be nice to be able to configure this globally. That way, running 

`Model.delay.do_something(model_id)` on a missing model wouldn't get retried.

If it would be done application side, the `.delay` call would have to be retred on a missing model.



vs



If the above were repeated across multiple asynchronous actions, it would be pretty repetitious when all you're doing is wrapping a static method

Likewise, if you don't configure sidekiq to ignore it, the behavior is unchanged.
",seanpdoyle,mperham
1480,2014-02-14 16:58:54,"You just need to add a rescue to do_something. You don't need a full Worker. 

> On Feb 14, 2014, at 8:40, Sean Doyle notifications@github.com wrote:
> 
> @mperham It would be nice to be able to configure this globally. That way, running
> 
> Model.delay.do_something(model_id) on a missing model wouldn't get retried.
> 
> If it would be done application side, the .delay call would become verbose by writing a Worker and wrapping the exception manually
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1470,2014-02-08 20:52:22,"@mperham Machine! Thank you!
",allaire,mperham
1469,2014-02-08 04:16:33,"@mperham Thanks for the info, that's what I thought, I rolled my own.

I'll close this but I have one more question, when I stop sidekiq via upstart using /sbin/stop, sidekiq leaves the pidfile, is this normal? I have the exact same upstart script for puma (using foreman export), and puma seems to cleanup it's pidfile before quit.

Thank you
",allaire,mperham
1469,2014-02-08 04:21:31,"I don't believe you are supposed to use a pidfile with Upstart. 

> On Feb 7, 2014, at 20:16, Mathieu Allaire notifications@github.com wrote:
> 
> @mperham Thanks for the info, that's what I thought, I rolled my own.
> 
> I'll close this but I have one more question, when I stop sidekiq via upstart using /sbin/stop, sidekiq leaves the pidfile, is this normal? I have the exact same upstart script for puma (using foreman export), and puma seems to cleanup it's pidfile before quit.
> 
> Thank you
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1467,2014-02-07 23:09:49,"@mperham - I'm new here... when will this be in sidekiq-pro? Thanks!
",ctaintor,mperham
1461,2015-11-28 07:30:10,"@mperham I did not add any specs yet and did not do a pull request, but please take a look if that makes sense to be merged to Sidekiq.

It's not always possible to keep all jobs idempotent, we download big amounts of data and process them, and Sidekiq is good at this even with MRI, but just one iteration of our worker thread could take half an hour or longer and in case of restart we then have to start all over again.

Having a simple ability to know inside the job that we're going to shut down would be very and very helpful. And probably not just for us.
",heaven,mperham
1461,2015-11-30 07:20:22,"@mperham any thoughts about this? Do you think this could be merged into Sidekiq eventually? This does not break the concept of idempotent jobs but adds an ability to gracefully terminate jobs by setting a single `terminated` flag on the job. And it's up to developers which concept to use and when. For my current project over 90% of all jobs are idempotent, but those 10% still exists and need a solution.
",heaven,mperham
1459,2014-02-04 07:06:13,"@mperham I think you misunderstand me. In my use case, some job takes too long and I could not figure out how to kill a single job (which is probably running in a thread)
",joneslee85,mperham
1458,2014-02-03 05:15:49,"@jonhyman Ok. thanks for clarifying my doubt.
",karunakaran,jonhyman
1452,2014-01-25 20:04:29,"@mperham what's your thought on fixing this. After a little digging I noticed this could be fixed by changing the cloning  to a json dump + parse at:

https://github.com/mperham/sidekiq/blob/cd151319988474f4e355ec5a29b3981139e0eef8/lib/sidekiq/processor.rb#L138
",betelgeuse,mperham
1447,2014-01-23 17:47:27,"@mperham that was it. I added `require 'sidekiq/pro/api'` to `config.ru` (standalone app) and it works. Thanks!
",jelder,mperham
1438,2014-01-22 16:20:00,"Thanks @mperham, I feel like I've seen timing issues on occassion when my tests directly interact with Redis, was the only reason I mentioned it. Probabaly poor coding on my part. ;)
",mbhnyc,mperham
1435,2014-02-04 05:46:24,"@mikegee You should be able to start new Sidekiq processes with Upstart by passing in an new index: `sudo start sidekiq index=2`  Adjusting based on load is an exercise for the reader.  :-D
",mperham,mikegee
1423,2014-01-10 19:59:13,"@mperham Updated to just remove the .async, left everything else the same now.
",jonhyman,mperham
1421,2014-01-09 20:38:56,"Hey @mperham, thanks for sharing my post! I hope it will be helpful for someone.

As far as I learnt from some time spent with profiler there is no actual leak in Sidekiq itself. I'm not exactly sure, but there was nothing suspicious in reports generated from heap dump.

Also I was experimenting with long-running workers on Ruby 2.1. My production setup includes periodical job that quiets sidekiq workers and rolls new ones. I've temporary disabled it on one of machines and let workers run for ~3 days. Each process has grown to ~1GB peak and then remained in this position, so I concluded that there are no actual leak, it's just a bloat that caused by some memory-intensive jobs.

Anyway, memory usage has definitely increased comparing to 2.0, for my case I was forced to decrease number of Sidekiq and Puma processes in order to calm down OOM killer.
",krasnoukhov,mperham
1421,2014-01-09 20:44:51,"Thanks for sharing @krasnoukhov, much appreciated! :metal: 
",mperham,krasnoukhov
1414,2015-01-28 21:39:49,"@mperham FYI that more than 1 database per Redis instance is deprecated and won't be supported in Cluster mode (but will in non-cluster mode): https://groups.google.com/forum/#!topic/redis-db/x3-6GByC3xE.

My recommendation is that at the end of the post: multiple Redis instances (on the same host). Redis is single-threaded, so you're not getting any concurrency advantages by splitting it up across databases or namespaces.
",jonhyman,mperham
1409,2013-12-25 19:46:05,"@mperham It's been a busy hour.  :)
",petergoldstein,mperham
1406,2014-01-02 20:52:09,"@mperham thoughts on releasing 2.17.2? I'll test this out to ensure that it is in fact fixing the issue.
",jonhyman,mperham
1406,2014-01-10 16:40:58,"@mperham Unfortunately this didn't fix the issue, though it seems to have reduced some of its occurrences. I added more logging, it looks like the Fetcher is still picking up jobs on its way to shut down. I'll keep investigating.


",jonhyman,mperham
1397,2014-01-03 10:27:31,"@mperham Well it's important for us to be able to test mixed instant/scheduled jobs, so we'll maintain this strategy ourselves as a monkey patch. Or do you have an other suggestion how to do this?
",jjoos,mperham
1397,2014-01-15 07:51:37,"@jonhyman Thanks, we're already testing it in our unit tests like that. 

Our objective is to cover the execution of the job in our integration test. Especially the order in which the jobs are executed and at which time (`timecop`), seem important to make these as realistic as possible (without waiting days for our integration tests ;)).
",jjoos,jonhyman
1390,2013-12-10 23:44:18,"@zenspider You going to be using Sidekiq or just poking around?
",mperham,zenspider
1386,2013-12-09 21:43:57,"@mperham check out https://github.com/mperham/sidekiq/pull/1387
",jonhyman,mperham
1386,2013-12-12 16:08:03,"@alexfarrill Both @mperham and I were unable to get this working within reasonable timeboxes in #1387. I'm going to update the changelog to remove the line which says that USR1 exits after stopping. I confirmed that the wiki still says that USR1 only stops workers, it does not exit the program.
",jonhyman,mperham
1384,2013-12-07 23:25:16,"@mperham @brianr oh, that's embarrassing... will try to never commit anything when it's 5am and i'm just about to go to sleep...

Thanks guys, all good!
",ixti,mperham
1380,2013-12-05 01:10:50,"@jonhyman, that works, but we want to avoid adding extra worker dynos on Heroku if at all possible.
",silasjmatson,jonhyman
1380,2013-12-05 01:16:04,"That sidekiq-limit_fetch looks awesome! Thanks @jonhyman ! We'll try it out.
",jamonholmgren,jonhyman
1378,2013-12-03 19:40:04,"Thanks a ton @mperham, is this in the docs somewhere for idiots like me?
",mbhnyc,mperham
1378,2013-12-03 19:41:35,"In bold on the best practices page. 

> On Dec 3, 2013, at 11:40, mbhnyc notifications@github.com wrote:
> 
> Thanks a ton @mperham, is this in the docs somewhere for idiots like me?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1374,2013-12-15 01:15:00,"@mikegee I'm using [postmark-rails](https://github.com/wildbit/postmark-rails) which uses a postmark API on the backend (via `action_mailer.delivery_method`).
",damien-roche,mikegee
1374,2013-12-15 03:14:28,"I would audit that gem to make sure it's thread safe and well written. Never heard of it before. 

> On Dec 14, 2013, at 17:15, Damien Roche notifications@github.com wrote:
> 
> @mikegee I'm using postmark-rails which uses a postmark API on the backend (via action_mailer.delivery_method).
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mikegee
1368,2013-11-28 13:56:41,"gnaarrgh! this fixed it! thanks @jonhyman and sorry for the annoyance!
",benben,jonhyman
1365,2014-03-18 17:58:58,"@mperham technically any of those extensions should interfere  in the delay extension jobs, but also it would be very hard to reproduce in my exact environment. As you mentioned, I already checked for old Sidekiq processes running and I didn't found in any of my servers.

So just to make sure it is now a known problem, is there any problem if I have Sidekiq running in a different server than the redis database? I'll try to check directly on the redis queue to see if the jobs are there.

Thank you for your time, and sorry for asking so many questions.
",felipeclopes,mperham
1361,2013-11-23 21:35:50,"@jonhyman Oh I see.  Your PR changed the semantics of USR1.  It's meant to be a quiet signal: finish your work in progress.  You must send TERM to get Sidekiq to actually shutdown.  Some people have lobbied for this change but I'm always reluctant to change semantics unless there's an obvious advantage.  wdyt?
",mperham,jonhyman
1361,2013-11-24 04:52:08,"@jonhyman It's designed to work with standard Capistrano deploys: notify sidekiq via USR1 it will be shutting down as early as possible during the deploy and then shut down Sidekiq as late as possible with TERM.  Since capistrano deploys usually take a minute or two, this gives a good amount of time to shutdown.

I don't prefer either semantic right now.  I do know that I won't accept this PR as is with the additional gem dependency.
",mperham,jonhyman
1361,2013-11-24 09:10:10,"Mike, I can suggest two alternative solutions to this:

1) implement a new signal that sidekiq recognizes as ""quiet, stop when finished"". 

2) implement a setting in sidekiq.yml that modifies the usr1 signal behaviour to ""stop when finished"".

If i'm getting your vibe, perhaps the first is more desireable to you, perhaps it's a variation of #1358. Perhaps it's something you might consider adding as a feature to sidekiq-pro.

Two minutes is not enough for me, my timeout when stopping sidekiq is 15 minutes. It never reaches the limit, but i do have some narly excel reports that take they're time to execute.

Either way, i cant work further on this PR, its solved my problem in a very isolated way - I'm just sharing.

It was nice exchanging ideas.

Best of luck.

On 24/11/2013, at 02:52, Mike Perham notifications@github.com wrote:

@jonhyman It's designed to work with standard Capistrano deploys: notify sidekiq via USR1 it will be shutting down as early as possible during the deploy and then shut down Sidekiq as late as possible with TERM. Since capistrano deploys usually take a minute or two, this gives a good amount of time to shutdown.

I don't prefer either semantic right now. I do know that I won't accept this PR as is with the additional gem dependency.

—
Reply to this email directly or view it on GitHub.
",alexbeeck,jonhyman
1361,2013-11-24 22:06:17,"@alexbeeck Thanks for offering the code, it's more than 90% of people do.

I'll stick with @jonhyman's new semantic.  I don't believe it will break the Capistrano integration because sidekiqctl should quietly exit if a stop command is issued for a process that does not exist.  We do find quiet Sidekiq processes hanging around occasionally for whatever reason; this should reduce that.
",mperham,jonhyman
1354,2014-06-27 06:47:30,"@mperham We’re wrestling with this as well. Would you welcome a pull request to fix this when Sidekiq is running on Ruby 2.1 (where `Exception#cause` is available)?
",sentience,mperham
1354,2014-06-27 06:52:47,"Yes!

> On Jun 26, 2014, at 23:47, Kevin Yank notifications@github.com wrote:
> 
> @mperham We’re wrestling with this as well. Would you welcome a pull request to fix this when Sidekiq is running on Ruby 2.1 (where Exception#cause is available)?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1341,2013-11-15 02:26:04,"This definitely seems like a time configuration issue.

Either at the database level or at the machine level. If it was at the database level, I would assume you would be able to reproduce this issue locally. But at @mperham suggested it's likely to be at the machine level.

Does there happen to be a significant difference between your local time and the time on the machine?
",aackerman,mperham
1331,2013-11-12 23:03:13,"For the record @jmdeldin is a Clymb co-worker of mine.  This is an issue we're having right now.

I just realized that we run sidekiq.conf through ERB by default, so we can just do this:



@jmdeldin Please verify and close if this proves to be the case.
",mperham,jmdeldin
1331,2013-11-12 23:33:38,"Yep! That does the trick. Thanks, @mperham!
",jmdeldin,mperham
1311,2013-11-04 19:05:58,"@mperham Wow that was a quick response! When I run the same statements in irb I get the same results as you have. When I do the same thing in `rails c`, I get the error. We have some additional sidekiq extensions (sidekiq-benchmark, sidekiq-superworker, sidekiq_monitor, sinatra for sidekiq web monitoring) and I think the issue is probably due to some cross-incompatibility there. I'm going to try disabling some of them and see if that makes a difference.
",MrLeebo,mperham
1311,2013-11-05 21:57:44,"@mperham I agree, thanks for your help. I'm using the latest which at the time of this post is v3.3.1. I logged the <a href=""https://projects.puppetlabs.com/issues/23072"">bug report</a> on Puppet's issue tracker in case anyone wants to lend their upvotes.
",MrLeebo,mperham
1310,2013-11-15 06:09:54,"@aackerman yes, it works.
",kryachkov,aackerman
1310,2013-11-15 09:19:55,"@aackerman yes works.
",cthulhu,aackerman
1309,2014-01-13 06:49:22,"Hi @mperham, looks like you added this feature, then pulled it back out.  I assume this isn't going to happen.

Would you please close the linked issue (#1319) with a note that it isn't being implemented at this time?

Thanks!
",mikegee,mperham
1307,2017-01-02 19:11:22,"@mperham For what it’s worth, there are constant-time algorithms for random queue popping (pick a random number *i*, between 0 and n; read the *i*th element and then replace it with the *n*th element).

I was also hoping for this feature. Maybe something just for Sidekiq Pro?",sferik,mperham
1307,2017-01-02 19:17:27,"@sferik I'm not clear those algorithms will work when X Sidekiq threads are all trying to pop a job at the same time.  I'd have to use Lua which would add a lot of overhead to the fetch scheme.

I don't think there's enough demand to warrant me building and supporting this feature but the [Fetch API](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/fetch.rb#L5) is stable and designed for 3rd parties to build their own fetch algorithms if you're so inclined.",mperham,sferik
1305,2013-11-15 03:25:00,"This looks good to me, what about you @mperham?
",aackerman,mperham
1300,2013-11-02 13:26:35,"@mperham heh, there are only two options for the embedded twitter feed that comes from twitter; a 'light' theme and a 'dark' theme.

@unity if you're referring to [here](https://github.com/seaofclouds/tweet) for jquery.tweet, since the twitter API changes in June 2013, that project no longer works without some kind of server support.

Twitter doesn't offer a lot of choices for customization :/
",aackerman,unity
1300,2013-11-02 13:26:35,"@mperham heh, there are only two options for the embedded twitter feed that comes from twitter; a 'light' theme and a 'dark' theme.

@unity if you're referring to [here](https://github.com/seaofclouds/tweet) for jquery.tweet, since the twitter API changes in June 2013, that project no longer works without some kind of server support.

Twitter doesn't offer a lot of choices for customization :/
",aackerman,mperham
1300,2013-11-02 18:10:28,"We can think of offering something with hull.io, we alleviate the need for a Backend. 

Right now we only support user-authenticated calls but if there is demand for it we could do this with proper caching etc. 

—
romain@hull.io
http://hull.io

On Sat, Nov 2, 2013 at 2:26 PM, Aaron Ackerman notifications@github.com
wrote:

> @mperham heh, there are only two options for the embedded twitter feed that comes from twitter; a 'light' theme and a 'dark' theme.
> @unity if you're referring to [here](https://github.com/seaofclouds/tweet) for jquery.tweet, since the twitter API changes in June 2013, that project no longer works without some kind of server support.
> 
> ## Twitter doesn't offer a lot of choices for customization :/
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/mperham/sidekiq/pull/1300#issuecomment-27621892
",unity,unity
1300,2013-11-02 18:10:28,"We can think of offering something with hull.io, we alleviate the need for a Backend. 

Right now we only support user-authenticated calls but if there is demand for it we could do this with proper caching etc. 

—
romain@hull.io
http://hull.io

On Sat, Nov 2, 2013 at 2:26 PM, Aaron Ackerman notifications@github.com
wrote:

> @mperham heh, there are only two options for the embedded twitter feed that comes from twitter; a 'light' theme and a 'dark' theme.
> @unity if you're referring to [here](https://github.com/seaofclouds/tweet) for jquery.tweet, since the twitter API changes in June 2013, that project no longer works without some kind of server support.
> 
> ## Twitter doesn't offer a lot of choices for customization :/
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/mperham/sidekiq/pull/1300#issuecomment-27621892
",unity,mperham
1300,2013-11-06 04:11:35,"This looks fantastic, thanks @aackerman.
",mperham,aackerman
1298,2013-10-30 21:46:44,"Thank you @mperham I tried your suggestion using 2.15.2 sadly its not resolving the problem.
Do you have a suggestion on how to debug this? Perhaps log the exact location the  private_pub call is trying to connect to? Im using sidekiq failures to get the provided stack trace which is not helping that much. 
",rubytastic,mperham
1298,2013-10-31 10:34:59,"@mperham 
Perhaps I should consider moving the part of code that sends data to web socket channel ( private pub call ) outside of the worker. anyway Its quite a frustrating issue. Thank you for your support.
",rubytastic,mperham
1296,2013-10-31 16:44:36,"@juanibiapina Can you detail how the new sidekiq_default_hooks is working for you?  Just updated and no calls to sidekiq are being made during deploy.  In my case at least sidekiq_default_hooks is never being set to true at the time the if check is made.  ??
",phallstrom,juanibiapina
1296,2013-11-01 12:21:25,"@phallstrom I'm using it set to false only. Haven't tried it set to true in a fresh project.
",juanibiapina,phallstrom
1296,2013-11-01 18:07:56,"@juanibiapina @mperham From what I can tell, the hooks will never be set with the current method as that variable isn't defined when this file is loaded.  My first thought was to move this check into the rake tasks themselves and always define the hooks, but that would mean calling them directly may not work.  I'm not sure if rake will tell you the task that invoked this task or not.  Alternatively we could add ""hook"" tasks specifically for this.

Any ideas on how you'd like to solve it Mike?   I'm happy to work on it.
",phallstrom,juanibiapina
1296,2013-11-06 18:37:41,"@juanibiapina Any opinions on making the sidekiq tasks available all the time and then tying them into capistrano hooks only if you include the capistrano file?  I'm happy to do the work...
",phallstrom,juanibiapina
1289,2013-11-21 03:49:17,"@aackerman Yes, I will update this issue if I find any way solve this problem .
",jjyr,aackerman
1289,2015-09-15 18:49:46,"It would seem that this only works when you are using cookie_store as your session backend. My application is using Redis for sessions and deleting/retying jobs in Sidekiq flat out will not work. If I switch to cookie store, then it starts working (without specifying a domain key). I am assuming the problem here is that SidekiqWeb does not ""know"" how to use the Redis session backend and this breaks the CSFR protection @mperham ? Any ideas how to make it work?
",tanelsuurhans,mperham
1289,2015-09-29 15:00:42,"@mperham yes, I know... I added that to my configuration but I'm still having the issue.
",rikas,mperham
1289,2015-10-02 21:33:42,"Ok. Turns out that the difference was that production has multiple app instances.

Sinatra, if given no secret for cookie session storage, generates a random one as the server starts. So I end up with different secrets on different app instances and cookies signed on one instance are not recognized on other one, which leads to new session with new csrf token, which does not match authenticity token anymore

Sidekiq::Web should probably set secret explicitly, though it should probably be configurable via ENV or sidekiq config

@mperham what do you think?
",dreyks,mperham
1289,2015-10-02 21:35:52,"@dreyks Sidekiq is not in the business of creating/managing sessions.  That's why this issue has been so painful: I can't control it.  The application must provide a valid session.
",mperham,dreyks
1289,2015-10-03 09:18:39,"@mperham as you rightly said it's up to the app to provide a valid session, but I think it's also up to Sidekiq to provide means of doing this.
How about something like this



Then if one wants to use say Redis for storing sessions, it can be done with something like



This is only a sketch, if you're interested I can pull it together into a PR
",dreyks,mperham
1289,2015-10-03 17:52:43,"@dreyks That's a silly amount of preamble when the user just needs to do this:

Sidekiq::Web.use Rack::Session::Redis
",mperham,dreyks
1289,2015-12-21 21:12:41,"Dug into this issue a little more by trying to trace down where things go wrong - because I can clearly see the session being present and a CSRF value being store, but for some reason the values don't match (the one from the session vs the one submitted with a form). 

The way Sinatra handles sessions when you just say `enable :sessions` is to use Rack::Session::Cookie and generate a `:secret` as an option for it using SecureRandom.hex. This all works fine and dandy, but what I'm seeing is this piece of code being ran twice with different process ID-s. Because the value then changes across different requests, the old value already rendered with buttons and forms is essentially invalidated and this is what causes the error when you submit any of those. If the cookie secret value is hardcoded inside `Sidekiq::Web`, everything works as expected - but this obviously is not feasible.

The setup I'm running this with locally in development mode is a Rails application with POW, behind a simple Nginx proxy. The main application is using Redis for sessions (but I don't think this makes any difference). I can reliably replicate this with the given setup. We also have the same issue in production, where we run multiple nodes running 10 Unicorn workers per application. The same issue happens there as well and logically it would be caused by different nodes having a different `:secret` key generated on the application startup. So now when node #1 submits the form to node #2, the values do not match and CSFR protection kicks in. This seems to be validated by not being able to reproduce the same behavior on our staging environment, which consists of one server with 10 workers.

As far as nice and clean fixes go, I'm still somewhat stuck. Initially I figured adding this to my initializer would help:
`Sidekiq::Web.use Rack::Session::Cookie, :secret => Settings.sidekiq_secret`
The problem is that this has no effect whatsoever unless it's done in config.ru and Sidekiq::Web mounted via that method - which in my case undesirable. 

@mperham is correct in the sense that when enabling sessions for Sinatra, its supposed to provide a working session, and it does, but it doesn't really work in a multi-process environment apparently. What we need is a nice way to optionally configure the sessions secret via the ""owner"" Rails application. This would allow to avoid having to mess around with separate rackup files etc. Is there a way to expose a configuration setting like that? Perhaps even defaulting to the Rails session secret if its present?
",tanelsuurhans,mperham
1289,2015-12-21 21:19:46,"Ha @mperham, while it directly does not solve the issue - as its not wildcard domain session related - it does contain the solution that I was looking for. I can set the missing session value for all nodes like this:
`Sidekiq::Web.set :session_secret, Settings.sidekiq_secret`

So instead of trying to make it use Rack::Session::Cookie once more (which had no effect), I can set the cookie secret value instead. At first glance it seems to be working locally, have to test it out in production too to be sure. Thanks.
",tanelsuurhans,mperham
1288,2013-10-30 12:39:14,"@mperham great, thanks!
",tisba,mperham
1281,2013-10-25 22:10:39,"@jbgo :+1: to your solution, but it is a circular dependency not a superclass mismatch. What's happening is that the class definition in contact.rb hasn't been completed so `Contact` still doesn't exist when it loads the concern. By defining the module in the concern as `module Contact::Avatarable` it triggers `const_missing` so `ActiveSupport::Dependencies` will try to load contact.rb. It sees that this has already been loaded so raises the circular dependency error. By changing the concern to `class Contact < ActiveRecord::Base` you eliminate the call to `const_missing` allowing the class definition to complete successfully.
",pixeltrix,jbgo
1281,2014-01-08 19:37:43,"@mperham OK. I will check my codes. but why it works after first crash? 
",chaizhenhua,mperham
1281,2014-01-09 14:54:23,"hi @pixeltrix  @mperham, please take a look at this gist https://gist.github.com/chaizhenhua/8335236. I think the crash is due to thread race condition. in my module code there are many dynamic methods. the module need some time to load, and other thread try to load the same module again, and then sidekiq crash. 

Is it a bug? or how to avoid the crash?
",chaizhenhua,mperham
1281,2014-02-19 09:30:23,"This is the scenario described earlier in this discussion - have you tried writing it this way:



I haven't tested this but this is the layout you need to adopt - my only concern is that `Validate` may clash with an existing Active Record constant.

To any future person looking at this ticket please leave @mperham alone - this isn't anything to do with Sidekiq - use one of the regular Ruby/Rails support channels and if you think you've found a bug with autoloading in Rails please report it on [our issues page](https://github.com/rails/rails/issues).
",pixeltrix,mperham
1280,2013-10-28 17:02:05,"Makes sense, thanks @mperham. If you think of something and would like me to help implement it then let me know.
",GAV1N,mperham
1272,2015-02-27 05:14:22,"@newdark Please don't comment on ancient issues; open a new issue if it's something you feel needs work.
",mperham,newdark
1270,2013-10-21 19:55:31,"@mperham the tests should pass now :)
Thanks
",salimane,mperham
1269,2016-05-13 18:04:37,"@salimane did you find a solution on using `sidekiq-unique-jobs` and `rspec-sidekiq` together ?

30 months later, we are still having this issue
",mathieujobin,salimane
1267,2013-10-21 16:05:28,"@mperham Indeed a Ruby issue.  For now was not able to upgrade to Ruby 2, mine being a bit old app.  Uninstalling ruby 1.9.3 and then installing it with <tt>rvm install 1.9.3 --with-gcc=clang</tt> fixed the issue for me.  Thanks!
",ankit8898,mperham
1263,2013-10-19 18:00:04,"@mperham the job's pretty complicated and split across several layers so not easy to show it here.  The timing is around the most critical (and slowest) part that is common between running in foreground and background.

Our comments probably crossed paths but I did think of that and changed concurrency to 1 as mentioned in the second comment here.  It didn't help the runtime though.
",bdmac,mperham
1263,2013-10-19 19:39:14,"I get an average processing time of **150.10ms** locally.  My local is about is as close to prod (or in this case staging)-parity as I would be comfortable with.  I use foreman locally with a procfile matching what I use on Heroku.  I even pulled down my sendgrid config from my staging config on Heroku to be sure that the mailer is running similarly...

I can't imagine this being a Redis problem since this is a single job we're talking about running.  Once it gets picked up and starts running I would assume there's nothing being done against Redis anymore, is that right @mperham?
",bdmac,mperham
1263,2013-10-23 04:00:18,"@mperham I doubt it since there's not really a filesystem to speak of there... not sure it would be able to write the HTML file.  I'll try to see if someone's gotten that working but so far not much luck.
",bdmac,mperham
1258,2013-10-17 02:51:49,"@mperham do you think this is something which `celluloid` could also benefit from?
We do actually have an async DNS in `celluloid-io`, but not everyone will be using that. 
",halorgium,mperham
1258,2013-10-17 03:00:54,"I'm not sure. That blog post is ancient  so it's unclear if this is still a problem with MRI. The GIL is still there so it's possible that calls into libc's DNS resolution don't release the GIL.  I don't want to cargo cult so it'd be nice to have someone knowledgable chime in. 

> On Oct 16, 2013, at 19:51, Tim Carey-Smith notifications@github.com wrote:
> 
> @mperham do you think this is something which celluloid could also benefit from?
> We do actually have an async DNS in celluloid-io, but not everyone will be using that.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1254,2013-10-19 22:58:02,"@mperham Fair enough.  I've modified the files to load up the right capistrano code based on it's version.
",phallstrom,mperham
1252,2013-10-21 15:43:04,"@mperham It works only with the first database (`0`).

I'd also like to be able to configure my redis connection with all the options supported by the Redis driver.

I'll take a look.
",jlecour,mperham
1252,2013-10-21 18:06:20,"Since I really need this, I'll do something.

Also, @mperham, great variant of PDI ;)
",jlecour,mperham
1252,2013-10-21 18:37:41,"@mperham @jlecour here you go :)  #1270 
",salimane,jlecour
1252,2013-10-21 18:37:41,"@mperham @jlecour here you go :)  #1270 
",salimane,mperham
1252,2013-10-21 20:41:37,"Thanks a lot @salimane
",jlecour,salimane
1240,2013-10-10 23:41:09,"@cpuguy83 It's more of a design and support issue.  It's a good thing™ to have your workers separate from your web processes.  This way you can cycle each independently, e.g.
",mperham,cpuguy83
1233,2013-10-06 23:54:16,"@halorgium it's already locked at >= 0.15.1, not sure what the problem would be in requiring an upgrade considering this was the only change in the release
",tarcieri,halorgium
1231,2013-10-08 01:45:46,"@mperham this is what I meant - they are just stuck at enqueued and scheduled.

![sidekiq-stuck](https://f.cloud.github.com/assets/794915/1285918/422cfd0a-2fbb-11e3-888c-587744ede296.png)

I also caught a different error - perhaps this could provide more hint?


",kenips,mperham
1231,2013-10-08 02:01:29,"And nothing in the logs?

> On Oct 7, 2013, at 18:45, Ken Ip notifications@github.com wrote:
> 
> @mperham this is what I meant - they are just stuck at enqueued and scheduled.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1231,2013-10-08 02:36:22,"@mperham My apologies I updated the original comment instead of posting another one. Here's the log again (since you appear to be replying from email).



I can now confirm this to be the issue. It appeared before and I did not catch it. And running `bundle exec sidekiq -c 1` seems to solve the issue.
",kenips,mperham
1231,2013-10-08 02:42:33,"I would upgrade JRuby if you can. There have been fiber issues with previous releases that are fixed in 1.7.5. 

> On Oct 7, 2013, at 19:36, Ken Ip notifications@github.com wrote:
> 
> @mperham My apologies I updated the original comment instead of posting another one. Here's the log again (since you appear to be replying from email).
> 
> 2013-10-07T13:57:51Z 9990 TID-1j1yho WARN: Sidekiq died due to the following error, cannot recover, process exiting
> 2013-10-07T13:57:51Z 9990 TID-1j1yho WARN: cannot resume a dead task (resuming fiber from different thread)
> 2013-10-07T13:57:51Z 9990 TID-1j1yho WARN: /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/tasks/task_fiber.rb:27:in `deliver'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/tasks/task_fiber.rb:23:in`deliver'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/tasks.rb:98:in `resume'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/responses.rb:11:in`dispatch'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/actor.rb:327:in `handle_message'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/actor.rb:174:in`run'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/actor.rb:157:in `initialize'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/thread_handle.rb:13:in`initialize'
> org/jruby/RubyProc.java:255:in `call'
> /var/projects/j-platform/vendor/bundle/jruby/1.9/gems/celluloid-0.15.1/lib/celluloid/internal_pool.rb:100:in`create'
> I can now confirm this to be the issue. It appeared before and I did not catch it. And running bundle exec sidekiq -c 1 seems to solve the issue.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1220,2015-01-20 23:56:36,"> $ bundle
> Fetching source index from http://www.mikeperham.com/rubygems/
> Retrying source fetch due to error (2/3): Bundler::HTTPError Could not fetch specs from http://www.mikeperham.com/rubygems/
> Retrying source fetch due to error (3/3): Bundler::HTTPError Could not fetch specs from http://www.mikeperham.com/rubygems/
> Could not fetch specs from http://www.mikeperham.com/rubygems/

Just received this. Is there a known issue with your gem server @mperham ?
",nickmerwin,mperham
1220,2015-01-21 00:14:16,"Thanks @ryansch, worked.
",nickmerwin,ryansch
1215,2013-09-30 18:56:58,"Thank you @mperham just updated from sidekiq version 1.12.1 to the newest one and everything is working properly.
",felipeclopes,mperham
1215,2014-05-29 12:00:08,"@felipeclopes @mperham how were you able to get around the fact that sidekiq uses `brpop` and twemproxy not supporting it?
",gjohnson,mperham
1213,2013-10-01 19:36:34,"@cpuguy83 Ooooo interesting. Thanks for the tip.
",mbhnyc,cpuguy83
1213,2013-11-21 06:19:01,"@aackerman  Yes, we are still facing the issue. We even scaled our server from small instance to medium instance. Everytime sidekiq starts processing jobs, CPU Utilization is 100%. If you want I share screenshot from cloud watch monitoring and htop from server, on your email.
",icicle-deploy,aackerman
1213,2014-03-10 15:46:40,"@mperham I think it safe to close this one too.
",seuros,mperham
1202,2013-11-21 00:32:55,"@jc00ke did you have any more info to post on this, I would be happy to help if you can provide more context?
",aackerman,jc00ke
1202,2014-07-11 06:04:36,"@mperham not much to go on here but sounds similar to what I've been emailing you about.
",bdmac,mperham
1202,2014-07-20 01:02:55,"@mperham I know you said it might help to make an issue of what we've been discussing here but I think this is basically the same thing we were seeing happen when using sidetiq which used scheduled jobs under the covers.  As mentioned via email, since switching to sidekiq_cron those jobs no longer fail BUT I do still think there is a serious problem with sidekiq scheduled jobs (which is why sidetiq struggled).

Since switching to sidekiq_cron the job that schedules notifications has not missed a beat.  Unfortunately though, that job actually fans out for individual notifications using delay_until (a form of sidekiq scheduled jobs).  I have noticed that we seem to be dropping about 10% of the recipients we should be emailing for no apparent reason and I suspect sidekiq scheduled jobs again. :-(
",bdmac,mperham
1202,2014-07-20 03:07:07,"What would you like to do at this point? Maybe you can repro it with a minimal rails app?

> On Jul 19, 2014, at 18:02, Brian McManus notifications@github.com wrote:
> 
> @mperham I know you said it might help to make an issue of what we've been discussing here but I think this is basically the same thing we were seeing happen when using sidetiq which used scheduled jobs under the covers. As mentioned via email, since switching to sidekiq_cron those jobs no longer fail BUT I do still think there is a serious problem with sidekiq scheduled jobs (which is why sidetiq struggled).
> 
> Since switching to sidekiq_cron the job that schedules notifications has not missed a beat. Unfortunately though, that job actually fans out for individual notifications using delay_until (a form of sidekiq scheduled jobs). I have noticed that we seem to be dropping about 10% of the recipients we should be emailing for no apparent reason and I suspect sidekiq scheduled jobs again. :-(
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1202,2014-07-20 03:14:38,"I'm out of ideas at this point. Just leaving it as a note here and I'll continue to try to think on it and update this with any new info. I have a feeling a  minimal app with minimal load would struggle to repro this sadly.~ Brian

On Sat, Jul 19, 2014 at 8:07 PM, Mike Perham notifications@github.com
wrote:

> What would you like to do at this point? Maybe you can repro it with a minimal rails app?
> 
> > On Jul 19, 2014, at 18:02, Brian McManus notifications@github.com wrote:
> > 
> > @mperham I know you said it might help to make an issue of what we've been discussing here but I think this is basically the same thing we were seeing happen when using sidetiq which used scheduled jobs under the covers. As mentioned via email, since switching to sidekiq_cron those jobs no longer fail BUT I do still think there is a serious problem with sidekiq scheduled jobs (which is why sidetiq struggled).
> > 
> > Since switching to sidekiq_cron the job that schedules notifications has not missed a beat. Unfortunately though, that job actually fans out for individual notifications using delay_until (a form of sidekiq scheduled jobs). I have noticed that we seem to be dropping about 10% of the recipients we should be emailing for no apparent reason and I suspect sidekiq scheduled jobs again. :-(
> > 
> > —
> > 
> > ## Reply to this email directly or view it on GitHub.
> > 
> > Reply to this email directly or view it on GitHub:
> > https://github.com/mperham/sidekiq/issues/1202#issuecomment-49535740
",bdmac,mperham
1198,2013-09-26 23:40:14,"@naaano This PR makes the current code better.  No one is claiming it is perfect.
",mperham,naaano
1198,2013-09-26 23:40:51,"@naaano In other words, I await your pull request. :-)
",mperham,naaano
1194,2013-09-21 22:46:11,"@cpuguy83 is correct. 
One side note is that relying on the registry to call to the manager does mean that old processors will always talk to the latest manager rather than the one which they were started from. 
If you head down this route, it would pay to check that `Celluloid::Actor[:manager]` is the original Manager. 

Also, I would suggest namespacing the registry entry as currently the key is global to the process. 
We have plans for this in [Trello](https://trello.com/c/oBCDIFSL). 
",halorgium,cpuguy83
1194,2013-09-22 00:23:05,"@halorgium wouldn't it be nice, if it is possible to tell a supervisor what to do if a actor crashes?

@mperham looks good to me
",cyrez,halorgium
1194,2013-09-22 00:23:05,"@halorgium wouldn't it be nice, if it is possible to tell a supervisor what to do if a actor crashes?

@mperham looks good to me
",cyrez,mperham
1193,2013-09-21 13:38:10,"This is really great feature. Thanks @ryansch 
",fred,ryansch
1193,2013-09-23 18:54:06,"@mperham That should run without any failures.  I see you've already updated the changelog.
",ryansch,mperham
1193,2013-09-25 17:12:45,"@mperham Bump.
",ryansch,mperham
1193,2013-09-25 17:15:05,"Thanks @ryansch, this is a great improvement.  Do you want commit access?
",mperham,ryansch
1193,2013-09-25 17:18:34,"@mperham Sure, but I'll still run all changes through pull requests to get them reviewed.  :-)
",ryansch,mperham
1193,2013-09-25 17:23:56,"@mperham Do you want me to update the wiki now or when 2.15.0 drops?
",ryansch,mperham
1187,2013-09-22 21:31:58,"@mperham What if it were just next to the the Sidekiq branding, and drop ""Status""
Here is a (very) rough cut-paste of this:

![image](https://f.cloud.github.com/assets/799078/1188411/55fa9e12-23ce-11e3-887e-63c978507a80.png)
",cpuguy83,mperham
1187,2013-09-22 21:33:21,"@cpuguy83 I think that looks fantastic.
",mperham,cpuguy83
1176,2013-09-11 12:56:32,"@halorgium OK, but is it done when invoking the rake task? Shouldn't this be done _by_ the rake task?
",jlecour,halorgium
1176,2013-09-12 21:37:37,"@jlecour The issue is that `minitest` uses an `at_exit` hook to _start_ the test suite. 
`celluloid` uses an `at_exit` hook to shutdown the system. 

This is definitely an incompatibility with the 2 gems; could you file this issue to the celluloid repo?
Note: this affects `rspec` and `sinatra` autorun too. 
/cc celluloid/celluloid#162
",halorgium,jlecour
1176,2013-09-13 12:12:39,"@jlecour this will be the change made between `0.14` and `0.15` of celluloid. 
sidekiq needs to add the `Celluloid.boot` before starting the test-suite. 
We need to figure out how to support this. 

/cc @tarcieri 
",halorgium,jlecour
1176,2013-09-21 23:33:07,"@mperham I understand. Part of the problem is that I could not find a way in `minitest` to add a hook before the suite starts. 

In 0.14, we did not disable the thread pool after shutdown and this resulted in unsafe behaviour after this point. 
In our test suites, we do a complete shutdown/boot (not a huge overhead) between each test to give good isolation. 
I would recommend heading this direction for `sidekiq`. 
",halorgium,mperham
1160,2013-09-05 02:23:54,"@mperham it seems to be a config option. 
@henry74 might i suggest you use the full path, sidekiq does not warn you if the file does not exist. 
",halorgium,mperham
1160,2013-09-05 02:49:43,"@halorgium It is picking up the worker files I've required within the same sidekiq.rb file so it's certainly able to read the file.


",henry74,halorgium
1160,2013-09-05 02:52:13,"@mperham If it's a bug, what is the suggested way to configure sidekiq outside the context of a rails or web application given I am  kicking off sidekiq with the foreman command and a config file.

If you look at line 19 in this file https://github.com/mperham/sidekiq/blob/master/lib/sidekiq.rb, the default includes an example of the require statement:


",henry74,mperham
1151,2013-08-31 21:39:10,"@mperham 

I don't see anything like that towards the end of the file:



Could there be another issue?
",JohnMerlino1,mperham
1148,2014-08-05 22:43:15,"I am also having same situation. Heroku worker eats all the memory that is available. Is there any cap or limit we can set. I did lots of search didnt get lucky. @mperham .
I am using sidekiq with anemone gem. Going thru 1000 websites and looking for specific word. Using betch of 50 per loop. Still it eats everything.>

Also @kwent and @barmstrong .did you guys find any luck.?
",joshidhruv,mperham
1136,2013-08-26 21:39:09,"@mperham thanks. what do i need to upgrade? if you don't mind linking me, thanks.
",masterkrang,mperham
1130,2013-08-25 03:09:11,"@mperham Sorry about that, we were trying to follow the diagnostics used in other issues. I re-added you. Thanks.
",killion,mperham
1123,2013-08-21 23:29:14,"Hello @mperham 

you can test it by running:
sidekiq -c 10 -r ./examples/cron.rb

And I though about this problem. I reused Poller class which works for enqueuing delayed jobs and secondly I use redis sorted set for remembering which job and when it was last enqueued, so there will be no problem with electing any process for it.

Ondrej
",ondrejbartas,mperham
1123,2013-08-24 18:45:25,"Had the same problem. Came up with the hackiest solution to this issue: have a job schedule it's own next run using MyWorker.perform_at. Check out [Scheduled Jobs](https://github.com/mperham/sidekiq/wiki/Scheduled-Jobs) for more info.

@mperham, any thoughts on whether or not you want to include a scheduled component? It's not a small decision.
",bwthomas,mperham
1123,2013-08-24 19:46:51,"@bwthomas Self-scheduling jobs are a reasonable approach, provided you don't need perfect tick-tock scheduling.  I've done that too.

I'm unlikely to pull this in.  It's too complex.  If I'm going to support a feature for years, I want to implement it myself so I know the code and any limitations very well.  There's nothing that says this can't be published as an add-on gem though.
",mperham,bwthomas
1123,2013-08-25 09:44:38,"Hello @mperham, 

I am going to release it as separate gem (https://github.com/ondrejbartas/sidekiq-cron), but I would like to know what do you think about my approach? Is bad, crazy, nice ... ? 

I will let you know when I will finish testing and publishing first version of it.

Thank you.
Ondej
",ondrejbartas,mperham
1121,2013-09-04 18:50:03,"@mperham, any update regarding this?
",yabawock,mperham
1111,2013-08-21 21:49:27,"@mperham I'm currently experiencing a similar behavior, where the batch 'notify' (Campfire) before a batch is actually completed.



In Campfire I'll get a message like this:

Sidekiq finished batch 429ac86dcc000f9e in 4 seconds, 117 of 118 successfully.

But in actuality the batch has a size in thousands. It's almost appears as if the queue is working faster then the batch can iterate overs the rows to be queued and processed.

My understanding from looking at the Middleware::Server module is that when a worker (jib) is completed it reports back to the batch (bid) and the batch. The 'add_success' method is called and the 'pending' and 'failed' counts are checked.

Is it possible that the conditional check is returning true before the batch has finished adding all the jobs to the queue. This would return a false positive cause Server::Batch#notify and Server::Batch#success to be called before the batch has been completed.

Any suggestions would greatly be appreciated.
",ttdonovan,mperham
1111,2013-08-21 22:55:21,"@mperham Just tossing out an idea. What about some kind of lock/unlock mechanism for batches. Before `batch.jobs` you do a `lock` and after the `jobs` block an `unlock`. Any jobs reporting back to the back cannot trigger the `on_success` or `on_complete` if the batch is in a locked state. My previous example would look something like this.



The `unlock` method would remove the locked state and do the conditional checks for `success` and `notify`.
",ttdonovan,mperham
1111,2013-08-30 00:41:48,"@mperham My issues with the batches was resolved by using `Sidekiq::Client.push_bulk` in the batch's jobs block. This is not mention on wiki Batches page. It was not until I starting digging into the source that this solution became obvious for my problem. If it's mentioned elsewhere in the wiki I must have missed it.
",ttdonovan,mperham
1111,2013-09-12 11:48:50,"@mperham I meant no harm. The patch is useless without context. This problem compromises greatly the usage of the batch feature. It would be great to have an official solution available.
",uiltondutra,mperham
1109,2013-08-18 07:57:14,"@mperham I've seen Sidekiq::Shutdown errors raised within the process.  Is this something that can trapped with a Sidekiq worker?
",paulwalker,mperham
1104,2013-08-20 16:18:19,"@mperham How about letting the developer decide how to serialize/deserialize objects of ANY kind?

I've written this as a monkey patch. It works great, and makes total sense:
https://github.com/elado/sidekiq_custom_serializer

Here's the ActiveRecord example:
https://github.com/elado/sidekiq_custom_serializer/blob/master/lib/sidekiq_custom_serializer/extensions/active_record.rb
",elado,mperham
1098,2014-01-30 17:48:20,"+1 @mperham You asked me to create an issue for this on twitter (@bentsolutions), but it seems like the issue already exists
",codebender,mperham
1095,2013-08-06 22:11:16,"@mperham no idea, and Sidekiq::Processor#initialize indeed looks trivial. But it's definitely blowing up in initialize somehow:



See: https://github.com/celluloid/celluloid/blob/0-14-stable/lib/celluloid.rb#L140

@rajofchennai do you see an error for Sidekiq::Processor occurring around the same time?
",tarcieri,mperham
1095,2013-08-06 22:23:16,"@mperham could be! this could potentially happen if the OS was unable to spawn a thread
",tarcieri,mperham
1095,2013-08-07 08:34:29,"@tarcieri makes sense 

@mperham I send TERM to sidekiq and wait for sometime then send QUIT signal to make sure the process is killed. Is there a cleaner way to do the same?. 
",rajofchennai,mperham
1095,2013-08-07 08:42:53,"@mperham maybe we need Celluloid::Actor.raise for this use case:

https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/manager.rb#L168
",tarcieri,mperham
1095,2013-08-07 10:01:49,"Sidekiq doesn't respond to QUIT. You want USR2 and then TERM. 

On Aug 7, 2013, at 1:34, rajofchennai notifications@github.com wrote:

> @tarcieri makes sense
> 
> @mperham I send TERM to sidekiq and wait for sometime then send QUIT signal to make sure the process is killed. Is there a cleaner way to do the same?.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1095,2013-08-07 10:03:40,"Wait, I'm all wrong. Check the Signals wiki page. I think QUiT then TERM is right. 

On Aug 7, 2013, at 1:34, rajofchennai notifications@github.com wrote:

> @tarcieri makes sense
> 
> @mperham I send TERM to sidekiq and wait for sometime then send QUIT signal to make sure the process is killed. Is there a cleaner way to do the same?.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1078,2013-07-29 18:44:32,"@cpuguy83 I actually have had 2 apps that had the same issue. On MRI everything precompiles just fine. If I switch to RBX on Heroku (it might be outdated, pretty sure it installs rc1), then for some reason a lot of my JS/CSS simply isn't compiled, breaking the app. It's like it precompiles N amount of characters and then just stops.
",mrrooijen,cpuguy83
1076,2013-07-27 17:05:58,"@mperham I've updated this to add a status page for scheduled jobs. I also upped the truncation to 2000 characters on the summary pages and display the full argument set on the status page.
",jonhyman,mperham
1069,2015-06-30 08:47:15,"@subelsky by any chance, were you able to try the alternate method suggested in production? Is the code available anywhere maybe? I'm running into a number of issues ([more info here](https://groups.google.com/d/msg/sidekiq/_eFQGtAWm6E/1UXOPstW7ggJ)), so this could help. Thanks!
",thbar,subelsky
1069,2015-06-30 12:17:43,"@subelsky no problem - thanks anyway, I'm investigating this possibility to solve my issue, appreciated!
",thbar,subelsky
1061,2015-07-28 19:28:12,"@mperham thanks!
",amiel,mperham
1058,2013-07-15 21:07:12,"@mperham let's say a 25 thread limit has been reached for the process. Yet I continue to add workers. What happens to those other workers? Are they stored in a queue in redis or are they ignored since the thread limit has been reached? 
",JohnMerlino1,mperham
1053,2013-09-21 22:22:44,"Just merged, thanks @ryansch! 
",mperham,ryansch
1053,2013-11-05 22:46:42,"thanks @ryansch @mperham, just picked up the new version with updates
",ilyakatz,ryansch
1053,2013-11-05 22:46:42,"thanks @ryansch @mperham, just picked up the new version with updates
",ilyakatz,mperham
1047,2013-12-04 13:50:01,"@x3qt , @mperham 
Perhaps _this_ is the issue and not sidekiq problem:
https://github.com/rails/rails/issues/12867

I have tried both with and without sidekiq running.  
Seems the issue persist in both cases and is related to active record (?)
",rubytastic,mperham
1046,2013-07-08 18:29:53,"@mperham 

This is the desktop view: http://cl.ly/image/1G3P313r1O35
This is the mobile view: http://cl.ly/image/1j3s0f3G3B1P
",manishval,mperham
1046,2013-07-08 18:34:18,"@manishval You can just drop images right onto the text editor, then they will display inline.
",mperham,manishval
1046,2013-07-08 18:40:14,"@mperham I think CloudApp is down. Here they are though:

### Desktop

![sidekiq-live-poll-location](https://f.cloud.github.com/assets/1205026/763454/c80b0634-e7fd-11e2-9e63-5dea6fafea9b.png)

### Mobile

![sidekiq-mobile](https://f.cloud.github.com/assets/1205026/763446/8f40ab38-e7fd-11e2-8be9-7300a9d0f10e.png)
",manishval,mperham
1046,2013-07-11 22:37:50,"@mperham so display the summary how it is right now with the two columns?
",manishval,mperham
1046,2013-07-11 22:58:21,"Two columns would look better.

On Thu, Jul 11, 2013 at 3:37 PM, manishval notifications@github.com wrote:

> @mperham https://github.com/mperham so display the summary how it is
> right now with the two columns?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/pull/1046#issuecomment-20847672
> .
",mperham,mperham
1046,2013-07-20 14:28:36,"@mperham Here is the mobile version with 2 columns. Let me know if this is acceptable and I will update the pull request.

![sidekiq-mobile-2](https://f.cloud.github.com/assets/1205026/830357/9db8fc48-f148-11e2-963e-11c9b0d3fb0c.jpg)
",manishval,mperham
1046,2013-07-21 02:08:53,"@mperham I fixed the two minor issues and made the graphs responsive as well. 

Whenever the page is loaded, we get the width of the summary bar since its width is fluid and render the graphs with that width. And whenever the window is resized the graphs are deleted from the page and re-drawn onto the page with the width of the summary bar. A delay has been added to the window resize event so the graphs aren't being reset every pixel. Not sure how suitable this method is.
",manishval,mperham
1045,2013-07-31 13:43:36,"@mperham I read a [blog](http://mikael-amborn.blogspot.in/2013/06/sidekiq-thread-dump-on-heroku.html) of how to get process stack trace using TTIN signals on Heroku. 

Based on that, I got these [logs](https://gist.github.com/varunlalan/6121211). Not sure if this is right or not. Just wanted to confirm if these logs are as expected.
",varunlalan,mperham
1045,2013-08-13 22:25:24,"@mperham re: ""My mistake, that limitation is still there on MRI, even with current Sidekiq versions."" you can probably safely remove the defer on Ruby 2.0 since its Fibers now have large(r) stacks
",tarcieri,mperham
1045,2013-08-13 23:02:01,"@halorgium sgb :wink:
",tarcieri,halorgium
1045,2014-02-25 03:09:20,"@mperham We're actually using Mysql and the mysql2 gem
",ekosz,mperham
1044,2014-02-25 23:28:21,"Sorry for bringing this up after 8 months but it sounds awfully close to the issue I have right now.

I implemented the manage many upstart setup outlined in this repository here:
https://github.com/mperham/sidekiq/tree/master/examples/upstart/manage-many

But as @mperham said one can't use the default cap scripts if upstart is used to manage sidekiq.

The issue also sneaks on you because even if cap task does not restart sidekiq everything is still functional until the release to which sidekiq is attached gets deleted (in my setup that's after 5 deployments as I keep the last 5 releases on the server).

Wouldn't it be a good idea to add capistrano tasks to the upstart examples then? Many capistrano newbies (myself included) would be immensely grateful.
",guareschi,mperham
1044,2014-03-17 18:13:40,"@seuros which version of sidekiq?
",c-castillo,seuros
1044,2014-03-17 18:54:51,"No , i mean version 3 of sidekiq (the one in master). It will be released by the end of this month according to @mperham .
",seuros,mperham
1040,2013-07-20 14:52:57,"@guiceolin Did you see the issue I raised?
",mperham,guiceolin
1039,2014-11-19 13:37:10,"I spoke too soon, it's happening again:



As you can see, I'm using Sidekiq v3.2.3, but the same thing happens with another project that is using v3.2.6.
This is my sidekiq.yml:



Any I'm starting Sidekiq like this:



@mperham, any idea what the problem might be?
",manuelmeurer,mperham
1039,2016-09-06 08:31:54,"Hi @mperham  did you end solving this problem?

My sidekiq is randomly doing this. Sometimes it goes days without incidents, but now and again it starts throwing these errors and stops processing.

Any ideas?
",nocivus,mperham
1037,2013-07-02 16:47:22,"@mperham I am not using the Ruby Timeout API explicitly, but we are making a lot of http requests and I suppose one of the libraries we are using could be.  Perhaps you know a list of common culprits?  What is the suggested workaround if one wanted an explicit timeout someplace or is using a library that uses the timeout API?
",paulwalker,mperham
1037,2013-07-02 17:02:23,"@mperham So, I have tracked down some job failures that are resulting in a Timeout::Error being raised.  The culprit in this case is MiniMagick -> net/http.  The logs show that the job is being enqueued for retry.

Is that what could be problematic?  Should I capture that error specifically and throw a different error?
",paulwalker,mperham
1037,2013-07-08 10:54:11,"@mperham EM thread was  reminent of some legacy code. I am removing it now. I am not seeing any more issues currently. 
",rajofchennai,mperham
1032,2013-11-15 15:23:45,"@mperham If the process did crash how do you remove those entries from the workers list? I've got only a few workers busy but my list of workers remains full of things that appear to be running for hours now.
",rmontgomery429,mperham
1032,2013-11-15 17:41:42,"I’ve had the same problem a few times. The workers would get stuck and stay in the queue for ~24 hours. I still have not been able to track down the issue, unfortunately.

On Nov 15, 2013, at 4:23 PM, Ryan Montgomery notifications@github.com wrote:

> @mperham If the process did crash how do you remove those entries from the workers list? I've got only a few workers busy but my list of workers remains full of things that appear to be running for hours now.
> 
> —
> Reply to this email directly or view it on GitHub.
",elsurudo,mperham
1032,2013-11-15 18:08:25,"@mperham yes. I've used that. I was a little unsure what that did exactly. Does that just clear those jobs from Redis or does it kill the workers or something else?
",rmontgomery429,mperham
1032,2013-11-15 18:27:19,"@mperham Thank you for the clarification.
",rmontgomery429,mperham
1032,2014-07-02 18:05:49,"@seuros - What ruby version fixed this?
",mattleonard,seuros
1030,2013-06-27 15:59:07,"@mperham f58f6b1
",jmazzi,mperham
1030,2013-06-27 16:23:21,"@mperham b41fcd2

On Thu, Jun 27, 2013 at 12:07 PM, Mike Perham notifications@github.comwrote:

> I think I'd like the new block to take the full msg, not the splatted
> args. We'll document the API change; I want the user to have the full
> context of the job, not just the args. This way they have access to the
> JID, etc.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/pull/1030#issuecomment-20133666
> .

## 

Justin Mazzi
",jmazzi,mperham
1030,2013-06-28 17:08:47,"@mperham if you ping me when release is ready, i can add the wiki pages for this and the delay feature.
",jmazzi,mperham
1030,2013-06-28 17:15:40,"@mperham  New APIs are being introduced and one of them has been
deprecated; I would bump the minor: 2.13.0

On Fri, Jun 28, 2013 at 1:14 PM, Mike Perham notifications@github.comwrote:

> What do you think: 2.13.0 or 2.12.5?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/pull/1030#issuecomment-20201433
> .

## 

Justin Mazzi
",jmazzi,mperham
1029,2014-03-26 20:39:02,"@mperham THANKS :+1: 
",rderoldan1,mperham
1027,2013-06-25 16:06:09,"@mperham I figured no special handling should be added and to just let it fail. Would you prefer it log and fallback?
",jmazzi,mperham
1027,2013-06-25 16:13:40,"@mperham my only concern is that applications written with a specific retry behavior may not want it rescheduled outside of what they had defined.
",jmazzi,mperham
1027,2013-06-25 16:36:06,"@mperham just pushed 8983f44
",jmazzi,mperham
1027,2013-06-25 17:57:48,"@mperham refactored this a bit, let me if you want anything changed.
",jmazzi,mperham
1027,2013-06-26 03:42:25,"@mperham reverted that, anything else?
",jmazzi,mperham
1027,2013-06-27 15:22:10,"@mperham looking fo guidance on the above. Is the wiki typically reserved for releases, or can it also document the features that are master only?
",jmazzi,mperham
1025,2013-06-29 00:47:02,"Here is a quick tweak to the layout as @cpuguy83 suggested.

http://cl.ly/image/0M0F1T0N071R
http://cl.ly/image/1j1O46060J3t

It fixes the problem, but now the 'Live Poll' button and the Sidekiq Status at the top of the page feel weird now. Maybe we can move the 'Live Poll' button to the right of the Status title.

http://cl.ly/image/1G3P313r1O35
",manishval,cpuguy83
1025,2013-06-29 13:53:15,"This is how it will looks on mobile:

http://cl.ly/image/1j3s0f3G3B1P

I agree with @cpuguy83 in that it seems like a lot of info once you have it running after the initial setting up. Maybe have an option to hide/show the status bar?

@mperham Putting all of that on one line will be too much and we will end up with the same issue where 9 figures cannot hold on one line.
",manishval,cpuguy83
1025,2013-06-29 13:53:15,"This is how it will looks on mobile:

http://cl.ly/image/1j3s0f3G3B1P

I agree with @cpuguy83 in that it seems like a lot of info once you have it running after the initial setting up. Maybe have an option to hide/show the status bar?

@mperham Putting all of that on one line will be too much and we will end up with the same issue where 9 figures cannot hold on one line.
",manishval,mperham
1022,2013-06-25 03:35:11,"@mperham But, for other error such as `ArgumentError`, sidekiq will silently push back to the queue and retry later. What this error causes sidekiq to crash?
",yangchenyun,mperham
1022,2013-06-25 06:50:05,"@mperham when the crash happens, the whole sidekiq process is died, I can only recover it by starting it up again.
",yangchenyun,mperham
1022,2013-06-27 16:28:07,"@mperham Thanks. I will try that. Just get the site running currently, if biz goes well definitely will upgrade to Sidekiq Pro! 
",yangchenyun,mperham
1020,2013-06-23 23:00:03,"@mperham here it is!

i noticed that some tests are failing every now and then.

is this normal?
",guiceolin,mperham
1019,2013-10-31 13:39:06,"@darkside, @aackerman 

The NewRelic-Sidekiq plugin and the instrumenter for Sidekiq provide different functionality. The built it Sidekiq support instrument Sidekiq Jobs, where as the plugin monitors the Sidekiq process.

So for example, I use the plugin to send new relic stats about the latency of the Sidekiq queue (https://github.com/mperham/sidekiq/wiki/Monitoring#monitoring-queue-latency) 

I can then configure an alert within NewRelic when the latency is above a certain threshold. 
",kfalconer,aackerman
1013,2013-06-24 19:56:19,"@mperham would you want me to refactor both?
",jmazzi,mperham
1013,2013-06-24 20:03:30,"@mperham It would be implemented separately, just wondering if you think it's worth changing `retries_exhausted` implementation to line up with what you defined above for defining retry counts. 

How do you envision the block syntax working, how would you want me to store that definition?
",jmazzi,mperham
1013,2013-06-24 20:31:43,"@mperham would storing the result of the blocks in a class variable be acceptable or did you have something else in mind?
",jmazzi,mperham
1005,2013-06-20 04:51:38,"@mperham Thanks for the reply, I debugged the issue and found out that the bottleneck was the connection pool size for redis which was defaulted to 5. With sidekiq concurrency of 25 this was becoming bottle neck and leading to some kind of deadlock. I think I missed a couple of lines in the error stack and misunderstood the issue. Increasing the connection pool size for redis to 30 fixed the issue for me. 
",rajofchennai,mperham
999,2013-06-15 03:31:01,"@mperham, it works as expect if we don't have the weights of the queues in the yml file! Thank you.
",anhkind,mperham
996,2013-07-20 14:51:18,"@brandonhilkert Do you want to give this another shot or should I close this?  Sad as it is to say, the results haven't been worth merging so far.  I wish I had better design chops and could help.
",mperham,brandonhilkert
996,2013-07-20 18:07:04,"I'm really at a loss as to how to proceed. However, doing this uncovered a
weird js bug that I need to extract from this and make a new PR. So you can
close this one.

On Jul 20, 2013, at 9:51 AM, Mike Perham notifications@github.com wrote:

@brandonhilkert https://github.com/brandonhilkert Do you want to give
this another shot or should I close this? Sad as it is to say, the results
haven't been worth merging so far. I wish I had better design chops and
could help.

—
Reply to this email directly or view it on
GitHubhttps://github.com/mperham/sidekiq/pull/996#issuecomment-21294674
.
",brandonhilkert,brandonhilkert
994,2013-06-11 00:45:03,"Thanks @mperham, that answers my immediate question about `after-fork`. I'm not sure if I have a good solution for managing connections they way I want to yet but I can experiment and see where I end up. Worst case I end up slightly over-provisioning the server and stop worrying.
",jonah-williams,mperham
987,2013-06-13 15:37:17,"@mperham when I tested this, I was using sendgrid and I am pretty sure I was not getting ratelimited. I think you're right about net::smtp
",iwarshak,mperham
987,2013-09-25 17:58:46,"@mperham anything actionable in this thread on Sidekiq's side? If not, I'll close.
",jc00ke,mperham
985,2013-06-07 02:22:06,"@fbjork Which version of Ruby?  You might try master and see if it gives you good performance again.
",mperham,fbjork
985,2013-06-08 01:00:16,"@mperham Ruby 1.9.3 patch level 429
",fbjork,mperham
984,2013-06-07 20:25:06,"Hi @mperham, thanks for the reply! :smile: 

We updated Sidekiq to 2.12.1 and we are using Process.spawn. Interesting that even with `spawn` the `convert` (ImageMagick) still appearing inside the `sh`. We tested our new `execute` method with `tail` and it appears without `sh`. The `convert` is a bin, not a `#!/bin/sh`. I didn't get it yet.

![screen shot 2013-06-07 at 5 14 01 pm](https://f.cloud.github.com/assets/105652/625884/d4413d72-cfae-11e2-8b99-ab6b85fcdc02.png)



The problem still the same (10 of 10 busy/CPU 0.0), after a while the Sidekiq gets stuck, it doesn't even respond to SIGTTIN.

![screen shot 2013-06-07 at 5 22 33 pm](https://f.cloud.github.com/assets/105652/625917/0390c7b8-cfb0-11e2-9a17-2c8e3f07bed1.png)

A dirty workaround is a Monit resource trigger:



But it restarts Monit every 5min (maximum) and it is hiding our problem.
",phstc,mperham
984,2013-06-16 16:26:51,"@phstc Thank you for reporting back!  It's great to know that 2.0 solves at least one lockup problem.  There's no special config for Ruby 2.0 for sidekiq.
",mperham,phstc
984,2013-09-11 18:49:15,"@mperham I'm not using a imaging gem.  I'm directing using Process.spawn like above.
",ekosz,mperham
983,2013-06-05 17:31:05,"Wow. You just saved me a lot of time. Thanks @brainopia!
",ryana,brainopia
983,2013-06-05 17:52:06,"Yeah. What @brainopia is suggested is exactly what I'm looking for. Thanks so much for building this. It's great. Gonna have it deployed in a few minutes :)
",ryana,brainopia
976,2013-06-04 18:24:11,"@mperham You suggest that the AR object will cause memory overflow? 
Comparing with the stable running status, what I've changed is adding two new types of work:
- both involve one AR instance fetch with `find`.
- both sending POST request to remote server with a timeout of 10 seconds.

The issues happened after I added this two type of work into sidekiq. 

Because the sidekiq just dies without leaving anything trackable, is there way I could inspect what happens then?
",yangchenyun,mperham
975,2013-06-03 07:43:17,"@halorgium, Seems that this used to be set to the info level celluloid/celluloid#94 before being changed to debug. There's a mention that this could be changed by a client?
",Soliah,halorgium
961,2013-05-29 22:40:21,"I like the idea of putting it into the Enqueued number in paren format. That's significantly clearer and doesn't add another stat to the summary. Thoughts @mperham ?
",cmwright,mperham
961,2013-05-31 01:05:13,"I thought about this some more and looked over the code. I'm not sure an average of the queue growth really helps. Speaking personally, when I dump a crap load of jobs into the queue, there's some process in a console somewhere trying to send as fast as possible. The graphs were meant to see what is happening in real-time, which I think they do for processing.

You bring up a good point that you don't get a good sense of enqueued changes when you're looking at the graph, unless you just stare at the enqueued stat in the summary box. At times, I've done quick math in my head to back into the change in enqueued jobs, so that number is and has been valuable to me.

Since that number can change over every poll for stats, I'm wondering if adding one more line to graph for the number of enqueued jobs over that period would give you that same value. Also, add a stat historical purposes so you can see how much you send over time.

However, I remember in the past, @mperham had turned down an offer to add something like that to the stats making the valid point that enqueued = processed + failed so you can back into the number. I hear that, but I also see how something on the graph could be appealing.

Thoughts?
",brandonhilkert,mperham
961,2013-05-31 15:21:00,"I'm not sure I totally agree with the last part. The historical graph provides processed and failed over time. Assuming you don't shut Sidekiq off for days at a time, i think it's safe to say over those historical periods that the system ran all those jobs. So the total historical jobs that were created are the sum of the historical processed and the historical failed.

I've personally never had a need to see what you're referring to. That doesn't mean it's not valuable, I just can't relate. I can relate to knowing in realtime how much is getting sent in, which is what I and what I think @mperham is speaking to. Perhaps this PR is diverging.

@mperham How about I create a separate PR to start discussions on visualizing real-time back pressure?
",brandonhilkert,mperham
961,2013-05-31 15:46:52,"Agreed on all points. To me, if you average those numbers, it blurs what's going on in real-time. If you want to add to  the historical graph, I can see where average would be appropriate, however, again, I think processed and failed summed together equate to what was sent in.

I can't see more value outside of the realtime number, but I'll @mperham decide what he prefers.
",brandonhilkert,mperham
954,2013-05-29 21:36:44,"@mperham the blocking database call should block the entire actor until the query is complete. This sounds like a bug where multiple actors (or potentially tasks) end up sharing the same connection, possibly due to, as you suspect, a bug in the new thread local code
",tarcieri,mperham
954,2013-05-30 06:11:54,"@mperham  I tried out the fix. I have run it in production for the last one hour. Errors have stopped coming.
",rajofchennai,mperham
954,2013-08-27 03:18:21,"@queso We're using the same versions/stack and don't see any issues.  I suspect you have some mysql connection sharing, possibly in forked processes.  By chance are you using rainbows or puma with a hybrid concurrency model?
",mperham,queso
954,2013-08-27 03:34:34,"@mperham,

Puma is running on another box, not the box throwing the errors.  Our worker box is throwing the errors.I think you are on the right track, but it is the sidekiq threading in this case. I will admit, this is starting to push the limits of my knowledge of rails/puma/sidekiq/mysql and connection pooling, etc but all signs seem to point to the error stemming from our sidekiq box/code. 
",queso,mperham
954,2013-08-29 04:33:43,"@queso I think you can do something like `ActiveRecord::Base.reset_active_connections!`  Check the docs.
",mperham,queso
943,2013-05-23 15:57:27,"@mperham it's about 2500 lines of stacktrace. Will try to create gist.
",EvilFaeton,mperham
943,2013-05-24 06:22:21,"@mperham I'm not sure about this, after reverting to 2.11.2 and 0.13 for celluloid all works fine.
",EvilFaeton,mperham
943,2013-05-29 05:59:57,"I will be with @mperham tomorrow and will try and diagnose this issue. Anyone in PDX should come along!
http://www.mikeperham.com/2013/05/26/celluloid-and-sidekiq-hackfest-in-portland/
",halorgium,mperham
943,2013-05-31 05:11:13,"@tarcieri @mperham I had a beer at lunch and got brave/stupid and rolled out to production. All running smoothly :+1: Great work guys!
",lsimoneau,mperham
943,2013-05-31 05:59:21,"@mperham, @tarcieri, all good here on production too for the last 3 hours. Thanks for all the hard work :heart:
",Soliah,mperham
941,2013-05-24 18:08:08,"@cap10morgan I'm not sure if you're on Rails 4, but at least the Rails 4 problems will be solved in a gem release once Rails 4 is actually released. See: https://github.com/smartinez87/exception_notification/issues/155
",elsurudo,cap10morgan
941,2013-05-24 19:30:15,"@mperham Understandable. Although no version of Sidekiq works with the latest release of exception_notification for reasons I was unable to determine (execution silently stops inside the compose_email method in lib/exception_notification/notifier.rb), so it's a tricky situation.

Now that I'm on master HEAD of exception_notification, I'd rather have this commit stay in Sidekiq. But I can lock the version of that easily enough in my Gemfile.
",cap10morgan,mperham
932,2013-05-24 02:47:13,"@plentz  Did you ever solve this Sidekiq problem? How?
",HenleyChiu,plentz
932,2013-05-24 11:45:09,"@plentz tried latest version of sidekiq? or a different distro?
",fred,plentz
932,2013-06-03 22:29:37,"@mperham thanks for the heads up. I will reduce it to 5 and see how it goes.
",plentz,mperham
932,2013-06-04 00:52:39,"@mperham Unfortunately, I already did almost that with no luck:
- once I found the problem, I rolled back our `Gemfile.lock` to the version before the deploy that caused the problem. The segfaults kept happening.
- then I updated to the last version of all gems... the problem didn't go away.

I also tried updating to every ruby version since the version we were, no luck either. Currently, I'm using ruby 2.0.0p195.

So I really thing this a problem triggered by a change in our code, but since it's a list of more then 150 commits, is really hard to guess which part can be the root cause of the problem.
",plentz,mperham
932,2013-06-04 00:58:58,"git bisect could help if you can use it. 

On 3 Jun 2013, at 17:52, Diego Plentz notifications@github.com wrote:

> @mperham Unfortunately, I already did almost that with no luck:
> 
> once I found the problem, I rolled back our Gemfile.lock to the version before the deploy that caused the problem. The segfaults kept happening.
> then I updated to the last version of all gems... the problem didn't go away.
> I also tried updating to every ruby version since the version we were, no luck either. Currently, I'm using ruby 2.0.0p195.
> 
> So I really thing this a problem triggered by a change in our code, but since it's a list of more then 150 commits, is really hard to guess which part can be the root cause of the problem.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
932,2013-08-08 21:47:45,"@mperham not really


",plentz,mperham
930,2013-05-16 21:32:14,"@didil Fantastic!  Would you mind adding the GitHub URL to your gemspec so people can find the repo associated with the gem?
",mperham,didil
921,2013-08-05 20:47:14,"Have you tried wrapping all of the DB calls in a mutex and reestablishing connection inside the mutex every time? I know it may seem like a bunch of overhead but it could solve the deadlock problem. @mperham may have some comment here, but it looks like your stack is very network/cpu bound and it can afford to have an inefficient database communication method. I don't have much help other than to make sure you're running the latest version of pg and sidekiq
",scootklein,mperham
921,2013-08-05 20:56:03,"Even a few moments scan of our code is a very generous offer @mperham. Thanks very much. I'll ping you privately with details.
",rsbrown,mperham
912,2013-08-03 10:27:45,"I'm having the same problem with Mongoid and Sidekiq. @durran the point is that the connections are correctly pooled and they are reused once a job is finished and a new one is started as expected. The problem is that it seems the authentication is made every time a job is processed.
I'm using moped 2 and mongoid 4 with the moped-2-integration branch and this is the output I get at the mongodb log when no authentication is required:



And that's it. So apparently the connections are extracted from the pool successfully. 
But when a user and password is passed, I get this:



And this is the test worker I wrote to isolate this behavior:



And as @fbjork pointed, this can hammer the database and degrade the global performance especially when there are a lot of open connections.
I know this issue might be more related to Mongoid/Moped than Sidekiq, but preferred to continue with this thread as other Sidekiq users might find the same issue(just let me know if we should move the discussion to the Moped project)
Thank you
",dagi3d,fbjork
897,2013-08-28 18:43:14,"@queso You aren't clear what the problem is.  Sidekiq has to kill any lingering workers so it can shut down in a timely manner.  Jobs that are shut down in that manner are pushed back onto the queue so they can be re-executed when Sidekiq starts back up.
",mperham,queso
897,2013-08-28 20:08:21,"@queso You shouldn't be using the EM client within Sidekiq jobs.  Use the blocking client since you have multiple threads.
",mperham,queso
897,2014-06-05 00:11:52,"@mperham, ah okay. Many thanks for your reply!

Is there a bug here with `Sidekiq::Shutdown` showing up inside the db query? Not a huge deal now that I understand it's not what is causing my job to restart. Just curious! Thanks again...
",benjaminwood,mperham
893,2013-05-02 20:53:34,"@dennisreimann I would prefer people fork and add smarts and options to the retry middleware.  The default retry middleware that Sidekiq ships with is a reasonable default and I don't want to add anymore complexity to it.
",mperham,dennisreimann
881,2013-10-29 22:21:45,"@aackerman I'm on 2.15.1 now, haven't had this issue in quite some time.
",marclennox,aackerman
880,2014-08-25 23:47:11,"@mperham - In general, if sidekiq is running as daemon, will it reload the source before starting a new job? Or do I need to restart sidekiq in order for this to happen?

For example,
- Code starts as version A
- Sidekiq starts as daemon
- Code is now at version B
- Job comes in and is processed - will it be processed with version A or version B?
",TimKJones,mperham
875,2013-04-25 17:22:25,"@brandonhilkert We just need to change the code to show the key if it doesn't exist in the locale.
",mperham,brandonhilkert
872,2013-04-25 19:07:52,"@mperham Thanks for your prompt response.So can you guide me with the solution on what is required to to make the implementation behave in desired manner as mentioned in my first post? Will it be correct if I do not use delay extension and consider the fact that BulkEmailWorker#perform_async should move the email sending task to background?

Update:

 Replacing 



 WITH



and invoking



doesn't even enqueue the task in any of the queues.I tried even with the default queue.



Thanks,
Jignesh
",JigneshGohel-BoTreeConsulting,mperham
872,2013-04-26 08:39:50,"Sorry it was my misunderstanding due to which I posted the comment https://github.com/mperham/sidekiq/issues/872#issuecomment-17034171. Actually the worker did processed the task as can be seen from the Stats.processed value.



However I misunderstood that it was not processed in the sense that I didn't received any email after replacing



WITH



But it was obvious that I didn't received any mail because I didn't invoked  **deliver** on **BulkMailer.general_mail(mail_template.id)** after removing **delay** from my ActionMailer class.

I did that change i.e.



and I am getting the mails being sent in the background triggered by the worker and it is being assigned to the custom queue too if I use a custom queue name.

My apologies once again for the inconvenience caused due to my own misunderstandings and @mperham appreciate your prompt help.

Thanks,
Jignesh
",JigneshGohel-BoTreeConsulting,mperham
862,2013-04-23 21:46:24,"@mperham I'm not that familiar with the threading code so I can't say for sure, but it looks like http://ruby-doc.org/core-2.0/Thread.html#method-c-handle_interrupt is meant to fix this? Specifically the safe resource allocation / deallocation.

There was also some code in ruby core to have timeout.rb guard from exceptions by default, but it was taken out of 2.0.0p0: https://github.com/ruby/ruby/commits/ruby_2_0_0/lib/timeout.rb

edit: looks like there was also related discussion in http://bugs.ruby-lang.org/issues/show/4283 , which was closed with a patch that was pulled into 1.9.2. Clearly that didn't solve our issues though, so there must be something else I'm missing...
",skyshard,mperham
862,2013-04-25 14:08:42,"@mperham Ah, that is currently not the case, like @ffmike pointed out.
",bartolsthoorn,mperham
862,2013-05-22 08:41:54,"No, I didn't have worker timeouts, just timeouts on blocking unreliable parts (eg. fetching resources over http). Most of the code had no timeout. I've had about 200,000 works done via Sidekiq using Timeout.timeout as suggested by @mperham  and I'm having 0 issues so far.
",Netherdrake,mperham
862,2016-01-18 07:49:36,"@geku @mperham What is a recommended HTTP client to use in Sidekiq jobs then, if `Net::HTTP` and `Excon` use `Timeout.timeout` for their open/connect timeouts?
",szimek,mperham
862,2016-01-18 08:35:01,"Timeout is only unsafe when wrapping a complex block of work. A block with a single network operation is safe. 

> On Jan 18, 2016, at 02:49, Szymon Nowak notifications@github.com wrote:
> 
> @geku @mperham What is a recommended HTTP client to use in Sidekiq jobs then, if Net::HTTP and Excon use Timeout.timeout for their open/connect timeouts?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
862,2016-01-18 08:39:47,"@mperham Thanks. Last weekend we had an issue where all workers were blocked for the whole day by the same job that makes a request to Facebook using `Net::HTTP` (via Koala and Faraday), even though we have open and read timeouts set. I thought that maybe it's somehow related to the fact that `Net::HTTP` is using `Timeout.timeout` for open timeout.
",szimek,mperham
862,2016-01-22 08:44:27,"@mperham thanks for clarification
",geku,mperham
862,2016-04-12 14:24:43,"@AdamFinley not really :/ as @ryansch suggested we switched from `Net:HTTP` to `Excon` (in Koala lib)  and fortunately we haven't had any similar issues with workers since.
",szimek,ryansch
859,2013-04-17 17:29:10,"@mperham I think that's a good alternative since we can't use find().. and I'm fine with using the existing delete functionality too.  Will update!
",jharbert,mperham
857,2013-04-18 13:07:59,"@mperham  I'm using ruby 2.1.0-dev and having a similar issue. Sidekiq randomly freezes up when performing jobs, and almost every time I try to shut it down. Tried 2.9.0 and 2.10.0 versions, no result.



After command-line interrupt it can be only killed with `kill -9 {pid}`.



With debug mode enabled:


",sthetz,mperham
857,2013-04-18 20:22:13,"@mperham I can't yet tell if random freezes are gone (they usually take up to several days to happen), but 2.10.1 seems to occasionally freeze up on shut down (when there are busy workers left). My ruby version is `2.1.0-dev`, but I also experienced those freezes on `1.9.3`. 
But now it seems to happen less, about 1 time in 5 tries.
",sthetz,mperham
857,2013-04-18 22:08:45,"@mperham @sthetz is there a way we could possibly track this down if it doesn't throw anything and the log is clean? This is an issue that severely affects system stability in the long run.
",fenelon,mperham
857,2013-04-24 08:32:59,"@TheHodge, do you mean you removed `require ""libxml""` or did you have to get rid of any xml libraries such as Nokogiri?
",sthetz,TheHodge
856,2013-04-16 20:31:13,"@mperham Cool - I'll close this and re-open with the new implementation
",jharbert,mperham
852,2013-04-15 22:09:29,"@mperham It ran for a good 30-40 minutes without any issues and then failed shortly after I started inserting jobs with timeouts again, so I strongly believe timeouts are the issue. Come to think of it, we didn't have any issues before we implemented timeouts in production either.
",jacobjervey,mperham
847,2013-04-11 18:07:37,"@mperham reading up.
",maxwell,mperham
847,2013-07-15 18:46:58,"I was plagued by this error and several related errors, triggered when we started a whole bunch of jobs at once. The only thing that worked was wrapping our `perform` method in this block:



seems like that would make an awesome middleware. @mperham is that something you would welcome as part of the existing ActiveRecord middleware, or is this something better left as custom code? 

FWIW all of our Sidekiq workers run in projects that are completely separate from Rails, but use ActiveRecord. Works great except for this glitch.
",subelsky,mperham
847,2013-07-15 18:50:11,"@subelsky That's an interesting idea.  It would add overhead to any Sidekiq jobs executing but not using AR.  On the other hand, it's got real potential to fix a common complaint.  I'd be ok adding it to the existing AR middleware.
",mperham,subelsky
847,2013-07-15 18:50:29,"Thanks! We've still been getting this error intermittently -- I'll try that code block and report back.

On Jul 15, 2013, at 1:47 PM, Mike Subelsky notifications@github.com wrote:

> I was plagued by this error and several related errors, triggered when we started a whole bunch of jobs at once. The only thing that worked was wrapping our perform method in this block:
> 
> def perform(args)
>   ActiveRecord::Base.connection_pool.with_connection do
>     # do stuff
>   end
> end
> seems like that would make an awesome middleware. @mperham is that something you would welcome as part of the existing ActiveRecord middleware, or is this something better left as custom code?
> 
> FWIW all of our Sidekiq workers run in projects that are completely separate from Rails, but use ActiveRecord. Works great except for this glitch.
> 
> —
> Reply to this email directly or view it on GitHub.
",matthooks,mperham
847,2013-07-15 19:13:58,"@mperham alright let me exercise it a bit in production and make sure it's definitely going to fix it
",subelsky,mperham
847,2013-07-16 01:11:14,"this middleware definitely helps but I'm still getting tons of ""PG: result has been cleared"" crashes - I know that's not a Sidekiq issue, but my gut is telling me it has to do with the way ActiveRecord's connection pool sets things up, like I'm trying to establish a connection too early and things are getting FUBAR'd. 

I tried moving my `establish_connection` call into the worker's initializer and got immediate `SIGTRAP` crashes as soon as I performed any jobs. I feel like what I need is a hook that gets called after the server starts a new thread, just before perform gets called. Is that something that could be done with middleware? I know @mperham is not a fan of hooks, just wondering if you had any ideas about how best to get Sidekiq running with AR completely outside of a Rails app. I'm having this problem with ActiveRecord 3 and 4
",subelsky,mperham
847,2013-07-22 13:40:10,"@mperham I'm having trouble getting my code to play nicely with the other tests (I'm having to do a lot of contortions to make sure it only runs when ActiveRecord is in use). Given your performance concerns do you think it makes more sense for me to write it as an optional middleware? Or would you mind if I added a conditional at the end of https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/processor.rb#L23 that doesn't add this middleware at all if ActiveRecord is not defined?
",subelsky,mperham
847,2013-07-22 16:16:53,"@subelsky I prefer things to be correct by default.  Asking someone to use Sidekiq, experience the error, find this issue and add the middleware manually seems user-hostile.  If your approach does help the problem, let's open a new issue focused on your issue and possible fix to discuss how best to integrate it.
",mperham,subelsky
838,2013-04-09 19:06:37,"@mperham sorry for the line noise - for some reason that other one didn't show up when I search before creating this.
",UnderpantsGnome,mperham
836,2013-08-01 12:57:01,"Seems like I'm having the same exact error for a standard GET request. I'm using version 2.12.4 with unicorn and have nothing inside the `after_fork` block.

Any help on how to debug this? I'm pretty clueless.

From what @mperham said seems like the unicorn worker started serving requests before actually booting the Rails application fully. I'm not sure that is even possible though...
",mtylty,mperham
834,2013-04-07 18:25:21,"@mperham what's happening?
",tarcieri,mperham
834,2013-04-07 19:02:28,"It was what we chatted about the other night.  Getting the underlying thread handle to raise Shutdown seems to block on the actor for some reason. 

On 7 Apr 2013, at 11:25, Tony Arcieri notifications@github.com wrote:

> @mperham what's happening?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
832,2013-04-13 06:26:11,"Hey @mperham thanks for looking into this. Here it is:


",ringular,mperham
832,2013-04-20 10:33:07,"thanks for looking at it @mperham I'm still not sure why this is happening. I'll investigate further on active record. Seems like this isnt anything to do with sidekiq. 
",ringular,mperham
827,2013-05-04 03:09:43,"Thanks for the tips. This is definitely not an issue with Sidekiq so I won't leave this open.

@mhenrixon where are you moving to?
",benubois,mhenrixon
815,2013-04-20 12:04:57,"@grosser You're right, it makes sense to have two shutdown modes: (1) take as much time as you need to finish work and exit; (2) finish work and exit within X seconds.  I think historical implementation issues prevented (1) but it should be doable.  I am mostly worried about leaving lingering Sidekiq processes which never shutdown - that's why I've preferred to use TERM.
",mperham,grosser
791,2013-04-01 12:26:01,"Thats it, @rmm5t . Closing issue =)
",hgsigner,rmm5t
789,2013-03-22 01:24:22,"Hi @bensie This seems terribly impractical. Lock is used in more classes than this. Additionally this is not a unique error. We're getting the for a variety of libraries. My impression was that adding the lib folder under autoload should have fixed it but we're finding out that's not the case. 
",juand,bensie
789,2013-03-22 04:19:42,"@mperham the but issues is again that it's not a practical solution, since it would mean we'd need to eager load for each class all the dependencies. If autoload is not safe, is there another way to load the entire dependency tree safely? 

Edit:
You had also recommended using the autoload feature on a previous thread, so i'm not entirely sure if it's then the best way to do it.
",juand,mperham
789,2013-05-29 18:45:49,"@mperham thanks for correcting me. Isn't Autoloading a basic configuration
for Rails though? I feel like this is probably one of those things that
people just take for granted in Rails and gloss over. It certainly happen
to me which is why I opened this thread to begin with.

I think that with Rails even though it does support thread safety, it's
something you need create your application around. If it's an existing
application that you're just dropping something like sidekiq in, you're
bound to encounter issues like this, unlike an earlang framework where the
entire language is thread-safe out the box.

This was my first time delving into multi-threading so I do apologize if
this has been discussed before, I just find this conversation very enriching.
",juand,mperham
785,2013-06-26 19:45:57,"@mperham let me know if you come up with an alternate solution that works well, please! :)
",steveklabnik,mperham
780,2013-03-21 19:52:17,"Thanks for the contribution and working through this with me, @jkassemi!  Oh want to update the changelog and give yourself some credit?
",mperham,jkassemi
780,2013-03-21 20:18:52,"@jkassemi Don't forget to add something to the Wiki about this if you haven't already. This is a great feature that other people should know about. Perhaps here https://github.com/mperham/sidekiq/wiki/Error-Handling
",brandonhilkert,jkassemi
780,2013-03-21 20:44:54,"Changelog's updated in #787 

@mperham - yes... I noticed that myself... brothers separated at birth, maybe?

@brandonhilkert - I'll get to it before I head out for the day. 
",jkassemi,mperham
780,2013-03-21 20:44:54,"Changelog's updated in #787 

@mperham - yes... I noticed that myself... brothers separated at birth, maybe?

@brandonhilkert - I'll get to it before I head out for the day. 
",jkassemi,brandonhilkert
780,2013-03-27 09:02:33,"/cc @mperham @jkassemi 
",ognevsky,jkassemi
780,2013-03-27 09:02:33,"/cc @mperham @jkassemi 
",ognevsky,mperham
780,2013-03-27 20:05:02,"@mperham I haven't even thought about this, thanks! 
",ognevsky,mperham
778,2014-05-14 20:34:40,"@mperham thanks for having a look. I AM on a old version of sidekiq (2.15.2).
https://gist.github.com/jasherai/2c3c7b6533494df0636c

I'm noticing some other oddness at the moment, so I shan't waste your time until I've checked those issues out. I'll drop in an update once I nail this down (or I'll be back begging for help! :smile:  )
",jasherai,mperham
778,2014-05-14 21:23:51,"oh gibbering turnip jugglers!

For me it was the unicorn config. (The purpose of the deploy was to move to env vars throughout). I apparently missed a YAML::load in my unicorn configs after_fork block. This apparently allowed unicorn to boot up, bit made sidekiq swoon at the hint of a request...

Hopefully this helps someone in the future...

@mperham  thanks for being my rubber duck debugger! :grinning: 
",jasherai,mperham
777,2014-04-14 12:30:04,"@seuros Thanks for the informative link, mike did some cool modifications in version 3. But as far as my application is concerned, it can live with 2.x for now.
But would definitely try upgrading to 3 in future.
",emtee,seuros
776,2013-03-14 22:38:22,"@mperham Ruby 1.9.3. It's in the Gemfile and here's the confirmation from the heroku console:


",rmm5t,mperham
776,2013-03-14 23:07:35,"@mperham Thanks. I'll continue to dig deeper. I've just confirmed that everything works as expected with Pow, Thin, and WEBrick. It's only under a unicorn environment that things go awry. 
",rmm5t,mperham
776,2013-03-14 23:58:22,"Okay, I appear to have fixed the issue by setting `preload_app true` in the unicorn config. When `preload_app` is false (the default for unicorn), ActionMailer::Base gets loaded in the master process and then again in each child process and appears to blow away the extension module. 

@mperham Does this behavior make sense? Is this worth documenting somewhere? 
",rmm5t,mperham
776,2013-09-06 12:20:05,"Hey @rmm5t, do you know if the moral of the story is still true for today's version of sidekiq?
",thbar,rmm5t
776,2013-09-06 12:47:57,"@thbar No, the `after_fork` is no longer necessary with sidekiq. @mperham [took care of this in v2.9.0](https://github.com/mperham/sidekiq/blob/master/Changes.md#290) (#794).
",rmm5t,mperham
776,2013-09-06 12:51:41,"@rmm5t thanks! I saw that but wasn't completely sure. Thank you for the confirmation.
",thbar,rmm5t
764,2013-08-19 14:44:16,"@nirvdrum sidekiq-limit_fetch has functionality to ""pause"" a particular queue (stop processing further items from that queue). Perhaps you could use that functionality to either loop through all the queues and pause them all, or look at the code and create your own method to do this. It looks like it uses a redis LUA script to filter out the ""paused"" queues: https://github.com/brainopia/sidekiq-limit_fetch 
",travisp,nirvdrum
760,2013-04-09 16:36:07,"Hi everyone,

I agree on keeping things simple. I don't like to clutter stuff just for the sake of doing it.

@mperham you're right. Our rule of thumb with Padrino is to teach and help the user make decisions instead of assuming everything for them - i.e., most people would know how to handle this situation. However, that doesn't mean that there're users that don't know all the internals of both systems and may feel overwhelmed when trying to link them together.

I'm in favour of closing this PR and creating a separate, `sidekiq-padrino` gem. The only drawback I see here is that [some parts of Sidekiq are tied to Rails](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/cli.rb#L189-L228) and for the gem to work it would have to override them and it would have to be kept in sync going forward. I did something similar a while ago trying to un-rails declarative_authorization and it wasn't a pleasant experience -it ends up looking like an ugly hack :(.

This isn't a big deal though. However, it might behave better if Rails support is stripped out into its own gem too; for simplicity purposes. In any way, I do understand that the main user base might be Rails-based so it's really up to you.

Thoughts?
",dariocravero,mperham
727,2013-02-22 20:00:03,"@benweint The code explicitly doesn't do what you say it does.  I'm confused.  Is something causing celluloid to be booted ahead of time?


",mperham,benweint
727,2013-02-22 20:12:47,"@mperham looks like celluloid is still being required via this path prior to daemonize:


",benweint,mperham
720,2013-04-09 06:20:41,"Hello, @mperham . Yep, we moved to another EC2 server, but even on new server we sometimes have such errors. Main problem what after this warning sidekiq stop working. Will be better if it will die or just try reconnect to redis. But right now it just stop working under workers, which is not good workflow.
",le0pard,mperham
720,2013-04-09 06:30:29,"@le0pard seems silly - but check you're not using an EBS backed instance with Redis's data set on the EBS volume (e.g. in /var/lib/redis, which is the default for the ubuntu packages) - I tweaked that on ours and timeouts have disappeared for the moment.
",Sutto,le0pard
720,2013-04-09 12:00:55,"Latest sidekiq master recovers from the error. 

On 8 Apr 2013, at 23:20, Alexey Vasiliev notifications@github.com wrote:

> Hello, @mperham . Yep, we try move to another EC2 server, but even on new server we sometimes have such errors. Main problem what after this warning sidekiq stop working. Will be better if it will die or just try reconnect to redis. But right now it just stop working under workers, which is not good workflow.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
720,2013-04-09 12:14:27,"Big thanks, @mperham . Can you show me what exactry commits (or pull request) fix this? I coudn't found its, because last tag v2.8.0 and diff too big from master:

https://github.com/mperham/sidekiq/compare/v2.8.0...master
",le0pard,mperham
720,2013-04-09 13:18:38,"See history for schedule.rb

On 9 Apr 2013, at 05:14, Alexey Vasiliev notifications@github.com wrote:

> Big thanks, @mperham . Can you show me what exactry commits (or pull request) fix this? I coudn't found its, because last tag v2.8.0 and diff too big from master:
> 
> https://github.com/mperham/sidekiq/compare/v2.8.0...master
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
719,2014-02-10 02:56:50,"@mperham,

I can write a PR tomorrow.
Basically I will follow @benweint suggestion: adding nohup instead of -d option.

Which strategy you think fits best?
1 - Detecting if its jruby from JRUBY_VERSION or RUBY_ENGINE.
2 - Adding a :sidekiq_daemonize flag, which by default is true. If it's set to false, nohup will be used.

If you got any other thoughts let me know. I will try to implement it.
",dballona,benweint
719,2014-02-10 02:56:50,"@mperham,

I can write a PR tomorrow.
Basically I will follow @benweint suggestion: adding nohup instead of -d option.

Which strategy you think fits best?
1 - Detecting if its jruby from JRUBY_VERSION or RUBY_ENGINE.
2 - Adding a :sidekiq_daemonize flag, which by default is true. If it's set to false, nohup will be used.

If you got any other thoughts let me know. I will try to implement it.
",dballona,mperham
719,2014-02-10 03:13:55,"Probably best to detect JRuby. 

> On Feb 9, 2014, at 18:56, Diego Ballona notifications@github.com wrote:
> 
> @mperham,
> 
> I can write a PR tomorrow.
> Basically I will follow @benweint suggestion: adding nohup instead of -d option.
> 
> Which strategy you think fits best?
> 1 - Detecting if its jruby from JRUBY_VERSION or RUBY_ENGINE;
> 2 - Adding a :sidekiq_daemonize flag, which by default is true;
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,benweint
719,2014-02-10 03:13:55,"Probably best to detect JRuby. 

> On Feb 9, 2014, at 18:56, Diego Ballona notifications@github.com wrote:
> 
> @mperham,
> 
> I can write a PR tomorrow.
> Basically I will follow @benweint suggestion: adding nohup instead of -d option.
> 
> Which strategy you think fits best?
> 1 - Detecting if its jruby from JRUBY_VERSION or RUBY_ENGINE;
> 2 - Adding a :sidekiq_daemonize flag, which by default is true;
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
710,2013-02-15 17:20:21,"@mperham How could that be? I restarted my laptop, restarted redis-server, and did a `redis-cli FLUSHALL`. Isn't that enough to get it back in sync?
Edit: hmm I did remove some local redis-related files, maybe that caused it. Still, I don't know how to completely 'reset' it.
",pointerbp,mperham
702,2013-04-15 23:54:29,"@mperham yes, using the timeout option on almost everything
",mariovisic,mperham
702,2013-04-15 23:58:16,"@mariovisic If you can reproduce the problem reliably, you might try removing the timeout and seeing if that helps with the issue.
",mperham,mariovisic
702,2013-04-16 00:01:53,"@mperham i'll see if I can test it out. The getting stuck is very random and has been fine for the last few days.
It seems to occur when we have a high amount of longer running jobs (maybe 10-30 seconds each), they are mostly blocking on API calls with SSL
",mariovisic,mperham
702,2013-04-16 00:18:41,"I don't use timeout on mine. 

Sent from my iPhone

On 2013-04-15, at 8:02 PM, Mario Visic notifications@github.com wrote:

> @mperham i'll see if I can test it out. The getting stuck is very random and has been fine for the last few days.
> It seems to occur when we have a high amount of longer running jobs (maybe 10-30 seconds each), they are mostly blocking on API calls with SSL
> 
> —
> Reply to this email directly or view it on GitHub.
",cmer,mperham
702,2013-04-16 00:22:59,"My jobs also get a high number of SSL failures, maybe one in every 10_000 jobs will fail due to an SSL negotiation failure. We run around 12_000 jobs every 30 mins or so; so it's fairly common.

Does the stack trace from my workers when they were stuck help you at all @mperham https://gist.github.com/mariovisic/939fb704e2d684b04353 ?
",mariovisic,mperham
702,2013-04-16 00:44:17,"Yep, that's exactly when I see it too.  Lots of long running jobs making
external ssl calls.

On 15 April 2013 20:02, Mario Visic notifications@github.com wrote:

> @mperham https://github.com/mperham i'll see if I can test it out. The
> getting stuck is very random and has been fine for the last few days.
> It seems to occur when we have a high amount of longer running jobs (maybe
> 10-30 seconds each), they are mostly blocking on API calls with SSL
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/702#issuecomment-16418798
> .
",marclennox,mperham
702,2013-04-16 19:10:12,"@mperham I think you're onto something with the timeout middleware.  I removed the timeout option from my workers right around the time that I stopped seeing stuck threads...
",marclennox,mperham
702,2013-04-17 03:01:43,"@mariovisic Indeed. We're moving to dedicated image processing machines and Dragonfly (vs Carrierwave). 
",cmer,mariovisic
702,2013-04-19 18:45:09,"@mperham pg doesn't link to OpenSSL itself, `libpq` does, so the links happen when Ruby and PostgreSQL are compiled. I've been trying to figure out how to detect this situation at extension compile time, though, so I can at least print out another advisory that everyone can ignore. :wink: 

Alternatively, perhaps I could figure out how to contribute a 'postgresql' package for RVM, which would also fix the problems for people running an RVM Ruby with the OpenSSL package.

Edit: Just noticed you're using rbenv, which apparently also installs its own OpenSSL. Arrrgh! So I guess an rbenv package, too?
",ged,mperham
702,2013-05-30 16:54:48,"@mperham is there any chance of reliable queueing being ported to the non-pro version of sidekiq, since there's a lot of people getting those crashing/stuck issues? my main problem is losing the jobs of those stuck workers.
",plentz,mperham
702,2013-05-30 16:59:27,"@plentz granted it's @mperham software, so any decision is up to him, but if something like this happens I'll be the first to ask for a refund, because it's not $20 we are talking about, but a good chunk of money. Beside it helps the developer to work more on this project.
",masterkain,plentz
702,2013-05-30 16:59:27,"@plentz granted it's @mperham software, so any decision is up to him, but if something like this happens I'll be the first to ask for a refund, because it's not $20 we are talking about, but a good chunk of money. Beside it helps the developer to work more on this project.
",masterkain,mperham
702,2013-05-30 17:01:38,"@masterkain and that's the reason I'm just asking, not demanding.
",plentz,masterkain
702,2013-05-30 17:06:03,"@plentz I want Sidekiq to be perfectly reliable but the crashing and stuck threads are due to gems and bugs outside of my control.  When there are sidekiq code or features which hamper reliability, I've fixed those issues as quickly as possible (e.g. removing the timeout feature).

I have no plans to move any features from Pro into free.
",mperham,plentz
702,2013-05-30 20:35:44,"To speak in @mperham's defense, once I upgraded to 2.11.0 and found the right configuration for Heroku environment (see #847), the stuck threads issue completely disappeared for me. Currently sitting at 0 failures for the last month or so.
",matthooks,mperham
702,2013-05-30 20:37:54,"I'm assuming you mean 2.12.0?

I'll be making another attempt in the next few days, at which point I'll
try to get some useful insights.

On 30 May 2013 16:35, Matt Hooks notifications@github.com wrote:

> To speak in @mperham https://github.com/mperham's defense, once I
> upgraded to 2.11.0 and found the right configuration for Heroku environment
> (see #847 https://github.com/mperham/sidekiq/issues/847), the stuck
> threads issue completely disappeared for me. Currently sitting at 0
> failures for the last month or so.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/702#issuecomment-18706525
> .
",marclennox,mperham
702,2015-07-17 21:50:21,"@jonhyman No, we did spend some time investigating it, but didn't find anything.
",lastomato,jonhyman
693,2013-02-08 21:48:55,"@willcosgrove Thanks for your help!
",mperham,willcosgrove
685,2013-02-21 10:06:21,"@mperham I'm seeing similar behavior in my cluster with `~> 2.7.2`. I'm using the following command to start sidekiq:

`nohup bundle exec sidekiq -e <env> -q default -q process_asset ... -C <path/to/config>/sidekiq.yml -P <path/to/pidfile> >> <path/to/log> 2>&1`

The interesting thing here is that I don't actually have a sidekiq.yml for these projects, even though the path to one is listed. Anyway, when I run the command while tailing the logs, I see something like this:



I've rolled back to `~> 2.6.5` for the time being. It might have something to do with not having a config file where it's expecting one (which previously wasn't an issue). It may also be related to the hard dependency on the sidekiq binstubs (which I don't use in production). There have been roughly 92 commits since 2.6.5, so I reckon git-bisect can narrow it down pretty quick (6 or 7 versions). Does this help at all?

Edit: **I'm not on Heroku, this is a direct EC2 deployment**
",SegFaultAX,mperham
685,2013-02-21 14:44:41,"Try 2.7.3

On 21 Feb 2013, at 02:06, Michael-Keith Bernard notifications@github.com wrote:

> @mperham I'm seeing similar behavior in my cluster with ~> 2.7.2. I'm using the following command to start sidekiq:
> 
> nohup bundle exec sidekiq -e <env> -q default -q process_asset ... -C <path/to/config>/sidekiq.yml -P <path/to/pidfile> >> <path/to/log> 2>&1
> 
> The interesting thing here is that I don't actually have a sidekiq.yml for these projects, even though the path to one is listed. Anyway, when I run the command while tailing the logs, I see something like this:
> 
> nohup: failed to run command `./bin/sidekiq': No such file or directory
> nohup: failed to run command`./bin/sidekiq': No such file or directory
> can't find config file /mnt/enthuse-rails-production/current/config/sidekiq.yml
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/lib/sidekiq/cli.rb:321:in `parse_config'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/lib/sidekiq/cli.rb:179:in`setup_options'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/lib/sidekiq/cli.rb:72:in `parse'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/bin/sidekiq:7:in`<top (required)>'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/bin/sidekiq:23:in `load'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/bin/sidekiq:23:in`<main>'
> nohup: failed to run command `./bin/sidekiq': No such file or directory
> nohup: failed to run command`./bin/sidekiq': No such file or directory
> nohup: failed to run command `./bin/sidekiq': No such file or directory
> nohup: failed to run command`./bin/sidekiq': No such file or directory
> nohup: failed to run command `./bin/sidekiq': No such file or directory
> nohup: failed to run command`./bin/sidekiq': No such file or directory
> nohup: failed to run command `./bin/sidekiq': No such file or directory
> nohup: failed to run command`./bin/sidekiq': No such file or directory
> nohup: failed to run command `./bin/sidekiq': No such file or directory
> can't find config file /mnt/enthuse-rails-production/current/config/sidekiq.yml
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/lib/sidekiq/cli.rb:321:in`parse_config'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/lib/sidekiq/cli.rb:179:in `setup_options'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/lib/sidekiq/cli.rb:72:in`parse'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/gems/sidekiq-2.7.2/bin/sidekiq:7:in `<top (required)>'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/bin/sidekiq:23:in`load'
> /mnt/enthuse-rails-production/shared/bundle/ruby/1.9.1/bin/sidekiq:23:in `<main>'
> nohup: failed to run command`./bin/sidekiq': No such file or directory
> I've rolled back to ~> 2.6.5 for the time being. It might have something to do with not having a config file where it's expecting one (which previously wasn't an issue). It may also be related to the hard dependency on the sidekiq binstubs (which I don't use in production). There have been roughly 92 commits since 2.6.5, so I reckon git-bisect can narrow it down pretty quick (6 or 7 versions). Does this help at all?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
685,2013-02-21 19:21:33,"@mperham That fixed it for me, thanks. What changed in `v2.6.5..v2.7.2` that was fixed in `v2.7.2..v2.7.3`?
",SegFaultAX,mperham
685,2013-02-21 19:24:37,"Oh, it looks like f333186ecf049b5d983e5c6269612540c73de818 was the fix for me. @mhenrixon does `2.7.3` work for you as well?
",SegFaultAX,mhenrixon
677,2013-02-03 19:34:44,"Perhaps this is related to @mperham now signing the gem?

EDIT: Working fine now. Probably some sort of transient RubyGems problem.
",davidcelis,mperham
672,2013-02-04 19:18:54,"@mperham any idea of how to look into it? Not sure what steps to take to figure it out.
",dfischer,mperham
651,2013-01-26 19:04:57,"@dennisvdvliet Does the ""myapp"" rails app work for you with this change? When I attempt to load it, i get:

![Screen Shot 2013-01-26 at 2 03 34 PM](https://f.cloud.github.com/assets/744212/100104/3d76831e-67eb-11e2-90be-a5bab3b3b14b.png)
",brandonhilkert,dennisvdvliet
646,2013-01-25 06:42:58,"@mperham sorry for the delay ... I had to make a sandwich.  I was SO hungry.  

Anyways the problem was somewhat less trivial than I expected.  I had to increase the number of operations rather than decrease.  This would probably only be used in development environments so hopefully it won't be too painful. 

Also I'm pretty open to changing the implementation somewhat radically.  No rush to merge.
",no0p,mperham
638,2016-09-22 08:31:33,"@mperham This post explaining the difference between the sidekiq client and sidekiq server is so helpful. It would be great if the same is added in either README.md or in one of the wiki pages.
",sriharshakappala,mperham
637,2013-01-24 18:43:28,"@mperham the only real problem is that if the sidekiq process is down, the `stop` task(and therefore the `restart` task as well) fails. to solve this, the only thing to change is: if the `stop` task detects that sidekiq's pid isnt ""up"" anymore, it just show a warning/message like ""process with pid 123 doesn't exist"" instead of failing. That way, capistrano will continue to the `start` task and the deploy will work.
",plentz,mperham
637,2013-01-24 18:50:19,"@plentz I'd love a PR to do just that.  Hard for me to do it since I can't reproduce.
",mperham,plentz
637,2013-01-24 22:18:43,"just saw @sfroehler patch and I really don't know what's the best approach. His code is a lot cleaner and short, but mine don't show a ugly error message and just say that sidekiq is not running. @mperham is your turn :)
",plentz,mperham
637,2013-01-24 22:30:13,"@plentz I prefer your approach at first glance.  Will investigate more tonight.
",mperham,plentz
637,2013-01-25 08:33:55,"I don't really like this long lines with a lot of bash stuff in it - I think they are hard to read/understand. But thats just a personal opinion. If it's just about the content of the error message: It can be amended in the sidekiqctl. I prefer the ""Process doesn't exists"" because thats the actual ""problem"". I would want to know that, so I can investigate what went wrong.
At the end @plentz is right - both patches will fix the issue and that's what we all want. ;)
",sfroehler,plentz
636,2013-01-22 15:54:50,"@mperham It goes up again after I `kill -9` his process.
",fenelon,mperham
636,2013-01-22 16:58:30,"@mperham haven't tried the other signals actually. Considered it stuck somehow and killed it with -9. What could be preventing it from connecting to redis? The number of redis connections free is good all the time. My app never takes more than 30. I use a globally initialised `$redis` in several modules. Might it be the cause. Thanks!
",fenelon,mperham
636,2013-01-22 19:41:32,"@mperham, I'm running redis on the same machine `$redis = Redis.new(:host => 'localhost', :port => 6379)`
",fenelon,mperham
636,2013-01-24 08:14:07,"@mperham, might it be helpful? 

In my case, Redis is perfectly fine, but at some point, Sidekiq becomes unable to connect to it.



![Screen Shot 2013-01-24 at 12 06 07 PM](https://f.cloud.github.com/assets/767838/92892/fb909736-65fc-11e2-9d56-167244fb1d68.png)



I can though use redis with no problem:



And then... If we restart it...

`kill -TERM 10518`

Magically...



And my initializer file:


",fenelon,mperham
636,2013-01-30 20:08:47,"@mperham Sorry for not giving feedback for such a long time. The redis connection problem is gone now. Although, I still have some issues with my background processing ecosystem. Maybe those points are not directly related to Sidekiq, but I think I'll list them just in case (and anoyone's expertise will be much appreciated):
- The `getaddrinfo: Name or service not known` error shows up once a day on `Net::HTTP calls` and the only cure I found is to restart Sidekiq (and, sometimes, server). It's extremely hard to automate monitoring of this bug so I'm still fixing it by hand. :cry: Might it be some system-related DNS problem? We're working on AWS.
- Recently, I started getting `An Errno::EMFILE occurred in background at 2013-01-25 16:53:26 +0400 : Too many open files - socket(2)` and as far as I found out, those limits are set in `/etc/security/limits.conf` (in Ubuntu, at least). I've added 2 lines to it:



But that doesn't seem to work, as if I run `ulimit -n`, I still get `1024`
I've also checked the list of open descriptors with `lsof` and it didn't notice anything suspicious. Only each of my Unicorns is eating about 135 descriptors. Sidekiq's number is also quite close to it. 
- The `Segmentation Fault` issue with `Nokogiri` and `libxml2` is quite annoying. It causes Sidekiq to crash and must be leaving some garbage behind. I've even reinstalled `libxml2` with `--with-threads` (which seems to be a default anyway) but no luck there. I'm still getting this about once per thousand of my searches.

Thank you for your help, Mike. If you or anyone you know could help us with this, could you please drop me a line? I would really appreciate that!
",fenelon,mperham
622,2013-01-16 19:56:10,"@mperham yeah ;) we are working on a major heroku auto-scaling app and scaling down was killing us. We switched from resque yesterday due to the same problem there - we couldn't get the retry-on-signals working well and sidekiq was advertised as handling this built-in, which now works pretty well.

However even with this patch we're still seeing ~0-2% of jobs getting dropped during downscaling cycles... debugging on that now. We might have some q's for you.
",apinstein,mperham
608,2013-01-04 20:43:11,"@mperham, sorry, was a hard day and I didn't notice ~>
- thanks
",alecnmk,mperham
604,2012-12-29 00:35:07,"@mperham #600 needs to be reverted?
",jc00ke,mperham
601,2012-12-29 05:51:35,"@mperham seems like @pixeltrix is entirely on to it.  Still unclear to me why that constant hasn't been referenced until _after_ the model is required, however that's mostly because I've only glanced at the source.
",NZKoz,mperham
592,2013-01-03 03:30:23,"@kyledrake Yep, there is a conflict between supporting multiple, weighted queues in one process and reliable queueing via Redis's brpoplpush.  I implemented multiple queues in Sidekiq to stay compatible with Resque and still think it was the correct choice to make. I really haven't got much push back from people with reliability concerns.

That said, I am considering adding optional support for brpoplpush to Sidekiq Pro so enterprise customers can opt for reliable queueing.  This will entail using only one queue per Sidekiq process.
",mperham,kyledrake
590,2012-12-18 13:21:02,"**Trace**



According to this, we need to upgrade redis: http://oldblog.antirez.com/post/everything-about-redis-24. I'm using 2.2 (which is what ubuntu installed). But it should be simple enough to check the version and make sure it's >= 2.4 in the view

@steverandy See this gist if you need help: https://gist.github.com/4327994
",scottkf,steverandy
590,2013-05-30 07:55:48,"Hello!

I'm also currently receiving an Internal Server Error when I try to access the dashboard. Nothing on the any of the logs. I've even tried shutting down redis as well as sidekiq and going to the /sidekiq route still gives me a 500. @mperham I've added the backtrace option to my workers. How would I obtain the debug information?
",commodity,mperham
590,2013-11-22 17:18:13,"I have the same problem, only in production, development is fine. Ruby 1.9.3p448, Passenger 4.0.10, Apache 2.2.22/mpm-event with mod_xsendfile 0.12, redis 2.6.16, sidekiq 2.16.1. The strange thing is it only happens sporadically but on all pages, reloading the page usually works. I'm also using the sidekiq-cron web ui extension, but disabling it makes no difference. I think I didn't see it with sidekiq while still on redis 2.2.12.

@mperham How can we get the backtrace? There is no info logged to the rails application log.

Update: OK, after editing sidekiq sinatra app to `set :raise_error => true` I am getting an error:



I'll open a new issue, as it seems unrelated.
",felixbuenemann,mperham
589,2013-06-21 08:03:19,"@mperham Setting the default_url_options doesn't work for me, at least in the console. I know for sure default_url_options is being set and can be accessed within the scope of the worker.

`1.9.3p125 :001 > ActionMailer::Base.default_url_options
 => {:host=>""localhost:5000""}`

Attempting to run the code which constructs the url returns the same error that @lowellk saw.

`ArgumentError: Missing host to link to! Please provide the :host parameter, set default_url_options[:host], or set :only_path to true`

I explicitly passed in the `:host` option to the url helper instead.

`activity_url a, locale: I18n.locale, host: ActionMailer::Base.default_url_options[:host]`

and that works.
",jingshen,mperham
585,2012-12-14 18:23:15,"@mperham You should ask for that for xmas :wink: 
",jc00ke,mperham
583,2012-12-16 08:00:57,"Thanks @mperham used your connection pool gem, works like a charm!
",ben-av,mperham
583,2013-02-24 23:04:13,"The cequel cassandra gem has the connection pool gem in it. This fixes similar problems we were seeing.

+1 on the great @mperham connection pool gem. Thanks mike.
",kbrock,mperham
581,2012-12-12 16:48:40,"@mrnugget You're right, bash is what does the redirection and so it would need to do the rotation.  Ugh, bit by bit I'm starting to understand why every Unix daemon has to reimplement this stuff.  I'll read through this again tonight and merge it if it looks good.  Thanks for helping me understand the issue better!
",mperham,mrnugget
581,2012-12-13 23:01:13,"Thanks @mrnugget!
",mperham,mrnugget
581,2013-08-21 15:46:33,"Thanks @mperham! Will do.
",bradical,mperham
575,2012-12-17 19:35:35,"@mperham I'm slightly confused with what you're suggesting.  Since most people define the queue within the worker (as below) why would this break anything?  When you say ""custom sidekiq processes"" are you referring to something other than sidekiq workers?  Sorry if I'm not understanding you correctly!


",biznickman,mperham
570,2012-12-10 20:12:04,"@mperham The above make sense or no?
",brandonhilkert,mperham
569,2012-12-09 09:26:46,"@mperham, here is my Gemfile.lock


",tigris,mperham
569,2012-12-12 04:40:06,"Thanks @mperham, here is the output after sending the USR1 signal to the sidekiq process that had stalled during attempted shutdown.


",tigris,mperham
566,2012-12-05 13:50:31,":smirk: Nice! @brandonhilkert what's this graph name?
",fabianoalmeida,brandonhilkert
559,2012-12-14 18:53:06,"I was afraid of that.  @brandonhilkert Can you revert?
",mperham,brandonhilkert
551,2012-11-30 18:03:53,"@ragalie Fair question.  Sidekiq Pro pays for my time supporting Sidekiq.  You are welcome to re-implement Pro features if you'd like, this is open source after all, but I'm unlikely to pull them into Sidekiq.  You'd have to maintain a separate fork or gem with the functionality.  And then you get to experience the joy of supporting something for free.
",mperham,ragalie
551,2014-09-04 15:04:24,"@mperham why not charge for a sidekiq enterprise setup/support/hosting contract like many companies do and still keep the features available for free? 
to name some examples: redhat, elasticsearch, mongodb, cassandra, ansible, deis, coreOS, ubuntu etc.
",developerinlondon,mperham
548,2012-11-30 13:35:20,"You're absolutely right. I didn't realize I was making this mistake when I changed the blank? code to a simple comparison. 

@mperham Do I create a new pull request with this, or is there a way to do this on this pull request? 
",nogara,mperham
548,2012-11-30 14:49:09,"New pr. 

On 30 Nov 2012, at 05:35, Luiz Gustavo Nogara notifications@github.com wrote:

> You're absolutely right. I didn't realize I was making this mistake when I changed the blank? code to a simple comparison.
> 
> @mperham Do I create a new pull request with this, or is there a way to do this on this pull request?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
545,2012-11-28 17:36:06,"@mperham I want to add middleware to the 'queue' and the 'process' phases.  I tried to use this code and I get an error when it loads:





What am I doing wrong?
",tfwright,mperham
545,2012-11-28 18:06:47,"@tfwright @jmazzi's block up top does exactly that.  MyClientMiddleware is client middleware, MyMiddleware is server middleware.
",mperham,jmazzi
545,2012-11-28 18:19:15,"@mperham Ah, yes, that makes sense now.

I think for me it was unexpected to not have client_middleware automatically add it's middleware to the server's client_middleware. However, depending on what your middleware is doing, that wouldn't always be ideal. 

Thanks for the clarification!
",jmazzi,mperham
540,2012-11-26 03:05:56,"@jc00ke The position you mentioned was my first thought, but both of those buttons are controlled by the checkboxes, and something told me to put it somewhere else so that ""Delete All"" wasn't misinterpreted for ""Delete All the ones on this page""? Does that make sense? My next thought was to maybe put it bottom left. Would that be better?

Agreed on not showing if there aren't jobs.
",brandonhilkert,jc00ke
540,2012-11-26 03:13:24,"@jc00ke Pushed. 

![dl](http://f.cl.ly/items/163N1c0V0x2m3P1K450L/Screen%20Shot%202012-11-25%20at%2010.14.18%20PM.png)

Is ""Retry All"" something you'd like me to add as well?
",brandonhilkert,jc00ke
540,2012-11-26 03:19:58,"@brandonhilkert re: `Retry All` @bensie had mentioned it, and if it's easy to add, might as well do it now.

Also, does that screencap reflect the changes? I was thinking...



That way the buttons that are activated by the checkboxes are under the checkboxes.
",jc00ke,bensie
540,2012-11-26 03:19:58,"@brandonhilkert re: `Retry All` @bensie had mentioned it, and if it's easy to add, might as well do it now.

Also, does that screencap reflect the changes? I was thinking...



That way the buttons that are activated by the checkboxes are under the checkboxes.
",jc00ke,brandonhilkert
540,2012-11-26 16:49:58,"This interface looks **incredible** @brandonhilkert - I personally can't wait till it makes it to master.
",geomic,brandonhilkert
536,2012-11-21 16:49:11,"@jmazzi I wrote that from memory, if `failed?` exists ya totally you can use it.

@tfwright Batches do track the jid and errors of any failed jobs so you can see why a given job failed.  You don't know when a particular job has been run, just that the batch is complete or not.  If the batch is complete and the jid is not in the batch's failures, you know that particular job succeeded.
",mperham,jmazzi
536,2012-11-21 16:53:27,"@mperham can you check to see if a jid is in the batch's failures _before_ the latter is complete?  If so that should work fine.
",tfwright,mperham
536,2012-11-21 17:03:42,"@jmazzi I think that's a great feature request for Pro.  I'll think about it over the next few days.
",mperham,jmazzi
536,2012-11-21 17:04:48,"@mperham thank your prompt replies and consideration :)
",jmazzi,mperham
536,2013-01-15 19:55:35,"@mperham what did you decide?
",jmazzi,mperham
530,2012-11-26 14:06:01,"@mperham I'll take this.
",brandonhilkert,mperham
523,2012-11-15 19:52:34,"@mperham I had a really weird issue with threads inside my worker. Even though, I cleared connection in every thread I was creating. I even tried Celluloid but the connection pool was still throwing timeouts. I had to give up threads completely in my workers. Though, they handle connections perfectly fine in my application code.
",fenelon,mperham
522,2013-01-27 06:25:48,"@mperham if you reduce the number of workers to 1 or 2, or even double to 50, does it still take about 6 sec?

On Jan 26, 2013, at 11:53 PM, Mike Perham notifications@github.com wrote:

> @iwarshak I got it running on my OSX machine and it works fine for me. 1000 jobs process in 6 seconds.
> 
> (M=8fbbd .rvmrc) ~/src/sideslow> RAILS_ENV=production bundle exec rails console
> Loading production environment (Rails 3.2.11)
> 1.9.3p327 :001 > 1000.times {|i| SlowWorker.perform_async({}) }
>  => 1000 
> 1.9.3p327 :002 > quit
> (M=8fbbd .rvmrc) ~/src/sideslow> git diff
> (M=8fbbd .rvmrc) ~/src/sideslow>
> Last few lines of the sidekiq output:
> 
> 2013-01-27T05:49:25Z 34160 TID-owrcp6cio SlowWorker JID-7f04b9c02f5135f3bb47e64c INFO: start
> 2013-01-27T05:49:25Z 34160 TID-owrcph4jk SlowWorker JID-0e997a49f2e6378d06f060b5 INFO: start
> 2013-01-27T05:49:25Z 34160 TID-owrcowgus SlowWorker JID-99f717ff5d16f01ca0f1876b INFO: done: 0.117 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcygrlw SlowWorker JID-c1dfd90dea227b0569b7c1ec INFO: done: 0.114 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcp9vkk SlowWorker JID-0c26f934b467814edba345ba INFO: start
> 2013-01-27T05:49:25Z 34160 TID-owrcpcpj4 SlowWorker JID-4ddf8536d671b37f8ad4412e INFO: done: 0.114 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcppac8 SlowWorker JID-addee65a22c95ff26983b6f6 INFO: done: 0.12 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcxiry8 SlowWorker JID-a0e0d291958177e8f805815a INFO: done: 0.132 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcwkpnk SlowWorker JID-3d5d8e20ec99796d7a187708 INFO: done: 0.12 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcs99bs SlowWorker JID-9ee26616d0095200ad6e7f96 INFO: done: 0.056 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcpigq0 SlowWorker JID-a84a171d2dc3b5622be0c39e INFO: done: 0.125 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcy4nek SlowWorker JID-8d292c381598f8a7baeb1a2b INFO: done: 0.057 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcyghwg SlowWorker JID-960cf061b19dce70ab2537cb INFO: done: 0.065 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcpicp0 SlowWorker JID-75c80506e20a1d3d1efe0dcf INFO: done: 0.054 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcst10c SlowWorker JID-3a7bf0c94bcaf1391ff0e263 INFO: done: 0.069 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcy3hkg SlowWorker JID-6fc138c1baf26645fe272721 INFO: done: 0.043 sec
> 2013-01-27T05:49:25Z 34160 TID-owrchutmw SlowWorker JID-00b231185d4c63832691d774 INFO: done: 0.055 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcmpiqo SlowWorker JID-71981d8fa157a5cb8aa20590 INFO: done: 0.045 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcrsy5g SlowWorker JID-3f7ddc5e575026b0a9502d6e INFO: done: 0.053 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcoyfjs SlowWorker JID-2d3254788035c4d8eb357c98 INFO: done: 0.045 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcph4jk SlowWorker JID-0e997a49f2e6378d06f060b5 INFO: done: 0.033 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcp6cio SlowWorker JID-7f04b9c02f5135f3bb47e64c INFO: done: 0.034 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcoqxbg SlowWorker JID-86a17f570f81c461d13ed2eb INFO: done: 0.056 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcoyz3o SlowWorker JID-d0c7f4700533020868d353b7 INFO: done: 0.064 sec
> 2013-01-27T05:49:25Z 34160 TID-owrcp9vkk SlowWorker JID-0c26f934b467814edba345ba INFO: done: 0.04 sec
> —
> Reply to this email directly or view it on GitHub.
",iwarshak,mperham
510,2014-11-10 17:30:38,"@mperham was thrilled to see this got implemented :)

What would you think about adding support for the following:



which would be functionally equivalent to:



I think that when we use `sidekiq_retry_in`, this kind of behavior would allow our developers to communicate their intent much more clearly.
",eprothro,mperham
510,2014-11-10 17:54:00,"@eprothro I'd say no.  I'm very conservative in applying any more changes to the retry logic as I don't want more and more knobs to twiddle so the Retry system in Sidekiq becomes a rat's nest of edge cases.
",mperham,eprothro
508,2012-11-09 16:28:12,"@nirvdrum that's probably because your frontend ignores `X-Sendfile` header.
",nikitug,nirvdrum
503,2012-11-05 17:15:31,"@jc00ke Unfortunately that won't solve his problem.

You can programmatically change the value in `Sidekiq.configure_server`, something like:



and that **might** work.  My understanding is that in the AR pool, connections are lazy created; are you sure that using a size of 20 is actually a problem for you?
",mperham,jc00ke
503,2012-11-07 17:01:15,"@mperham so how do I actually trace/fight that? Does Sidekiq close them? What happens if an exception occurs?
",fenelon,mperham
503,2012-11-07 19:07:56,"@mperham could you possibly explain your idea further? How is it possible that if I have 30 connections in my pool and MySQL allows 135 the database still complains about 'too many connections' error? 

Does Sidekiq shares the same AR pool as my app or every process (every Unicorn + Sidekiq) has it's own pool?

Also, I'm using RMagick gem. Could it possibly be caused by it?

I apologize for bothering the community, but I'm just puzzled about where to start digging. Thanks a lot!
",fenelon,mperham
503,2012-11-08 10:18:12,"Thanks, @Ragmaanir, for the info. Today I had to reboot my DB instance twice because of this error. Can you or @mperham suggest a way to debug this? Something I could test my system with and get back with my findings.

Here's my setup for reference:



sidekiq.yml



database.yml


",fenelon,mperham
503,2012-11-10 11:59:01,"@Ragmaanir, unicorns seem to be ok. This all happens in the normal flow. But now I'm 90% sure I've found what may be causing it. I use threads to process third-party services requests. Seems they do not properly use connection pool out of the box. The next step I think I need to take is taking those operations under Celluloid's control. I'll let you know if it works out. 

@mperham, could I have a bit of your expertise up there? Does the Celluloid handle connections for me or I still gonna need to explicitly check them back and forth on each Actor?

The only question still remains. 90 connections on four unicorns is equal to 22 (max connection pool) \* 4 (unicorns) + 1 (my shell) + 1 (aws monitoring). Add to this 15 Sidekiq workers (in my tests they took only as much as 12) and you end up with 105 connections open at max. How could it possibly cause 'too many connections' on MySQL when it allows 135..?

Thank you all, guys! Nothing is more valuable then the community!
",fenelon,mperham
503,2012-11-10 17:59:55,"@mperham, where can I check out at the way you do that in Sidekiq?

I do not have any connection-pool related code in my Sidekiq workers code, but they seem to work fine. Do I need to wrap my  worker code in `with_connection` call?

Thank you so much!
",fenelon,mperham
503,2012-11-10 18:24:29,"@mperham and the AR pool? Does it work well with threaded code by itself?
",fenelon,mperham
503,2012-11-10 18:32:32,"@mperham, As I understood from Johnathan's article (http://bibwild.wordpress.com/2011/11/14/multi-threading-in-rails-activerecord-3-0-3-1/) the AR connection pool sometimes shows unpredictable behaviour when used with threads. In his case the connections was not returned to the pool. He advises to wrap threaded code in `with_connection` block to make the AR explicitly check out and return the connection when it's finished. Sidekiq has no problems with that, but I can't say so about my code.
",fenelon,mperham
503,2012-11-10 18:49:09,"@mperham, so you mean that `ActiveRecord::Base.clear_active_connections!` piece in run after each worker and makes sure they return the connections they used to the pool? Does this mean that if I include this call to my actors I can probably avoid the connection bloat?

Michael, I feel like getting you a beer :)
",fenelon,mperham
503,2012-12-05 23:35:29,"@mperham 

I wonder if we should update the **Concurrency** section of the [Advanced Options](https://github.com/mperham/sidekiq/wiki/Advanced-Options) wiki page to advise programmatically changing the ActiveRecord connection pool size via



rather than the _hack_ I suggested. It seems sensible that you'd want a small connection pool for your Unicorn workers, or threads, etc., but a substantially larger pool for the Sidekiq process.

For instance, we have an app on Heroku running 2 Unicorn workers per dyno, at 75+ dynos, and a single Sidekiq worker with concurrency of 50. The hacky method of setting the connection pool size means that each Unicorn worker _could_ soak up that many connections, but the default (5) is enough for them. But we'd like to have a connection pool of 50-ish on the Sidekiq dyno.

Does that all make sense?
",stevenharman,mperham
503,2012-12-08 01:47:53,"@mperham I'd buy that.

Even so, I'm wondering if it would be better to explicitly set Sidekiq's connection pool to a larger one via the initializer rather than the `database.yml` in general. Especially in the case of running on Heroku where you have to _hack_ the database URL to tack the `pool=xxx` parameter on.

Thoughts?
",stevenharman,mperham
503,2012-12-31 18:48:42,"@sjahandideh `database.yml` has no effect on Heroku as they inject their own database config. Furthermore, the programatic approach suggested by @mperham doesn't work on Heroku as `ActiveRecord::Base.configurations` is empty.

I still don't understand exactly why it's empty on Heroku only, but it seems to be causing other folks heartache as well: https://www.google.com/search?q=ActiveRecord%3A%3ABase.configurations+is+empty+on+heroku

Maybe @wuputah or one of the @heroku folks can chime in?
",stevenharman,mperham
503,2013-01-03 16:13:18,"You might want to write some custom code in your sidekiq workers to establish a separate connection to the same db but with a different pool size and let the default be 5 for your unicorn workers. This also might be possible via middleware @mperham?

We used to inject entries into 'ActiveRecord::Base.configurations' so we could manage our db sharding/multiplexing with certain gems that required that all of the db entries be in the configurations hash so you could probably do something similar and make explicit connections to that 2nd manually added entry which has a higher pool size.
",TheCorp,mperham
503,2016-11-08 07:32:42,"Thanks both @stevenharman and @espen for your provided workarounds. Both work well and can be really useful also in other scenarios. Ideally, I wanted to deal with the situation without having to ""bother"" the other developers. The only option for that would be to execute a custom script during the deployment to copy a `config/databases.yml.production` to `config/databases.yml`. As I'm in heroku, maybe I'll check if adding a custom buildpack (or modifying ruby one) pays off.
",waiting-for-dev,espen
501,2012-11-03 05:41:28,"Well said, @bensie.
",mperham,bensie
493,2013-03-06 11:32:26,"As a reference, I have extended @leemhenson original idea a little to stub Batches and Status:



It obviously leave out a couple methods, but it works for my simple workflow of adding jobs to batches and waiting for them to run with `status.join`.
",fabiokr,leemhenson
484,2012-11-01 22:35:53,"@mperham I believe `sass-rails` needs to do something like this in their 3.x branch: https://github.com/hornairs/sass-rails/commit/7021ceeb0116360a6acd21471773f065c5ecd31f

The problem is that they have overridden the `Sass::Template` class sprockets will use to compile sass for all clients of Sprockets, not just the Rails one, which means your previously happy little Sinatra app is now trying to use the `Sass::Rails::Sass::Template` instead of the one that comes with sprockets. 
",airhorns,mperham
484,2012-11-01 22:53:09,"@mperham I am so absurdly swamped it wouldn't even be funny for someone to see me because the swamp is so gosh darn smelly. That commit also isn't perfect yet, there's some weird issues with Sprockets's environments in prod vs dev. So yeah, I will, but I can't say it will be within the next month. Sorry :(
",airhorns,mperham
481,2012-10-31 17:47:51,"@krasnoukhov interested, I don't use sidekiq-failures, wonder why removing it fixed it for you?
",fbjork,krasnoukhov
481,2012-10-31 17:50:51,"@fbjork Also i've updated all related gems. Now i not able to investigate why it helps.
",krasnoukhov,fbjork
481,2012-10-31 19:22:49,"Some internals of web.rb changed that sidekiq-failures used. 

On 31 Oct 2012, at 10:50, Dmitry Krasnoukhov notifications@github.com wrote:

> @fbjork Also i've updated all related gems. Now i not able to investigate why it helps.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,fbjork
481,2012-11-02 20:02:04,"Hey @mperham, you mentioned master, but it merged into `simple_ui`. Is it right?
",krasnoukhov,mperham
480,2012-10-30 20:24:42,"@bbhoss That would be rad.  I've run into the same issue before but not badly enough for me to fix it.
",mperham,bbhoss
480,2012-10-30 21:02:15,"@mperham It doesn't look like you have any existing test infrastructure for the retry_at time. Would you like me to add some or is a simple 1-line patch to the DELAY proc ok?
",bbhoss,mperham
475,2012-10-30 21:58:12,"@unity The UI is never set in stone.  you are welcome to clean up as you see fit.

I had to move the redis/time info to a navbar footer since hostnames can get long and ours didn't fit into that tiny sidebar box.  Polish would be very welcome there.
",mperham,unity
471,2012-11-07 23:20:57,"@jfirebaugh Yeah, there's no good solution for catching and dealing with Sidekiq core exceptions right now.  Thankfully they've been very rare in my experience but suggestions welcome.
",mperham,jfirebaugh
463,2012-10-31 15:16:39,"@phillipoertel yes that's a very good feature specially to monitor workers and memory leak between apps.

I've been trying to break my head around that trying to figure it out.

What I could not figure out is how to get the Namespace constant. 
Since the namespace is initialized from config block used for redis-namespace gem, I can't find it stored anywhere as a constant. 



In redis-namespace gem, I did not find how to retrieve the namespace. neither in Sidekiq code I could find any leads.

@mperham any hints you could provide? 
",fred,mperham
463,2012-11-01 10:24:29,"@mperham Monitoring by PID was my first thought as well. Our admins couldn't get their monitoring to pick up the new PID on sidekiq restarts, however, so they suggested monitoring by process name. They are off-site and not very involved in our dev process / Ruby, so I didn't insist. It was easiest to patch the procname method. 
I realize I'll have to review the patch when we update the sidekiq gem. 

I had also considered a PR to make the procline string configurable, sth like config.procline = ""sidekiq [:active_workers of :total_workers busy]""), but then thought that'd bloat the sidekiq codebase needlessly. If you find many people want to display a different procline, you could still consider this.

The most reliable solution today would be monitoring by PID, as you suggested. Maybe I should poke dem admins once more! ;-)

Anyhow, thanks for making sidekiq. It's been a joy to use so far!
",phillipoertel,mperham
461,2012-10-23 08:32:54,"@mperham I don't think that's entirely true. If you have:



In your application.rb, Then it will automatically lacy load the files as you use them, if you have a valid module/folder structure of cause, which it sees that you have. I don't see why sidekiq is giving that error though??? You say that the problem only occurs sometimes, and only when spinning a lot of works up - strange...
",NielsKSchjoedt,mperham
460,2013-06-17 16:28:26,"Hi @durran and @mperham. I do love your work, so I made this gem.

https://github.com/dlibanori/sidekiq-delay
",dlibanori,mperham
460,2013-06-17 17:51:38,"Hi @mperham, I think it is safe.

Sidekiq::Delay do not rewrite `delay` instance method unless user explicitly includes its module and `delay` class method always remain untoached.

Tell me if it is not ok for you.
",dlibanori,mperham
447,2015-12-01 14:26:08,"@mperham yep, with `require_dependency` this is working. :+1: :beers: 
",g-ilham,mperham
446,2016-08-18 10:22:39,"@mperham I am wondering if your comment is outdated. Is it still the only way to pipe sidekiq's output to syslog if I want to logrotate logs?

> We pipe sidekiq's output to syslog with | logger -t sidekiq and let the OS rotate syslog for us.
",nextofsearch,mperham
446,2016-08-18 15:02:39,"@mperham got it!
",nextofsearch,mperham
445,2012-10-15 10:59:13,"@mperham: I believe the hoptoad/airbrake-inspired [errbit](https://github.com/errbit/errbit) project still uses hoptoad_notifier.
",ezkl,mperham
445,2012-10-15 11:04:22,"@ezkl That's the main reason. We cannot use the newest version of Errbit at the office so we are forced to use HoptoadNotifier instead of Airbrake.
",stephankaag,ezkl
445,2012-10-15 16:00:21,"We use Errbit at The Clymb, works fine with Airbrake.  @stephankaag this sounds like a good case for a monkey patch.  I don't want to support obsolete stuff.
",mperham,stephankaag
444,2012-10-16 03:09:54,"@mperham this look alright to you? (besides the fat fingered `hequire` WHAT WAS I THINKING?)
",jc00ke,mperham
444,2012-10-16 04:06:46,"@mperham What do you think about adding a deprecation warning when connecting? Necessary, or is the changelog enough?
",jc00ke,mperham
443,2012-10-14 18:02:15,"@mperham which version? Are you thinking of explicitly support all providers or taking a general approach?

If we go general, we may want to issue a warning so people using it on Heroku now don't get a nasty surprise :smile: 
",jc00ke,mperham
443,2012-10-14 18:03:30,"I think a general approach sounds like a great idea.
On Oct 14, 2012 11:02 AM, ""Jesse Cooke"" notifications@github.com wrote:

> @mperham https://github.com/mperham which version? Are you thinking of
> explicitly support all providers or taking a general approach?
> 
> If we go general, we may want to issue a warning so people using it on
> Heroku now don't get a nasty surprise [image: :smile:]
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/443#issuecomment-9423710.
",mperham,mperham
431,2012-10-10 13:42:40,"Hey @joneslee85 - Yeah, I did give that a go with no luck. Maybe I'll try again this evening.

Thanks for the tip
",geoffw8,joneslee85
423,2012-11-27 16:23:36,"@mperham I investigated a little more. I was able to get the stuck workers within a couple of minutes. Could it be that it gets stuck on the db connections? I saw that your connection pool doesn't release/close the connections. I am using Mysql2 not through the AR adapter, but with your connection pool. Any hint on how I can prevent them from getting stuck? Any other known issues with AR connection pooling apart from `verify_active_connections!`? I haven't explicitly used it anywhere but I got a backtrace from Airbrake stating that it has a problem with `clear_active_connections!'`:

**ThreadError: deadlock; recursive locking**



Thanks a lot. Sidekiq is awesome!
",dschneider,mperham
423,2012-11-29 04:46:58,"I will work to make Carrierwave thread-safe within the next week and will report back here when it's done in master.

@mperham Have you worked with ActiveSupport's class_attribute before? Wondering if I'm going to run into issues there with thread-safety:
https://github.com/rails/rails/blob/master/activesupport/lib/active_support/core_ext/class/attribute.rb
",bensie,mperham
423,2012-11-29 06:10:23,"@bensie There's an issue with requiring, and optional features / gems. https://github.com/jnicklas/carrierwave/issues/911
",codezomb,bensie
423,2012-11-29 06:44:43,"@bensie np, I use carrierwave on almost all of my projects. Just like to contribute where I can.
",codezomb,bensie
423,2012-11-29 19:30:03,"@bensie with the master branch, it processed a few files, but locked up again.
",codezomb,bensie
423,2012-11-29 19:31:44,"@bensie I ran the same test using Thread.new, and the result was the same. 
",codezomb,bensie
423,2012-11-29 19:36:56,"@bensie This is the entirety of the script I'm running. It's within a Rails 3.2.8 app, but there's no models/controllers or anything else loading at this time, as I removed it all.

I'm just loading up rails console, and going from there. The rails server isn't running either.

https://gist.github.com/4171304
",codezomb,bensie
423,2012-12-01 01:52:28,"@bensie and @mperham I think this may only be with rubinius. I just tested on MRI 1.9.3-p327 and minimagick has no issues w/ sidekiq.
",codezomb,mperham
423,2012-12-01 01:52:28,"@bensie and @mperham I think this may only be with rubinius. I just tested on MRI 1.9.3-p327 and minimagick has no issues w/ sidekiq.
",codezomb,bensie
423,2012-12-01 05:27:38,"@jc00ke I'm installing using rvm, and from what I can see of the install it's pulling origin/master from git://github.com/rubinius/rubinius.git. I checked the repo out and diffed, and I'm not seeing any difference.
",codezomb,jc00ke
423,2012-12-01 05:34:16,"@jc00ke, ah I installed via just rvm install rbx. I'll try rbx-head explicitly, and report back.
",codezomb,jc00ke
423,2012-12-01 05:57:30,"@jc00ke this is happening with all versions of rbx I install.

$ rvm list known

rbx[-head]
rbx-2.0.testing
rbx-2.0.0-rc1

I've used all of the above, and get the same result.
",codezomb,jc00ke
423,2013-03-20 23:57:52,"@mperham Quick update actually, not sure how relevant this is but once we removed a particularly memory intensive section from our workers (our now 2 million+ jobs a night) run flawlessly with no dead/stale workers. 

I haven't looked into what @zquestz mentioned or how that might affect us but anyone still having these issues and who are on Heroku (I assume that's part of the issue) should consider looking into how much memory each of your workers are using and try and slim that down. 

Basically we just pulled out the memory intensive section and had it run in its own job.
",TheCorp,mperham
417,2012-09-27 00:03:38,"@ezkl many, many thanks!!
",mperham,ezkl
407,2012-09-26 15:58:02,"@unity I'm pretty sure this still won't work with Github Pages.  You've checked everything into a `source/` directory, including a lot of Ruby stuff that has nothing to do with a basic static html site.  I was envisioning a pull request that just had updated index.html, styles.css, a few .pngs, etc.

I'll go through this and port it over to the current filesystem layout tonight.  I still very much appreciate your help!
",mperham,unity
407,2012-09-26 18:45:18,"Yes, as I told you we use a Sinatra setup with sprockets, sass, compass, that does concatenation and a bunch of stuff.   

I see no way to generate something that would work easily with github pages, apart from precompiling everything, which is what I did initially.  

I thought commiting the source would allow you to generate static sites while keeping something clean and well organized.  

If you point me to a way to keep a clean CSS structure with compass, I'd be happy to convert for you.  

R.   

## 

Romain Dardour, Oahu
romain@oahu.fr
Please note : Oahu is now hull.io

On Wednesday, September 26, 2012 at 5:58 PM, Mike Perham wrote:

> @unity (https://github.com/unity) I'm pretty sure this still won't work with Github Pages. You've checked everything into a source/ directory, including a lot of Ruby stuff that has nothing to do with a basic static html site. I was envisioning a pull request that just had updated index.html, styles.css, a few .pngs, etc.
> I'll go through this and port it over to the current filesystem layout tonight. I still very much appreciate your help!
> 
> —
> Reply to this email directly or view it on GitHub (https://github.com/mperham/sidekiq/pull/407#issuecomment-8895000).  
",unity,unity
406,2012-09-20 19:25:23,"@hakanensari Yeah, that's on my TODO list.
",mperham,hakanensari
397,2012-09-11 21:06:18,"@bzanchet is da man :) :+1:
",felipecsl,bzanchet
391,2012-09-08 22:31:47,"@mperham you probably want to revert that change until I can repro this problem and fix it
",tarcieri,mperham
391,2012-09-09 00:15:11,"Can a committer take care of this?

On 8 Sep 2012, at 15:31, Tony Arcieri notifications@github.com wrote:

> @mperham you probably want to revert that change until I can repro this problem and fix it
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
391,2012-09-09 02:51:24,"@mperham awesome, thanks
",tarcieri,mperham
388,2012-09-05 23:08:24,"@mperham re workers [lib/sidekiq/web.rb#L52-61](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/web.rb#L52-61)
",jc00ke,mperham
388,2012-09-05 23:47:18,"@jc00ke You need to load the msg json so you can display all the msg info in _workers.slim.
",mperham,jc00ke
386,2012-09-03 06:52:46,"I haven't contributed in a while, hope that PR does the trick.

It'd be nice to have a `Sidekiq::Stats` namespace for all the stats used in the web UI and other libs like `hirefire`. @mperham would you be interested in that kind of refactor?
",jc00ke,mperham
386,2012-09-03 16:06:02,"@jc00ke I'm not sure what you mean.  Can you give more detail?
",mperham,jc00ke
386,2012-09-03 16:28:02,"Thanks @jc00ke @mperham - I merged it in, will modify the last part later. I'll keep the ticket open in case there is an ongoing discussion regarding `Sidekiq::Stats`. If not, feel free to close it. 

@mperham I think @jc00ke is referring to something like this: https://github.com/defunkt/resque/blob/master/lib/resque.rb#L366-377 - but perhaps more detailed with more methods and namespaced in a different class/module that can be easily accessed to extract computed Sidekiq stats/data.
",mrrooijen,jc00ke
386,2012-09-03 16:28:02,"Thanks @jc00ke @mperham - I merged it in, will modify the last part later. I'll keep the ticket open in case there is an ongoing discussion regarding `Sidekiq::Stats`. If not, feel free to close it. 

@mperham I think @jc00ke is referring to something like this: https://github.com/defunkt/resque/blob/master/lib/resque.rb#L366-377 - but perhaps more detailed with more methods and namespaced in a different class/module that can be easily accessed to extract computed Sidekiq stats/data.
",mrrooijen,mperham
386,2012-09-03 23:36:47,"@jc00ke Send me a PR so we can discuss the overall diff using a nice UI.
",mperham,jc00ke
383,2012-09-02 22:07:52,"@mperham Would you be amenable to a pull request? Do you see any technical barriers?

FYI, this kind of behavior is sometimes called ""in-flight"" messages: http://eric.lubow.org/2012/architecture/pros-and-cons-of-redis-resque-and-sqs/ (SQS has it, for example.)

I am considering BRPOPLPUSH as a way to do this, since it is blocking and atomic. It seems like it would be a relatively small change.
1. I see that Sidekiq currently uses RPUSH to push a message and BLPOP to fetch one. (So, my suggested change would involve a queue ""handedness"" flip.)
2. Then, when a worker finishes, it would remove the message from the in-flight list.
3. I'm not sure where / how yet to implement a failure timeout to reclaim an abandoned message. I just need to look around the code more I think to figure that out.
",bluemont,mperham
381,2013-03-01 13:18:59,"@mperham it says ""`<class:DelayedMailer>': undefined method` sidekiq_options' for Sidekiq::Extensions::DelayedMailer:Class (NoMethodError)""
",kirs,mperham
377,2013-03-19 20:53:29,"@mperham :/




",MSch,mperham
370,2012-08-23 18:16:11,"@mperham What version should I be running?
",dchapman1988,mperham
370,2012-08-23 18:24:33,"@mperham These all would be solved by splitting sidekiq-web to it's own gem. I know from previous issues that you are against it but in case you reconsider I could put some work in to making it happen.
",betelgeuse,mperham
370,2012-08-23 18:31:39,"@betelgeuse The problem is that breaking it out would require three gems: sidekiq-client, sidekiq-server and sidekiq-web since web uses the sidekiq client redis connection.  Then I could see sidekiq-test being very useful...  I don't want to get into a Maven situation where we have N tiny gems, each with their own versions, release process, github repo with issues, etc.
",mperham,betelgeuse
370,2012-08-23 18:40:03,"@mperham I don't see sidekiq-web gem creation needing any additional split. It calls into Sidekiq.redis so if we have just a sidekiq gem it will use it however that gem configures it for the current process. I think it's most important to have all dependencies accounted for in gemspecs. As rubygems don't support Gentoo style use flags then the only option is to either have unused dependencies or split gems. Now everytime we introduce features that rely on newer sinatra versions people have to first see the web interface fail with an error and then figure out that they must upgrade their locked sinatra version.
",betelgeuse,mperham
370,2012-08-23 18:42:28,"@mperham Upgrading `sinatra` worked beautifully. 

The problem was that I was using the taps gem which relied on `sinatra (~> 1.0.0) ruby`
",dchapman1988,mperham
370,2012-08-23 18:46:46,"@betelgeuse Yeah, you're right that would work.  I don't necessarily like having two gems in the same repo but having two different repos shouldn't be that big of a pain.  Let me think about it some more.
",mperham,betelgeuse
367,2012-08-25 00:29:33,"@ezkl Thanks, but yeah, I already have the after_fork block setup. This is a very odd issue!
",cmer,ezkl
367,2012-08-25 00:38:36,"It seems to have something to do with Unicorn or the way it forks. @ezkl gave me the idea to test with Unicorn locally and I reproduced the issue. With Pow, I can see the right number of jobs, with Unicorn, everything is at 0.

Here's my Unicorn config file (slightly modified to run locally): https://gist.github.com/3457954 (notice Dalli in there as well ;-) ). I started Unicorn with `RAILS_ENV=development unicorn -c config/unicorn/development.rb`.

Hopefully this is enough information to get to the bottom of this. Let me know if you need anything else, @mperham. Thanks!
",cmer,ezkl
367,2012-08-25 00:38:36,"It seems to have something to do with Unicorn or the way it forks. @ezkl gave me the idea to test with Unicorn locally and I reproduced the issue. With Pow, I can see the right number of jobs, with Unicorn, everything is at 0.

Here's my Unicorn config file (slightly modified to run locally): https://gist.github.com/3457954 (notice Dalli in there as well ;-) ). I started Unicorn with `RAILS_ENV=development unicorn -c config/unicorn/development.rb`.

Hopefully this is enough information to get to the bottom of this. Let me know if you need anything else, @mperham. Thanks!
",cmer,mperham
367,2012-08-25 12:47:13,"@cmer yeah with unicorn you need to have sidekiq in after_fork and then configure it with the same connection settings as in the initializer. The code in the wiki article pointed out by @ezkl is not meant for blind copying (I will adjust).

@mperham I think a good addition for sidekiq would be to add official api to reconnect and document that in the wiki so that people will only need to maintain settings in one place (of course the unicorn config could source them from one place but could make it easy for people by providing like the redis client).
",betelgeuse,ezkl
367,2012-08-25 12:47:13,"@cmer yeah with unicorn you need to have sidekiq in after_fork and then configure it with the same connection settings as in the initializer. The code in the wiki article pointed out by @ezkl is not meant for blind copying (I will adjust).

@mperham I think a good addition for sidekiq would be to add official api to reconnect and document that in the wiki so that people will only need to maintain settings in one place (of course the unicorn config could source them from one place but could make it easy for people by providing like the redis client).
",betelgeuse,mperham
354,2012-08-18 12:40:55,"@mperham any ideas why the dates are not serialized properly?
",mhenrixon,mperham
349,2012-12-03 09:50:38,"@mperham Why is this still open, if not merged in?
",NielsKSchjoedt,mperham
349,2012-12-03 14:06:49,"Because I don't want it. 

On 3 Dec 2012, at 01:50, NielsKSchjoedt notifications@github.com wrote:

> @mperham Why is this still open, if not merged in?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
347,2012-08-14 10:55:00,"@mperham you should probably warn people about running anything greater than 2.0.3 in production environment....
",mhenrixon,mperham
342,2012-09-21 07:57:50,"@mperham I'll see what I could do. Just have to my head around first. You can assign me into this issue.
",joneslee85,mperham
340,2012-08-08 23:02:14,"@mperham is it possible do not cancel duplicate job, but schedule it again after 20sec wait? So it would be something like serial jobs processing? 
",shtirlic,mperham
340,2012-08-08 23:48:15,"@mperham sure, I know, but it's big issue since sidekiq is really fast and multithreaded - so the same job could be run concurrently with no way to know who was finish first and using unique jobs is not a option, is there any ""good"" way to serial processing the same jobs as they pushed in the queue. If there are no ""good"" ways I will try to write middleware for that.
",shtirlic,mperham
339,2012-08-08 03:39:09,"@mperham 

But `redis-server --version` shows
`Redis server version 2.4.16 (00000000:0)`
",jimhj,mperham
339,2012-08-08 03:50:34,"@mperham 
It's ok now after restarted redis-server.
",jimhj,mperham
338,2012-08-08 05:25:40,"@mperham can you put RMagick on _the_ ""troublesome gems"" list :wink:
",jc00ke,mperham
336,2012-08-08 17:17:08,"@mhenrixon interesting. Would you mind adding some notes to the wiki on this? I think this could really help out others.
",jc00ke,mhenrixon
336,2012-08-08 17:30:05,"@mhenrixon @jc00ke That specific issue you're mentioning seems to be documented here: https://github.com/mperham/sidekiq/wiki/Problems-and-Troubleshooting

Under the last heading of the page, it says ""Sidekiq is so fast that it is quite easy to get transactional race conditions where a job will try to access a database record that has not committed yet. The clean solution is to use after_commit""
",jakemack,jc00ke
336,2012-08-08 17:30:05,"@mhenrixon @jc00ke That specific issue you're mentioning seems to be documented here: https://github.com/mperham/sidekiq/wiki/Problems-and-Troubleshooting

Under the last heading of the page, it says ""Sidekiq is so fast that it is quite easy to get transactional race conditions where a job will try to access a database record that has not committed yet. The clean solution is to use after_commit""
",jakemack,mhenrixon
336,2012-08-08 17:33:44,"@jakemack thanks buddy I have completely missed the bottom of the page or it was added pretty recently.
",mhenrixon,jakemack
336,2012-09-21 11:06:16,"I can confirm it too, it works fine!
@mperham thank you very much!
",qw3r,mperham
332,2012-09-04 18:37:32,"@JonasNielsen I have the same question.

I think http://ruby.runpaint.org/exceptions explains it: ""StandardError ... The parent class of most recoverable errors. Caught by a bare rescue statement modifier or clause.""

I can see the argument going like this -- why try to recover from non-recoverable errors?  -- these are system-level problems that won't be solved with a retry. @mperham is this your rationale for only handling `StandardError`?

That said, the non-recoverable exceptions are, of course, still a problem.
",bluemont,mperham
318,2012-07-30 16:12:48,"@tarcieri just tried the remove_defer with celluloid 0.11 and master, its still happening. So you're planning to remove the use of Fibers in Celluloid? Or just for some types of actors?

@mperham ahh yea, I see what you mean in the Gemfile.. I was using sidekiq as a gem, and the gemspec points at 0.11. 
",pkieltyka,mperham
318,2012-07-30 16:39:24,"@tarcieri good, I'm glad you're keeping fibers in because it will become more useful as async IO takes off (_hopefully!!!_). The fiber-thread propagation is a cool idea.. ~5% is worth it if it solves the world of hurt that we are currently in.

@mperham have you noticed that even the redis connections via connection_pool are also being affected? Looking at my console I see the workers reconnecting as they process each job. Which makes sense, I was just looking at the code and it also uses thread local storage.

Perhaps ConnectionPool should be rewritten to use class variables? with some basic variable synchronization.. it could even mimic thread local storage by having a different pool per thread.. you guys would know better, but would that cause more or less issues with threads/fibers?
",pkieltyka,mperham
312,2012-08-02 23:56:40,"@mperham this also included the switch from defer to exclusive, right?

There weren't any significant changes to Celluloid itself between 0.10.0 and 0.11.1 unless you were using Celluloid::Pool. There have been many significant changes in HEAD.

You might try running an older Sidekiq with a newer Celluloid and see if the problems persist.
",tarcieri,mperham
312,2012-08-04 00:43:55,"@aselder can you try running Sidekiq master but revert 3d869cd and see if it works for you?
",tarcieri,aselder
312,2012-08-15 23:26:42,"@mperham Celluloid 0.12.0 will provide thread-based tasks in addition to fiber-based ones and you'll be able to selectively enable this on a class-by-class basis. You will be able to use that in lieu of defer and it will cut down the number of threads on JRuby.
",tarcieri,mperham
303,2012-07-21 15:34:53,"@mperham thanks for the clarification, I am then going to request you to consider extending the delay method to see if sidekiq_options can somehow be accommodated? At the moment all ActiveRecord classes where we end up using backgrounding end up with the same default sidekiq options. 

What would you suggest / How would you suggest having sidekiq options on the proxies?
",asanghi,mperham
303,2012-07-22 03:43:13,"@asanghi Back to one of your original questions



That is a suggested philosophy of both Ruby and OO in general. The [S](http://en.wikipedia.org/wiki/Single_responsibility_principle) in [SOLID](http://en.wikipedia.org/wiki/SOLID_%28object-oriented_design%29) says it all. Take @mperham's example of



One could argue that the `User` class shouldn't know about charging a credit card. While I know Mike was just using that example to show why using `current_user` is bad with regards to Sidekiq, you can extrapolate that example & ask yourself if all those methods you use as workers should really be in your class in the first place.

I prefer to have a worker class perform a single task. It's easier to test and easier to change. Having a bunch of little worker classes is not a bad thing.
",jc00ke,asanghi
303,2012-07-22 03:43:13,"@asanghi Back to one of your original questions



That is a suggested philosophy of both Ruby and OO in general. The [S](http://en.wikipedia.org/wiki/Single_responsibility_principle) in [SOLID](http://en.wikipedia.org/wiki/SOLID_%28object-oriented_design%29) says it all. Take @mperham's example of



One could argue that the `User` class shouldn't know about charging a credit card. While I know Mike was just using that example to show why using `current_user` is bad with regards to Sidekiq, you can extrapolate that example & ask yourself if all those methods you use as workers should really be in your class in the first place.

I prefer to have a worker class perform a single task. It's easier to test and easier to change. Having a bunch of little worker classes is not a bad thing.
",jc00ke,mperham
303,2012-07-22 05:43:38,"Thanks @jc00ke I understand and have some appreciation of Single Responsibility Principal but I fear it's a bit impractical for me to split all my background functions into one worker class each. I could mitigate my fears to some extent with using mixins and inheritance and it is certainly an option for me to consider and migrate towards.

With `delay/delay_for` the suggestion is quite clear. Use classes over instances, use simpler arguments over complex ones. (Simple argument suggestion applies regardless of worker classes or delay strategy).

I've now got the feeling from @mperham that perhaps `delay/delay_for` are not really second class citizens but they are still a bit rigid since they come with a default worker class baked in which is harder to control/configure.

Would you accept a PR which adds a bit more flexibility there? Something that lets the `delay` receiver object, determine which worker class to use?
",asanghi,jc00ke
303,2012-07-22 05:43:38,"Thanks @jc00ke I understand and have some appreciation of Single Responsibility Principal but I fear it's a bit impractical for me to split all my background functions into one worker class each. I could mitigate my fears to some extent with using mixins and inheritance and it is certainly an option for me to consider and migrate towards.

With `delay/delay_for` the suggestion is quite clear. Use classes over instances, use simpler arguments over complex ones. (Simple argument suggestion applies regardless of worker classes or delay strategy).

I've now got the feeling from @mperham that perhaps `delay/delay_for` are not really second class citizens but they are still a bit rigid since they come with a default worker class baked in which is harder to control/configure.

Would you accept a PR which adds a bit more flexibility there? Something that lets the `delay` receiver object, determine which worker class to use?
",asanghi,mperham
302,2012-07-26 06:33:46,"I haven't released any gem yet because I'd like a second pair of eyes on this but the repo can be found over at https://github.com/form26/sidekiq_unique_jobs.

The test @mperham ripped out are running fine though.
",mhenrixon,mperham
302,2012-07-26 06:40:22,"@mhenrixon Nice one! Will test it out shortly. My only feedback would be to name it sidekiq-unique-jobs, to use the same convention as the other existing sidekiq extensions out there, i.e sidekiq-scheduler and sidekiq-mailer
",fbjork,mhenrixon
302,2012-07-26 07:03:02,"@fbjork fixed that the repository is now located here https://github.com/form26/sidekiq-unique-jobs.git
",mhenrixon,fbjork
302,2012-09-05 21:54:33,"Hey there, i've recently created [sidekiq-middleware](https://github.com/krasnoukhov/sidekiq-middleware) gem which contains unique jobs as we discussed with @mperham in #281. Maybe you're interested in, please feel free to contat with me and contribute.
",krasnoukhov,mperham
294,2012-07-19 01:19:37,"@mperham 

I agreed that retries view cover most of the function. 

However, when I disable retry in my worker, I could not find the failed job in the retries view. Is it possible to still show the failed jobs in the retries view even I disable retry?

I might raise an new issue if you are OK for this
",leomao10,mperham
291,2015-11-05 10:39:08,"Hello @mperham, Is this gem `sidekiq-priority` https://github.com/socialpandas/sidekiq-priority useful ?
Sometimes, we want to set priority as `high` or `low` for few jobs that we trigger from console but with same existing queues that we already defined as critical, high, medium, low.

Scenario - We have few queues defined in our app as critical, high, medium, low. Now our users use the app and it triggers few jobs that are queued in various queues as per priority - fair and good enough. Now we want to do some hot fix and trigger few jobs from console assuming all queues are empty at this moment. We trigger - say 10K jobs from console and they are queued in various queues defined by us in our app, and being executed by Sidekiq. During this same time, our Live users performs some  operation in the app that results into 1K jobs. Now they are also queued behind the existing queue of 10K running jobs - in various queues. We want to give priority to User's jobs and next priority to console jobs that we manually triggered. In this case we think gem `sidekiq-priority` will be useful.
Your thoughts ?
",rohandaxini,mperham
291,2015-11-05 17:40:47,"@mperham actually in my case lets say Low queue is already having 10K jobs running that I executed via console. Now my users comes and triggers a functionality that in turn runs some jobs thru Low queue. Now I want preference to user's jobs in low queue and not my 10K jobs running via console that I already queued in Sidekiq. In such cases will that gem be useful ?
",rohandaxini,mperham
291,2015-11-05 17:51:38,"Thanks for the suggestions @mperham Sure
",rohandaxini,mperham
291,2015-11-09 18:43:22,"@mperham Love that you included this API. Quick question though, will using `Sidekiq::Client` override the `sidekiq_options` queue value if you have it set in the worker already? I have several workers designed for heavy processing for which I specify a `compute` queue in the `sidekiq_options`, but would like to elevate them to a separate queue under certain conditions. Just want to make sure this will work
",onetwopunch,mperham
291,2015-11-09 19:34:54,"@mperham Awesome! Thanks for the quick response! :+1: 
",onetwopunch,mperham
276,2012-07-04 01:33:26,"hey @jc00ke yes I've tested this on EY.
",seamusabshere,jc00ke
275,2012-06-28 06:06:59,"Ok, I see how it works now, thanks @ryanlecompte 

I'm thinking `Sidekiq::Client.registered_queues` could be used to do the same thing in Sidekiq. I'd have to put some thought into how to test it (and probably refer to Resque's tests) but maybe I'll put together a PR for this. :)
",stevenh512,ryanlecompte
274,2012-06-28 02:13:59,"@betelgeuse per client and server middleware,I can take a crack at this. But some initial hints would be great:

1) How do I detect if sidkiq is running from the client side ?
2) How do I detect that all the queues are empty on the server side?

Thanks 
",acds,betelgeuse
274,2012-06-28 19:42:07,"@mperham  Thanks...

I got the first bit from Wiki as indicated...

I think I need to enumerate 



for all queues to trigger a shutdown. I just need to identify the queues...

On the client I see 



but not on the server side. This could also be defied on the server side though and it would have the same result ?



I guess for the start up one can allays just start the workers ? as running 



multiple times has no effect it seems.

BTW: I assume firing up multiple sidkiq process is not advisable, to solve the different queses with different concurrency problem ?
",acds,mperham
274,2012-10-01 23:57:29,"@mperham I think it's more a matter of paying for a worker to run full-time when you don't need to. No one is arguing against Sidekiq's performance advantage over Resque. :) Just for clarification, are you against adding autoscaling to Sidekiq or is it just a low priority?
",gpxl,mperham
274,2012-10-01 23:59:13,"Auto-scaling sounds like an _awesome_ new Sidekiq Pro feature!

On Mon, Oct 1, 2012 at 4:57 PM, Gerlando Piro notifications@github.comwrote:

> @mperham https://github.com/mperham I think it's more a matter of
> paying for a worker to run full-time when you don't need to. No one is
> arguing against Sidekiq's performance advantage over Resque. :) Just for
> clarification, are you against adding autoscaling to Sidekiq or is it just
> a low priority?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/274#issuecomment-9054555.
",ryanlecompte,mperham
274,2012-10-02 01:09:02,"@mperham Thanks for clarifying!
",gpxl,mperham
269,2012-06-26 20:42:11,"@betelgeuse 
Our current workaround : we have all sidekiq worker classes in separated gem, with different loading approach;
For apps - we are loading just base classes(abstract), for worker -- we are loading actual classes where `perform` implemented.
",shtirlic,betelgeuse
269,2012-06-28 12:19:40,"@betelgeuse Thanks for the clockwork hint.
",cryo28,betelgeuse
268,2012-06-24 02:34:23,"@fbjork If you are using a connection pool, your connections should never grow past N connections \* M processes.  If they do, there's a bug somewhere.

@tarcieri Yes, connections are stored in a thread local while they are checked out so that reentrant checkouts return the same connection.
",mperham,fbjork
268,2012-06-30 03:39:18,"@fbjork Alright, try out the `remove_defer` branch and see if it improves your memory and connection usage.  Requires celluloid HEAD.
",mperham,fbjork
268,2012-07-04 16:14:51,"@fbjork Will you be able to test this anytime soon?
",mperham,fbjork
262,2012-06-22 02:01:10,"thanks @jc00ke
",JoshMcKin,jc00ke
260,2012-08-30 09:25:23,"@mhenrixon Same thing is happening to me. Although I'm on Apache. Do you think its definitely an webserver setting? In the logs I can see a request is made for the files, then I get a timeout shortly after. Like you say, it looks pretty fugly!
",geoffw8,mhenrixon
260,2012-08-30 16:02:22,"What @mperham meant is on the bottom of https://github.com/mperham/sidekiq/wiki/Problems-and-Troubleshooting there is a section on why but not how to solve it. If your webserver (like mine) drops all requests to assets that aren't originating from the same folder as the web app is running in those requests will end up with a 404 and the web ui will look like shit. As I wrote in my previous entry check for something like:


",mhenrixon,mperham
260,2012-09-02 12:39:55,"@mhenrixon here is my nginx config  
server {
        listen       80;
        server_name  localhost;
        root /home/railsapp/public;
        passenger_enabled on;
        rails_env production;


",inetufo,mhenrixon
260,2012-10-26 17:08:11,"@mperham I'm not sure why you keep pushing this aside as an individual user server config issue (and in your FAQ).  Isn't the way `sidekiq-web` handles these assets completely the opposite of the way assets are normally handled?

The typical configuration is to have your assets precompiled in production, with your server set up to serve as static assets in order to avoid hitting your rails app for CSS/JS requests.  For the server to let sidekiq serve the assets directly from the gem, you are requiring people to set up a location block **specifically for your gem**.  I.e. I was having the same problems, and this fixes it in Nginx:



You have to specifically pass the `/sidekiq/assets` location to your rails app to be served out the gem.

There really should be an option to copy the assets out of the gem and package into `/public/assets`/ in production.  We shouldn't be hitting the app server to request CSS & JS files.

My $0.02.
",brandonparsons,mperham
260,2012-10-26 17:25:49,"@mperham Can you share your nginx config?

On Fri, Oct 26, 2012 at 11:24 AM, Mike Perham notifications@github.comwrote:

> @brandonparsons https://github.com/brandonparsons Our assets work fine
> and we don't have any sidekiq-specific nginx configuration. _That's your
> user-configuration issue._ If you do the simplest thing in nginx, it will
> work. People try to be smart and break this edge case.
> 
> The simplest thing is this:
> 1. try to have nginx serve the asset from the filesystem
> 2. if it does not exist, pass the request to Rails.
> 
> That's it. If it doesn't work, it's because you aren't doing #2https://github.com/mperham/sidekiq/issues/2
> .
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/260#issuecomment-9820478.
",brandonparsons,mperham
260,2012-10-26 17:43:07,"@mperham Cheers - thanks!  Appreciate it.
",brandonparsons,mperham
260,2012-11-01 13:56:06,"I use Apache, I have this issue. Two servers, EXACT same setup. Works on
one, not the other...

On Fri, Oct 26, 2012 at 6:43 PM, brandonparsons notifications@github.comwrote:

> @mperham https://github.com/mperham Cheers - thanks! Appreciate it.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/mperham/sidekiq/issues/260#issuecomment-9821070.

## 

BR,

Geoff Wright
Founder & CEO

w: weartolook.com
t: @weartolook http://www.twitter.com/weartolook

weartolook LTD
St John's House,
54 St John's Square,
London, EC1V4JL
",geoffw8,mperham
260,2012-12-15 18:16:08,"I have this problem as well. My nginx config is almost identical to the one posted by @mperham and I get the following rails error: 

ActionController::RoutingError (No route matches [GET] ""/home/chetan/.rvm/gems/ruby-1.9.3-p327/gems/sidekiq-2.5.4/web/assets/stylesheets/application.css"")

Oddly, when I hit the ruby server (unicorn in this case) directly, the asset is served just fine, but when I hit nginx, I get the above error. Haven't been able to debug it any further than that, and don't want to spend much more time on it, but if you have any ideas, I can try to get more info. 

The symlink posted by @nragaz works nicely for me, so that's what I'm going with for now. 
",chetan,mperham
260,2013-07-09 15:33:34,"I've tried @mperham 's nginx configuration file and it works for me.
",babaru,mperham
257,2012-07-09 21:50:53,"@mperham Consider an application such as google calendar that has reminders for events. Say you set 3 reminders per event. If the event changes N times, then you'd have N \* 3 ""phantom"" jobs that don't have permission to run. It seems a little more explicit and clear to simply remove the old jobs and create the new ones.
",jonhinson,mperham
257,2012-10-29 19:10:01,"@rmello Yeah, I realized that oversight last night.  I'll fix it.
",mperham,rmello
257,2013-05-06 15:05:28,"Sorry I should have been more specific.  I was curious about the status of documentation on this.  I ended up looking through api.rb and figured it out.  Thanks @mperham 
",yanismydj,mperham
256,2012-06-19 18:59:22,"@jc00ke Can you update the readme with the basics of how to sub/unsub and make me an admin if possible?
",mperham,jc00ke
249,2012-06-14 23:46:24,"@mperham how do I not load ZenTest?
",hermanccw,mperham
248,2012-10-16 16:14:23,"@chewi Once you have something working, please open a new PR.  I'd prefer to review and comment on the code there.
",mperham,chewi
243,2012-10-10 00:49:52,"I had a similar problem as @johnreilly, but resolved with @mperham's suggestion along with an additional step.

Previously I was simply returning if the object was already in a ""running"" state in order to prevent duplicate long running tasks running concurrently.

I switched to adding use of [unique_jobs](https://github.com/krasnoukhov/sidekiq-middleware) to prevent that situation and adjusted my state machine configuration to handle state change to ""running"" from ""running"".

After initial tests, it seems to work as expected.
",walter,mperham
233,2012-06-12 16:29:26,"@dim I don't know what to tell you.  Others aren't reporting this issue so I have to assume it is specific to your environment.  Maybe open a Celluloid issue because the actor appears to be dying silently?
",mperham,dim
229,2012-06-14 18:26:56,"@mperham I can arrange that with no problem.
Let me know what you need.
",KensoDev,mperham
229,2012-06-14 18:36:02,"@KensoDev I'm looking for someone who can look over the current UI, understand the domain and data to be displayed and redesign the current pages/flow.  In other words do what a good web designer does.  I'm happy to implement but need the design direction.
",mperham,KensoDev
229,2012-06-14 18:40:02,"@mperham I can definitely help with that, more then willing to supply the web designer resource + implementation.
Now that I know this is something that needs improving, I will be happy to work on it.

Expect an issue/pull request opened by me, we will discuss it further there.
",KensoDev,mperham
228,2012-08-09 18:03:19,"When I started with sidekiq I also expected there to be a way to pass the options down to the redis driver. Adding a support for that gets my vote but let's see what @mperham says. @tmak regardless of where sidekiq goes it could be a worthwhile addition to redis-rb to support urls like unix:///foo/bar?db=1 for unix sockets.
",betelgeuse,mperham
227,2012-06-07 13:30:21,"@mperham no. It's not finishing early for an unknown cause. I know it takes some hours to finish, so I was checking it via the WebUI. After some minutes of being launched it disappeared, then I checked the processes via `ps` command and sidekiq showed it was, indeed, processing it and at the same time the WebUI showed no taks currently running.

I should also mention that my Rails app has `threadsafe!` option set. Could this break something?
",brutuscat,mperham
211,2012-06-05 10:47:32,"@mperham I have similar problem. Some of my jobs can be take reaaaaaally looong time, and they are disappearing from the web UI. Although if I run `ps axf` I can see sidekiq is processing it `sidekiq 2.0.0 [1 of 10 busy]`

I don't need a Timeout here, since I want the job to be processed until it ends. My issue is that the UI is missing track of the being-processed job. 

Should I open a new issue? Seems the same to me...
",brutuscat,mperham
202,2015-05-19 18:05:34,"@mperham I know this issue is old, but we have a bunch of Rails apps running Sidekiq and we are interested in having this implemented.. any chance this topic is reconsidered?
",ncuesta,mperham
200,2012-06-09 22:17:32,"Maybe it doesn't help @aselder though because it only makes sure there's one copy running and not that they are processed in insertion order.
",betelgeuse,aselder
197,2015-11-26 15:44:49,"@mperham Is this still a no?
",nijikon,mperham
197,2015-11-26 16:18:44,"Fwiw there are a few places where we do this. We have a custom job parameter encoding class that can encode and decode objects (using a combination of marshaling, gzipping and base64 encoding). It has been very beneficial for a few different places. We do it on a case by case basis. I'll tell you that when we upgraded from Rails 3 to Rails 4 it was a challenge because one object had contained an active support timezone in an instance variable, which changed representations between 3 and 4 and we had to write custom logic to handle that for in flight or scheduled jobs that were marshalled in Rails 3. So you need to take care for this. I'm supportive of @mperham not including this option. Imo you should know what you're doing and be aware of the consequences if you pass around encoded objects. 
",jonhyman,mperham
187,2012-05-12 05:10:35,"Thanks for reporting @ezkl.
",mperham,ezkl
185,2012-05-11 20:59:24,"What @ryanlecompte said.  Redis is pretty heavily embedded into Sidekiq at this point and I don't regret that decision at all.  Redis offers a number of useful data structures like queues, time-sorted lists, etc which Mongo and other data stores can only simulate.
",mperham,ryanlecompte
185,2012-05-14 17:05:06,"I've thought about implementing something like this wrt. Resque, but instead of redis, using a zookeeper backend, as it can support many of the same operations needed. I think instead of having redis-specific calls all over the codebase, having an interface that encapsulates Redis, and exposes an action-oriented interface would be a real win.

@mperham saying ""I don't regret that decision at all"" is somewhat besides the point. If it works well for you, great, but I think what's being suggested here is that people would like to extend your project, and would like to do it in a way that didn't require that they maintain a long-term fork of it (the way I did with Resque, because I wanted `brpoplpush` so I wouldn't lose jobs).  You may not regret the decision, but some of your users do.

It doesn't matter if mongo ""can only simulate"" these kinds of data structures, that's rather the point of abstraction, no? So long as someone can provide a class with the proper behavior, it shouldn't matter how the back end is implemented. Some people _hate_ redis, just as some _hate_ mongo. Making it possible for both groups to be satisfied i'd think is a noble goal, especially if someone else is proposing to do the work to make it happen.
",slyphon,mperham
182,2012-08-08 13:41:26,"I suppose this issue can be closed because @mperham nuked UniqueJobs from sidekiq
",shtirlic,mperham
181,2012-05-29 21:14:23,"@aselder I'm hoping to get the next version of Celluloid out in the next few days
",tarcieri,aselder
173,2012-05-04 23:16:53,"@panthomakos did you get the deadlock error quickly? When I lock up like that on Ubuntu I never see that msg.
",jc00ke,panthomakos
173,2012-05-04 23:24:08,"@jc00ke I get it very quickly, but only when I comment out the second stat test, otherwise the suite freezes after the failed test.
",panthomakos,jc00ke
173,2012-05-05 04:22:06,"@jc00ke Just rm the file?
",mperham,jc00ke
173,2012-05-05 04:50:39,"Ha, yeah I could have done that.

So if I remove that test, then everything is fine.

The offending lines, as denoted by @mperham before are [here](/mperham/sidekiq/blob/master/test/test_manager.rb#L44-48)
",jc00ke,mperham
173,2012-05-09 17:43:46,"@ezkl That's probably because the tests are ordered differently between the Rake task and command line.
",panthomakos,ezkl
173,2012-05-09 17:55:04,"@mperham didn't you say something about `rake` forking or shelling out?
",jc00ke,mperham
173,2012-05-16 17:58:54,"@panthomakos yes, the tests pass on Celluloid HEAD. I am adding an explicit kill mechanism that can be used on Actors, so at the very least you don't have to iterate through the entire thread pool just to kill off actors from the tests.
",tarcieri,panthomakos
173,2012-06-17 04:36:45,"@panthomakos Can you make progress on this issue or close it?
",mperham,panthomakos
171,2012-05-02 00:02:36,"@panthomakos You are kicking butt today.  I'm going to let this one sit for a day to percolate in my brain but unless someone hates it, I'll merge it in soon.

Would you update the changelog with your changes?
",mperham,panthomakos
171,2012-05-02 01:12:01,"@mperham Added the change to the changelog.

Would you like me to create a separate pull request with my previous change that made `Sidekiq::Client#enqueue` work with the `sidekiq/testing` file?
",panthomakos,mperham
166,2012-05-03 03:32:43,"@jc00ke It's too bad the user has to manually include the module.
",mperham,jc00ke
166,2012-05-03 05:37:24,"@mperham hmm, I meant to move that to `Mongoid::Document`. I'll give that a try.
",jc00ke,mperham
166,2012-05-03 10:00:33,"@jc00ke hey, sorry for the late reply. I haven't gotten around to try it out in one of the projects I'm working on. You doing another commit to move it in to `Mongoid::Document`? Let me know and I'll give it a shot.
",mrrooijen,jc00ke
166,2012-05-11 11:49:57,"@jc00ke do you think it is okay to redefine `included` on `Mongoid::Document`? It could be used by MongoID (in the future, or maybe even right now, I'm not familiar with the code).
",ghost,jc00ke
164,2012-07-22 17:34:56,"@mperham im also having segmentation faults now. Mostly coming from pg_ext gem
here is the full trace http://pastebin.com/gCyc5LrW
",fred,mperham
154,2012-05-02 19:47:23,"@kyledrake Any progress on this? Let me know if you're not planning to do it and I'll have a go at it.
",fbjork,kyledrake
154,2012-05-02 20:00:11,"@fbjork ^^^
",kyledrake,fbjork
152,2012-04-25 21:26:51,"@ryanlecompte Can you be more specific with a code example?  We use paperclip for our product images and I just tested that sidekiq can delay both a class and instance method.
",mperham,ryanlecompte
149,2012-04-22 20:51:22,"@mperham Encode is aliased to dump, it just throws warnings. If you don't want warnings, you need to feature-detect.
",sferik,mperham
149,2012-04-22 21:04:53,"I've cleaned up the patch, per @jc00ke's suggestion.
",sferik,jc00ke
149,2012-04-22 22:03:59,"Yes, much better. Thanks @sferik!
",jc00ke,sferik
132,2012-04-15 22:05:00,"@mperham maybe not the full server code, but how about through plugins?

I think your ""poor man's integration test"" is a good start. I will work on it when I have a chance. I can provide a simple implementation then we can from there. Sound like a plan?
",ahawkins,mperham
129,2012-04-13 22:28:07,"What version are you running? The UniqueJobs middleware was removed by default on 56bda62.

Actually there looks to be a remnant with `sidekiq_options` [here](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/worker.rb#L49). @mperham should that `:unique => true` still be there?

Update: heh, 2 minutes late. Question about remnant still stands though :smile:
",jc00ke,mperham
129,2012-04-13 22:29:13,"@jc00ke I would like to retain the chance to enable/disable unique jobs on worker basis.
",masterkain,jc00ke
126,2013-10-02 15:34:52,"Hello @mperham 

I have trouble with UTF8 arguments and sidekiq. When I enqueue a job with the argument encoded in utf8, say `Sébastien`, I get `WARN: ""\xC3"" on US-ASCII` as an error and the job won't be processed.

When I look at the encoding of my string **before** it gets put in Redis, it is `UTF-8`, and it goes throught the Sidekiq json serialization.

The thing is, if I modify the `Sidekiq::Fetcher#fetch` by setting the default external encoding



No more errors! The json deserialization of arguments works perfectly and I can go on.

So what should I do here? Is there a mis-handling on Sidekiq side? I set up `Encoding.default_external = Encoding::UTF_8` at the very beginnig of my `config.ru`, so I'm pretty sure that's the most I can do on my side...

Thank you!
",ssaunier,mperham
121,2012-04-16 19:06:35,"I’ve been unable to reproduce the issue on my laptop since friday (have done quite a few round trips). I added a logging statement right after the blpop, printing the MD5 hash of the message (so if I found a non-processed message later, I could look it up and see if the fetcher _did_ fetch it).

Considering I’m no longer on the project using this code base I won’t be exposed to the issue too much anymore (actually wasn’t last week either, but the issue was bugging me so I kept at it), I will be laying my personal effort to rest. Considering the project is running an old version of Sidekiq (and the TerminateJobs middleware), I’d expect the developers now maintaining the code to upgrade Sidekiq and remove the crazy middleware — if the issue persists after that I hope they’ll be back.

Thanks for your help @mperham, I appreciate it.
",Burgestrand,mperham
120,2013-04-29 04:27:22,"@masterkain Correct, you do not need to put anything in `after_fork` anymore.
",mperham,masterkain
120,2013-05-01 16:45:50,"@mperham what version / sha contains these changes?  Want to make sure my site is good to go.
",subdigital,mperham
120,2014-08-01 20:25:26,"@mperham Re:

> Correct, you do not need to put anything in `after_fork` anymore.

Are [these docs](https://github.com/mperham/sidekiq/wiki/Connecting-to-Redis#forking-app-server) out of date?  Just trying to figure out the correct current answer.
",tjschuck,mperham
119,2012-04-23 20:13:06,"@fbjork The issue with that line you linked is that even if the value is set to true, Sidekiq will still allow dupe payloads unless the user has configured the client and server middleware properly.  So yeah, the docs probably need updating but it's a tricky thing to explain to the end-user.
",mperham,fbjork
117,2012-04-09 13:12:52,"@joneslee85 @mperham is right here. 

I solved it by having just one worker and using a sidekiq.yml where the concurrency is about 25 connections. 

The connection pool on the redis to go mini I think it about 50 connections. 

https://github.com/mperham/sidekiq/blob/master/examples/config.yml
",ivanacostarubio,mperham
117,2012-04-09 13:12:52,"@joneslee85 @mperham is right here. 

I solved it by having just one worker and using a sidekiq.yml where the concurrency is about 25 connections. 

The connection pool on the redis to go mini I think it about 50 connections. 

https://github.com/mperham/sidekiq/blob/master/examples/config.yml
",ivanacostarubio,joneslee85
117,2012-04-09 22:59:27,"@mperham Thanks, I got it resolved.
",joneslee85,mperham
117,2012-10-16 04:27:29,"Hi, I'm getting the same problem here...

I copied Redis-to-Go conf file and run Redis locally with the same restrictions, 10 max connections.
Watching the log I noticed Sidekiq opens (concurrency + 2) Redis Connections, as @mperham said, **plus** 1 new connection to every new job (each ""perform_async"" call).
The point is after the job code have been executed the connection **still active** until the Redis close it as ""idle client"", long time after.

Is it right?
",uchoaaa,mperham
117,2012-10-17 03:30:46,"Thanks @mperham, it seems ok now.

One more question, if I set the pool size to 1 and concurrency to 5 Sidekiq Client will create 5 threads and all 5 threads will share only one Redis connection, right? If so, this scenario could generate some issues, like race condition?
(actually I'm trying to understand the the relation of connections pool and concurrency :-) 
",uchoaaa,mperham
117,2012-10-17 12:45:12,"@mperham man, you are awesome! Thanks, it's so clear now!
",uchoaaa,mperham
117,2013-06-05 09:18:20,"I have the exact same issue as @FlopTheNuts. I don't fully understand how all the parts combine together, but based on what I've read the settings that FlopTheNuts has should work and they don't I get `ERR max number of clients reached` constantly, along with this:



I have Redis mini with 50 connections and the CleaDB Drift plan with 30 connections to the Mysql database.  

Redis server = 4
Redis client = 1
Sidekiq pool = 5
dynos running in a single job = 3
concurrency (bundle exec sidekiq -c 10) = 10

Mysql connections should be ok 3 \* 5 = 15 but I don't know about the rest.

I am running Rails 3.2 with Thin so no mutlithreads. 

I've been trying all sorts of combinations that **should work** according to what I've read but none of them do. 

Even setting the concurrency value to 6 which @mperham  says follows this formula: server pool size -2 \* 2



Constantly gives me the following error and lots of failed jobs that never get run again:



Any help would be greatly appreciated I'm going crazy with this. 

thanks. 
",kakubei,mperham
117,2016-01-06 08:33:23,"Thanks a lot @mperham for the help. 

When you write `Web = 4 * 3 = 12` I also need to add the puma connections ?  On my `puma.rb` I have `MAX_THREADS = 20` and `WEB_CONCURRENCY = 2`

> A good formula for determining the number of connections each application will require is to multiply the MAX_THREADS by the WEB_CONCURRENCY. This will determine the number of connections each dyno will consume.[[1](https://devcenter.heroku.com/articles/deploying-rails-applications-with-the-puma-web-server#database-connections)]

So It means I have to add this **40** to my web count ? `Web = 4 \* 3 + 40 = 52 ?

Sorry quite out of thread.
",benoittgt,mperham
117,2016-01-06 16:28:01,"Great. Thanks @mperham 
",benoittgt,mperham
115,2012-04-06 18:22:17,"Hopefully @mperham's old issue for dynamically increasing the Fiber stack size will get some love, although it was filed 2 years ago. :-(

http://bugs.ruby-lang.org/issues/3187
",ryanlecompte,mperham
113,2012-04-04 22:50:03,"@matthewford EY doesn't require you to use utility instances for workers, and the chef recipe takes that into account.
",jc00ke,matthewford
110,2012-04-06 05:39:32,"@Burgestrand I took a look at your TerminateJobs middleware at https://gist.github.com/2290629. I think there may be a race condition with the signals:

Here's a scenario:

1) Thread A is executing its middleware chain for a job. When it gets to yield in the TerminateJobs middleware, it hangs for a while waiting on I/O or some other long operation.

2) Meanwhile, Thread B comes along and happily executes its middleware chain. It gets to the TerminateJobs middleware, and upon executing yield it blocks for a while too since it's another long-running operation. However, before it gets to yield it also traps the new signals for itself, meanwhile preserving the signals set from #1 above since the currently installed signal handlers were from Thread A.

3) Meanwhile, Thread A from #1 finishes executing, and restores its ""old_signals"" in the ensure clause that it originally set before it got to yield. Note that while it was executing it never saw the new signal handler that Thread B set for itself to ensure that its job gets rescheduled if Terminate is raised (i.e., ""old_signals"" never gets updated if other threads install new signal handlers).

The final outcome is that Thread A ends up overriding the custom signal handler that Thread B (or any other threads potentially) scheduled for itself, and if Sidekiq terminates via TERM/INT then Thread B's long-running job won't get rescheduled since Terminate will never get raised.
",ryanlecompte,Burgestrand
110,2012-04-06 22:20:19,"@ryanlecompte ah, that is true! After thinking about it though, even if the process of solving this with a middleware is an attractive approach I’m not sure it’s a good idea.

There are two issues currently being discussed:
1. the one I’ve created this issue for, where Sidekiq does not forcefully shutdown/abort workers after five seconds, even though [it looks like it would attempt to](https://github.com/mperham/sidekiq/blob/2e58b1d9d8f3f06ec8d2499238121fc2ec6b1ed6/lib/sidekiq/manager.rb#L61). My hope for a resolution to this issue is to actually **forcefully** shut down all workers after the five seconds has passed and re-queue the job they were working on, instead of _asking_ them to terminate (and risk getting SIGKILLED by Heroku if the busy workers don’t finish their work).  
   My _main_ concern is that Sidekiq [makes the appearance of allowing workers to finish for another five seconds before killing them](https://github.com/mperham/sidekiq/blob/2e58b1d9d8f3f06ec8d2499238121fc2ec6b1ed6/lib/sidekiq/manager.rb#L57), while it is in reality waiting _forever_ until the workers finish. This is because [ActorProxy#terminate](https://github.com/celluloid/celluloid/blob/7e02f248a673075e32ce8e3b0d20f48d3a03d879/lib/celluloid/actor_proxy.rb#L60) does not terminate the worker directly, but instead sends it a message (using [Mailbox#system_event](https://github.com/celluloid/celluloid/blob/8b926200892989404512006b421dacd9dde5fde8/lib/celluloid/mailbox.rb#L36)) that won’t be received until the worker finishes what it is currently working on.  
   I don’t know if Celluloid has any way of forcefully and violently killing an actor currently working on a task, other than raising an exception in the actor thread. Perhaps raising an error in the actor thread _is_ the recommended approach of really interrupting an actor. This is a key part if one wishes to re-queue jobs that did not finish in time on shutdown.  
   Now, I’ve noticed an earlier attempt at re-queuing jobs on the five-second-forceful shutdown, that was removed with no replacement in dec7472f33a609760b259abe62c12fce2c9ef3be. @mperham @ryanlecompte is there any way both of the above things (killing the busy actors, and re-queuing their unfinished work) can be solved in an elegant manner using middleware?
2. the one of losing jobs on an immediate shutdown (SIGKILL et al), which would require brpoplpush/blpoprpush and probably a very large change to Sidekiq’s internals. This is a separate (and very complex) issue, and probably best served from a separate issue ticket.

Re-reading my initial post about the issue I explained myself very badly and mixed these two issues into one. Sorry about that.
",Burgestrand,ryanlecompte
110,2012-04-06 22:20:19,"@ryanlecompte ah, that is true! After thinking about it though, even if the process of solving this with a middleware is an attractive approach I’m not sure it’s a good idea.

There are two issues currently being discussed:
1. the one I’ve created this issue for, where Sidekiq does not forcefully shutdown/abort workers after five seconds, even though [it looks like it would attempt to](https://github.com/mperham/sidekiq/blob/2e58b1d9d8f3f06ec8d2499238121fc2ec6b1ed6/lib/sidekiq/manager.rb#L61). My hope for a resolution to this issue is to actually **forcefully** shut down all workers after the five seconds has passed and re-queue the job they were working on, instead of _asking_ them to terminate (and risk getting SIGKILLED by Heroku if the busy workers don’t finish their work).  
   My _main_ concern is that Sidekiq [makes the appearance of allowing workers to finish for another five seconds before killing them](https://github.com/mperham/sidekiq/blob/2e58b1d9d8f3f06ec8d2499238121fc2ec6b1ed6/lib/sidekiq/manager.rb#L57), while it is in reality waiting _forever_ until the workers finish. This is because [ActorProxy#terminate](https://github.com/celluloid/celluloid/blob/7e02f248a673075e32ce8e3b0d20f48d3a03d879/lib/celluloid/actor_proxy.rb#L60) does not terminate the worker directly, but instead sends it a message (using [Mailbox#system_event](https://github.com/celluloid/celluloid/blob/8b926200892989404512006b421dacd9dde5fde8/lib/celluloid/mailbox.rb#L36)) that won’t be received until the worker finishes what it is currently working on.  
   I don’t know if Celluloid has any way of forcefully and violently killing an actor currently working on a task, other than raising an exception in the actor thread. Perhaps raising an error in the actor thread _is_ the recommended approach of really interrupting an actor. This is a key part if one wishes to re-queue jobs that did not finish in time on shutdown.  
   Now, I’ve noticed an earlier attempt at re-queuing jobs on the five-second-forceful shutdown, that was removed with no replacement in dec7472f33a609760b259abe62c12fce2c9ef3be. @mperham @ryanlecompte is there any way both of the above things (killing the busy actors, and re-queuing their unfinished work) can be solved in an elegant manner using middleware?
2. the one of losing jobs on an immediate shutdown (SIGKILL et al), which would require brpoplpush/blpoprpush and probably a very large change to Sidekiq’s internals. This is a separate (and very complex) issue, and probably best served from a separate issue ticket.

Re-reading my initial post about the issue I explained myself very badly and mixed these two issues into one. Sorry about that.
",Burgestrand,mperham
106,2012-04-03 03:25:40,"Bundler hooks in at [deploy:finalize_update](https://github.com/carlhuda/bundler/blob/master/lib/bundler/capistrano.rb#L8) -- perhaps Sidekiq could always run after that? The kill/quiet process doesn't need to know anything about the (prior) environment since it's just reading a PID file so there's no reason it can't run after that. @mperham were you just trying to make sure that the process got quieted as early as possible in the deploy process so it had the most possible time to quiet before being terminated?

That said, even though this is included in sidekiq proper, I really don't like the idea of encouraging process management with a cap recipe. Something like god, monit, or upstart should be used to ensure that the process starts and stays running.
",bensie,mperham
106,2012-04-04 03:05:05,"@bensie Yes, that's the idea behind the cap integration.

Sidekiq's stance is simplicity.  Integrate with best of breed tools like capistrano, airbrake and heroku to make the developer's life as simple as possible.  I don't want to force anyone to use god or monit just to start sidekiq.  That said, the `examples/` directory exists for a reason.
",mperham,bensie
106,2013-07-25 02:59:52,"@josepjaume This issue was fixed a year ago.  The cap tasks all check for the existence of a PID file.
",mperham,josepjaume
106,2013-07-25 05:06:17,"Sorry @mperham, I made a bad diagnose of the problem. It turns out I had a sidekiq PID there that got created when I deployed an experimental branch (I'm transitioning from delayed_job) so sidekiqctl tried to run even if it wasn't on the Gemfile of the previous deploy. Deleting the pidfile fixed it.

Thanks!
",josepjaume,mperham
106,2013-09-13 14:43:16,"Thanks @josepjaume, you helped me debug my deploy very quickly :8ball: :+1: 
",danman01,josepjaume
106,2013-12-09 22:04:59,"same thing here, @josepjaume :) 
",danteregis,josepjaume
101,2012-03-29 18:38:54,"This is awesome.  Really good stuff, @jcoene!
",mperham,jcoene
100,2012-04-10 16:52:45,"@hinrik did the UI button work for you?
",jc00ke,hinrik
99,2012-03-29 17:11:07,"Thanks @hinrik!
",mperham,hinrik
88,2012-03-23 20:43:50,"@seamusabshere You are exactly right.  SIngle threaded and forking can be safer but comes at a non-trivial cost.  Processing efficiency is almost always a trade-off between safety and bare metal execution.  C's unchecked array access vs Java's array access checking is one example.  I'm always happy for suggestions on how to make Sidekiq ""safer"" for developers without throwing out the radical efficiency gains that threading gives me.
",mperham,seamusabshere
87,2012-03-22 15:30:44,"Tried running the tests too. Sidekiq tests won’t run for me on my laptop. Fresh pull of Sidekiq, new rvm gemset and using nothing but `bundle` to install the dependencies.

Running 1.9.3p125, with the following Gemfile.lock: http://goo.gl/rmeIo

@ryanlecompte do they run even if you do a `bundle update` to bring your Gemfile.lock up to date (if it was not already)?
",Burgestrand,ryanlecompte
87,2012-03-22 15:39:45,"@Burgestrand Do you have more info than ""won't run""?  A backtrace maybe?
",mperham,Burgestrand
87,2012-03-22 16:59:08,"@mperham sorry, forgot to mention I was getting the same issue as @JamesKyburz.

After removing test_web, this is what I get:



If we don’t remove it, both me and @JamesKyburz got the following backtrace instead (on two different machines): http://pastie.org/private/e5e2un4qyfgb1z0vvqtr9g
",Burgestrand,mperham
87,2012-03-22 17:05:57,"@Burgestrand You are using Rails 2.3.2 according to that stack trace.  Unsupported.
",mperham,Burgestrand
87,2012-03-22 17:37:18,"@mperham I’m not using rails at all. Like I mentioned before; empty gemset, fresh bundler install. Here’s the trace from another machine: http://pastie.org/private/mcaad57aqfor0abisbfa

Why it installs activesupport 2.3.2 I have no idea (certainly not because of some stray Gemfile.lock). Using bundler 1.1.2 to install these gems. Not really interested in digging in it more; if you are you have the backtrace.
",Burgestrand,mperham
87,2012-03-22 17:48:07,"@Burgestrand Sorry, that's our buggy gemspec.  Doesn't specify a minimum version for the activerecord and actionmailer gems.
",mperham,Burgestrand
86,2012-03-19 19:47:01,"Thanks @mperham - that did the trick.
",bensie,mperham
85,2012-03-19 18:11:57,"@masterkain That's a clean shutdown, despite the backtrace.  I'm not sure why Foreman shows that exception; I don't see it normally on the command line.
",mperham,masterkain
85,2012-04-10 16:54:16,"@masterkain are you still seeing this issue?
",jc00ke,masterkain
85,2014-05-14 17:42:02,"@mperham I'm opening this thread because I'm having this problem everything I start sidekiq using foreman.

My Procfile looks like this



It's not a Rails app, it's a rack app, but I think that's not a problem. 

When I hit Ctrl+C, puma goes down but sidekiq never goes. It's still there



Any advice or special configuration to avoid it?
",azisaka,mperham
85,2015-07-17 01:29:23,"@mperham awesome!  Thanks!
",jfelchner,mperham
84,2012-03-19 05:41:10,"@brandonhilkert are you on OS X? What version of Ruby are you using? I've saw this error when testing Sidekiq out on JRuby and it was a YAML bug when trying to convert an array.
",jc00ke,brandonhilkert
84,2013-07-09 11:34:36,"Thanks @planetmcd & @mperham 
",jwswj,mperham
84,2013-07-15 17:41:58,"@planetmcd & @mperham 
I just wanted to confirm that this definitely fixes the issue outlined here. :+1: 
",shawndeprey,mperham
84,2013-08-12 20:06:24,"Had the same problem on heroku. Thanks everyone!

@mperham is this exception explicitly rescued by sidekiq and then sent to stderr? It'd be easier to trace the cause of the exception with a full stack trace.
",ajsharp,mperham
70,2012-03-19 16:57:32,"@mperham np, I hadn't noticed the middleware to begin with. If the failed jobs queue no longer exists, the failed jobs web view isn't really necessary. I think we can scrap this pull request. Alternatively I can simply rename a few variables and routes web.rb and change the failed view to a retry view. Sound ok?
",eignerchris,mperham
69,2014-09-19 20:11:24,"@mperham could you expand on why CONT seems like an unnecessary signal? 

It helps us make operations easier (since it's not necessary to restart the process if we just needed to disable job processing for a little while), and it makes a migration from Resque easier since you'll have feature parity.
",ecin,mperham
66,2012-03-11 22:22:48,"I've needed this functionality, often times scheduling future jobs (10 minutes from now) from other background jobs. Often we use this logic for failure & retry logic: attempt this FB API call, if it failed due to rate limiting than re-schedule this same job in X minutes from now.

Currently we use Resque and the [resque-scheduler](https://github.com/bvandenbos/resque-scheduler) gem to achieve this. 

I am looking into switching to Sidekiq and would need a similar solution. I do however see @mperham point in that it adds un-necessary complexity to the core. So if there is a way to tack it on to an auxiliary gem, much like resque-scheduler that would be fantastic.
",ruckus,mperham
66,2012-06-20 05:10:41,"@mperham hey~ I cannot use the scheduler in sidekiq now. It's seems that the example of scheduler.rb is not correct.

How can I use Delayed job now? not in Rails app.
",crhan,mperham
66,2013-06-17 13:45:49,"@yabawock Your gem looks great, and I do need that functionality for my metrics, but it doesn't appear to solve the other scenario discussed in this thread of scheduling one-off jobs at any given point in the future, which is another requirement I have.

@mperham Is it possible to just set the enqueued_at to a date in the future, say `Time.zone.now + 30.days`?  This is the sort of thing I need to do, and it is a dynamic requirement, so I cannot solve it with a cron-like setup.  Are you aware of any ways to do something like this?  Why wouldn't simply setting the enqueued_at date to a future time not _just work_?
",pboling,mperham
66,2013-06-17 13:48:42,"Actually it looks like the one-off future jobs has been implemented:
http://ruby5.envylabs.com/episodes/282-episode-278-june-5th-2012/stories/2473-sidekiq-2-0-gets-scheduled-jobs

!!! Thanks for all your work @mperham 
",pboling,mperham
54,2012-02-28 19:28:18,"Shouldn't matter whether you're on 1.9.2 or 1.9.3. Although as @mperham mentioned you might be hitting memory limits. Heroku provides you with 512mb ram per dyno. I believe this is a hard limit. So, once you reach it, Heroku will SIGTERM your process and restart it. Pretty sure that that's what is happening here since ""garbage"" memory grows over time (pretty rapidly I might add, especially with ORM/ODM objects like ActiveRecord, Mongoid, etc) and Ruby's GC does a poor job at collecting it. Eventually you will hit the 512mb ram wall and will get a force restart from Heroku.
",mrrooijen,mperham
51,2012-03-19 16:23:50,"@dim Celluloid technically ""owns"" the processor threads and I don't believe it provides any functionality like that.  It would be a bad idea for Sidekiq to muck with Celluloid internals.  Maybe @tarcieri might have an opinion?
",mperham,dim
51,2014-04-21 19:28:45,"@mperham I'm having a problem with long-running jobs (not easily decomposed into smaller jobs) that looks like this one, but I assumed `reliable_fetch` would protect me. Is it still the case that if a process gets killed while that the messages get lost?

I'm already tracking a lot of job state in our database so I can write a detector that looks for this case and re-queues lost messages, just wondering if I'm using Sidekiq correctly.
",subelsky,mperham
51,2014-04-21 19:40:32,"It should work fine.  They'll just be restarted when sidekiq restarts. 

> On Apr 21, 2014, at 12:28, Mike Subelsky notifications@github.com wrote:
> 
> @mperham I'm having a problem with long-running jobs (not easily decomposed into smaller jobs) that looks like this one, but I assumed reliable_fetch would protect me. Is it still the case that if a process gets killed while that the messages get lost?
> 
> I'm already tracking a lot of job state in our database so I can write a detector that looks for this case and re-queues lost messages, just wondering if I'm using Sidekiq correctly.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
45,2012-02-19 22:10:33,"@mkremer was first so I merged his.
",mperham,mkremer
37,2012-02-19 05:51:48,"@mperham are you planning on adding the re-enqueue logic, when a worker gets killed, to sidekiq as default behavior?
",fbjork,mperham
35,2012-02-22 00:20:02,"Any progress on this @bensie?  I'd love to get this in a 0.7.0 release real soon.
",mperham,bensie
34,2012-02-17 04:46:11,"Hi there, thanks for your work on this. I think I've tracked this down, though I'm not sure how @mperham wants to resolve it given that it involves how we use any non-default middleware.

Your initializer code is calling `Sidekiq::Processor.middleware.register`, which is setting up the default chain (since it doesn't exist). The problem is that `Sidekiq::Manager.redis` is not established, yet is being referenced when it adds the default UniqueJobs middleware. That class is getting nil as its redis instance variable and throwing the errors we see.

As a quick and dirty fix, I'm explicitly setting the redis value on both client and manager in my initializer, which has resolved the error for me. Here's my initializer:



Any thoughts on what it would take to improve this behavior? At the moment it seems like using any non-default middleware would require this workaround.
",jcoene,mperham
31,2012-02-15 19:06:34,"Annnd I now see I completely misunderstood the reason that Sidekiq::Clients.queues exists. @mperham, do you think it's worthwhile to be able to get a list of existing queues from redis? I'd be happy to re-implement that in a way that doesn't conflict with the workers' ability to set a queue for themselves.
",indirect,mperham
19,2012-02-13 06:47:13,"Looks awesome, @jc00ke! 
",ryanlecompte,jc00ke
14,2012-11-01 09:44:20,"I emailed them @mperham. Wonder what they'll say.
",matthewrudy,mperham
14,2013-02-14 19:44:49,"@mperham Did you get any more info from New Relic during your recent visit?  Is the Ruby agent now thread safe, opening up Sidekiq integration as an option?
",petergoldstein,mperham
14,2013-02-14 20:02:51,"It's under active development now, due for release in the next month or two. 

On 14 Feb 2013, at 11:44, Peter Goldstein notifications@github.com wrote:

> @mperham Did you get any more info from New Relic during your recent visit? Is the Ruby agent now thread safe, opening up Sidekiq integration as an option?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
14,2013-03-19 18:58:54,"@benweint I did have custom instrumentation, good to know that won't be needed anymore. Thanks.
",dterror,benweint
14,2013-03-21 13:50:16,"@benweint besides the `include`, we can remove the `add_transaction_tracer :work, :category => :task` as well?
",plentz,benweint
14,2013-03-21 14:54:03,"@plentz Yup, you shouldn't need any additional code in your jobs at all now.
",benweint,plentz
10,2012-02-10 04:35:53,"@mperham yes.
",jingweno,mperham
10,2012-02-10 08:54:36,"@mperham great! I unfortunately don't have an app to run it with just yet. I'm preparing a rewrite of HireFireApp however and I've found good use-cases of where this multi-threaded worker library could be of great use. It currently runs on my ""hand rolled"" thread-scaled processes (which are pure Ruby, hence the `-r` request :)). However, using Redis as a store would allow me to easily distribute work across multiple processes or even servers if necessary with relative ease. Especially with the ability to specify a queue-type as well. A web-ui like that of Resque would be nice, but until now I've gotten along without one. I read that Sidekiq uses the same stats as Resque so it's probably not too much work/too hard to incorporate.

In any case, once I start implementing this in the project, I will see what I come across during the process and provide feedback (if any) on polishing / improvements / features. Hopefully I'll be able to contribute back to Sidekiq in some way!
",mrrooijen,mperham
10,2012-08-12 00:10:11,"@mperham if rails is no longer required with sidekiq, would it be fine to submit a PR removing the rails requirement? Or is it necessary for some other reason?
",josegonzalez,mperham
8,2012-02-12 19:48:28,"@mperham Sure: https://github.com/amarraja/resque-web/wiki/screenshots
",amarraja,mperham
8,2012-02-12 20:01:52,"@mperham What's left for Sidekiq to be 100% compatible with resque-web?
",fbjork,mperham
8,2012-02-12 20:12:09,"@mperham they are coming from Rails. However, these errors only occur when running it through Sidekiq. Do you not get these errors under Rails 3.2.1 (latest) + Ruby 1.9.3p0? Might be something on my OS if not.
",mrrooijen,mperham
8,2012-02-13 00:57:33,"@mperham do I need the following snippet inside an initializer for jobs to be added in the resque namespace?


",fbjork,mperham
6,2012-02-10 09:42:59,"Resque uses something like this:



But, I agree with with @ryanlecompte that using a class method instead of a class variable would allow for more flexibility because you can pass in more options to a method if necessary, like `weight` and you don't have to specify that in the CLI if that's the case.



The `weight` isn't something I'd personally change a lot (or at all). It's something I'd set once. If it were me I'd remove the option to set the `weight` from the command-line and move it in to the `queue` method. The most important thing from the CLI perspective I think is to tell which queues to process, as I think your ""application"" should know the weight of things, and the CLI should only know what to process when you ask it to.
",mrrooijen,ryanlecompte
6,2012-02-10 15:30:04,"Hmm scratch that. Re-thinking the process model I'd say abolish the `weight` concept and just use queue orders which you can set via the CLI as @fbjork said. You can kill 2 birds with 1 stone that way since you tell the process which queues to process, but also in what order.

Then, looking at `max_connections` I'm not sure whether you'd rather want to be able to set it at the class level, or just from the CLI as well since I guess it's a more ""global"" thing, no?
",mrrooijen,fbjork
6,2012-02-10 16:53:07,"@mperham ok, I take back my ordering argument in favor of the weighting. Makes a lot of sense. Can you elaborate on why max_connections makes no sense on the client side?
",fbjork,mperham
6,2012-02-10 16:59:00,"@mperham good point. I somehow forgot the whole point of this library is for allowing high concurrency. When you put it that way (translating weight in to a percentage of the total threads) it makes a lot more sense to go with weights rather than ordering like Resque does, since it's single-threaded. Knowing/Understanding your intention now vs what I had in mind, I actually like `-q foo,10 -q bar,1` more than anything anything else.

So I take it that the weight (percentage) is automatically figured out. So how does this work? Say you set the concurrency level at 100 threads, and you set the weight on `foo` to be 10, and `bar` to be 1. Then I assume we have a thread pool of 100 threads, of which about 90 will process `foo` and 10 will process `bar`. But let's say that `foo` is done processing, but `bar` still has a lot of jobs to process, would `bar` be able to borrow threads from `foo` in order to process jobs faster?

(So basically what I'm asking is whether `bar` can borrow threads from `foo` when `foo` doesn't utilize 100% of it's thread allowance?)

I like your current approach and actually think it should not be changed, it makes perfect sense in a high concurrency worker library.
",mrrooijen,mperham
6,2012-02-10 17:05:07,"If you take a look at cli.rb you'll see that the weighted implementation is essentially just adding N queue references where N is the weight that you specify for your queue. This has the net effect of a weighted queue since the manager will tend to pick items from a queue that has a higher weight than others. 

On Feb 10, 2012, at 8:59 AM, Michael van Rooijenreply@reply.github.com wrote:

> @mperham good point. I somehow forgot the whole point of this library is for allowing high concurrency. When you put it that way (translating weight in to a percentage of the total threads) it makes a lot more sense to go with weights rather than ordering like Resque does, since it's single-threaded. Knowing/Understanding your intention now vs what I had in mind, I actually like `-q foo,10 -q bar,1` more than anything anything else.
> 
> So I take it that the weight (percentage) is automatically figured out. So how does this work? Say you set the concurrency level at 100 threads, and you set the weight on `foo` to be 10, and `bar` to be 1. Then I assume we have a thread pool of 100 threads, of which about 90 will process `foo` and 10 will process `bar`. But let's say that `foo` is done processing, but `bar` still has a lot of jobs to process, would `bar` be able to borrow threads from `foo` in order to process jobs faster?
> 
> (So basically what I'm asking is whether `bar` can borrow threads from `foo` when `foo` doesn't utilize 100% of it's thread allowance?)
> 
> I like your current approach and actually think it should not be changed, it makes perfect sense in a high concurrency worker library.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/mperham/sidekiq/issues/6#issuecomment-3909499
",ryanlecompte,mperham
6,2012-02-10 17:08:32,"@fbjork The client runs in a single threaded process.  There will never be more than one connection.
",mperham,fbjork
6,2012-02-10 17:09:29,"@mperham Ah ok, got it. What about the max_connection option inside the worker class definition?
",fbjork,mperham
6,2012-02-10 23:35:14,"@fbjork There is no max_connection option in the Worker class, that was a hypothetical API design.
",mperham,fbjork
6,2012-02-10 23:35:54,"@mperham I meant the -c CLI command line option right now.
",fbjork,mperham
4,2012-02-11 03:46:33,"Fixed by @ryanlecompte's client side middleware work.
",mperham,ryanlecompte
4,2013-07-31 00:30:30,"Sorry to be a dunce here, but can I confirm (@mperham or @ryanlecompte or anyone else who knows) the fix for how to do this using the middleware would be something like...

In the `call` method of my middleware class, search through the `Sidekiq::Queue` I'm passed looking for a job with a matching payload, and only `yield` if I **don't** find it.

Do I also have to check `Sidekiq::Workers` or will the job still be in `Sidekiq::Queue` even if it's being worked on?
",smathy,ryanlecompte
4,2013-07-31 00:30:30,"Sorry to be a dunce here, but can I confirm (@mperham or @ryanlecompte or anyone else who knows) the fix for how to do this using the middleware would be something like...

In the `call` method of my middleware class, search through the `Sidekiq::Queue` I'm passed looking for a job with a matching payload, and only `yield` if I **don't** find it.

Do I also have to check `Sidekiq::Workers` or will the job still be in `Sidekiq::Queue` even if it's being worked on?
",smathy,mperham
4,2013-07-31 00:59:05,"Jason, you cannot implement unique jobs using the sidekiq API. There's many many race conditions in what you suggest. 

On Jul 30, 2013, at 17:30, Jason King notifications@github.com wrote:

> Sorry to be a dunce here, but can I confirm (@mperham or @ryanlecompte or anyone else who knows) the fix for how to do this using the middleware would be something like...
> 
> In the call method of my middleware class, search through the Sidekiq::Queue I'm passed looking for a job with a matching payload, and only yield if I don't find it.
> 
> Do I also have to check Sidekiq::Workers or will the job still be in Sidekiq::Queue even if it's being worked on?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,ryanlecompte
4,2013-07-31 00:59:05,"Jason, you cannot implement unique jobs using the sidekiq API. There's many many race conditions in what you suggest. 

On Jul 30, 2013, at 17:30, Jason King notifications@github.com wrote:

> Sorry to be a dunce here, but can I confirm (@mperham or @ryanlecompte or anyone else who knows) the fix for how to do this using the middleware would be something like...
> 
> In the call method of my middleware class, search through the Sidekiq::Queue I'm passed looking for a job with a matching payload, and only yield if I don't find it.
> 
> Do I also have to check Sidekiq::Workers or will the job still be in Sidekiq::Queue even if it's being worked on?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
3403,2017-03-22 15:39:48,"@mperham personally, I'd love to see a release for this fixup, I would wager this breaks more than eigilsagafos and our gems dependent on sidekiq but not rails.",eprothro,mperham
3402,2017-03-22 07:45:18,"@mperham Issue #3384 breaks Sidekiq for us. We are not using Rails, but we are using ActionView (5.0.2) which depends on rails-html-sanitizer. Rails HTML sanitizer lives within the Rails namespace (Rails::Html::Sanitizer) so `!Rails.env` crashes with a no method error.",eigilsagafos,mperham
3398,2017-03-21 01:31:30,"Ruby version: 2.3.1
Sidekiq / Pro / Enterprise version(s): Enterprise

@mperham ,

Is there a way for us to open a pull request for sidekiq enterprise? I have an issue where My batch count for pending jobs goes to -1. It always happens around the time of a release so I would assume that there is some sort of race condition where a job completes, decrements the counter right before it is terminated and added back into the queue to be processed when the server restarts. Happy to fix myself but not sure how your handling pull requests on Enterprise. 


    - LMK & Thanks

 ",jondavidchristopher,mperham
3391,2017-03-17 15:20:59,@seuros wdyt?,mperham,seuros
3377,2017-03-09 16:23:15,"Hello @heaven,

When mounting the `Sidekiq::Web` middleware, could you try setting up the Session options manually?

E.G.



See [this page](http://www.rubydoc.info/github/rack/rack/Rack/Session/Cookie) on how to configure it. Do not forget to pass `app` instead of `Sidekiq::Web` to `mount`.

PS: It seems that it's possible to pass the session options with: `Sidekiq::Web.set :sessions, opts`, maintaining your mounting code, @mperham might have more info on this.",badosu,mperham
3326,2017-01-21 17:07:12,"This is a feature request following up on the discussion in issue #3321 .  

When a batch is cancelled using `invalidate_all` and the cancel pattern suggested in the wiki is used, both the success and complete callbacks are fired.  But from the callback code it is currently not possible to determine whether the batch completed normally or if it was cancelled.  This makes clean cancellation impossible.

We'd like to be able to see whether a batch was cancelled from the callbacks.  That would allow the callback method to change behavior based on whether the batch was cancelled or proceeded to completion without cancellation.  

The simplest approach would probably be to introduce a 'cancelled' value for the status with which the callback is invoked.  But alternate approaches (passed values in the options, etc.) could work as well.  @mperham may have ideas here.
",petergoldstein,mperham
3316,2017-01-13 23:21:26,@mperham Have seen this fail in Travis.  Going to sort that out now.,timhaines,mperham
3316,2017-01-13 23:31:44,"@mperham Fixed the Travis issue, ready for review now.  👍 ",timhaines,mperham
3316,2017-01-14 00:19:56,"@mperham have addressed your review comments.  Both great ideas, thanks.",timhaines,mperham
3289,2016-12-22 11:33:24,"We have followed exactly what have you told on (removing size: 1)https://stackoverflow.com/questions/41041194/connection-timed-out-please-suggest-us-regarding-the-configuration but still getting error .

Please suggest should we upgrade redis plan?

#3271 
should we took redistogo update version? currently it is lite

should we took sidekiq pro/premium?

Please advice us @mperham

Many thanks
Rajarshi


Ruby version:
Sidekiq / Pro / Enterprise version(s):

If relevant, please include your initializer and any error message with the full backtrace.
",rajcybage,mperham
3271,2016-12-22 04:44:43,"We have followed exactly what have you told on (removing size: 1)https://stackoverflow.com/questions/41041194/connection-timed-out-please-suggest-us-regarding-the-configuration  but still getting error .

Please suggest should we upgrade redis plan?

should we took redistogo update version? currently it is lite 

Please advice us @mperham 


Many thanks
Rajarshi",rajcybage,mperham
3243,2016-11-18 05:14:21,"Ruby version: 2.3.1
Sidekiq / Pro / Enterprise version(s): Enterprise

We're running Sidekiq in a production environment on a large codebase with tens of contributors. As a result, at times, there are multiple dead jobs in the morgue of various importance. Rarely (but it happens), someone on the team accidentally clicks `Delete all` instead of `Delete` which is *very* dangerous for us. 

Would it be possible to have a configuration option to disable/hide the `Delete All` and `Retry All` buttons from the Morgue Web UI? Because this may not be useful for most users of `Sidekiq`, it would work for us if it were an enterprise only option.

Thanks in advance @mperham, and happy to submit a PR if you're OK with the idea. 
",Chetane,mperham
3221,2016-11-06 09:24:23,"@matthewd / @sj26: do you have any feedback here, or ideas for a less convoluted approach?
",eugeneius,sj26
3199,2016-10-20 18:36:40,"Ruby version:
Sidekiq / Pro / Enterprise version(s): Sidekiq

@mperham Is using `sleep()` okay to use with sidekiq? Or is there something better you would recommend?

My situation is that I send out a number of http requests sequentially from a worker and need to account for some network latency (us-east1 -> china). In order to ensure that requests come in a specific order and have time to complete (a response from http request does not symbol complete, in my case).

So I tested by putting `sleep(0.2)` in between some of the commands and that took care of the issue.

But before I roll with this solution, I want to ensure this is the appropriate mechanism within the sidekiq env.

Thank you!
",dsshap,mperham
3180,2016-10-06 09:33:21,"Upgrading from Sidekiq 4.1 to Sidekiq 4.2 induce regression of #2730 

To refresh your memory - We're using wildard domains in Rails
`Dummy::Application.config.session_store :cookie_store, domain: :all`

after authentication (with Devise), Sidekiq::Web create two cookies:
- _foo @ .localhost.dev
- _foo @ jobs.localhost.dev

Since Sinatra dependency has been removed, the suggested fix in #2730 doesn't work.

I've also suggested a fix in https://github.com/mperham/sidekiq/issues/2555#issuecomment-149594650 which doesn't work too.

@mperham you tried to broach the subject in #3147, but the issue is already closed.

So what's the proper solution today to use authentication ?
I'm still trying to fix it on my side, but advices are welcome :)
",inkstak,mperham
3166,2016-09-28 05:12:32,"The new Rails reloader enables the query cache within every yield and expects to have access to the current connection that it enabled the query cache for at the end of the block to clear the cache and then release the connection. The Sidekiq ActiveRecord middleware which is added automatically releases the connection earlier, the query cache of another connection may instead be cleared, and the dirty query cache might be used by another worker.

This change makes sure that the ActiveRecord middleware cannot be used in tandem with the new Rails reloader (in case folks have added it to their middleware stacks explicitly) and removes it from the default middleware stack when the reloader is in play.

I couldn't figure out a way to raise the error from the middleware during startup. It seems the middleware is instantiated per job and so the raise only happens when a job is run? Not sure if there's a better way.

Fixes the query cache issue in #3157.

/cc @mperham @matthewd
",sj26,mperham
3141,2016-09-16 05:15:27,"Ruby version: **2.3.0**
Sidekiq / Pro / Enterprise version(s): sidekiq-pro (3.0.0)
Full context:



**Problem:** : While doing bundle roughly  20 hrs ago i.e. `2016-09-14 08:25:43.151117 UTC`

> stdout: Could not fetch specs from https://gems.contribsys.com/

**Context**: I am using ansible to pull the latest codebase during autoscaling. And yesterday all of my worker instances were chocking with same error like, it cound't fetch specs from  _gems.crontribsys.com_  

**Was there any issue with server ?** Looks like we faced some server timeouts during that period. Lucky yesterday, no damange in TAT because of it  :see_no_evil: , but  it could be a serious disaster :skull: in days to come.

**cogent evidence**: raw  ansible debug logs: (not sure if its useful) 



I found similar story https://github.com/mperham/sidekiq/issues/1220 
@mperham @kajisaap @sameergautam
",thapakazi,mperham
3133,2016-09-12 22:09:42,"Thanks @mperham!
",connorshea,mperham
3127,2016-09-07 21:53:49,"Yeah, the page should not be cached at all.  @badosu This was reported by someone else too.  Any idea what's wrong?
",mperham,badosu
3079,2016-07-28 16:58:26,"See #3070 

Now that https://github.com/sinatra/rack-protection/pull/111 has been merged in, this should work for users pulling `sinatra` and `rack-protect` from master (e.g. edge Rails folks). It _should_ be backwards compatible, though I've only tested against Rails 4.2 and 5 personally.

@mperham - it seemed like you thought that Sinatra 2 should already be backwards compatible, so let me know if you'd prefer to fight this fight upstream. Also - is adding a method here a reasonable way to allow folks to configure if needed, or would you prefer something else?
",jamesdabbs,mperham
3026,2016-06-21 17:37:28,"We're still on 4.x but I know @jonhyman has some experience with newer mongoid.
",ryansch,jonhyman
3007,2016-06-09 15:38:06,"So I thought @brandonhilkert fixed the breaking change on this a while back, but it may be worth revisiting the discussion in issue #2663  .  The observed behavior sounds similar, and the problem may have been reintroduced.
",petergoldstein,brandonhilkert
2981,2016-05-21 00:46:38,"The ""Queues"" tab in the Sidekiq Dashboard has a ""Delete"" button for each queue. We rarely (actually never) want to delete an entire queue, but we sometimes want to clear all jobs in a queue. I'd like to request that we add a ""Clear"" button to this page, so that we can clear the queue without deleting it entirely.

Currently we do this in a prod console: `Sidekiq::Queue.new(:queue_name).clear`.

I'm happy to submit a PR if you like this idea @mperham .
",jonathan-upstart,mperham
2981,2016-05-21 01:26:45,"I believe delete and clear are semantically identical. 

> On May 20, 2016, at 17:46, jonathan-upstart notifications@github.com wrote:
> 
> The ""Queues"" tab in the Sidekiq Dashboard has a ""Delete"" button for each queue. We rarely (actually never) want to delete an entire queue, but we sometimes want to clear all jobs in a queue. I'd like to request that we add a ""Clear"" button to this page, so that we can clear the queue without deleting it entirely.
> 
> Currently we do this in a prod console: Sidekiq::Queue.new(:queue_name).clear.
> 
> I'm happy to submit a PR if you like this idea @mperham .
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly or view it on GitHub
",mperham,mperham
2912,2016-04-07 16:29:28,"@jonhyman Do you know of any mongoid issues?
",mperham,jonhyman
2902,2016-03-28 04:36:11,"Hi @mperham, I got problem when workers process jobs, the workers get stuck and cannot finish. 
Here is the TTIN output:
[TTIN](https://gist.github.com/ancv1990/4a733d9265bb1f004e27#file-ttin-txt)

And here is log of sidekiq.log:
[https://gist.github.com/ancv1990/c32faaf90601f874535c](https://gist.github.com/ancv1990/c32faaf90601f874535c)

Please help me.
Thanks,
",ancv1990,mperham
2822,2016-02-07 18:49:12,"@mperham done.
",davydovanton,mperham
2809,2016-02-02 21:25:55,"This was in my todo list for long time.  

ping @davydovanton 
",seuros,davydovanton
2777,2016-01-17 18:48:11,"- Fix canonical links on some pages
- Defer script loading to DOMContentLoaded with defer attribute.
- Use 1 CDN (cloudflare) instead of 2
- Glyphicons -> woff2 on cloudflare
- Use https on Google Fonts, allowing HTTP/2 connection

@mperham, you've got a lot of network blocking happening because of all of the PNG files on the homepage. You can only download the browser's maximum connection limit at a time, which I think is usually like 6. The image downloads sometimes also crowd out more important JS requests served from your domain. I suggest you sign up for Cloudflare free and pipe everything through them - that'll serve all of sidekiq.org over HTTP/2, which will allow those images to download in parallel more efficiently.
",nateberkopec,mperham
2757,2016-01-07 21:35:59,"@mperham I guess I answered my own question. It doesn't look like it was that hard.
",jcarlson,mperham
2753,2016-01-06 17:06:10,"Now I think all tests will be pass
/cc @mperham 
",davydovanton,mperham
2716,2015-12-15 00:39:15,"thanks for merge @mperham! :purple_heart: 
",davydovanton,mperham
2682,2015-12-01 15:06:05,"thanks, @seuros !
",davydovanton,seuros
2672,2015-11-19 18:45:03,"Hi @mperham,

The upgrade to 4.0 went smoothly for me and everything has been stable. Thanks! 

However, one thing I noticed is that average execution time went up after the upgrade. Here's a few jobs that get run a lot on Feedbin. 

![performance](https://cloud.githubusercontent.com/assets/133809/11280134/3ad71bea-8ea9-11e5-8cb0-dce4452e959a.png)

The vertical line is when the upgrade happened. The large spikes are from daily database maintenance and backups.

I'd be happy to provide more information or dig into this but if it's an isolated incident then no worries, this isn't negatively impacting anything for me.

Here's the code that measures performance:


",benubois,mperham
2663,2015-11-17 16:29:34,"@sethvargo @brandonhilkert This appears to be due to the queue-based jobs change that was recently introduced.

Specifically, the worker class' `jobs` method used to return a reference to the underlying array of jobs.  That array gets updated when new jobs are added.  Now the `jobs` method returns an array derived from the underlying array at the time the method is called, and this derived array is not updated as jobs are added to the queue.  See below:


",petergoldstein,brandonhilkert
2663,2015-11-17 17:10:09,"@brandonhilkert I'm pretty busy at rubyconf.  Can you fix and/or revert, whatever you're comfortable with?  I'll get a 4.0.1 release out asap with whatever you decide.  I'm ok with killing the feature if it's half-baked.  Likely no one is using it yet.
",mperham,brandonhilkert
2647,2015-11-09 18:12:40,"not sure why the CI build seems to taking a while

@mperham, I memoized the string as requested
",jcavalieri,mperham
2634,2015-10-30 04:04:23,"@mperham 

We were checking the excited upcoming realease. 

We are getting the following error in sidekiq 4.0.0 pre, any ideas?

Timeout::Errorgems/connection_pool-2.2.0/lib/connection_pool/timed_stack.rb:85



@sahin
",muhammet,mperham
2634,2015-10-30 04:07:54,"What is the size of your server connection pool?  Looks like it is too small. 

> On Oct 29, 2015, at 21:04, Muhammet notifications@github.com wrote:
> 
> @mperham
> 
> We were checking the excited upcoming realease.
> 
> We are getting the following error in sidekiq 4.0.0 pre, any ideas?
> 
> Timeout::Errorgems/connection_pool-2.2.0/lib/connection_pool/timed_stack.rb:85
> 
> bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/launcher.rb:115:in `❤': uninitialized constant Sidekiq::Launcher::PROCESSED (NameError)
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/launcher.rb:70:in`heartbeat'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/launcher.rb:137:in `start_heartbeat'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/util.rb:16:in`watchdog'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/util.rb:24:in `block in safe_thread'
> 
> Caused: gems/connection_pool-2.2.0/lib/connection_pool/timed_stack.rb:85:in `block in pop': Waited 1 sec (Timeout::Error)
>     from org/jruby/RubyKernel.java:1292:in`loop'
>     from gems/connection_pool-2.2.0/lib/connection_pool/timed_stack.rb:77:in `block in pop'
>     from org/jruby/ext/thread/Mutex.java:151:in`synchronize'
>     from gems/connection_pool-2.2.0/lib/connection_pool/timed_stack.rb:76:in `pop'
>     from gems/connection_pool-2.2.0/lib/connection_pool.rb:89:in`checkout'
>     from gems/connection_pool-2.2.0/lib/connection_pool.rb:61:in `block in with'
>     from org/jruby/RubyThread.java:659:in`handle_interrupt'
>     from gems/connection_pool-2.2.0/lib/connection_pool.rb:60:in `with'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq.rb:81:in`redis'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/launcher.rb:81:in `❤'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/launcher.rb:70:in`heartbeat'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/launcher.rb:137:in `start_heartbeat'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/util.rb:16:in`watchdog'
>     from bundler/gems/sidekiq-18bc1fc5529e/lib/sidekiq/util.rb:24:in `block in safe_thread'
> @sahin
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2621,2015-10-24 01:52:21,"@mperham ,

We spoke a few weeks ago on one of your free support sessions. I had an issue w/ not having available database connections in the pool. Well we solved it.

The problem ended up being that Pool Size in the rails app database.yml was not being used. :(

If you happen to have questions from folks, that use Amazon OpsWorks, The Rails Apps they offer utilize Chef recipes.

The settings that drive the DB connection and configuration are defined in the OpsWorks infrastructure, 
NOT from the   /app/config/database.yml 

This is where the recipe reads / writes out the config file that will end up on the EC2 instances:

https://github.com/aws/opsworks-cookbooks/blob/release-chef-11.10/rails/templates/default/database.yml.erb#L11

So whoever is dealing with this, needs to set custom JSON inside of OPSWorks.
ex:



![Screen Shot](https://www.evernote.com/l/AJGDAjSTla9MAabqtgPf6kwfR3pFvUOeydQB/image.png)

Hopefully it helps someone.

Cheers & Thanks again,

-Mark
",markalanevans,mperham
2598,2015-10-09 19:03:09,"Together with my colleague @brainopia we continue to search for memory leaks in our application,
as previous issue (https://gist.github.com/gazay/3b518f72266b5a7e88ff) still wasn't the reason of many memory peaks.

And we've found an another leak, this time in Sidekiq itself, and this leak caused a number of problems.

Here is a problem:



Before starting to execute the task, Processor does an async call to Manager (`real_thread` method) to add processor's thread to `@threads` hash in Manager.
After that, if work crashes – `trap_exit` calls `processor_died` method where the thread of processor
should be deleted from hash – so all links to this thread are gone, and it can be cleaned by GC. 
If something goes wrong – for example, the manager needs to execute many calls about 
processor crash – then there will be a race condition, 
and `processor_died` method will be finished before `real_thread`.
Celluloid doesn't allow to execute async calls without order,
but actor crash is a system event, which has the highest priority and goes to very beginning of the queue.
As a result, `@threads` hash now has a dead thread with all the things it holds.

You can reproduce this problem pretty easily with quite severe restrictions (100% of errors on 10-20 workers).
I've reproduced it also on lighter restrictions like 10% of errors and 100 workers, but it is very non-deterministic.

Another important moment is that if task takes a long time to execute enough before failing,
or can be retried (which is a pretty long operation – to put retry info back to Redis) –
most of events will be proceeded in right order.
It can be reproduced by adding magic `sleep 0.126` before raise.

You can reproduce this behavior with my script (https://gist.github.com/gazay/a106917e3adb74a11d50)
or by running `bin/sidekiqload` form this PR with `$TEST_THREADS=true`.

Here is output of my script. I don't start to count threads before finish because
it can hold threads some milliseconds and affect results of the test:

`concurency: 10, errors: 100%, tasks: 10_000, retry: 0`

`sidekiq v3.5.0, celluloid v0.17.2`



`finished tasks: rss (Fibers: alive/total, Threads: alive/total)`

Here is output from `bin/sidekiqload` script, which is executed without latency to redis – 
this is a pretty common case for one-server applications, 
which have their redis on the same server. 

What is going on here – first 500 jobs finished without exception to heat up process. 
Then 2500 jobs raise an exception and after another 1000 tasks we start to track threads count – 
this way we don't affect test results by holding dead threads when we count them.



I understand that the situation when you have 10k failed jobs in one row is not exactly normal, but it still can happen. 
For example, in our application it happened when Facebook API wasn't available 
for couple hours couple times in last month. 
Our application runs hundreds of thousands of jobs using Facebook API,
and those are not so important jobs, as they just collect data every n-minutes.
We've rescued API-specific problems in those jobs, but we haven't rescued Network errors.
As result we had couple of OOM server restarts.

This PR fixes this problem
",gazay,brainopia
2596,2015-10-09 12:57:43,"@mperham Is it possible that sidekiq on two cpu core processor may not process job, I am asking it because i am getting this error on one of my cpu processor `Processor: ip-172-30-43-16:19323, NameError: uninitialized constant AppSidekiqJob.` But I didn't find any error in failures tab for my other processor which i think is my main processor. ie.   `Processor: ip-172-31-62-180:19323` because I get this IP on ssh to my server. Is it related to multiple cpu core or ruby mri. My sidekiq.yml file contain



Is there any thing wrong with my sidekiq.yml or is it something related to which I don't know. My jobs file are inside `app/jobs` folder. 
",brahamshakti,mperham
2595,2015-10-09 08:14:19,"@mperham Would you consider giving a view into jobs pending in private queues on the WebUI? We recently ran into a problem where a task from over 3 months ago re-ran when it shouldn't have (we've fixed it's idempotency since). We're on AWS and 3 months ago when that process was killed, it remained in the private queue for that hostname (and queue name and index) in redis. The server was shutdown then and decommissioned. A few days back, Opsworks created another server with the same hostname and that task ""reliably"" got pulled into this server and started executing.

I had misunderstood earlier that private queue tasks would be executed on the next available process but having peeked into the code, I learnt that tasks are ONLY re-run if the machine's hostname remains the same. (_So reliable execution of a job can be somewhat shrouded if while running a job, the server is shutdown and a server with the same hostname is not restarted._)

If we had a view into jobs in internal queues, we would be able to make informed decisions. What's your opinion on this? Happy to invest on a pull request, if I know your views.

/cc @justanshulsharma @gaurish
",asanghi,mperham
2587,2015-10-06 19:48:19,"@mperham any solution? why did you close it? 
",pepibumur,mperham
2583,2015-10-02 17:46:26,"I suggest we yank @jdantonio in here to explain why concurrent-ruby is awesome :green_heart: 
",searls,jdantonio
2560,2015-09-18 19:24:34,"I was continuing to get a 403 Forbidden in Production with sidekiq version 3.5.0, but I was unable to reproduce the problem locally with the my app nor the sidekiq sample rails app.  All signs pointed to SSL/https. Luckily I found this blog post: [Rack-protection and Nginx](http://www.sourcediver.org/blog/2015/07/01/rack-protection-and-nginx/) by @mguentner.

After adding `proxy_set_header X-Forwarded-Proto $scheme;` to my nginx configuration. :boom:!! It worked!

@mperham Perhaps you should add a link in the Wiki that points to the blog post or the nginx config for those that use nginx and https

Many thanks to @mguentner
",codebender,mperham
2548,2015-09-10 21:50:09,"Batches are a current scalability limit to Sidekiq Pro because they can't be spread across shards like jobs can.  Allow the user to define a set of shards and have batches allocate randomly across the shard set.  The BID can store the shard for retrieval.

@jonhyman has already provided a working prototype which I've refactored.  Needs more testing.
",mperham,jonhyman
2517,2015-08-29 20:33:23,"I think that this is cosmetic changes :grin:
@mperham what do you think?
",davydovanton,mperham
2503,2015-08-21 12:02:06,"As a gem : :+1: . I don't think @mperham wants to add such feature to sidekiq core.

PS: I have something like that. we can work on OSS it.
",seuros,mperham
2503,2015-08-25 09:30:15,"@mperham and what do you think?
",davydovanton,mperham
2495,2015-08-15 17:24:04,":+1:
@mperham what do you think? Can I merge this changes?
",davydovanton,mperham
2491,2015-08-14 15:36:08,"@mperham I just updated to sidekiq-pro to version 3.4.2. Attempting to start sidekiq results in an error 


",bartimaeus,mperham
2491,2015-10-30 18:00:55,"How did you resolve this @mperham 
",onlyyouandty,mperham
2485,2015-08-12 17:42:09,"@mperham was about to do another PR and then realized that that would not work ... this is still a good change I guess ... do you want it ?
",grosser,mperham
2484,2015-08-12 17:19:25,"cocurrency 0 makes the manager just sit there and do nothing,
which is hard to debug / understand without knowing what to look for

we were passing concurrency via an ENV variable, so it was not obvious that this was the problem,
looked into queues / redis trouble first before realizing this ... since I think there is no valid usecase for 0 / negative concurrency, this would be a nice fix to prevent this in the future ...

@mperham 
@melvinram
",grosser,mperham
2474,2015-08-05 17:22:54,"I know that @jonhyman runs batches with hundreds of thousands or even millions of jobs in them.  He tracked down a number of job loss bugs years ago but l know of no job loss issues in the last year.  What 3rd party sidekiq extension gems are you running?  for instance, unique jobs can cause jobs to be registered with the batch but then never actually pushed to redis.
",mperham,jonhyman
2473,2015-08-16 12:03:40,"@mperham Is this missing anything else? 
",pik,mperham
2461,2015-07-28 20:07:51,"[Example Repository](https://github.com/hbrysiewicz/padrino-sidekiq-example/tree/master)

When trying to mount Sidekiq application within Padrino, `Rack::Protection::AuthenticityToken Error` is produced. See example repository for bare bones demonstration. The exact same project works when Sidekiq is explicitly set to 3.4.1. 

Much thanks to the Padrino team and also @jc00ke on the Sidekiq team for the great communication up until now.
",hbrysiewicz,jc00ke
2455,2015-08-13 18:32:17,"@mperham you good on this?
",jonhyman,mperham
2402,2015-06-22 11:01:56,"so, @mperham, what do you think, we need to fix it or not?
",davydovanton,mperham
2396,2015-06-20 10:38:36,"@mperham we should remove example with AR from wiki page
",davydovanton,mperham
2387,2015-06-16 01:45:34,"@mperham 

We started to get this issue a lot. Sidekiq is retrying and we dont see any error at the end of the day but we see these in our bugsnags/honeybadger. 

We are in latest version sidekiq  and rails 4.2.0

Is it a memory issue?

NameError gems/activesupport-4.2.0/lib/active_support/inflector/methods.rb:261


",sahin,mperham
2331,2015-05-05 15:36:53,"@davydovanton ?
",mperham,davydovanton
2301,2015-04-16 20:14:27,"@mperham It looks like you bumped pro 2.0.2 but never tagged or released.  I'm looking to upgrade to pro 2.x with the new 2.2.0 connection_pool stuff.
",ryansch,mperham
2301,2015-04-16 20:17:05,"2.0.2 has not been released. You can just bump connection pool's version to pick up the fix. 

> On Apr 16, 2015, at 16:14, Ryan Schlesinger notifications@github.com wrote:
> 
> @mperham It looks like you bumped pro 2.0.2 but never tagged or released. I'm looking to upgrade to pro 2.x with the new 2.2.0 connection_pool stuff.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2293,2015-04-09 22:41:54,"@mperham, @seuros I completed this PR, what do you think? 
",davydovanton,seuros
2293,2015-04-09 22:41:54,"@mperham, @seuros I completed this PR, what do you think? 
",davydovanton,mperham
2288,2015-04-05 16:06:09,"@mperham @jonhyman fixed all, thanks for catch :thumbsup:
",davydovanton,mperham
2288,2015-04-05 16:06:09,"@mperham @jonhyman fixed all, thanks for catch :thumbsup:
",davydovanton,jonhyman
2257,2015-03-24 21:08:58,"@mperham thanks!
",davydovanton,mperham
2255,2015-03-24 17:42:56,"/cc @mperham 

I'm running into an issue where if I have `Sidekiq::Testing.inline!` turned on, it will run jobs that are scheduled to run hours in the future.

This really blows up my integration tests, as certain future-scheduled jobs are meant to run as expirys, etc, and I don't want those to prematurely run expiration code in the lifecycle of the test.

If we can't modify `Sidekiq::Testing.inline!` due to compatibility reasons, I'd love to be able to turn off `inline!` for jobs made with `perform_at`.

Thoughts?
",dbalatero,mperham
2248,2015-03-24 00:33:40,"@mperham Thanks!
",mcfiredrill,mperham
2196,2015-02-19 05:17:38,"![sidekiq](https://cloud.githubusercontent.com/assets/2508980/6262185/11c85098-b7b3-11e4-96f9-688936655ce2.png)

@mperham , I start to see this scene a lot. There is [0 of X] but there is high CPU usage and in UI there is no worker. The workers are not stuck either meaning they are accepting new jobs if come. 

We have around 20 small worker apps distributed in multiple server. 

We are in ruby 2.2.0, latest version of sidekiq 

Any ideas how can we find the high CPU usage?
",sahin,mperham
2192,2015-02-18 05:44:54,"Hello, @mperham.
I would like to have an access to the repo 😋
1. admin@hipflat.com
2. I assign all rights, including copyright, to any future Sidekiq Pro work by myself to Mike Perham
",mkaschenko,mperham
2186,2015-02-11 16:44:36,"That's a good point, we deprecated `delay` with 4.2 but it doesn't offer full backwards compat.

@seuros It seems like we need to ""undeprecate"" the ActionMailer delay.  WDYT?
",mperham,seuros
2145,2015-01-22 14:55:51,"The motivation came from this issue: https://github.com/mperham/sidekiq/issues/1886

Our problem is that we'd have to search our quite large set of scheduled jobs and then additionally delete some and we do this often.  You might want to wait for @mperham for some guidance on which parts of this algorithm are inefficient.
",ryansch,mperham
2132,2015-01-11 16:56:50,"Hi @mperham !

Thanks again for sidekiq. It's such an amazing tool.

I'm having a strange issue, and it's probably not a sidekiq problem, but I thought I'll double-check.

We're in the process of upgrading to Ruby 2.2, so I've set-up a new staging server and we've been running it for a couple of days. One odd thing that I noticed is that _occasionally_ we're seeing these kinds of errors in our sidekiq log:

`2015-01-11T16:02:16.656Z 11444 TID-42mh0 ERROR: Error fetching message: Connection timed out`

followed by [this trace](https://gist.github.com/gingerlime/6561cc9b41eb55c50e9c), and then

`2015-01-11T16:02:18.881Z 11444 TID-42mh0 INFO: Redis is online, 2.223784923553467 sec downtime`

So it does look like an issue with our redis, but I see absolutely nothing in the redis logs, and the server stats also look pretty clean. CPU / IO seems idle. No other errors or anything that might suggest a problem.
#2003 mentioned a similar error, as well as one comment about seeing issues after upgrading ruby. However, in our case, sidekiq does not seem to be stuck.

Our redis is running on localhost, so I don't suspect any networking issues. It could be a platform / VPS issue, so I'm already in the process of setting up another VPS and trying to see if it produces similar errors. I just thought I'd post this here, in case someone else bumped into this or something similar and maybe we can ""compare notes"".

p.s. we're running redis 2.8.17 and sidekiq 3.3.0 / celluloid 0.16 on Ubuntu 14.04 64 bit
",gingerlime,mperham
2132,2015-01-11 19:42:53,"Make sure you aren't swapping. Use Redis's latency monitoring tools and slow log to see if there are any shenanigans going on. 

> On Jan 11, 2015, at 08:56, gingerlime notifications@github.com wrote:
> 
> Hi @mperham !
> 
> Thanks again for sidekiq. It's such an amazing tool.
> 
> I'm having a strange issue, and it's probably not a sidekiq problem, but I thought I'll double-check.
> 
> We're in the process of upgrading to Ruby 2.2, so I've set-up a new staging server and we've been running it for a couple of days. One odd thing that I noticed is that occasionally we're seeing these kinds of errors in our sidekiq log:
> 
> 2015-01-11T16:02:16.656Z 11444 TID-42mh0 ERROR: Error fetching message: Connection timed out
> 
> followed by this trace, and then
> 
> 2015-01-11T16:02:18.881Z 11444 TID-42mh0 INFO: Redis is online, 2.223784923553467 sec downtime
> 
> So it does look like an issue with our redis, but I see absolutely nothing in the redis logs, and the server stats also look pretty clean. CPU / IO seems idle. No other errors or anything that might suggest a problem.
> 
> #2003 mentioned a similar error, as well as one comment about seeing issues after upgrading ruby. However, in our case, sidekiq does not seem to be stuck.
> 
> Our redis is running on localhost, so I don't suspect any networking issues. It could be a platform / VPS issue, so I'm already in the process of setting up another VPS and trying to see if it produces similar errors. I just thought I'd post this here, in case someone else bumped into this or something similar and maybe we can ""compare notes"".
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2120,2015-01-07 12:20:57,"Hello, @mperham. Thank you for the gem!

I face strange behavior of Sidekiq Pro's Reliability feature [1].

I have TestWorker [2]. Also I use 'weighted random' fetch algorithm [3].
I run sidekiq the same way as in [3] and push the worker (TestWorker.perform_async).
I kill the sidekiq process (kill -9 pid).
I run sidekiq again.

And now 2 TestWorkers run instead of 1.
If I change the weight `sidekiq ... -q default,2 ...` to `sidekiq ... -q default,5 ...`, then 5 TestWorkers run and so on.

What do you think about it?

[1] https://github.com/mperham/sidekiq/wiki/Reliability
[2] https://gist.github.com/mkaschenko/24da18c795962da3c970
[3] https://github.com/mperham/sidekiq/wiki/Reliability#weighted-random-algorithm
",mkaschenko,mperham
2112,2014-12-30 20:58:35,"@mperham 
replace useless color noise with actual information :)

![screen shot 2014-12-30 at 12 57 54 pm](https://cloud.githubusercontent.com/assets/11367/5582778/89535ebc-9023-11e4-9557-c10d37dac583.png)
![screen shot 2014-12-30 at 12 57 34 pm](https://cloud.githubusercontent.com/assets/11367/5582779/8ad403ea-9023-11e4-92f0-eed63d5a9983.png)
",grosser,mperham
2111,2014-12-30 20:56:21,"@mperham 
",grosser,mperham
2110,2014-12-30 20:52:12,"@mperham fixes https://github.com/mperham/sidekiq/issues/2109
",grosser,mperham
2109,2014-12-30 19:18:30,"looking at the code it should work, but somehow it does not :/

https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/middleware/server/logging.rb#L7-L17

any ideas @mperham ?


",grosser,mperham
2109,2014-12-30 19:36:25,"I'd guess there's some code monkeying with the logger. 

> On Dec 30, 2014, at 11:18, Michael Grosser notifications@github.com wrote:
> 
> looking at the code it should work, but somehow it does not :/
> 
> https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/middleware/server/logging.rb#L7-L17
> 
> any ideas @mperham ?
> 
> 13176 TID-otszewf94 FooWorker JID-aca9134a8afe7d0a19344805 INFO: start
> ....
> 13176 TID-otszewf94 INFO: done: 1.5 sec
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
2107,2014-12-30 02:17:09,"Hi,

Sorry if the description below is too long!, but the **TL;DR** is basically the title and what follows is my adventure in Debugging Land.

I'm opening this issue to **a)** ask if this is a known problem and **b)** understand the underlying reason so it won't bite me in the future.

<hr>

I've been tracking down a memory leak in a Sidekiq process. I started debugging my original Rails application, then reduced it to a smaller, minimal Rails app, then to an even simpler Sinatra app and, finally, thanks to the example by @grosser in #1353, to just one file and a few lines of code:

https://gist.github.com/deborasetton/713229c641ba13c6b1b0#file-leak-rb

The results:
- When running this script with 5000 jobs and LEAK=0, the memory usage peaks at **~34MB**;
- When running the same 5000 jobs with LEAK=1, the memory usage goes beyond **250MB**!

After some time debugging both Sidekiq and Celluloid to find the difference in the code path for these two cases, it looks like [this line](https://github.com/celluloid/celluloid/blob/master/lib/celluloid/actor.rb#L167) from Celluloid, if removed, would solve the problem:



When I remove it and re-run the test script, it seems to work, but I can't explain **why** this fixes my problem. I know very little about Sidekiq and Celluloid internals, so I couldn't find out where this `raise` gets `rescued` (even when stepping into the code with byebug/debugger), or even if it happens within Sidekiq or Celluloid, because, at this point, it seems the code keeps bouncing between the two and a lot of Actors and stuff... So I'm kind of stuck at my investigation.

Has anyone ever come accross this issue before? If not, I would still appreciate any pointers on where to look next!

<hr>

Extra information:
- I've now learned the hard way that I should be raising something else instead of `Exception`, but I'm still curious to understand why this has such different consequences in this case.
- I've tested this code with Ruby 2.0.0, 2.1.4 and 2.2.0, and with Sidekiq 3.2.6 and 3.3.0, all with similar results.
- If the aforementioned Celluloid line is removed, Celluloid specs still pass, so I wasn't able to find a spec or explanation for why it exists, but it's been there since commit [2394d7](https://github.com/celluloid/celluloid/commit/2394d7).
- I got to this line in Celluloid after following @krasnoukhov's [blog post on profiling Sidekiq](http://blog.krasnoukhov.com/posts/2013/01/07/profiling-memory-leaky-sidekiq-applications-with-ruby-2.1.html), so props to it!
- The leaked memory is not released after the jobs are done, but it seems this is normal behavior.

If you got here, thanks so much for your patience! Can you help me? :)
",deborasetton,krasnoukhov
2107,2014-12-30 02:17:09,"Hi,

Sorry if the description below is too long!, but the **TL;DR** is basically the title and what follows is my adventure in Debugging Land.

I'm opening this issue to **a)** ask if this is a known problem and **b)** understand the underlying reason so it won't bite me in the future.

<hr>

I've been tracking down a memory leak in a Sidekiq process. I started debugging my original Rails application, then reduced it to a smaller, minimal Rails app, then to an even simpler Sinatra app and, finally, thanks to the example by @grosser in #1353, to just one file and a few lines of code:

https://gist.github.com/deborasetton/713229c641ba13c6b1b0#file-leak-rb

The results:
- When running this script with 5000 jobs and LEAK=0, the memory usage peaks at **~34MB**;
- When running the same 5000 jobs with LEAK=1, the memory usage goes beyond **250MB**!

After some time debugging both Sidekiq and Celluloid to find the difference in the code path for these two cases, it looks like [this line](https://github.com/celluloid/celluloid/blob/master/lib/celluloid/actor.rb#L167) from Celluloid, if removed, would solve the problem:



When I remove it and re-run the test script, it seems to work, but I can't explain **why** this fixes my problem. I know very little about Sidekiq and Celluloid internals, so I couldn't find out where this `raise` gets `rescued` (even when stepping into the code with byebug/debugger), or even if it happens within Sidekiq or Celluloid, because, at this point, it seems the code keeps bouncing between the two and a lot of Actors and stuff... So I'm kind of stuck at my investigation.

Has anyone ever come accross this issue before? If not, I would still appreciate any pointers on where to look next!

<hr>

Extra information:
- I've now learned the hard way that I should be raising something else instead of `Exception`, but I'm still curious to understand why this has such different consequences in this case.
- I've tested this code with Ruby 2.0.0, 2.1.4 and 2.2.0, and with Sidekiq 3.2.6 and 3.3.0, all with similar results.
- If the aforementioned Celluloid line is removed, Celluloid specs still pass, so I wasn't able to find a spec or explanation for why it exists, but it's been there since commit [2394d7](https://github.com/celluloid/celluloid/commit/2394d7).
- I got to this line in Celluloid after following @krasnoukhov's [blog post on profiling Sidekiq](http://blog.krasnoukhov.com/posts/2013/01/07/profiling-memory-leaky-sidekiq-applications-with-ruby-2.1.html), so props to it!
- The leaked memory is not released after the jobs are done, but it seems this is normal behavior.

If you got here, thanks so much for your patience! Can you help me? :)
",deborasetton,grosser
2102,2014-12-26 17:33:21,"A while back I submitted [a PR](https://github.com/mperham/sidekiq/pull/1938) that exposed a way to customize how a job was executed, in so much as how perform was actually called on the worker. I duplicated that in the sidekiq/testing, and have since determined that was a mistake and am rectifying that here.

In doing what I talk about in that original PR, I realized there was still some finagling to get it to behave correctly for the specs, and then I realized that it wasn't very unified and didn't push through to the actual functionality that I wanted to make sure was working -- after some back and forth (captured on https://github.com/mperham/sidekiq/pull/2097) @mperham decided he'd rather remove it.

Also cleans up the drain method in the test harness.
",jejacks0n,mperham
2102,2014-12-26 17:37:30,"/cc @aprescott
",jejacks0n,aprescott
2097,2014-12-24 06:53:19,"A while back I submitted [a PR](https://github.com/mperham/sidekiq/pull/1938) that exposed a way to customize how a job was executed, in so much as how perform was actually called on the worker. I duplicated that in the sidekiq/testing, and have since determined that was a mistake and am rectifying that here.

In doing what I talk about in that original PR, I realized there was still some finagling to get it to behave correctly for the specs, and then I realized that it wasn't very unified and didn't push through to the actual functionality that I wanted to make sure was working -- after some back and forth (captured on this PR) @mperham decided he'd rather remove it.

Also cleans up the drain method in the test harness.
",jejacks0n,mperham
2097,2014-12-24 21:13:47,"@mperham if you aren't digging this, that's fair. If that's the case I'd prefer to pull it out and just call `worker.perform` like both places used to. I'm happy to modify this to clean it up, but I don't want to leave it stand as the original PR I submitted because it doesn't work cleanly in terms of those objectives and is probably just a degradation of code quality.
",jejacks0n,mperham
2097,2014-12-24 23:47:15,"@aprescott it can be useful and clean though, and so that was my first attempt with this PR. @mperham had some valid feedback, so the only alternative I saw at a fix (current draft of this PR) is to extract it out to a higher level so it can be shared cleanly -- I'm unsure about how he'll feel about this though.

As a last resort I offer to remove it and still provide some of the cleanup around the `drain` method.
",jejacks0n,mperham
2073,2014-12-04 18:52:00,"Sidekiq uses Celluloid's TaskFiber by default.  MRI was recently discovered to have a Fiber bug which could lead to uncommitted transactions, open locks and other really odd behavior.  I'm unclear how to reproduce the problem but we should check TaskThread again to see if it's a stable replacement.

https://bugs.ruby-lang.org/issues/10540

/cc @halorgium
",mperham,halorgium
2030,2014-10-29 08:31:48,"cc @mperham  .
Strange, i though the Wiki is editable by everybody.
",seuros,mperham
2019,2014-10-21 14:47:53,"As @seuros commented in #2016, I added a test for generator.
Thank you!
",dlackty,seuros
2016,2014-10-21 10:10:12,"@rselk , could you take a stab for the generator tests ?
",seuros,rselk
2012,2014-10-24 16:02:27,"e.g. http://www.subelsky.com/2014/05/fixing-socketerror-getaddrinfo-name-or.html @subelsky is a big Sidekiq user and if he says it's ok to use, I'd believe him.
",mperham,subelsky
2002,2014-10-14 08:42:23,"This pull-request implements numeric priorities inside queues.

Priority is either defined by an `Integer` or a `Proc` that takes the `#perform` method arguments as its own arguments, and it's defined on the `sidekiq_options` call. An example would be:



Lower priority value items are picked up first. Same priority value items work on a FIFO basis.

I've made sure the fetches are atomic, the tests pass, but the only couple things I'm not sure are:
- Latency (because the last item in the list might not be the last one inserted.)
- Migration path (current queues will have the wrong data type in Redis)

@mperham could do with some feedback regarding these points (and the whole PR in general.)
",andremedeiros,mperham
1999,2014-10-11 14:50:26,"Hi @mperham I have a question is it possible to get the job id inside of a worker? 

Currently I can get the job id using 



but what I want is to get the job id inside of the worker like this: 


",ChunAllen,mperham
1999,2014-10-11 15:13:14,"jid 

That's it. 'self.jid'

> On Oct 11, 2014, at 07:50, Allen Chun notifications@github.com wrote:
> 
> Hi @mperham I have a question is it possible to get the job id inside of a worker?
> 
> Currently I can get the job id using
> 
> job_id = MyWorker.perform_async(""test"")
> but what I want is to get the job id inside of the worker like this:
> 
> class MyWorker
> 
>    def perform(name)
>         //get current job id here
>     end
> 
> end
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1993,2014-10-08 03:27:36,"@mperham -- I've been encountering an issue since upgrading from 3.2.1 to 3.2.5 where the busy queue just stops processing randomly... with items remaining in the busy queue.  Similiar to #1963 

The problem seems to occur when i spin up rake tasks to send jobs to sidekiq.  There are no errors in the logs around the time of first stalled job.  When trying to view the UI for the first time after jobs have staled the UI times out for the first few times before loading.  The jobs still are stuck in the busy queue until a restart.

I'm running on Heroku.
- sidekiq 3.2.5
- celluloid 0.15.2
- sidekiq-pro 1.8.0
- timers 1.1.0

Is this still a reported issue?  It's happening several times a day
",anazar,mperham
1993,2014-10-08 03:48:37,"I'll review the recent changes tomorrow and see if I can determine what could cause that.

> On Oct 7, 2014, at 20:27, Adam notifications@github.com wrote:
> 
> @mperham -- I've been encountering an issue since upgrading from 3.2.1 to 3.2.5 where the busy queue just stops processing randomly... with items remaining in the busy queue. Similiar to #1963
> 
> The problem seems to occur when i spin up rake tasks to send jobs to sidekiq. There are no errors in the logs around the time of first stalled job. When trying to view the UI for the first time after jobs have staled the UI times out for the first few times before loading. The jobs still are stuck in the busy queue until a restart.
> 
> I'm running on Heroku.
> 
> sidekiq 3.2.5
> celluloid 0.15.2
> sidekiq-pro 1.8.0
> timers 1.1.0
> Is this still a reported issue? It's happening several times a day
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1984,2014-10-04 22:19:47,"Look good to me after the typo fix and a commit squash. 
cc @mperham 
",seuros,mperham
1979,2014-10-02 16:47:27,"@mperham any idea ?
",seuros,mperham
1972,2014-09-29 15:54:01,"@rselk do you want to do this task ?
",seuros,rselk
1965,2014-09-22 15:55:27,"@aprescott good point. Reliable fetch doesn't respect the `retries` configuration option and #1493 does appear to touch on this, assuming that the ""easy win"" @mperham talks about isn't the final solution for #1493. I'll close out as a duplicate and watch that issue.
",jonhyman,mperham
1951,2014-09-16 18:16:50,"ping @mperham 
",seuros,mperham
1933,2014-09-09 11:59:33,"Now that ActionMailer has such extension i don't see why we should duplicate work, just use AM's `#deliver_later`.

@mperham likes to keep Sidekiq code base simple, adding conditions for versions checks will just be bad.
",seuros,mperham
1929,2014-09-07 03:11:41,"@mperham we are using sidekiq all the time... few dozens deploy every day to worker servers, 1M jobs daily.

We just start to have problem. in our cap, we are stopping the workers just before the deploy. and restart them, it is working like that for a long time with no problem.

I just updated 3.2.3 and it started to stuck stopping as follows. How do u think we can debug this?

deployer@worker03:~$ ps aux | grep '[s]idekiq'
deployer  8316 49.6 31.0 2012920 1095936 ?     Sl   02:55   6:44 sidekiq 3.2.3 workers_app [0 of 60 busy] stopping
",sahin,mperham
1929,2014-09-07 03:36:42,"If you are using capistrano-sidekiq, I'd ask this question there.

On Sat, Sep 6, 2014 at 8:11 PM, sahin notifications@github.com wrote:

> @mperham https://github.com/mperham we are using sidekiq all the
> time... few dozens deploy every day, 1M jobs.
> 
> We just start to have problem. in our cap, we are stopping the workers
> just before the deploy. and restart them, it is working like that for a
> long time with no problem.
> 
> I just updated 3.2.3 and it started to stuck stopping as follows. How do u
> think we can debug this?
> 
> deployer@worker03:~$ ps aux | grep '[s]idekiq'
> deployer 8316 49.6 31.0 2012920 1095936 ? Sl 02:55 6:44 sidekiq 3.2.3
> workers_app [0 of 60 busy] stopping
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/mperham/sidekiq/issues/1929.
",mperham,mperham
1919,2014-08-31 21:02:24,"One long-standing issue with Sidekiq Pro is the non-atomic nature of Batch definition.  Two scenarios:
1.  You try to define a batch with 10 jobs but the network dies after the fifth job.
2. You try to define a batch with 10 jobs but job creation is so slow that the other Sidekiqs ""complete"" the batch before all 10 are defined, the [well-known race condition](https://github.com/mperham/sidekiq/wiki/Batches#race-condition).

I've fixed these scenarios in Sidekiq Pro on the `atomic_batch` branch.  Anyone who uses Batches and has source access is welcome to try out the fix. The fix is simple from the API user's POV, use `define` instead of `jobs`:



Let me know what you think.  /cc @jonhyman @ryansch 
",mperham,ryansch
1919,2014-08-31 21:02:24,"One long-standing issue with Sidekiq Pro is the non-atomic nature of Batch definition.  Two scenarios:
1.  You try to define a batch with 10 jobs but the network dies after the fifth job.
2. You try to define a batch with 10 jobs but job creation is so slow that the other Sidekiqs ""complete"" the batch before all 10 are defined, the [well-known race condition](https://github.com/mperham/sidekiq/wiki/Batches#race-condition).

I've fixed these scenarios in Sidekiq Pro on the `atomic_batch` branch.  Anyone who uses Batches and has source access is welcome to try out the fix. The fix is simple from the API user's POV, use `define` instead of `jobs`:



Let me know what you think.  /cc @jonhyman @ryansch 
",mperham,jonhyman
1914,2014-08-27 20:21:00,"@mperham , We have around 10 workers servers + 50 queues, processing a lot of jobs. 

I would love to see/make some improvements for WEBUI in free or paid..

1) Better Tables with filtering
   maybe with http://www.datatables.net/
2) Better Live Pool ( Better partial updates)
3) Better Filtering/Cleaner for Dead
4) Job History

I can totally do them in a different git repo as an extension sidekiq-webui or in free sidekiq or premium but I would like your feedback first. 
",sahin,mperham
1909,2014-08-22 15:42:59,"@mperham

Let me know if i should continue . 
",seuros,mperham
1898,2014-08-13 12:43:50,"Thanks you.

@mperham 
Related : should we skip /test/test_manager.rb:142 in jruby ? it failing from time to time : https://travis-ci.org/mperham/sidekiq/jobs/32375718
",seuros,mperham
1892,2014-08-12 17:54:11,"@mperham Like myself, I believe many people are going to this page. 
https://github.com/mperham/sidekiq/wiki/Related-Projects

I already updated to alphabetical order. I would love to do few more improvements.

Sidekiq has very high quality but when you add bad extensions, it totally ruins the experience. I personally lose a lot time when I installed an extension, which damaged the sidekiq and lost a lot time.

I would like to divide the list into 3 parts if it is ok with you.
1) Support 3.0
2) Support 2.0
3) Older versions

and maybe add few rules, like each gem in the list should at least %90 test coverage, code climate etc etc. 
",sahin,mperham
1889,2014-08-10 17:40:42,"In my opinion this feature should be added as external gem.

cc / @mperham 
",seuros,mperham
1867,2014-07-28 22:00:53,"Is ""Kill"" the right word?  @subelsky does that button label make sense?  I'm worried that users will confuse ""Delete"" and ""Kill"".
",mperham,subelsky
1866,2014-07-28 13:51:46,"hey @mperham what do you think about a button in the Retries UI that moves jobs into the morgue? Sometimes we get exceptions where I'm working on a fix, and I'd like the job to stop retrying while I fix (maybe because it uses up resources) -- but I'd still like to keep the job around and retry it later. It would be cool to save the dead job in the morgue, then ""resurrect"" it when I'm ready to try again.
",subelsky,mperham
1857,2014-07-22 03:39:34,"@mperham we love sidekiq a lot, sorry to report any bugs :)

We are in 2.1.1. and using 3.2.1 master branch. 

This happends when we enter retries tab , or some when I click dead, 

I amnot sure but I think where there is a job with some parameters, and anytime WEBUI try to list it, it shows the following error.


",sahin,mperham
1855,2014-07-21 09:03:20,"I see your use case it valid but very rare. 
But as @mperham said `Sidekiq's mantra is ""simple, efficient"". Simplicity is achieved not by adding features but by explicitly not adding them where possible. Sometimes that means we don't handle rare edge cases perfectly.`
Adding multitenancy is a nightmare in maintaining that feature. Sidekiq workers listen to one namespace and configured queues only. If you add a new namespace , you will have to spawn new processes to listen to that namespace.

Adding such feature will need a big API change/rewrite and the rewrite to the webinterface/javascript.
",seuros,mperham
1843,2014-07-12 02:31:30,"@mperham This is a sketch of the change I'm considering.  I'd like your opinion on the problem and this solution before I write up the test and perhaps factor out the error message modification to a private method.
",mikegee,mperham
1842,2014-07-17 12:16:02,"cc @mperham .
",seuros,mperham
1839,2014-07-10 14:03:53,"@mperham what do you think about removing some old branches from the repo  (rails4, eager_load ..)?
",seuros,mperham
1838,2014-07-10 13:55:38,"@mperham, Let me know if i need to reformulate the error message.
",seuros,mperham
1838,2014-07-21 09:12:52,"@mperham, It ok if i merge this pr ? It will remove 1.9.3 from travis.yml
",seuros,mperham
1838,2014-07-21 12:50:15,"You should check explicitly for MRI, not Java. 

> On Jul 21, 2014, at 2:12, Abdelkader Boudih notifications@github.com wrote:
> 
> @mperham, It ok if i merge this pr ? It will remove 1.9.3 from travis.yml
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1837,2014-07-10 13:01:12,"@mperham jruby is detected as 1.9 or 2.0+ ? The tests passed but just to be sure.
",seuros,mperham
1828,2014-07-05 11:02:11,"ping @mperham
",seuros,mperham
1815,2014-06-30 16:14:40,"ref #1810
ping @mperham , text is missing.
",seuros,mperham
1814,2014-06-30 09:44:47,"/ping @mperham
",seuros,mperham
1812,2014-06-30 01:32:39,"ping @mperham 
",seuros,mperham
1800,2014-06-24 23:05:26,"/cc @brandonhilkert 
",mperham,brandonhilkert
1795,2014-06-23 16:11:08,"@mperham  done!
",lyfeyaj,mperham
1782,2014-06-16 17:17:40,"@tdantas That doesn't make a difference. What @aprescott says is correct. 
",etagwerker,tdantas
1770,2014-06-10 20:33:09,"Ah, thanks, that's key to understanding.  I suspect @aprescott broke it in a323e2fb3ce.
",mperham,aprescott
1735,2014-05-26 13:50:30,"thanks @mperham. plan to upload to rubygems ?
",tdantas,mperham
1735,2014-05-26 13:58:21,"Yes later today. 

> On May 26, 2014, at 6:50, Thiago Dantas notifications@github.com wrote:
> 
> thanks @mperham. plan to upload to rubygems ?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1726,2014-05-21 17:16:35,"Fixes #1713

I checked the initial polling behavior again after seeing @brandonhilkert's comment and he's right in that the polling did indeed not start right away. 

I found and fixed the bug: an extra `clearInterval()` on document load which prevented the polling from starting. It should be working as expected now.
",madebydna,brandonhilkert
1715,2014-05-19 07:54:32,"@mperham 

When I visit /sidekiq/busy I get Internal Server Error.

The issue was closed https://github.com/mperham/sidekiq/issues/1537 
but I guess needs to be rechecked.

I am using:
Rails 3.2.17
Ruby 2.0.0
Redis-Server 2.4.16

Below is the log ...



Things work perfectly fine on development machine; the issue occurs on production machine.
",nikunj0407,mperham
1715,2014-05-19 09:57:36,"Your Redis version is too old. You need 2.4+

> On May 19, 2014, at 0:54, Nikunj Thakkar notifications@github.com wrote:
> 
> @mperham
> 
> When I visit /sidekiq/busy I get Internal Server Error.
> 
> The issue was closed #1537 
> but I guess needs to be rechecked.
> 
> Below is the log ...
> 
> Redis::CommandError - ERR wrong number of arguments for 'srem' command:
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/redis-3.0.7/lib/redis/client.rb:97:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/redis-3.0.7/lib/redis.rb:1228:in`block in srem'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/redis-3.0.7/lib/redis.rb:37:in `block in synchronize'
> /usr/local/rvm/rubies/ruby-2.0.0-p451/lib/ruby/2.0.0/monitor.rb:211:in`mon_synchronize'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/redis-3.0.7/lib/redis.rb:37:in `synchronize'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/redis-3.0.7/lib/redis.rb:1227:in`srem'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/lib/sidekiq/api.rb:493:in `block in each'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/connection_pool-2.0.0/lib/connection_pool.rb:58:in`with'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/lib/sidekiq.rb:69:in `redis'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/lib/sidekiq/api.rb:493:in`each'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/web/views/busy.erb:14:in `each_with_index'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/web/views/busy.erb:14:in`block in singleton class'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/web/views/busy.erb:131067:in `instance_eval'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/web/views/busy.erb:131067:in`singleton class'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/web/views/busy.erb:131065:in `__tilt_108197010'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/tilt-1.4.1/lib/tilt/template.rb:170:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/tilt-1.4.1/lib/tilt/template.rb:170:in `evaluate'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/tilt-1.4.1/lib/tilt/template.rb:103:in`render'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:814:in `render'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:665:in`erb'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sidekiq-3.0.2/lib/sidekiq/web.rb:42:in `block in <class:Web>'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1603:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1603:in `block in compile!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:966:in`[]'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:966:in `block (3 levels) in route!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:985:in`route_eval'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:966:in `block (2 levels) in route!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1006:in`block in process_route'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1004:in `catch'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1004:in`process_route'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:964:in `block in route!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:963:in`each'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:963:in `route!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1076:in`block in dispatch!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1058:in `block in invoke'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1058:in`catch'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1058:in `invoke'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1073:in`dispatch!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:898:in `block in call!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1058:in`block in invoke'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1058:in `catch'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1058:in`invoke'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:898:in `call!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:886:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-protection-1.5.3/lib/rack/protection/xss_header.rb:18:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-protection-1.5.3/lib/rack/protection/path_traversal.rb:16:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-protection-1.5.3/lib/rack/protection/json_csrf.rb:18:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-protection-1.5.3/lib/rack/protection/base.rb:49:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-protection-1.5.3/lib/rack/protection/base.rb:49:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-protection-1.5.3/lib/rack/protection/frame_options.rb:31:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/nulllogger.rb:9:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/head.rb:9:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:180:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:2014:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1478:in `block in call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1788:in`synchronize'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/sinatra-1.4.5/lib/sinatra/base.rb:1478:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/routing/mapper.rb:42:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/journey-1.0.4/lib/journey/router.rb:68:in `block in call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/journey-1.0.4/lib/journey/router.rb:56:in`each'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/journey-1.0.4/lib/journey/router.rb:56:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/routing/route_set.rb:612:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-pjax-0.7.0/lib/rack/pjax.rb:12:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/wicked_pdf-0.10.2/lib/wicked_pdf/middleware.rb:15:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/client_side_validations-3.2.6/lib/client_side_validations/middleware.rb:17:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/warden-1.2.3/lib/warden/manager.rb:35:in`block in call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/warden-1.2.3/lib/warden/manager.rb:34:in `catch'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/warden-1.2.3/lib/warden/manager.rb:34:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/best_standards_support.rb:17:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/etag.rb:23:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/conditionalget.rb:25:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/head.rb:14:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/remotipart-1.2.1/lib/remotipart/middleware.rb:27:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/params_parser.rb:21:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/flash.rb:242:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/session/abstract/id.rb:210:in`context'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/session/abstract/id.rb:205:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/cookies.rb:341:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activerecord-3.2.13/lib/active_record/query_cache.rb:64:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activerecord-3.2.13/lib/active_record/connection_adapters/abstract/connection_pool.rb:479:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/callbacks.rb:28:in `block in call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:405:in`_run__238861133__call__378299929__callbacks'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:405:in `__run_callback'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:385:in`_run_call_callbacks'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activesupport-3.2.13/lib/active_support/callbacks.rb:81:in `run_callbacks'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/callbacks.rb:27:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/remote_ip.rb:31:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/debug_exceptions.rb:16:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/show_exceptions.rb:56:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/railties-3.2.13/lib/rails/rack/logger.rb:32:in`call_app'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/railties-3.2.13/lib/rails/rack/logger.rb:16:in `block in call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activesupport-3.2.13/lib/active_support/tagged_logging.rb:22:in`tagged'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/railties-3.2.13/lib/rails/rack/logger.rb:16:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/actionpack-3.2.13/lib/action_dispatch/middleware/request_id.rb:22:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/methodoverride.rb:21:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/runtime.rb:17:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/activesupport-3.2.13/lib/active_support/cache/strategy/local_cache.rb:72:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/lock.rb:15:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-cache-1.2/lib/rack/cache/context.rb:136:in `forward'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-cache-1.2/lib/rack/cache/context.rb:245:in`fetch'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-cache-1.2/lib/rack/cache/context.rb:185:in `lookup'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-cache-1.2/lib/rack/cache/context.rb:66:in`call!'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-cache-1.2/lib/rack/cache/context.rb:51:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/railties-3.2.13/lib/rails/engine.rb:479:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/railties-3.2.13/lib/rails/application.rb:223:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/content_length.rb:14:in`call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/railties-3.2.13/lib/rails/rack/log_tailer.rb:17:in `call'
> /var/www/rails_apps/quikchex_testing/shared/bundle/ruby/2.0.0/gems/rack-1.4.5/lib/rack/handler/webrick.rb:59:in`service'
> /usr/local/rvm/rubies/ruby-2.0.0-p451/lib/ruby/2.0.0/webrick/httpserver.rb:138:in `service'
> /usr/local/rvm/rubies/ruby-2.0.0-p451/lib/ruby/2.0.0/webrick/httpserver.rb:94:in`run'
> /usr/local/rvm/rubies/ruby-2.0.0-p451/lib/ruby/2.0.0/webrick/server.rb:295:in `block in start_thread'
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1703,2014-05-14 03:35:55,"Heroku does not allow USR1.  Instead provide an API which allows a Sidekiq process to be signalled indirectly.  Quiet and Stop should both be possible.

TODO
- [x] Refactor ProcessSet
- [x] Implement quiet! and stop!
- [x] Implement heartbeat changes

/cc @halorgium
",mperham,halorgium
1702,2014-05-13 18:11:59,"@mperham done!
",lucianosousa,mperham
1699,2014-05-13 13:45:49,"I was noticing a recuring pattern in my current project; we would use a parent worker (RunnerWoker) which enqueue a child worker for each model. 
simplified example:



That being said, I was thinking of expending the current ActiveRecord extensions:
https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/extensions/active_record.rb 
with another method, that runs a worker on for a given model query



which essentially does:



@mperham WDYT? 
Should this be part of the Sidekiq::Worker DSL or do you think it would work better as an separate gem?
",yelled3,mperham
1679,2014-04-28 17:50:26,"This was opened and closed previously - https://github.com/mperham/sidekiq/issues/1223 (for good reason.) Per @mperham I'd like to see if there is any desire in the community for this feature.  We use namespacing in redis to segregrate queues between services.  Currently, we provision/start a web ui per namespace.  Is this issue affecting anyone else?
",dbelwood,mperham
1656,2014-04-18 04:10:06,"@brandonhilkert Any chance you can take a stab at this?
",mperham,brandonhilkert
1655,2014-04-15 13:16:17,"@mperham what do you think about changing this:



to this:



and something similar for sidekiq-pro's batch callback handler.

I've got an occasional bug in my callback code which is hard to track down, and this would help.
",subelsky,mperham
1626,2015-05-05 15:59:37,"It is not.  I'm working with @davydovanton this summer to build a Sidekiq history gem which will track more metrics.  These are more possible use cases for it.
",mperham,davydovanton
1624,2014-03-31 18:13:10,"@mperham @jonhyman 

I think that Rubinius  don't like this love symbol :heart: 
https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/manager.rb#L151
Can we rename this method to make the tests pass ?
",seuros,mperham
1624,2014-03-31 18:13:10,"@mperham @jonhyman 

I think that Rubinius  don't like this love symbol :heart: 
https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/manager.rb#L151
Can we rename this method to make the tests pass ?
",seuros,jonhyman
1619,2014-03-29 19:58:35,"~~Are you sure you using Sidekiq ?~~  
~~It look like you using delayed job (which use .delay)~~

~~Here is a railscast about how to use sidekiq : http://railscasts.com/episodes/366-sidekiq~~
~~Your final code will be something like RecommendationWorker.perform_async(@recommendation, sender_name)~~

~~In the worker~~



While you are on it , upgrade sidekiq to the lastest version 3.0.0~~

Read the @mperham's answer below.
",seuros,mperham
1607,2014-03-27 08:58:55,"@mperham, There is a feature that we would love to see in sidekiq, restarting sidekiq in each deploy can have problems. ( beginners or advanced users) 

We are nearly used and using many type of servers like thin, unicorn, puma etc etc.
You have to restart the servers in capistrano(or similar) , it is always a problem.
But in passenger, there is a very cool feature. 
""By creating or modifying the file tmp/restart.txt in the Rails application’s root folder. Phusion Passenger will automatically restart the application during the next request.
For example, to restart our example MyCook application, we type this in the command line:
touch /webapps/mycook/tmp/restart.txt
Phusion Passenger checks whether the timestamp of this file has changed in order to determine whether the application should be restarted.""

It will be so great to add smth like this. When we touch the sidekiq_restart.txt, sidekiq will automatically load new code. What do u think?
",sahin,mperham
1603,2014-03-25 17:39:19,"/cc @jonhyman 
",mperham,jonhyman
1593,2014-03-24 02:32:15,"Right now, stats expire in 180 days. Why do you want to do this? Stats take up a trivial amount of space and it removes the ability for you to meaningfully track quarter-over-quarter growth without ensuring that you record it.

@mperham I can submit a pull which removes the expiration if you agree.
",jonhyman,mperham
1593,2014-03-24 02:53:11,"Just to prevent a memory leak. They aren't really intended to be long term or used by anything but the Web UI. That said, I'm ok if you want to expand the TTL to something like 5 years. 

I'm happy to entertain a wider discussion around aggregate or historical metrics and any improvements possible. 

> On Mar 23, 2014, at 19:32, Jonathan Hyman notifications@github.com wrote:
> 
> Right now, stats expire in 180 days. Why do you want to do this? Stats take up a trivial amount of space and it removes the ability for you to meaningfully track quarter-over-quarter growth without ensuring that you record it.
> 
> @mperham I can submit a pull which removes the expiration if you agree.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1567,2014-03-16 10:21:16,"@weichienhung Do the translations look ok to you or do we need two different dialects?
",mperham,weichienhung
1557,2014-03-14 17:51:59,"Spanish correction for #1554
cc @mperham
",joseluistorres,mperham
1555,2014-03-14 17:31:10,"As per @mperham request (#1554).
",jodosha,mperham
1551,2014-03-20 18:23:50,"@mperham -- we're still trying to track down this issue.... we run a minimum of 1 heroku worker and scale up from there.  What we're seeing is that after running for a long time the main heroku worker `sidekiq_worker.1` seems to grind to a hault.  In the case of this morning the jobs were still in the busy queue but they had actually been processed... just not removed from the busy queue.  worker1 was no longer receiving any jobs.  Then after about 30-60mins it seemed to clean up itself and started receiving and processing like normal but quickly froze up again with jobs stuck in the busy queue.  We had to manually restart the worker.  The good news is that it does appear that no jobs are being lost... but just that the worker is dealing with some sort of crash or memory leak.

A list of our workers:



A tail of the sidekiq_worker.1 logs (note the super long processing times)



No errors are being raised.  We upgraded to `ruby 2.1.1` which seems to have fixed a number of issues were having before that seemed to cause net connections to randomly segfault.  It also seems to have fixed the random 5 second timeouts we were getting w/ active record.

Any ideas on why this might be happening?  @subelsky - have you seen this at all?
",anazar,subelsky
1550,2014-03-12 15:26:48,"Remove capistrano code from core in deference to new capistrano-sidekiq gem, owned by @seuros. https://github.com/seuros/capistrano-sidekiq
",mperham,seuros
1549,2014-03-12 12:16:01,"Hi,

Sidekiq using high memory in 37 connections redis using about 3.65 GB memory. 
After booting 25 queues, each queue has 10 concurrency.
### sidekiq

![screen shot 2014-03-12 at 14 04 57](https://f.cloud.github.com/assets/170820/2396753/1a72c54e-a9df-11e3-97d5-1e87d427dd59.png)
### scout

Scout reporting the same result;

![screen shot 2014-03-12 at 14 09 48](https://f.cloud.github.com/assets/170820/2396758/48dbd90c-a9df-11e3-8487-68245c8e0dff.png)
### redis-cli

redis_version:2.8.7
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:8a4b2cac15686a65
redis_mode:standalone
os:Linux 3.2.0-36-virtual x86_64
arch_bits:64
multiplexing_api:epoll
gcc_version:4.6.3
process_id:951
run_id:2ce417bcbdcd91983200e55872872da6dbd2aa84
tcp_port:6379
uptime_in_seconds:2531
uptime_in_days:0
hz:10
lru_clock:1050568
config_file:/etc/redis/6379.conf

connected_clients:38
client_longest_output_list:0
client_biggest_input_buf:0
blocked_clients:1

used_memory:3919404792
used_memory_human:3.65G
used_memory_rss:3939889152
used_memory_peak:3919530496
used_memory_peak_human:3.65G
used_memory_lua:33792
mem_fragmentation_ratio:1.01
mem_allocator:jemalloc-3.2.0

I'm driling down my queries, if any memory leak occurring. 
But I was wondering why using excessive ram without ""any"" busy or scheduled job.

/cc @mperham 

Thanks.
",seyhunak,mperham
1537,2014-03-09 17:18:21,"@mperham 

I just updated to latest master branch. We are using ruby 2.1

I am getting the following error. 
https://www.dropbox.com/s/oz09bs4epupnsbt/Screenshot%202014-03-09%2010.17.55.png

in the logs.


",sahin,mperham
1527,2014-03-03 05:30:08,"Can you provide more info?  Sidekiq/Pro/Ruby versions?  Is it always the same type of job or all different types?  Are you using any Sidekiq extensions or middleware?

@jonhyman has been running 100,000+ jobs/min in his system with reliable fetch with great success now.
",mperham,jonhyman
1527,2014-03-03 05:36:52,"Sidekiq pro
Sidekiq master
Ruby 2.0.0
Rails 4.1.0.rc1
Hirefire (to scale worker dynos... we're scaling up to 5)

@jonhyman - whoa!  we've been struggling to get that kind of performance... we're processing about 100k jobs per hour and struggling to scale up to that.  Definitely could use your advice.  Any chance you're on heroku?

Here's my sidekiq config:


",anazar,jonhyman
1513,2014-02-25 14:53:40,"Hey @mperham,

Is there any way to see the list of failing jobs without going to sidekiq logs? If not, is there plans/interest of having this feature?

Thanks
",filipebarcos,mperham
1513,2014-02-25 15:50:30,"Yes, they are called Retries. 

> On Feb 25, 2014, at 6:53, Filipe Costa notifications@github.com wrote:
> 
> Hey @mperham,
> 
> Is there any way to see the list of failing jobs without going to sidekiq logs? If not, is there plans/interest of having this feature?
> 
> Thanks
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1459,2014-02-04 04:29:08,"@mperham explained to me that you could not kill a thread in a worker process as it is quite dangerous. However for my usecase, I need total control on job killing. I am thinking of running multiple workers each with 1 thread, so I could kill the PID instead. It does come with a resource cost though. And then @mperham suggested this: ""or have the worker thread check if should it halt"". I don't truly understand what does it mean, this ticket is dedicated for explanation on that
",joneslee85,mperham
1458,2014-02-01 07:20:45,"@mperham 

Suppose queue1 consists of 10 jobs, After starting the sidekiq,  jobs should be processed one by one. Is it right. 

If first jobs takes 1 minute to complete. When the second and third job will start. Will it start before first job finishes.

Else if all are jobs are processing at same time. Jobs will mismatching with the data.

Can you clarify me with simple example. Other wise do we need to use separate gem to limit the queue size and process size
",karunakaran,mperham
1450,2014-01-24 12:37:15,"@mperham 

I given require sidekiq/capistrano in deploy file. So i can able to sidekiq in different environments. 

Now 3 sidekiq process(development,staging,testing) is running in same server. If one sidekiq process is starting in development. That process is executed in sidekiq process of which process is started first.

Example : I depolyed development first and then staging, the sidekiq worker which needs to work in staging are executed in development sidekiq process. So the log and database are taking development. its wrong.

So i am running sidekiq for multiple environments on same server. I need each sidekiq process to be executed for respected environments. Also i am seeing same number of jobs processing in the UI interface for all environments. I need to get seperation in UI too.
",karunakaran,mperham
1450,2014-01-24 12:40:44,"You need to use different Redis namespaces or database IDs for each env. 

> On Jan 24, 2014, at 4:37, karunakaran notifications@github.com wrote:
> 
> @mperham
> 
> I given require sidekiq/capistrano in deploy file. So i can able to sidekiq in different environments.
> 
> Now 3 sidekiq process(development,staging,testing) is running in same server. If one sidekiq process is starting in development. That process is executed in sidekiq process of which process is started first.
> 
> Example : I depolyed development first and then staging, the sidekiq worker which needs to work in staging are executed in development sidekiq process. So the log and database are taking development. its wrong.
> 
> So i am running sidekiq for multiple environments on same server. I need each sidekiq process to be executed for respected environments. Also i am seeing same number of jobs processing in the UI interface for all environments. I need to get seperation in UI too.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1449,2014-01-24 12:19:03,"@mperham 

I need to send email notifications if sidekiq crashes or stops at anytime and also can i send notification when sidekiq start.

It will be really helpful for me if i get notification email.

Thanks in advance.
",karunakaran,mperham
1449,2014-01-24 12:39:00,"Use monit to do that. 

> On Jan 24, 2014, at 4:19, karunakaran notifications@github.com wrote:
> 
> @mperham
> 
> I need to send email notifications if sidekiq crashes or stops at anytime and also can i send notification when sidekiq start.
> 
> It will be really helpful for me if i get notification email.
> 
> Thanks in advance.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1445,2014-01-22 12:51:00,"@mperham 
I am storing a xls file in one temporary location and opening the xls file for reading .
While saving the xls to amazon s3. I am getting the below error in sidekiq.log for large amount of data 

ERROR: Cannot allocate memory - file -b --mime 'Test.xls'

Once i get this error for one process. Then i generate the next xls file  with sidekiq process. Am getting the same error even for very smaller datas.

If i do restart the sidekiq after getting this error,  then only i can able to generate next xls file for smaller datas.
",karunakaran,mperham
1445,2014-01-22 14:01:51,"Sounds like something needs more memory but the error message is too vague for me to have any sense of what the problem might be. 

> On Jan 22, 2014, at 4:51, karunakaran notifications@github.com wrote:
> 
> @mperham 
> I am storing a xls file in one temporary location and opening the xls file for reading .
> While saving the xls to amazon s3. I am getting the below error in sidekiq.log for large amount of data
> 
> ERROR: Cannot allocate memory - file -b --mime 'Test.xls'
> 
> Once i get this error for one process. Then i generate the next xls file with sidekiq process. Am getting the same error even for very smaller datas.
> 
> If i do restart the sidekiq after getting this error, then only i can able to generate next xls file for smaller datas.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
1423,2014-01-10 16:57:28,"Perhaps a fix for the issue described in #1406.

@mperham see any issues here? I'm still not a celluloid pro so it's possible this is not good, but all the tests pass.
",jonhyman,mperham
1408,2013-12-25 12:31:37,"@mperham Support for the `-q foo,3,bar` syntax has been removed.
",DouweM,mperham
1394,2013-12-12 16:09:34,"@mperham I thought about adding a note to explain that it was an errorenous changelog entry, but I figured it'd be more harmful than good going forward. The wiki says that USR1 just stops, does not exit, so that seems like the good source of truth anyway IMO.
",jonhyman,mperham
1386,2013-12-09 20:52:36,"Paging @jonhyman ...

Anything in the logs?  If you can reproduce, enable verbose logging, trigger USR1 and copy the output here.
",mperham,jonhyman
1382,2013-12-05 17:24:59,"I'm not sure if these are here deliberately, or only as a vestige from back in the day, but I'd like to suggest that these directives be removed.

One of the big plusses for Travis is the ability to do CI runs on forked repos and PRs.  With the branches restriction this doesn't happen unless development occurs on the master branch.  In practice this means that I always wind up making a commit that removes these directives and then rolling it back when I submit a PR.

At the same time we don't want to notify the IRC channel or mailing list every time there's a failed build on a forked repo.  

So I suggest removing both these directives.  @mperham - your thoughts?  
",petergoldstein,mperham
1353,2013-11-19 03:07:05,"made an example to see if our memory problem is from sidekiq or our code,
looks like sidekiq is not to blame, but you might want to keep this test-case / proof of innocence ;)

@mperham
",grosser,mperham
1335,2013-11-14 20:42:37,"Awesome. Thanks @mperham !
",hjhart,mperham
1303,2013-11-01 09:50:30,"I'm also currently receiving an Internal Server Error when I try to access the dashboard. Nothing on the any of the logs. I've even tried shutting down redis as well as sidekiq and going to the /sidekiq route still gives me a 500. @mperham I've added the backtrace option to my workers. How would I obtain the debug information?
",abhasg,mperham
1300,2013-11-02 05:57:51,"Much better.  Can you change the white background to match the gray background of the code snippets, so we don't have half a dozen different shades of white/gray? @unity @brandonhilkert Any thoughts/suggestions?
",mperham,unity
1300,2013-11-02 05:57:51,"Much better.  Can you change the white background to match the gray background of the code snippets, so we don't have half a dozen different shades of white/gray? @unity @brandonhilkert Any thoughts/suggestions?
",mperham,brandonhilkert
1296,2013-11-01 18:07:56,"@juanibiapina @mperham From what I can tell, the hooks will never be set with the current method as that variable isn't defined when this file is loaded.  My first thought was to move this check into the rake tasks themselves and always define the hooks, but that would mean calling them directly may not work.  I'm not sure if rake will tell you the task that invoked this task or not.  Alternatively we could add ""hook"" tasks specifically for this.

Any ideas on how you'd like to solve it Mike?   I'm happy to work on it.
",phallstrom,mperham
1292,2013-10-29 19:24:38,"It's not backwards compatible. @mperham may you please fix it?
",AlekSi,mperham
1231,2013-10-04 15:56:34,"Those look like pool threads that are just waiting on messages to process, not a problem. @tarcieri @halorgium Confirm/deny?
",mperham,halorgium
1192,2013-09-21 06:04:41,"@mperham I missed that, but it's fixed now.
",kremso,mperham
1174,2013-09-11 11:48:55,"@mperham i think you should add libxml-ruby to unstable gems with sidekiq. see  https://github.com/celluloid/celluloid/issues/328 for more info
",Saicheg,mperham
1161,2013-09-06 02:44:29,"FYI @halorgium, I think we should revert that check and ship 0.15.1 ASAP
",tarcieri,halorgium
1095,2013-08-06 11:29:16,"[Edit by @halorgium, correct the report sidekiq version]

I use sidekiq 2.12.4 on rails 3.2.13 on ruby-1.9.3-p194. I get this exception now and then. They are not  frequent, May be once a week or so.


",rajofchennai,halorgium
1095,2013-08-06 15:38:03,"@tarcieri @halorgium ?
",mperham,halorgium
1089,2013-08-01 17:00:32,"@mperham sorry, I don't know what I've done
",abacha,mperham
1070,2013-07-24 17:00:14,"I removed MultiJson because the developer @sferik stated it was no longer necessary and recommended using the plain JSON gem instead.
",mperham,sferik
1046,2013-07-21 20:44:32,"This looks fantastic.  I'll merge as is but if you or @brandonhilkert have ideas to improve the graph rendering, just send a new PR.
",mperham,brandonhilkert
1027,2013-06-25 15:17:31,"Allow custom retries to be defined per-worker as discussed in #1013

@mperham how does this look?
",jmazzi,mperham
1013,2013-06-20 19:47:13,"@mperham any thoughts on the above?
",jmazzi,mperham
1010,2013-06-19 03:26:51,"I'd like a 3'x3' square design for Sidekiq stickers to go on laptops, etc.

The Kicker SVG is a good start but it needs to say Sidekiq also.

https://dl.dropboxusercontent.com/u/3425424/Kicker.svg

/cc @unity 
",mperham,unity
996,2013-06-13 10:56:02,"@mperham Thoughts?
",brandonhilkert,mperham
991,2013-06-10 23:14:41,"Paging @brandonhilkert ...
",mperham,brandonhilkert
974,2013-06-08 04:55:53,"@mperham Anything I should keep in mind before creating such a PR in future, as this got rejected?
",vipulnsward,mperham
971,2013-05-31 16:43:58,"@mperham #966 
",grosser,mperham
969,2013-05-31 15:48:22,"@mperham

Prevent this when running tests:
`/Users/mgrosser/code/tools/sidekiq/lib/sidekiq/web.rb:5:in`<top (required)>': The Sidekiq Web UI requires slim 1.3.8 or greater.`
",grosser,mperham
966,2013-05-30 23:17:29,"@mperham 

If you have say 8.167.491 keys in your redis then keys with \* get's pretty slow and when 30 or so worker do it at the same time redis is not happy :D

I'd like to make a pull to either:
- only do it once every 10 days (via a redis key like last_cleaned_up_at)
- use expire on the processed / failed so it is not necessary

would you merge any of these / what would you prefer ?
",grosser,mperham
958,2013-05-29 15:12:35,"I am using rails 3.2.13, with latest sidekiq gem. When I restart sidekiq I get many of these errors. After sometime these errors slowly decrease and finally stop. 

I looked at https://github.com/brianmario/mysql2/issues/99 also tried out @mperham 's solution as well. Seems to be causing more errors. This is happening in production environment not in test environment.

I am not sure if this is a sidekiq issue. 

My guess is, AR creates connections lazyly and sidekiq workers tries to access some connection before it is created and so once the connections are completely created the errors stop. 

Any help will be useful. 
",rajofchennai,mperham
912,2013-09-02 18:42:08,"Why do ActiveRecord connections work fine?  I'm under the impression they do the same thing.  Do they have the same problem? Maybe @tarcieri or @halorgium can advise if your monkeypatch is a good idea or not.
",mperham,halorgium
907,2013-05-07 15:40:47,"Yes, I'm working with @dbussink.

Evan, yep.
",cpuguy83,dbussink
903,2013-05-06 18:24:59,"Hi @mperham, love sidekiq thanks!

I was wondering if there is a preferred way to put a job back into the queue if I determine it's not time to process it yet.

Thus far I have been intentionally raising an exception so the `retry: true` will keep happening. Suppose another option would be to ""process"" the job by not doing anything and call `perform_in`/`perform_at`?
",ksheurs,mperham
876,2013-04-25 18:11:24,"Hi @mperham,

I have modified the Japanese translation, such as Status and Polling.

Regards,
ogom
",ogom,mperham
875,2013-04-25 16:50:13,"Hi @mperham,

Added Japanese locale is great. will assist with translation.

Custom tab will be included in the translation?



Regards,
ogom
",ogom,mperham
864,2013-04-19 03:54:22,"Hi @mperham,

Added Failures key for the sidekiq-failures web extension is great.

We want to use the English locale unknown, please fix.

Regards,
ogom
",ogom,mperham
859,2013-04-17 01:04:01,"Functionality to find and delete Sidekiq jobs by the job id.  @mperham, I think this is more in line with what you were thinking.

Example usage:

**Finding and Deleting Job by ID**



**Finding and Deleting Invalid Job ID**



**Or you can use it on ScheduledSet to access the scheduled queue directly** 


",jharbert,mperham
859,2013-04-17 01:13:45,"Can you name the method 'find' like AR and use the existing delete method to delete the job?

On 16 Apr 2013, at 18:04, Jason Harbert notifications@github.com wrote:

> Functionality to find and delete Sidekiq jobs by the job id. @mperham, I think this is more in line with what you were thinking.
> 
> Example usage:
> 
> Finding and Deleting Job by ID
> 
> Sidekiq::SortedSet.new('schedule').find_job_by_id('2eef6b752dab8a4c89a7aa19')
> => #<Sidekiq::SortedEntry:0x007fd5a910e858 @value="".....> 
> 
> Sidekiq::SortedSet.new('schedule').delete_job_by_id('2eef6b752dab8a4c89a7aa19')
> => true 
> Finding and Deleting Invalid Job ID
> 
> Sidekiq::SortedSet.new('schedule').find_job_by_id('2eef6b752dab8a4c89a7aa19')
> => nil 
> 
> Sidekiq::SortedSet.new('schedule').delete_job_by_id('2eef6b752dab8a4c89a7aa19')
> => nil 
> Or you can use it on ScheduledSet to access the scheduled queue directly
> 
> Sidekiq::ScheduledSet.new.find_job_by_id('719a82379213ccab7551bc7e')
> => #<Sidekiq::SortedEntry:0x007fd5a928f6a0 @value="".....>
> 
> Sidekiq::ScheduledSet.new.delete_job_by_id('719a82379213ccab7551bc7e')
> => true
> 
> Sidekiq::ScheduledSet.new.find_job_by_id('719a82379213ccab7551bc7e')
> => nil 
> 
> Sidekiq::ScheduledSet.new.delete_job_by_id('719a82379213ccab7551bc7e')
> => nil
> You can merge this Pull Request by running
> 
>   git pull https://github.com/jharbert/sidekiq master
> Or view, comment on, or merge it at:
> 
>   https://github.com/mperham/sidekiq/pull/859
> 
> Commit Summary
> 
> adding functionality to return details of a scheduled job given a job id
> removing code from client, placing into API on SortedSet
> File Changes
> 
> M lib/sidekiq/api.rb (9)
> M test/test_api.rb (14)
> Patch Links:
> 
> https://github.com/mperham/sidekiq/pull/859.patch
> https://github.com/mperham/sidekiq/pull/859.diff
",mperham,mperham
856,2013-04-16 19:50:16,"Had a similar issue as @jmazzi (https://github.com/mperham/sidekiq/issues/536#issuecomment-10604878) where I needed information on a scheduled Sidekiq job.   

Example usage:

Sidekiq::Client.get_scheduled_job('b0e879cbe7fcf3460acc2b67')
 => {""retry""=>true, ""queue""=>""default"", ""class""=>""Sidekiq::Extensions::DelayedClass"", ""args""=>[""---\n- !ruby/class 'MyClass'\n- :test\n- []\n""], ""at""=>1366142912.6503942, ""jid""=>""b0e879cbe7fcf3460acc2b67""} 

Please let me know if I've totally overlooked a better way to do this.

Cheers!
",jharbert,jmazzi
834,2013-04-07 16:29:25,"@mperham Just to stay current, tests still pass.
",grosser,mperham
807,2013-04-02 23:11:18,"@mperham I'd love your input :)
",gregorym,mperham
760,2013-03-08 03:46:12,"Hi @mperham,

I believe Sidekiq is a great platform and I reckon it's time we make Padrino a first class citizen on it :), that's why I've implemented its support along with the possibility to add more frameworks in the future.

Now you can just run `bundle exec sidekiq` on your Padrino app and it will work as well as it does on Rails! :)

There's still one catch and it has to do with ActiveRecord methods, at the moment you have to send them yourself in `config/boot.rb` as follows:



You'll find a demo app with the same functionality than the Rails app has in `/demo-apps`.

Let me know what you think. :)

Thanks,
Darío
",dariocravero,mperham
760,2013-03-08 14:48:34,"@mperham here we go
",dariocravero,mperham
760,2013-04-09 14:58:07,":-1: It is better to move this into separated gem. `sidekiq-padrino` or so. I am sure @mperham you do not want to maintain integration with every framework in the Universe.

(btw I am using sidekiq+padrino at my current project, and do not completely understanding what problems this integration solves)
",sumskyi,mperham
681,2013-02-08 01:16:30,"Ok, I get it. To be honest, I've never heard of this issue before. It makes me question the design of your workers if the args are so large that 25 on a page cause the whole thing to crash. 

I'm uncomfortable adding this bit of complexity to the web UI in order to satisfy what seems to be questionable design of workers.

@mperham thoughts?
",brandonhilkert,mperham
681,2013-02-08 03:11:39,"I think you're exactly right. Sidekiq jobs should not contain state/documents. 

On 7 Feb 2013, at 17:16, Brandon Hilkert notifications@github.com wrote:

> Ok, I get it. To be honest, I've never heard of this issue before. It makes me question the design of your workers if the args are so large that 25 on a page cause the whole thing to crash.
> 
> I'm uncomfortable adding this bit of complexity to the web UI in order to satisfy what seems to be questionable design of workers.
> 
> @mperham thoughts?
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
680,2013-02-06 14:56:37,"thanks @mperham!
",subelsky,mperham
680,2013-02-06 17:55:38,"Thank you @mperham !
",dinedal,mperham
597,2012-12-19 17:50:36,"Trying to follow the instructions for using batches [here](https://github.com/mperham/sidekiq/wiki/Batches) but I got an error about `Sidekiq::Middleware::Client` not existing.  I figured it was because we were requiring `sidekiq` instead of `sidekiq-pro` in the initializer but when I changed that line I got the following error when trying to load rails:



Our gemspec:



What am I doing wrong?

cc @jmazzi
",tfwright,jmazzi
551,2012-11-30 17:49:10,"I checked [the FAQ](https://github.com/mperham/sidekiq/wiki/Pro-FAQ) and the mailing list archives and I couldn't find a policy on development of Pro features for the non-Pro version.

I've been considering building out functionality like that described in #536 for the non-Pro version. At what point, if ever, will a pull request building out functionality be rejected because something is a Pro feature? Put another way, has this feature been ""claimed"" for Pro? Would it be exclusive to Pro if it were already included in a Pro release? My preference is that development of the non-Pro version be uninhibited by the existence of the Pro version.

@mperham what do you think?
",ragalie,mperham
545,2012-11-28 15:36:19,"@mperham could we get some clarification on this?
",jmazzi,mperham
540,2012-11-26 04:37:55,"Yeah, looks great. Once @mperham's suggestion about the `clear` method is implemented please squash then we'll merge.
",jc00ke,mperham
540,2012-11-26 13:11:56,"@mperham How's that?
",brandonhilkert,mperham
537,2012-12-02 20:15:21,"@mperham 

The delete action on the queues encodes the message for the form using `to_json`. Seems that `MultiJson.encode` is more appropriate here. You agree?



If so, I can make that change.
",brandonhilkert,mperham
537,2012-12-02 21:05:23,"Or even better, Sidekiq.dump_json. Go for it. 

On 2 Dec 2012, at 12:15, Brandon Hilkert notifications@github.com wrote:

> @mperham
> 
> The delete action on the queues encodes the message for the form using to_json. Seems that MultiJson.encode is more appropriate here. You agree?
> 
> 
> 
> If so, I can make that change.
> 
> —
> Reply to this email directly or view it on GitHub.
",mperham,mperham
503,2012-11-05 17:09:55,"You could incorporate @mperham's [connection_pool](https://github.com/mperham/connection_pool) gem so you could have your own pool outside of Rails.
",jc00ke,mperham
490,2012-10-31 17:35:16,"I do prefer slim to erb and Sinatra outsources view generation to Tilt.  I would be ok with moving to ERB if it gets rid of tilt.  That said, I think Rails uses tilt so we might be over-optimizing in this case.  90% of Sidekiq users are using Rails already.

I want to make sure that guys like @unity understand and are ok with removing the SASS / compass stuff since he set them up.  They do cause a lot of runtime pain but make UI development easier.
",mperham,unity
424,2012-10-02 19:43:30,"@jakemack did the initial implementation and it worked fine then but maybe some of the recent changes messed it up. If we have some time we'll dig into it.

Would love to hear if anyone else is seeing this.
",TheCorp,jakemack
419,2012-09-28 15:08:13,"@mperham this is an example of something we could work around if we have sidekiq-web with a dedicated gemfile as we could exclude the problematic versions until the problem is fixed.
",betelgeuse,mperham
417,2012-09-26 23:50:47,"This is a quick compilation of @unity's great sidekiq.org redesign (see: #407) into a merge-able, GHpages-friendly structure. It probably isn't perfect, but maybe it'll save someone a little bit of time?
",ezkl,unity
407,2012-09-27 02:39:08,"Pulled in @ezkl's version, see http://sidekiq.org!
",mperham,ezkl
407,2012-09-27 02:42:20,"I love it! Looks great on my new iPhone 5 too. :-)

On Sep 26, 2012, at 7:39 PM, Mike Perham notifications@github.com wrote:

> Pulled in @ezkl's version, see http://sidekiq.org!
> 
> —
> Reply to this email directly or view it on GitHub.
",ryanlecompte,ezkl
393,2012-09-11 01:36:24,"Hi, I'm trying to use sidekiq with devise through devise-async, and found a bug.

At first, I believed that it was a devise-async bug, but, later, me and @mhfs found that it's a bug in processor.rb

https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/processor.rb#L107

Original issue: https://github.com/mhfs/devise-async/issues/10
Stackoverflow: http://stackoverflow.com/questions/12361077/devise-async-is-not-working-with-sidekiq

Thanks
",caarlos0,mhfs
385,2012-09-02 07:16:02,"

This means that long running jobs will not show up in stats after one hour. @mperham is still some kind of a leftover or what is the logic here?
",betelgeuse,mperham
363,2012-08-21 15:13:45,"Minor improvement as suggested by @jc00ke on #361.
",mhfs,jc00ke
336,2012-08-07 15:51:38,"I just pushed 2.1.1 with @subelsky's improved error handling.  See if that logs the problem.
",mperham,subelsky
330,2012-08-03 14:32:07,"Changing the queues of a sidekiq process currently requires a restart so what you want would need to be implemented in external monitoring infrastructure. The first step towards helping your use case would be to allow configuring the listened queues at runtime but @mperham do you think this is a good idea?
",betelgeuse,mperham
312,2012-08-04 19:19:16,"We have one (see readme), I just don't use IRC.  @jc00ke hangs out there.
",mperham,jc00ke
296,2012-08-04 03:54:03,"Just an update on this - the script provided by @jackbit was not a good solution for me, at all.  It doesn't handle stopping workers afaict, plus I figured @mperham wasn't just making up that capistrano task he'd written :)  Turns out I was missing my config/sidekiq.yml somehow, and then I didn't have my tmp/pids directory created on the server.  Fixing those two things resolved everything nicely.
",knewter,mperham
276,2012-06-27 16:29:47,"hi,

This pull request fixes the fact that config files are now suffixed with .yml (not .conf).

Also it removes an unused function from the init script (thanks @betelgeuse!)

Best,
Seamus
",seamusabshere,betelgeuse
228,2012-06-08 05:52:00,"Currently it is not possible because `Sidekiq::RedisConnection.build_client` [explicitly builds](https://github.com/mperham/sidekiq/blob/master/lib/sidekiq/redis_connection.rb#L18) with a `:url`. I'm not sure if we'd accept a patch for sockets because they are only accessible locally. @mperham would have to give his blessing.
",jc00ke,mperham
192,2012-05-12 19:22:32,"Ah, I see now.



So yeah, `SIGINFO` is only supported on alpha.

@mperham is there another signal we can use? `INFO` works on OS X but not on Ubuntu.
",jc00ke,mperham
185,2012-05-11 20:55:06,"If you can come up with some gem that reliably replaces Redis with another datastore, go for it, but I know @mperham isn't interested in using any other datastore in Sidekiq officially besides Redis. I'd be interested to see an implementation of unique jobs & retry though.
",jc00ke,mperham
178,2012-05-07 21:04:00,"fyi, we prefer questions like this to be here in issues so others can find/partake in the discussion ;)

I'll let @mperham chime in, but I don't think you'd want to raise, as that could end up being expensive & then you have the whole retry thing to deal with.
",jc00ke,mperham
164,2012-04-27 21:17:50,"Environment
- OS X 10.7.3
- Ruby 1.9.3-p194 built using RVM and osx-gcc-installer (instead of clang as I saw another post from @mperham that suggested clang can build bad rubies)
- Sidekiq 1.1.4

Problem: running my job under Sidekiq results in a seg fault that appears to be outside of sidekiq. Running the same job multiple times results in a new seg fault but in a different place, so the fault location is not consistent.

Running the job inline in the console (just calling `perform` directly) results in the job running successfully. So this seg fault only happens under sidekiq.

I realize that this seg fault appears to happen outside of sidekiq, but it does at least appear to be related to Celluloid. 

Full gist with stacktrace here: https://gist.github.com/2513242

Sorry if this is not an issue with sidekiq and lies elsewhere. But like I said the code runs fine when not invoked via Sidekiq.
",ruckus,mperham
88,2012-03-23 18:36:24,"I found out about and migrated to sidekiq through its association (real or assumed) with resque.

At first, I imagined the difference to be something like:

resque:
- pop job
  *\* fork
- pop job
  *\* fork

sidekiq:
- pop 20 jobs
  *\* fork
- pop 20 jobs
  *\* fork

Now of course I realize that's wrong, but I still think it would be nice if Mike (@mperham) did an explicit comparison between how resque uses child processes and sidekiq uses threads (via celluloid).

In particular, should people consider sticking with resque if their workers can get really big - if their jobs are huge and relatively far between?
",seamusabshere,mperham
77,2012-03-10 20:12:24,"@mperham thanks, should I open a new ticket for the `NameError`?
",masterkain,mperham
31,2012-02-15 19:00:15,"Reverted @indirect's pull request.
",mperham,indirect
4,2012-02-07 11:32:55,"Hi David,

sidekiq currently doesn't support a way to queue up jobs uniquely once per payload as you describe. However, I think support for this could be fairly easily added to the project in a generic way. Normally extensions to sidekiq would be done via custom middleware, but in this case we would want to perform a uniqueness check before the middleware chain would ever get executed.

We could keep track of a redis set that contains a base64 value of all currently queued payloads. If a configuration option is enabled to only enqueue unique items, then we would first consult this set before adding a new job to the queue to make sure it doesn't already exist in the to-be-processed queue.

I went ahead and implemented this approach in a separate branch with tests. @mperham, this may not be the direction we would want to go here, feel free to comment otherwise:

https://github.com/mperham/sidekiq/compare/unique_payloads
",ryanlecompte,mperham
