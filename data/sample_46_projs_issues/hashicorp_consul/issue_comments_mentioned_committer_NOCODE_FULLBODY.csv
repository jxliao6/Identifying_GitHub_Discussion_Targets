issue_num,datetime,body,login,mention_login
2820,2017-03-23 17:29:22,"Hi @slackpad 

I tried with `CONSUL_CLIENT_INTERFACE=eno33557248` and I followed your advice, deleting the two lines `-client` and `-bind`.



I may be missing something...

Regards,
Thomas",notuscloud,slackpad
2814,2017-03-22 19:07:44,"@slackpad I'll try it with 0.7.5. It doesn't happen every time. It seems to take several cycles of register/unregister before it fails on an unregister. It also seems to mostly happen on a specific service which takes a few minutes to come up and also registers two services (one for SSL, one for non-SSL). I tried it on a different service which comes up quickly, hoping for a faster repro cycle, but no luck. 

I think once it happens it seems to happen more consistently. I'll try to verify that and see if it happens on each unregister after the first failure. ",plorenz,slackpad
2814,2017-03-23 20:05:22,"@slackpad I was unable to reproduce the issue with 0.7.5, which is great. Because it was so hard to reproduce, we'll keep an eye for similar behavior in future. If does recur, we'll try to come up with more easily reproducible test case :)",plorenz,slackpad
2794,2017-03-10 23:58:26,@slackpad Thank you for the temporary fixed link. Would you have handy some links to understand the reasoning behind the deprecation? (I haven't been keeping up with Consul development).,dweomer,slackpad
2792,2017-03-10 11:30:54,"@slackpad Just for curiosities sake, when might this be released as a binary?  We'll put in work arounds for our playbooks for now, but would like to revert these changes asap.  Thanks",nathanwebsterdotme,slackpad
2792,2017-03-10 16:13:37,@slackpad thanks for the update. I work with Nathan and can confirm that the change worked as expected. Will there be a 0.7.x version with these changes in them? or is it best to wait for the 0.8 release? Thanks again for the quick resolution on this issue.,wclarke1,slackpad
2792,2017-03-10 16:57:36,"Thats fine thanks @slackpad , we will wait for 0.8 release.",wclarke1,slackpad
2782,2017-03-23 08:34:07,@slackpad your documentation now produces usage errors when copied verbatim. Please explain the peers.json recovery as I am unable to bring up the server node now,ThatJames,slackpad
2780,2017-03-01 18:28:27,"@slackpad thank you very much sir for a quick response. It is working now.

I also had to update the config.vm.network in my vagrantfile to access the consul ui from the host browser as my consul agents are running in vagrant machines.

Here is my vagrantfile for reference :- 


 ",cdharma,slackpad
2749,2017-03-01 07:47:16,Welcome @slackpad ,hadielmougy,slackpad
2743,2017-02-15 02:30:03,Hi @v6 thanks for the kind words and the PR!,slackpad,v6
2742,2017-02-14 15:37:04,"@slackpad Yes I am giving the node name.
Also, the cluster is not in outage state while I am running force-leave.",stefreak,slackpad
2728,2017-02-10 18:37:39,"@slackpad We ran into the same issue while renaming our datacenter. We were able to bring back the cluster. But for some reason one of the old server is still showing in. We have completely removed this node but still the master consul info shows it in the Voter list. Thoughts?

",gvenka008c,slackpad
2728,2017-02-14 03:45:31,"@slackpad I terminated the client-mode agent instead of server-mode agent. According to consul document on ""leave_on_terminate"", the default behavior of consul client is graceful leave when TERM signal is received. But the client is in ""failed"" status instead of ""left"". I also try to enable leave_on_terminate on a client agent explicitly, it does not work as well.",mikezh15,slackpad
2724,2017-02-09 20:00:40,Thanks @mpuncel that helps show that this probably isn't related to `slow_notify()` which I initially suspected. Linking https://github.com/hashicorp/go-immutable-radix/issues/11 which may be related.,slackpad,mpuncel
2724,2017-02-09 23:01:33,@cityofships and @mpuncel are either of you able to reproduce this pretty readily? I've got some tests going now to try to trigger it but haven't had any luck.,slackpad,mpuncel
2724,2017-02-15 23:00:07,@slackpad Thanks!  We were considering both approaches and will try the former,jtchoi,slackpad
2705,2017-02-27 12:42:19,"I agree with @janisz , tests take much more time now. Is it possible to minimize this?",kaskavalci,janisz
2705,2017-03-02 14:54:49,"This is still an issue in 0.7.5. My tests tooks from [20 seconds](https://travis-ci.org/allegro/marathon-consul/builds/207016255#L186) to [150 seconds](https://travis-ci.org/allegro/marathon-consul/builds/207016419#L195).

@slackpad How can I tune this to work better and be more predictable?

",janisz,slackpad
2705,2017-03-08 19:51:40,"@janisz I don't know what exactly is going under the hood when you set `raft_multiplier` to 1 but it speed up my tests. Ten invocations of starting Consul with `raft_multiplier` set to 1 took 17s and the same 10 invocations with `raft_multiplier` set to 5 took ~1m. I've prepared some test which shows difference, you can run it on your local machine:

https://github.com/pszymczyk/embedded-consul/commit/dd01686e59d314389ded726da4b49bd8a57c28da",pszymczyk,janisz
2701,2017-02-02 02:59:45,"@talonx you are correct, it does work. Some of my ansible playbooks didn't like it but its an easy workaround.",Deric4,talonx
2672,2017-01-25 07:38:14,"@slackpad thanks for the reply, I have seen that there is only one TCP connection between agent and server. But how about application to agent? Is there many HTTP Request for Blocking Query to watch key/value change?",huyjack178,slackpad
2671,2017-01-25 18:33:40,"Amazing, good job @slackpad !",jippi,slackpad
2670,2017-01-24 16:22:00,"Hey @slackpad, thanks for the response. 

I don't have access to the logs from that exact server, since we were re-imaging it. Here is the log from another consul server in the cluster:



At this point, we shut it down for re-imaging. Do the warnings indicate the leave didn't go as it should have?",duijf,slackpad
2670,2017-02-06 09:23:50,@slackpad Is there any further info I can provide here? Should I try to reproduce this? Or is that unproductive since you think it was an operator error?,duijf,slackpad
2648,2017-01-13 07:47:24,"@slackpad  I do not have any health check code in my program
I think use renew session is enough. is that true? as you say, it will be tied to the serfHealth check for the node that created the session.
I think selfHealth checked will be success, because my consul deployment is server agent and there is no network interrupt

By the way, i set LockDelay of session  is 0sï¼Œis it any problem?


",linking12,slackpad
2648,2017-01-16 02:19:29,"i have found the reason. 
the reason is when i request rest api to consul return error. and make next TTL scheduler is failed.
this is my fault. thanks @slackpad",linking12,slackpad
2640,2017-01-09 10:56:11,"Hi @moofish32 
If I understand you correctly then yes, I think this would cover my use case perfectly.

Basically, in a setup where you want to talk to the local consul agent you can simply use, in your config, ""agent.consul"" and the bind address is returned. Where you have the same service deployed on multiple hosts, with each host having a local consul agent or a pre-defined 'neighbourhood' agent, the config file for that service need not change to handle talking to the local agent.

I also think returning the advertise_addr might also be the correct behaviour if it has been overridden.

I also think this would help with people understanding that you should only ever register and modify a service with the local agent - you can't do it with just any random agent in the cluster.",far-blue,moofish32
2640,2017-02-08 03:34:11,Hey @moofish32 this looks like a good solution! I think we'd want to add a check to make sure there's nothing preceding `agent` and update the docs. It's probably fine to reuse `nodeLookup` though this technically doesn't need to go up to the Consul servers at all. That might be an optimization worth considering.,slackpad,moofish32
2640,2017-03-13 03:12:21,"@slackpad -- sorry for the delay on my end here, I missed your comment nearly a month ago. 

I updated the documentation and actually started trying to attempt the optimization. I ran in to a lot of edge cases that was making testing difficult. I started by trying to use agent config struct to pull `BindAddr` but discovered that might be `0.0.0.0`, then it might IPv6. At that point I started thinking of ways to use system calls to obtain the address and ran into the Docker deviations. 

For now, I have updated the documentation to reflect the fact a DNS lookup is going to the server for this call because I thought the edge cases would be hard to document and hard to test. Instead I was considering trying to use a caching optimization. Effectively, we know the IP can't change without restarting the agent and one dns lookup should be ok. What do you think?

I also see you cut 0.8.0, let me know if you want this in another version, branch etc.",moofish32,slackpad
2634,2017-01-06 09:44:17,"@moofish32 
Hi i have tried the same but not get any luck to resolve urlprefix issue  , 
 
 **project-stages.yml file** 

service:
    hpgdtv:
        service-name: ""GAGAN""
        service-tags: [""urlprefix-/hpgdtv""]
swarm:
    port:
        offset: 100
    consul:
        url: ""http://127.0.0.1:8500""
---
project:
    stage: production
service:
    hpgdtv:
        service-name: ""GAGAN""
        service-tag: ""/hpgdtv""
swarm:
    port:
        offset: 100
    consul:
        url: ""http://127.0.0.1:8500""

**Fabio Log and Consul log also attached , please go with once so that you can provide me better solution to fix this-**

[consullog.txt](https://github.com/hashicorp/consul/files/689496/consullog.txt)
[Fabio_log.txt](https://github.com/hashicorp/consul/files/689497/Fabio_log.txt)


",gagan2u2002,moofish32
2634,2017-01-06 12:08:24,"@moofish32: try `""tags"": [""urlprefix-/foo"", ""urlprefix-/bar""],`",magiconair,moofish32
2634,2017-01-07 02:47:28,"@magiconair  : if you looking Fabio_log.txt 
consul: Registered fabio with health check to ""http://[10.131.126.127]:9998/health""
consul: Health changed to #39
from that i understand service is passing health check.
As per the fabio log 
consul: Registered fabio with tags """"
from that statement i understand in consul tag is not set properly.

 even in console UI ,  i can able to see service GAGAN is GREEN , consul service  is GREEN and Fabio service also registered in consul and it is also GREEN but when i look routing table interface (http://localhost:9998/routes ) it will not have any records. 

can you share one example on git hub which have basic service who registered in consul and Fabio can pick this it would be a great help.

And yes i am going to open the same ticket on Fabio too.",gagan2u2002,magiconair
2634,2017-01-09 06:33:45,"@magiconair  Still i am not able to get any solution , when i am looking consul log it now say , health of service GAGAN is passing as true -
 **2017/01/09 11:43:10 [DEBUG] http: Request GET /v1/health/service/GAGAN?passing=true&wait=5s&index=117 (5.046s) from=127.0.0.1:65260**
 but still Fabio is not able to pick this -

Again i am share with you the screen shot of Consul UI , fabio_log.txt , consul_log.txt and Project-stages.yml in text format.  Please have a look and suggest me how can i resolve this issue or where i need to correct myself.
[consul_log

.txt](https://github.com/hashicorp/consul/files/692808/consul_log.txt)
![consul_ui](https://cloud.githubusercontent.com/assets/10513267/21758576/358c4608-d663-11e6-9925-c4b49d820aaf.png)
[fabio_log.txt](https://github.com/hashicorp/consul/files/692809/fabio_log.txt)
[Project-stages.yml.txt](https://github.com/hashicorp/consul/files/692810/Project-stages.yml.txt)






",gagan2u2002,magiconair
2634,2017-01-09 07:14:54,"@moofish32  Project-stages.yml is only a configuration file and if you are looking it i am able to assign helthcheck and urlprefix tags into this  and on the same time consul is able to pass healthcheck parameter as true if you are looking consul log which i shared earlier. 
So i need to understand where i am doing wrong or how can i resolve this issue as it become bottleneck for my project.

Or if you have any simple example of REST service  (like Hello world ) which is registered in consul with url prefix tags  and fabio can pick the same service then it would be helpful at my end.",gagan2u2002,moofish32
2634,2017-01-09 07:28:58,@moofish32  i have tried it as you suggest but i am getting same result :(,gagan2u2002,moofish32
2634,2017-01-09 07:31:45,"@gagan2u2002 - I would suggest opening an issue with what ever framework is reading that yml file. Consul and Fabio I believe are behaving as expected.  The most likely issue is that yml file is not getting translated correctly into a consul configuration. Perhaps @magiconair has additional experience, but I don't know the framework you are using.",moofish32,magiconair
2634,2017-01-09 07:48:45,"@moofish32 - for creating service i am using wild fly-swarm and then i will register this service in consul below is the Java code which i am using to get resource from  ""project-stages.yml"" , So i am not reading anyhow any yml file i am just get Resource from Yml and assign it to swarm container.

URL stageConfig = Main.class.getClassLoader().getResource(""project-stages.yml"");
Swarm swarm = new Swarm().withStageConfig(stageConfig);

Configuration overlays using stage properties
https://wildfly-swarm.gitbooks.io/wildfly-swarm-users-guide/content/v/2016.11.0/configuration/project_stages.html
",gagan2u2002,moofish32
2634,2017-01-09 10:42:47,"@magiconair  yes now we are on same page , this is the challenge i am facing at my end urlprefix- tag is not registered.
  i have window 7 machine with me . i have consul , Fabio and wild fly service on my box . 
To validate this point whether wildfly service have issue with consul i need to validate 
whether a  simple service is working with consul and Fabio.  **Now one quick question are you have any service example ready at your end so that i can validate this with consul and Fabio on window box.**",gagan2u2002,magiconair
2634,2017-01-10 04:31:22,"@magiconair  No i am not looking for this , i am looking for one Rest Service which i can deployed on App server like JBoss / Wildfly and then check this service integration with Consul and Fabio . Have we tested Consul and Fabio Integration with Jboss / Wildfly ?",gagan2u2002,magiconair
2634,2017-01-17 18:25:09,"@magiconair  yes it make sense to me ,   i already put this in front of wildfly swarm community too.",gagan2u2002,magiconair
2626,2017-02-13 03:23:24,"Hi @slackpad  
I'm sorry, I think it is my personal use of the error. We cluster more than 10,000 nodes, and the cluster nodes will often change, resulting in often registered service, in the DeregisterCriticalServiceAfter function before we do not deregister the service. The program we run for about a year, and now the situation is to request the registration service, the request timeout, simply traced the reason is because the request time locked for too long, I moved to a new cluster There is no such a situation.
thanks.",celeskyking,slackpad
2589,2016-12-11 16:06:10,I understand your point of view. Thank you for your quick answer @jippi.,mytototo,jippi
2589,2016-12-11 18:46:43,Agree with @jippi on this one :-) This isn't on the roadmap at this time.,slackpad,jippi
2576,2016-12-06 19:24:42,"awesome, thanks @slackpad ",chiefy,slackpad
2573,2016-12-05 21:38:10,"@brianshumate Can you include/verify samples for each?  For instance on some of the variables we require a scheme, like `unix://`, and others we don't.",sean-,brianshumate
2573,2016-12-06 17:56:48,"Hi @brianshumate 

This looks really great, and thank you so much for typing this up. I have a few concerns though:

1. This lives under the ""commands"" section, but it's not really a command. This will muck up the SEO, since the path will be ""docs/commands/environment.html"". If we ever added a `consul env` command (for some reason), this would add additional confusion.
1. There's a bit of a disconnect between this page and the CLI pages themselves. The envvars do apply to the CLI, but they technically apply to the agent. It's the agent that reads these values, not the CLI.

As such, I would provide two possible recommendations:

- Move this into an ""other"" section like [Vagrant does](https://www.vagrantup.com/docs/other/environmental-variables.html)
- Put this as its own page under the ""agent"" (https://www.consul.io/docs/agent/environment.html)

What do you think?",sethvargo,brianshumate
2570,2017-01-12 23:28:32,"Thanks for the PR, @vancluever! This is a nice piece of functionality to have alongside the EC2 join stuff.",kyhavlov,vancluever
2570,2017-01-13 00:29:55,No prob and thanks for the merge @kyhavlov!,vancluever,kyhavlov
2562,2016-12-02 01:41:32,"HI @slackpad, thank you for clarifying the about the management token, that makes sense.
I created a fresh management token and I found the following:

""failed to sync ACL changes: ACL rule compilation failed: Failed to parse ACL rules: key 'key app03acl' expected start of object ('{') or assignment ('=')

That ACL something I created using the create endpoint a while back in 0.6.3. Not sure if this significant. 

 As soon as I deleted that key sync started working for me. 

Could you clarify whether after enabling ACL syncing we we are still bounded by the TTL's of the cached tokens in the event of a network partition? 

Previously since  we use a default deny we would bump the TTLs up to something reasonably high. Is this no longer needed with ACL sync? I

ts not clear from the docs how the interaction of these three related directives:

acl_replication_token: ""xxxxx-xxxxx-xxxxx-xxxxx""
""acl_down_policy"": ""extend-cache
""acl_ttl"": ""300s""

Thanks again for your help.",cliff-ops,slackpad
2549,2017-01-11 12:24:42,"Hi @slackpad , thanks for your answer.
I think it's an other problem. Here, the problem is that there is no filtering on the catalog services end point.
Indeed, we currently have to get all existing services, or list every services we want when we use the consul discovery (e.g. with prometheus). But the list of services may change over time, and hard-coding the list of services watched in other tools that use the consul discovery become painful. It seems a good idea to allow querying the catalog using a regexp to only get a subset of services (==services that match the regexp).
This feature has already been discussed in prometheus/prometheus#2028, and it seems that the filtering mechanism should not be client-specific but should be integrated in consul.",Thib17,slackpad
2549,2017-02-08 08:53:09,"@slackpad I'm not sure this fixes anything. Our initial issue is that when you have tons of services it's more efficient to do the filtering server side. Having a single TCP connection to watch multiple services would probably work too but be way less efficient (as we would be woken up by a lot things we don't really care about).

If you think that server side filtering for the catalog is not something that will happen, that's probably fine too, but please state it explicitly so we can make progress with prometheus/prometheus#2028 :).
",iksaif,slackpad
2549,2017-03-27 06:05:31,@slackpad : any way to make progress on this ?,iksaif,slackpad
2546,2016-12-01 05:15:52,@sean- mind rebasing this to resolve the conflict?,slackpad,sean-
2542,2016-11-29 18:57:05,@slackpad   https://getkong.org/,huyifanstar,slackpad
2539,2016-11-29 09:40:38,@slackpad i am now trying a 3 node setup with 0.7.1. I'll let you know. But in any case that doesn't explain why it's trying to contact nodes on a non-existing IP i think.,thecodeassassin,slackpad
2539,2016-11-30 05:59:31,"@slackpad not possible, i create new machine images for every upgrade and replace the nodes with them. ",thecodeassassin,slackpad
2539,2017-01-16 14:53:17,"@slackpad This is still happening as of Consul 0.7.2. I create a fresh consul installation with packer and i don't start it. Then when i bootstrap the nodes the wrong ip addresses show up and consul cannot start the leader selection. I cannot explain where these 10.132.x.x ip's are coming from ðŸ˜• 



",thecodeassassin,slackpad
2535,2016-11-30 18:57:02,"@slackpad If I add & remove some keys to consul KV over a long period (say P = 1 month) of time while at any time (say T) in period P I have nearly constant count of keys, do I have to expect memory footprint grow trend?

Thanks in advance",alexeyknyshev,slackpad
2529,2016-11-28 20:49:38,"@mckennajones @babbottscott That's a good suggestion in general, but I'd keep the current behavior for Consul and not auto-create the directory. We use the presence of state in that directory to tell if a cluster is fresh and whether it's safe to bootstrap, for example, so I'd rather be conservative and have it error out. For non-servers it might be safe to create it on the fly, but that's probably too subtle/complex to have a behavior difference.",slackpad,mckennajones
2528,2016-11-22 19:58:59,"Thanks @slackpad  Given that I remove that acl_token, it still won't solve a problem of bypassing ACL, right?

Thanks!",akamalov,slackpad
2528,2016-11-22 21:15:31,"Thanks @slackpad. If you have time, would you mind pulling  and trying to run your consul off this image, please ?? Meanwhile, I will look into my Dockerfile as well... Thanks!!",akamalov,slackpad
2528,2016-11-23 13:50:29,Resolved. You were right @slackpad. I had to provide args to my Marathon JSON to point to the config file. Once done it started working. Thanks again!,akamalov,slackpad
2522,2016-11-20 02:49:08,"Hi @slackpad. I was not getting a leader election in the past and no checks were getting rpc errors, probably related to https://github.com/hashicorp/consul/issues/993 so i had added bootstrap_expect 1 on one of the nodes based on the comments.

Tried different combinations, finally had to  rm -rf /var/lib/consul everywhere  add readd bootstrap_expect 3 to get a consistent result and now i do see num_peers 2. 

Thanks a lot.
",jijojv,slackpad
2516,2016-12-29 02:53:30,"@kyhavlov @slackpad I realize this is merged, but this seemed the best place to comment about an issue before possibly opening a new bug/item. 

The TestAgent_Reload in the tests for this feature break on a machine with 2 private IP's. It took me a while to figure out how to get the output from the MockUi, (this drove me NUTS btw) but once I did it led me to the understanding that while nexConfig is called to get a config, it's never actually used to create the instance of the server used in the test. It builds a DefaultConfig on a Run(), but in that default, the bind is 0.0.0.0. If that's the bind, the agent fails to start because of the multi-private-ip issue. 

Not sure how/if this needs to be fixed. I've worked around it by simply adding a -bind to the args list for the Command. It seems odd I haven't hit this for any other tests, so I'm not sure what this test is doing that's different from the rest. I haven't dug into it deeply yet.",rhyas,kyhavlov
2482,2016-11-09 02:12:12,"Hi @amiryal thanks for opening an issue. I think this would require us to build platform-specific C code to work and we really don't want to give up Consul current status as pure Go, which makes it much easier to support multiple platforms. This kind of interface could be done as a separate project which shims these interfaces and uses the Consul API under the hood to talk to the local agent; that's probably a better approach here.
",slackpad,amiryal
2478,2016-11-07 22:24:36,"Hi @brianhays could you move this to match the parsing for the datacenter name param? https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L267-L275
",kyhavlov,brianhays
2478,2016-11-07 23:24:12,"Hi @kyhavlov thanks! I moved it to command.go as suggested and also added the validDatacenter check.
",brianhays,kyhavlov
2474,2016-11-10 11:15:51,"@slackpad I've added tests. Would you have advices regarding failing tests? I'm unable to see if it is related to my patch or not.
",kamaradclimber,slackpad
2474,2016-11-28 11:11:15,"Hi @slackpad,

I finally managed to make test pass. Would you have any feedback regarding this PR?",kamaradclimber,slackpad
2474,2016-12-16 08:50:12,I've just rebased. @slackpad any feedback?,kamaradclimber,slackpad
2474,2017-01-13 17:35:32,"Hello @slackpad,

would you have some feedback on this PR?
If it suits you, could you consider it for merge?

Thanks",kamaradclimber,slackpad
2474,2017-02-03 09:07:12,"Hello @slackpad,

would you have some comments?
Thanks,",kamaradclimber,slackpad
2474,2017-03-17 08:28:55,@slackpad @simplechris any feedback on that PR. What can I do to make it progress?,kamaradclimber,slackpad
2461,2016-12-14 23:13:29,"@slackpad I'll look at that.  In the meantime, that's pretty much what I'm getting at.  We understand that if we give it one good value, it will gossip (good), but the list given by -retry-join is never revisited, and this can cause problems as outlined above.

I'm very excited about the AWS auto discovery, but I think it might still have the same problem in the case I mentioned.",spanktar,slackpad
2432,2016-10-27 06:13:55,"@slackpad, I am not asking for running multiple consul client instances on one machine, this makes no sense obviously. actually I have a domain specific component coupled with a consul client and I want to deploy it onto a 3-nodes HA cluster. the problem is that the node name (specified by -node) for these 3 consul client instances can not be the same, otherwise 2 of them would fail to start because of the name conflict. if I name them with different names, we don't have HA anymore.  
",hehailong5,slackpad
2432,2016-10-28 01:39:46,"Hi @slackpad, I am using the agent api ([Agent](https://www.consul.io/docs/agent/http/agent.html)) to perform the service create/update/delete as suggested in the official doc. Suppose in a 3-nodes HA cluster, client1 runs on node1, client2 runs on node2 and client3 runs on node3. in a typical HA scenario, suppose the first create request hits on node1, and the client1 creates the serviceA via the agent interface. suppose a subsequent update request on serviceA hits on node2, the client2 does NOT recognize serviceA because it was registered by client1, thus the update request would return with nothing done. If the client2 performs the update via the catalog interface ([Catalog](https://www.consul.io/docs/agent/http/catalog.html)) since all the services are there, the ANTI-ENTROPY would overwrite the update with the copy from client1 within one minute. the update performed by client2 still not work. 
Hopefully I made this clear.
",hehailong5,slackpad
2432,2016-10-28 03:37:04,"Hi @slackpad, yes, in my case, the process is running on the same node where the consul agent runs, and the process always talks to 127.0.0.1:8500. I just want all the process instances manage the same a single view for each service, that's exactly what HA requires. how about this, when the create request comes to node1, the registration process on the node1 asks the client1 on the node1 to register serviceA via 127.0.0.1:8500/v1/agent; after a while, a update request on serviceA come into the cluster, and the HA infrastructure chooses node2 to serve this request, the registration process on the node2 then asks the client2 on the node2 to update serviceA, how to do it? so that any query request via Catalog api from other client will get the updated  serviceA??
",hehailong5,slackpad
2432,2016-10-28 03:51:15,"@slackpad not limited to update, how to delete serviceA from client2 that created by client1, so that the serviceA will be completely removed from catalog?
",hehailong5,slackpad
2432,2016-10-28 06:40:19,"sorry @slackpad, I don't understand why this would achieve the HA. a create, update example would help :)
",hehailong5,slackpad
2432,2016-10-28 06:49:24,"I did the same as @slackpad suggestion.
",cmingxu,slackpad
2432,2016-10-31 08:51:26,"@cmingxu , @slackpad could you please explain more about this way? in my understanding, if I register serviceA via client1 with ""deregister_critical_service_after"", I still can not modify serviceA via client2. if the ttl expires, it does not exist in the catalog anymore. what all these are to do with the HA? 
",hehailong5,slackpad
2432,2016-12-20 03:05:47,"Hi @slackpad, the services and consul clients are running on different nodes. the registrator running on the service node contacts with one consul client each time to send the add/update/delete request. the goal is to achieve the consul client side HA. is that possible?

![image](https://cloud.githubusercontent.com/assets/17330257/21336790/b5a22054-c6a2-11e6-8938-7e0c5803cc45.png)
",hehailong5,slackpad
2430,2016-11-22 17:38:21,"Hi @ross wanted to clarify did you see any health flaps _for_ nodes that were not part of this pair with duplicate IPs, or were you just seeing memberlist messages across the whole fleet related to those two nodes? The latter would be expected as the nodes fight it out, and we could see consul template being busy if quiescence wasn't set. We'd definitely not expect the former where some node outside of this pair actually has its own health affected by this.",slackpad,ross
2430,2016-11-22 19:24:46,"> Hi @ross wanted to clarify did you see any health flaps for nodes that were not part of this pair with duplicate IPs, or were you just seeing memberlist messages across the whole fleet related to those two nodes?

We were seeing consul-template restarts on nodes that matched up with the memberlist messages in the logs on that node. So somelb-ab12cd56 would log those messages and at the same point in time the restart command would fire. This happened frequently enough that things were restarting as quickly as we'd allow them. 

The conflicting nodes were just test/dev nodes that had no services on them, included in the lb's template or otherwise. I wasn't expecting the health/membership of those 2 nodes to cause consul-template to think it needs to re-generate a template and restart the services. Is that what you're saying is expected in this case? ",ross,ross
2428,2016-11-09 17:20:33,"Are you joking @slackpad? Please reopen this issue.

Something like the following causes the crash.


",pascaldekloe,slackpad
2427,2016-10-21 22:00:58,"potencially we do, i'll turn them off and compare results. thanks a lot @jippi !!
",adrianlop,jippi
2427,2016-11-02 02:41:20,"how to config to let the outputs to log file? @jippi 
",xautjzd,jippi
2427,2016-11-02 16:50:23,"Hi @adrianlop there shouldn't have been anything new in 0.7 to cause this. If you look at [telemetry](https://www.consul.io/docs/agent/telemetry.html) and look at the counts for metrics with `fsm` in the name that may help narrow down what's churning.
",slackpad,adrianlop
2427,2016-11-03 08:30:23,"hi @slackpad thanks for the help.
Please find attached some additional info. do you see anything abnormal?

consul info output:



consul monitor output:



telemetry samples (gathered using `nc -u -l` during 5sec then `| grep fsm`, this is the result):


",adrianlop,slackpad
2427,2016-11-03 17:01:58,"Thanks @adrianlop that looks like the only churn over that 5 second period is writes to the KV store. Do you have something in your infrastructure that could be writing a large-ish value some set of keys over and over? We don't have a super great way to chase that down on the server side - if you have debug logging turned on your agents (or use `consul monitor` for a little while with debug enabled) you will be able to see the requests to /v1/kv on the agent side.
",slackpad,adrianlop
2427,2016-11-04 10:47:20,"@slackpad thanks a lot for the help! that's it.
we're using [consul-alerts](https://github.com/AcalephStorage/consul-alerts) for a basic alerting system on top of consul, and it's writing to the KV its own healthcheck info to compare previous data and generate alerts.
I'll try to tweak this tool to reduce intensive KV writing.
",adrianlop,slackpad
2424,2016-10-19 15:33:50,"Hi @sobertooth I think @jippi is right here. Haven't used consulate too much myself, but it looks like the datacenter gets configured for the client itself, not per-call - https://github.com/gmr/consulate/blob/master/consulate/__init__.py#L51.
",slackpad,jippi
2417,2016-11-03 19:57:46,"Thanks @moofish32!
",slackpad,moofish32
2407,2016-10-17 20:59:28,"@slackpad potentially, I've been running 0.7.0 with Sierra for a while now and not had problems. Just wanted to post for posterity. If I can help out any further let me know. It might help if @nugend posted the output of `go env`
",charliestrawn,slackpad
2407,2016-11-08 14:41:34,"Thanks @magiconair and @lowzj. We got Go upgraded to 1.7.3 last night via https://github.com/hashicorp/consul/pull/2281 so that should fix this for the next release.
",slackpad,magiconair
2407,2016-11-08 15:06:44,"@slackpad any ETA for the next release?
",Sandmania,slackpad
2405,2016-11-18 03:36:52,"Hi @slackpad  
Beacuse of we need to send a lot of http requests for getting  or checking status for a group of service.
This can be a time-consuming operation for applications.
So we need a  batch interface.
",stevenLX,slackpad
2405,2016-11-18 08:11:24,"Hi @slackpad
Not only for dashboard.For example,I write a application need access muti services,  so I need get the service's info (inculde regist info and health status)from consul.At this moment I should call the same http api muti-times, and wait for all responses back. It is a time-consuming.
So, Could I push the batch interface for this kind of case?
",stevenLX,slackpad
2403,2016-10-07 22:40:51,"@slackpad I could sniff the transaction and/or point the test code above to a dummy webserver.  What I have tested:
- Curl with a header _or_ a query parameter _works_ against a v0.7.0 server
- The v0.7.0 API does _not work_ with client config set to use a token against a v0.7.0 server
- The v0.7.0 API does _not work_ with QueryOptions passed with a token to a v0.7.0 server
- The v0.6.4 API using the exact same code above _works_ against a 0.7.0 server

I suspect the header is not being passed by the v0.7.0 API with either the client config or the QueryOptions set.  I will try and get confirmation though by using a dummy http server.
",leprechau,slackpad
2403,2016-10-07 23:47:49,"@leprechau thanks for the repro case. This is super weird as I see the token header going into the `Do()` call for the request in both examples. Will keep tracing this.
",slackpad,leprechau
2403,2016-10-11 00:01:23,"Hi @leprechau I think the root cause of this one is https://github.com/golang/go/issues/4800. With older versions of Go, the HTTP client will drop the headers when it is following redirects. It looks like a fix for this is teed up in master and will go out with the next release of Go, but in the meantime, if you get rid of the slash you won't get the redirect and the headers will display:



Your sample app happened to have the same behavior as Consul because it was querying with a double slash. I think we should make the API client smarter and drop any leading slash in the KV path, since it's not necessary.
",slackpad,leprechau
2403,2016-10-11 02:45:57,"@slackpad Interesting ... that makes sense.   I also agree about enhancing the API client to not hard-code the prefixing slash when making requests.  That was a rabbit hole.
",leprechau,slackpad
2393,2016-10-06 15:32:51,"@blalor thanks for opening an issue and sorry for the confusion. We will get this cleaned up!
",slackpad,blalor
2390,2016-10-09 04:12:36,"Hi @slackpad , this was indeed the problem. I can confirm it now works.

This was due to registrator, we had passing --ip, once this was removed, this works as intended.

Although this causes a problem now with the consul HTTP healthchecks, since consul does a GET on it, since there is no IP for $SERVICE_IP, those health checks will fail. Is there anyway to tell consul to use its own local lan IP, as the lan and wan IP show up properly, but not its service IP, so it can't run it's health check. 

I am a little afraid to enable in registrator the --internal option, but not too sure if this will mean it will register that now as the SERVICE_IP, and then I would lose my wan/lan capabilities.
",JoeOrtiz,slackpad
2382,2016-10-20 16:41:28,"Thanks @zaunerc that's a good addition.
",slackpad,zaunerc
2375,2016-11-21 11:30:15,@slackpad done. And thanks for your advise.,xychu,slackpad
2374,2016-10-20 16:37:27,"Hi @slackpad, no it never comes back to normal, cluster needs to be bootstrapped from scratch. I waited an hour or two,  logs continue same as in Log Fragments.
",muradm,slackpad
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,slackpad
2374,2017-01-13 16:49:37,Nice @slackpad! Whats the ETA for 0.8 launch?,galindro,slackpad
2374,2017-01-14 01:38:23,"Hi @slackpad, does it mean the recovery policy would change? the peers.json with ips will be abandoned? currently my script is dependent on the ip based peers.json for all the recovery scenarios. hopefully it would still work till then.",hehailong5,slackpad
2371,2016-09-29 13:37:48,"@ryanslade you might want to update your code URLs to point to specific commits and not master. Your links may break if anyone changes those files.

Not sure if you know this trick, but if you press your `y` key while viewing source code in GitHub it'll change your URL to the specific commit. `https://github.com/hashicorp/consul/blob/master/api/lock.go#L132` became `https://github.com/hashicorp/consul/blob/d5b7530ec593f1ec2a8f8a7c145bcadafa88b572/api/lock.go#L132`.
",theckman,ryanslade
2371,2016-10-06 01:03:28,"Hi @ryanslade thanks for opening an issue. We should definitely document this and I'm not totally sure if we should change the behavior. It seems like we should stop updating the session whenever the leader channel closes, but I'd need to think through if there are any other implications if we change that.
",slackpad,ryanslade
2365,2017-02-11 01:41:40,"@kyhavlov fwiw, `consul lock -http-addr=127.0.0.1:8501` works for me also, with
",wyardley,kyhavlov
2363,2016-09-27 15:35:13,"Hi @slackpad, I was indeed thinking about the effect of big values would have on replication just after I submitted this. I'll open one at TF to check there what can be done.
Since Consul now supports transactions for updating multiple keys, perhaps splitting the state could be the way to go.
",gpaggi,slackpad
2360,2016-09-26 21:44:07,"@sethvargo that failing test is a known flaky one unrelated to this - sorry about that.
",slackpad,sethvargo
2350,2016-09-24 01:13:22,"@mckennajones awesome! I think the `=` matches more of what's there and is clearer when reading documentation.
",slackpad,mckennajones
2348,2016-09-21 04:09:21,"Hi @pszymczyk thanks for opening an issue an PR but I have to agree this is kind of an anti-pattern. There are good tools for pre-vetting config, and depending on where the typo is you might end up in a dangerous state so it's much safer to have Consul bail out when given a bad config. As @daveadams hinted, you should be able to use https://www.consul.io/docs/commands/configtest.html even as part of Chef or Puppet to stop early.
",slackpad,pszymczyk
2348,2016-09-21 04:09:21,"Hi @pszymczyk thanks for opening an issue an PR but I have to agree this is kind of an anti-pattern. There are good tools for pre-vetting config, and depending on where the typo is you might end up in a dangerous state so it's much safer to have Consul bail out when given a bad config. As @daveadams hinted, you should be able to use https://www.consul.io/docs/commands/configtest.html even as part of Chef or Puppet to stop early.
",slackpad,daveadams
2348,2016-09-21 07:12:43,"@daveadams @slackpad thanks for feedback, I will try to implement `consul configtest` before restart Consul process. 
",pszymczyk,slackpad
2348,2016-09-21 07:12:43,"@daveadams @slackpad thanks for feedback, I will try to implement `consul configtest` before restart Consul process. 
",pszymczyk,daveadams
2347,2016-09-27 07:05:43,"Thank you very much!!! @slackpad 
",zhaojigang,slackpad
2335,2016-09-13 15:32:29,"Hi @pszymczyk thanks for the feedback on the RC build! There's a 512 byte limit for UDP responses so that can affect the number of results, especially if you have a long service name. Does that seem like it could be the case here?

If you query by TCP you'll get all of them, and the UDP results are shuffled, so if your app is trying the first entry it will get a different one there if it re-queries.
",slackpad,pszymczyk
2331,2016-09-08 08:32:53,"@moofish32    thanks
",junneyang,moofish32
2325,2016-09-05 17:42:16,"Hi @janisz thanks for opening a PR. I've got one here https://github.com/hashicorp/consul/pull/2281 that had to deal with a few library changes related to TLS that came along with 1.7. Also, there's still a remaining issue with the unit tests that I haven't had a chance to track down yet, so we aren't quite ready to upgrade until that's done.
",slackpad,janisz
2317,2016-09-01 15:25:52,"Greetings, @slackpad.
I had thoughts that this system might result in problems with multi-node configuration on non-leader nodes.
As of now I'm working on a coreos/flannel change that would allow to use consul as one of the variants alongside etcd. From what I understand, flannel depends on TTL behaving like in etcd, as in reflecting the real time of the key's life.
The key's TTL in flannel is set at 24 hours, and with that it's presumed that even when flannel is turned off it'll be possible to restore the configuration if that time didn't run out.
",illeatyourheart,slackpad
2314,2016-09-20 23:45:48,"Hi @janisz and @kshep, some health checks can be expensive, and multiple services might get registered all in one go, such as with a `consul restart`, so we always stagger them to try to randomize their phase. You can set the initial health state, so you can default healthy or unhealthy until the first check. Having it not show up until it has run the first check is an interesting idea. It's practically the same as starting it unhealthy, but I could see how you might care about that if you have monitoring set up.
",slackpad,janisz
2299,2016-08-23 16:29:25,"Hi @far-blue - what uses were you thinking of? We probably should just have Consul tag itself automatically for most things (leader, follower seems like a good one for servers), any other use cases you had in mind?
",slackpad,far-blue
2297,2016-08-24 09:33:03,"@slackpad it seems most connection don't show a remote port in the lsof. They just read:
consul  8566 root 1020u     sock       0,6      0t0 255716323 protocol: TCPv6
",arie-stratoscale,slackpad
2263,2016-09-02 05:16:33,"@sweeneyb thanks for the PR!
",slackpad,sweeneyb
2248,2016-11-10 01:52:39,"@slackpad I would like to take a Look. Can you assign the issue to me? 
",lucasalcantara,slackpad
2224,2016-07-29 17:53:26,"Hi @brianshumate this is a great idea and is definitely an FAQ :-) There are some other ports we use, so it would be good to clarify this FAQ as ""between Consul agents"" and link to [docs/agent/options.html#ports](https://www.consul.io/docs/agent/options.html#ports) or replicate the full list here.
",slackpad,brianshumate
2224,2016-07-29 18:34:28,"Thanks for the feedback @slackpad!

I think the FAQ should probably just point the reader to the ports as already described at [Ports Used](https://www.consul.io/docs/agent/options.html#ports) instead. It was a bit tough to discover and maybe being linked from the FAQ page will help with visibility.
",brianshumate,slackpad
2223,2017-02-13 10:18:30,"Hi @slackpad 

The behavior is the same using the agent API and definitely doesn't match the documentation. Adding a service via v1/agent/service/register:


Ends up being registered as:

![consul](https://cloud.githubusercontent.com/assets/13365164/22879315/c19960c8-f1dd-11e6-9e41-8a5438be78ec.png)

Version tested: 0.7.3
",user31459,slackpad
2219,2016-08-13 00:20:41,"Hi @maxvt thanks for the PR! I've done a rebase under #2271 and make a couple tweaks to the unit test.
",slackpad,maxvt
2217,2016-12-02 14:55:29,"@mfischer-zd , while this doesn't address the binding to multiple IP addresses portion of your issue, there is code in `master` now that will let you bind to an IP on a named interface:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,mfischer-zd
2217,2016-12-02 20:42:45,"That's great news, @sean- .  Let me know how I can help finish the work.",mfischer-zd,sean-
2216,2016-07-29 12:41:25,"@highlyunavailable yes, it's the same issue.
",WoZ,highlyunavailable
2210,2016-08-11 11:24:54,"@jhmartin should this issue not be https://github.com/hashicorp/docker-consul ?
",swade1987,jhmartin
2203,2016-07-26 20:17:30,"@slackpad Thank you for the quick response! Quick question regarding release:

This issue represents a significant bug in our deployed software today. Do you guys have any intention of releasing a patch (0.6.5) or an ETA on the next minor release (0.7.0)? If not, we will need to produce and deploy an in-house build with the bolt db upgrade. Thanks!
",autoric,slackpad
2203,2016-07-27 15:09:57,"Hey @slackpad, I code reviewed what you checked in and then did a build of `master` on `windows 2000 R2` using `TDM-GCC` tool chain, and ran gatling against it with the boltdb upgrade.  `raft.db` was able to expand beyond `65 MB` to `256 MB` without any issues.

Test run was from @Tzinov15 here:
[SlamKeyValue](https://github.com/Tzinov15/GatlingConsul/wiki/Running-Gatling)

Here are the metrics from SlamKeyValue if you're curious (everything is ms and OK means REST response 200, KO means non REST 200 was returned, and a `-` means no KO):



The other 2 stress tests look to be passing as well.

Only artifact from upgrading boltdb I noticed was that `raft.db.lock` is a new file which shows up when boltdb opens the memory map.  Once it releases the memory map, the `raft.db.lock` file goes away.
",FrankHassanabad,slackpad
2200,2016-07-21 15:57:08,"@slackpad so we did some thorough network related testing and were able to confirm that all nodes are able to communicate over UDP on port 8301 (we are using default ports). We made sure to investigate those avenues before opening up an issue. 

The one thing that did show up was that the consul servers did not seem to be probing each other (via UDP on 8301). This behavior differed from our other clusters in that, while not that often, that traffic was being sent. While that is not definitive (those packets might be tried at some point either before or after we were monitoring), no UDP send or receives showed up between the consul servers themselves (monitoring done via tcpdump). 
",carkmorwin,slackpad
2200,2016-07-26 15:13:23,"@slackpad thanks for the info, will look into this further. 
",carkmorwin,slackpad
2188,2016-07-18 18:21:46,"Hi @maier noted a few small things in comments but otherwise looks good. We'd need to update the vendored go-metrics (I can do that after pull if you'd like) as well as the documentation (it's in the same repo here under website).
",slackpad,maier
2188,2016-07-18 20:28:24,"@slackpad  I haven't used godep before and it isn't cooperating with me. I don't want to break anything so, I'll leave that one to you (if you don't mind). I did update the documentation, I believe I added the configuration setting information in the right location.
",maier,slackpad
2185,2016-07-19 09:05:38,"@slackpad Updated with that change, cheers.
",richard-hulm,slackpad
2179,2016-11-18 00:08:33,"@sean- any thoughts on this one? I don't fully understand what the difference is here.
",slackpad,sean-
2176,2016-07-14 06:54:51,"Hi @akbarahmed you are correct - that's an error. Appreciate the offer for a PR!
",slackpad,akbarahmed
2176,2016-07-14 20:38:44,"@slackpad I'll work on submitting the PR before Sunday. Knee deep in some complicated code...so I'll get this done when I need a breather.

BTW, thanks for releasing Consul. We're loving it.
",akbarahmed,slackpad
2175,2016-07-10 20:26:20,"@armon this looks great! One tiny comment and it would be good to add a unit test for this :-)
",slackpad,armon
2173,2017-01-05 12:29:36,hi @slackpad can you share me how to use Catalog API to register a service without running an agent,bhargavchukka234,slackpad
2172,2016-07-07 18:42:02,"@slackpad only the node names, the ip addresses stayed the same.
",zankich,slackpad
2172,2016-07-07 23:04:03,"@slackpad we would like to change our orchestration to detect whether the cluster is scaling down vs. being rolled, and either leave or pull the plug accordingly.  Right now, we can't change that, and it will always leave.

We want to consider the following option:
1. Tear down the existing cluster (each node doing a ""leave"") -- we will lose all data with this, which is okay.
2. Bring up a brand new cluster with new names, but at the same old IPs.
3. Somehow make sure all clients can start talking to the new cluster without having to roll all clients.

We don't have control over the teardown logic, but we do have control over the startup logic.  We're concerned that when all the nodes leave, the clients will forget about them, and then when the nodes come back up, the servers (having lost all data) won't know about clients, and the clients have no reason to remember the servers because they've received the leave announcements.  Is there a way on startup for the new servers to reannounce themselves to the clients, assuming we could tell them a list of client IPs?  If so, would we need to know all client IPs or just some, and then rely on Serf to propogate the presence of the new servers to the rest of the clients?
",Amit-PivotalLabs,slackpad
2172,2016-07-08 18:07:43,"Thanks @slackpad, good to know we have that option.  One more question, let me know if you'd rather I start a different issue or ask on the mailing list instead, but if I have access to a node's raft.db, is there any way to determine what its name was before being shutdown?  The scenario I'm imagining:
- 3 node running cluster, under one naming convention
- one node leaves, stops, disk is detached, new VM is created, old disk re-attached, and something on the new VM deduces what the node's name was based on what's in raft.db
- the consul server is started on the recreated node, being fed its old node name.

Would there be a way to find out what the node name was for the VM I'm on?  Would probably need to be able to do this without the Consul server running, since by then the server needs to have a node name given.  And I believe this rules out obvious things like running `consul members` or something like that.
",Amit-PivotalLabs,slackpad
2172,2016-07-12 01:37:52,"Thanks @slackpad!

We'll have a think about using that, but we have a workaround if there are any issues with it.  As usual, thanks for all the help.
",Amit-PivotalLabs,slackpad
2172,2016-08-08 08:09:56,"@slackpad do you have any insight on what's happening here? Can we rename a server while keeping the same ip address?
",iverberk,slackpad
2166,2016-07-05 19:15:46,"@slackpad how would i check this for sure - not wanting to confuse you. What i do to register this service is



And then i restart consul to pick up the service. The node does not have any checks. You should even see this issue in the node-list:

https://goo.gl/vj7Fyf

As you see, i can see the services when selecting the node. As you see, since the UI has yet no token, you see all nodes have 0 services ( on the left side ) listing the services looks like this https://goo.gl/ixSxej

It should be pretty easy to reproduce and you see this issue gets visible from different angles.
",EugenMayer,slackpad
2154,2016-06-30 15:54:09,"@slackpad Slackpad. Rereading the documentation I now see that the `consul lock` command doesn't restart a command! ðŸ‘  Closing this!
",JensRantil,slackpad
2153,2017-02-23 18:06:08,"(just seeing this now). @brianshumate Nice! Thanks for doing this work, it will be very helpful.",dnblankedelman,brianshumate
2152,2016-06-29 22:07:23,"@slackpad Thanks you for a quick reply.
I really glad to hear what some work is done towards this issues, but about logging, there is TCP ping log here: https://github.com/hashicorp/consul/blob/v0.6.4/vendor/github.com/hashicorp/memberlist/state.go#L292 and I wonder why I can see it in my logs
",Oloremo,slackpad
2152,2016-07-01 12:32:47,"@slackpad I think this is the same as https://github.com/hashicorp/consul/issues/916 right?

Did you see my last comment on this topic? 
",rgardam,slackpad
2151,2016-06-29 20:22:11,"@slackpad - you're right, it all depends on the use case. Gave the `RemoveEmptyTags` a try - with just the basic test in place.
",tpotega,slackpad
2148,2016-07-06 14:58:54,"Hi @rboyer sorry for the delay - working through a review backlog but this should make it into the next release for sure - looks like a good change.
",slackpad,rboyer
2145,2016-06-28 06:56:19,"Hello @slackpad . That's great. I actually didn't find it because I searched on 'ui'.
I went through the code quickly and it seemed like a lot of work already, thank you.

Support for something like copy-tree and move-tree would indeed be interesting for a lot of people in my opinion. It would allow to easily switch between two configurations or test some settings while making a sort of local backup of the current state.
",EvertMDC,slackpad
2142,2016-06-23 18:28:20,"@slackpad thanks for the feedback.

Here is the log:



what I noticed is after consul boots, eto0 comes up:



Thoughts on how to make consul wait to start?
",clintonm9,slackpad
2141,2016-08-11 01:10:18,"Hi @rboyer thanks for the PR! This is a common use case so I think we want something like this. Once we get 0.7.0 out I'll give this some cycles.
",slackpad,rboyer
2139,2016-08-11 07:36:05,"Hi @slackpad, you can close this, I was being stupid and not querying the services correctly. Sorry for the trouble.
",byrnedo,slackpad
2137,2016-06-22 02:57:15,"@ryanuber took a look through and added some comments - this is looking good! I think the `.Source` thing is the biggest change since that's already there, otherwise some minor stuff.
",slackpad,ryanuber
2137,2016-07-01 00:20:04,"@ryanuber looks good! I still think we need to revert the `parseSource()` changes and the only other thing is to mention this in the docs. Otherwise, :shipit:.
",slackpad,ryanuber
2120,2016-10-21 14:10:14,"@slackpad I am seeing the same error on all my 3 nodes



Here is the config for bootstrap node



Here is the config for 2 other nodes



Here is the consul version



Thoughts?
",gvenka008c,slackpad
2118,2016-08-15 23:16:27,"Hey @DWvanGeest thanks for the PR and sorry for the delay. I did a little follow on work for this under #2275 and will be merging here in a sec. Code looked great!
",slackpad,DWvanGeest
2113,2016-08-11 00:58:19,"Closing as we haven't heard back (thanks for the help @tiwilliam)! Please let me know if you are still running into issues.
",slackpad,tiwilliam
2086,2016-06-02 20:04:19,"@slackpad what is the expected i/o rate for consul from your experience?
The base is 4 nodes cluster, with 3 servers.
",rom-stratoscale,slackpad
2082,2016-06-01 14:11:27,"@c4milo yes, everything is fine in the network.

What about suspect message?
",shakisha,c4milo
2082,2016-06-01 15:43:58,"Hi @shakisha, @c4milo is correct - this looks a lot like there was a temporary network disruption on that node that caused the server to close the TCP connection to this agent and caused other nodes to think the agent was failed. This can be caused by problems with the network itself, or it's also common on cloud platforms like AWS with small instance types where periods of high activity can steal resources from network packet processing and cause high packet loss. From the log I don't think Consul actually crashed, it seems like it's starting to recover near the end there (seeing some suspect messages from other nodes thinking it's down), though there are still i/o timeouts so it looks like it's not fully back yet. I suspect that if you ran a network test when this was happening you'd see heavy packet loss independent of Consul.
",slackpad,c4milo
2080,2016-06-01 07:34:00,"Hi @slackpad running consul in three server, when reboot one server would not affect the cluster, until leave all the consul then need us to recover manually.   do i understand right ??? 
",zackshen,slackpad
2080,2016-06-02 02:05:30,"@slackpad  thank you very much!
",zackshen,slackpad
2063,2016-05-31 14:36:01,"@ross sorry for the delay - I'll pull this down locally and take a look soon. Definitely interested in seeing this land!
",slackpad,ross
2063,2016-05-31 14:49:20,"> @ross sorry for the delay - I'll pull this down locally and take a look soon. Definitely interested in seeing this land!

No worries. Just wanted to make sure before I put a bit more time in to clean it up, both visually and code-wise. I should get to that in an evening later this week or early this weekend.
",ross,ross
2063,2016-08-10 23:57:18,"Hi @ross sorry about the delay on this one. I ended up making a tiny JS change over in https://github.com/hashicorp/consul/pull/2251 that I think we will need to rebase and port over here. There was a JS error if coordinates were not available. I can help you rebase, or if you'd like to we can get this in - please let me know!
",slackpad,ross
2063,2016-08-11 01:00:34,"Hi @slackpad. May be best for you to rebase & fix as it'll take me a bit before it'd get back to the top of my todo list.
",ross,slackpad
2062,2016-05-28 09:10:38,"@slackpad Thanks James!
",sspreitzer,slackpad
2056,2016-08-11 16:10:40,"@slackpad Nope. Just checked again and did not see anything in stderr log when starting. I also tried restarting rsyslog before starting consul with syslog enabled, but that did not seem to work or showed anything in stderr log. 
",carkmorwin,slackpad
2054,2016-08-03 05:13:50,"Thanks for the review and comments @ryanuber. I followed all of them (I think).

After following your suggestion to check the result from `cmd.Wait()`, I discovered that `cmd.Run()` calls `cmd.Wait()` under the hood. This meant that, previously, my explicit call to `cmd.Wait()` was redundant, and was producing a [""wait already called""](https://github.com/golang/go/blob/master/src/os/exec/exec.go#L430) error. So, I removed that line of code. 

So far, the only error I've gotten from  logging the error from `cmd.Process.Kill()` is, on occasion, [""os: process already finished""](https://github.com/golang/go/blob/master/src/os/exec_unix.go#L53). I'm able  to produce this by terminating the watch process is terminated with `Ctrl-C`. I'm not sure how to get around this error. It seems pretty harmless; not worth doing a `goto ERR` for, I think.
",maxenglander,ryanuber
2046,2016-05-17 16:56:50,"@ross Looks super great!
",armon,ross
2046,2016-05-17 17:00:02,"@ross My only ask is to use the median distance instead of average, since you have it sorted and its less likely to get affected by outliers
",armon,ross
2046,2016-05-17 17:46:05,"> @ross My only ask is to use the median distance instead of average, since you have it sorted and its less likely to get affected by outliers

Updated version with median in place of average. 

Do you want the hover behavior, https://github.com/ross/consul/commit/a8370a0de9d0a78fb568f58b6867021f319fcb85, as-is? It's really nice functionality, but the implementation is lacking due to me knowing nothing about Ember.js
",ross,ross
2046,2016-05-17 18:39:59,"@ross I haven't played with it, but I worry it might be unwieldy for large clusters where there are too many nodes.
",armon,ross
2046,2016-05-17 19:31:04,"> @ross I haven't played with it, but I worry it might be unwieldy for large clusters where there are too many nodes.

Not sure if you're referring to the hover behavior or this PR in general. I've tested with with a couple thousand lines/nodes (by faking more data) and that works fine. Past that the svg rendering starts to bog down. 

My thought was to sample data (every Nth node) past some reasonable value, probably a few hundred, so that the chart would never be too bad and still be representative of the whole. 
",ross,ross
2046,2016-05-18 05:06:36,"Hi @ross thanks for this! Left a few comments - let's go ahead and add the mouseover as well. I like the down sampling - that seems like it should be effective for large clusters.
",slackpad,ross
2046,2016-05-19 02:07:03,"@ross thanks again!
",slackpad,ross
2039,2016-08-10 23:46:14,"Hi @jlambert121 thanks for the PR! I'm working on getting the 0.7.0 release right now but I'll try to give this some cycles soon.
",slackpad,jlambert121
2038,2016-05-12 02:17:59,"Hi @slackpad this isn't causing any problems, it was just a little off to me.. I can add additional logic around this.
",dmyerscough,slackpad
2027,2016-08-10 20:55:24,"@daveadams thanks for the suggestion - I agree this would be super useful. I think Vault has a similar concept via ""token accessors"".
",slackpad,daveadams
2025,2016-05-05 17:47:10,"@slackpad thanks for the response. I'm curious what the perms should be. 
",fxdgear,slackpad
2025,2016-05-05 18:13:43,"@slackpad so for a bit more info I'm using


",fxdgear,slackpad
2025,2016-05-05 18:30:08,"@slackpad ahh sorry I realized this is an issue with docker-machine and not with consul. :( 
",fxdgear,slackpad
2025,2016-06-09 09:14:45,"@jhmartin I'm having this issue on a fresh Ubuntu 14.04 server box (no SELinux).
",deviantony,jhmartin
2025,2016-06-09 14:38:41,"@slackpad 
do you mind letting us know which issue in [https://github.com/hashicorp/docker-consul ](url) tracks this one here ?

@jhmartin 
the z or Z options do not work for me

Ubuntu 16.04 , no SELinux,  
$ docker version
Client:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

Server:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

# docker logs:

$ docker logs consul
WARNING: ca_cert.pem does not contain exactly one certificate or CRL: skipping
WARNING: ca-certificates.crt does not contain exactly one certificate or CRL: skipping
WARNING: ca-cert-consulca.pem does not contain exactly one certificate or CRL: skipping
==> WARNING: Expect Mode enabled, expecting 3 servers
==> Starting Consul agent...
==> **Error starting agent: Failed to configure keyring: mkdir /data/serf: permission denied**
",barbarello,jhmartin
2025,2016-06-09 14:38:41,"@slackpad 
do you mind letting us know which issue in [https://github.com/hashicorp/docker-consul ](url) tracks this one here ?

@jhmartin 
the z or Z options do not work for me

Ubuntu 16.04 , no SELinux,  
$ docker version
Client:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

Server:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

# docker logs:

$ docker logs consul
WARNING: ca_cert.pem does not contain exactly one certificate or CRL: skipping
WARNING: ca-certificates.crt does not contain exactly one certificate or CRL: skipping
WARNING: ca-cert-consulca.pem does not contain exactly one certificate or CRL: skipping
==> WARNING: Expect Mode enabled, expecting 3 servers
==> Starting Consul agent...
==> **Error starting agent: Failed to configure keyring: mkdir /data/serf: permission denied**
",barbarello,slackpad
2022,2016-06-03 22:40:32,"@evan2645 sorry about that - I'd definitely take a PR to update the docs and push that out while we work on the fix.
",slackpad,evan2645
2022,2016-06-04 00:31:41,"@slackpad no apology needed :) opened https://github.com/hashicorp/consul/issues/2090
",evan2645,slackpad
2017,2016-05-04 00:48:19,"@clstokes definitely an issue! Submitted a pull request to fix.
",captainill,clstokes
2015,2016-08-18 02:07:03,"Closing this out as this isn't the behavior we'd like, since Consul handles the AND-ing of the dependency on the serfHealth check under the hood. Please let us know if there's any follow up from @sean-'s comments that we can help with.
",slackpad,sean-
2011,2016-08-10 20:38:34,"@slackpad thanks, I'll give that a try!
",devth,slackpad
2006,2016-04-29 08:41:59,"Hi @fusiondog .  Thanks for the suggestion.  Can you add a small bit to this that includes a reference to the `recursors` option?  Without at least one specified, users with this configuration will have a hard time resolving non-Consul addresses.  In general we recommend a caching DNS service vs relying exclusively on Consul because Consul does not cache, it forwards.  Thanks!

https://www.consul.io/docs/agent/options.html#recursors
",sean-,fusiondog
2006,2016-06-02 23:08:40,"Hey @fusiondog, ah yes I forgot to mention that. I use recursors option actually, when I haven't applied the iptables rule everything was fine, I can resolve other TDL such google.com with this command `dig @localhost -p 8600 google.com`, but after I applied those rules I mentioned above, suddenly I couldn't resolve any host other than consul. Do you know why it's happen?
",akurniawan,fusiondog
2006,2016-06-02 23:43:52,"@fusiondog the recursors is on the same system.
Here is the output from `iptables -L -t nat`



Here is the output from `tcpdump -ni any udp port 53`


",akurniawan,fusiondog
2002,2016-06-22 09:34:40,"@sean- @slackpad 
Any update on this PR?
We hit the similar issue about the DNS retry.
",bingosummer,sean-
2002,2016-11-17 23:57:49,"@sean- any thoughts on this one? We added the RPC hold timeout which paves over leader elections and we've made allow_stale opt-out with aggressive max_stale, so we may be able to call this good enough for now?
",slackpad,sean-
1988,2016-04-27 06:55:05,"Hi @jippi it's definitely true that not everybody will want to use the official image, but it's pretty simple to configure something outside of Consul to do the reaping in your own container, so we will document that. The [reap lock](https://github.com/hashicorp/go-reap/blob/master/reap_unix.go#L23-L29) is just plain ugly and it's super easy to forget to do it in the code and introduce subtle errors, so that doesn't seem worth the liability. Adding reaping inside the container was basically just a matter of including `dumb-init` and adding a [single line](https://github.com/hashicorp/docker-consul/blob/master/0.6/docker-entrypoint.sh#L1) to the entrypoint, which is a lot cleaner.
",slackpad,jippi
1988,2016-04-27 07:57:53,"@slackpad alright, kill it with fire then :)
",jippi,slackpad
1986,2017-01-13 03:28:22,"@kyhavlov i am not familiar with how to get Chrome to pass a cert request to the UI.
I can understand needing it for api requests, but not the web ui",shortdudey123,kyhavlov
1984,2016-07-05 20:19:26,"Hey @kylemcc, this looks great! Just a few minor comments but otherwise LGTM. Sorry for the delay!
",ryanuber,kylemcc
1984,2016-07-07 16:38:07,"@ryanuber I've made a few changes based on your feedback. The test failure here seems unrelated to my changes - it may be due to my rebasing on top of master. They do pass for me locally though.

Let me know if you have any other feedback.
",kylemcc,ryanuber
1984,2016-07-07 16:47:54,"@kylemcc great, will review again shortly!
",ryanuber,kylemcc
1984,2016-07-19 15:20:28,"@kylemcc I added a [PR](https://github.com/kylemcc/consul/pull/1) to your branch to include TLSSkipVerify in the api. Please review before this gets merged!
",cavemandaveman,kylemcc
1983,2016-04-25 00:03:50,"Hey @slackpad, thanks for the suggestion, but apparently no dice:



(I also tried `CGO_ENABLED=1`, just in case of typo, but that's no good either).

After some more digging, turns out this is a false alarm: I upgraded Go to 1.6 over my previous installation (because I missed the bit about removing the old Go install first) and now all appears to be well.  Sigh... that's Monday morning for you...
",mpalmer,slackpad
1969,2016-07-17 11:56:45,"@slackpad this is great! Do you have any idea when we might get a first drop of this, ideally as a release, but if not then as a master commit we can at least test/build off? Thanks :)
",nickithewatt,slackpad
1969,2016-09-28 14:17:11,"Hi @slackpad - did this change make it into the 0.7 release? I've seen the new performance config in 0.7, but even with the defaults we're still seeing timeouts when a consul server is destroyed and replaced with a new node in AWS. Server nodes are `t2.medium`s, but even then, we get timeouts which trigger leader election.
",madAndroid,slackpad
1969,2016-09-30 06:20:03,"@slackpad - We're still seeing the same behaviour, I'm afraid :(

We have 3 server nodes, one per AZ .. and we've now bumped these up to `m3.medium`'s, and have set `raft_multiplier` to 8 .... when we randomly killl one of the servers, ASG event kicks in, and replaces that box ... and when it comes back up, it attempts to join the rest of the cluster (at this point we still have a leader, since the quorum of 2 ensure that) ... it joins at first ... then we see heartbeat timeouts, and a leader election triggered on the node that attempts to join. The remaining two nodes reject the election request, and this continues



Config:



When the leader election is flapping we see this when running `consul operator raft -list-peers`


",madAndroid,slackpad
1969,2016-10-06 06:32:06,"@slackpad - I'll need to do some more testing, but most recently I've seen that the node that joins will enter this flapping state for some time; during this time, the instance will appear to connect, logs indicate that it joins.. then the heartbeat fails, and it reenters candidate mode; the other two nodes don't enter that same state: they reject leader election requests from the node that enters candidate state with messages saying ""Rejecting vote request from 10.206.54.87:8300 since we have a leader"". The cluster does eventually stabilise, after an extended period of time - not sure exactly how long this continues for, but during this time anything that's using Consul for discovery and/or DNS endpoints, is in an unknown/unstable state.

I'll do some more testing and post more findings here
",madAndroid,slackpad
1965,2016-06-11 02:35:37,"Hey @fusiondog 

Stumbled upon your work when I was reading the mailing list and this really fits into what I'm experiencing as well.

I'd love to get Consul to output to graphite and have this kind of handler.

Have you been updating any of this work lately?

Perhaps we can discuss this with @armon as well in regards to getting the ball rolling again here? :)
",cdrage,fusiondog
1965,2016-08-11 00:32:44,"@fusiondog thanks for the PR! I'll try to give this some cycles once we ship 0.7.0.
",slackpad,fusiondog
1958,2016-04-18 15:03:08,"Thanks @moofish32, but you may didn't understand my question, so thanks, I will clear it up.
I already setup my env, including the consul cluster.
My scheduling process runs only after Terraform finished to setup the env.
btw, the private IP addresses are remain the same when I stop the instances.
",panda87,moofish32
1958,2016-04-19 17:54:34,"@moofish32 - I know that this scenario is not expected and not by design, but still, I want to make sure whether this scenario I can work with or not.
Second, my env is pretty big with many components, part of them are still not fully automated, so I prefer to keep the env and not rebuild it every morning.
",panda87,moofish32
1957,2016-05-19 02:42:43,"Hi @siddharthist thanks for the PR and sorry for the delay in looking at this. I'm thinking we should incorporate the listing of allowed methods into [here](https://github.com/hashicorp/consul/blob/master/command/agent/http.go#L196). We could make a new registration function that turns this:

`s.mux.HandleFunc(""/v1/kv"", s.wrap(s.AgentSelf))`

Into something like this:

`registerEndpoint(""/v1/agent/self"", ""GET,PUT,DELETE"", s.wrap(s.KVSEndpoint))`

This way we can build the data structure one time alongside the registration of the endpoints. What do you think?
",slackpad,siddharthist
1957,2016-05-19 19:45:13,"@slackpad That makes a lot of sense. Most of the work on this PR was just finding out what endpoints respond to which methods, so I'm happy to redo the code :)
",siddharthist,slackpad
1957,2016-05-19 21:18:05,"@slackpad What are the supported methods on the `/v1/txn` endpoint?
",siddharthist,slackpad
1949,2016-04-13 07:48:02,"Hi, @slackpad In my config i set a service named ""web"", its service_ttl is 10s, like this
 `""dns_config"": {         
         ""service_ttl"": {
               ""web"": ""10s""
         }
}`
The TTL of ""web"" is 10s when queryed with dns lookup,  
If i register a new service(example: ""web2"") with http api, how can i set service_ttl of ""web2""  to 5s?
I want to set it with http api not to write in configï¼Œthx
",wxjs33,slackpad
1936,2016-12-06 19:08:07,@slackpad is there any docs around `-ui-dir` and `-ui` combo? I just ran into this with the latest version of consul and couldn't figure out the issue for the life of me. ,chiefy,slackpad
1930,2016-11-18 12:27:51,"@slackpad When using location rewrites with nginx proxy, it should be possible to customize the URI on which consul ui responds. If my nginx proxy is setup to forward `/server-1/consul-ui` to an upstream where consul ui is running, consul ui needs to be set to use `/server-1/consul-ui` context path. This setting is akin to `application.context` from Play framework, `-web.external-url` from Prometheus or Jetty `setContextPath`.

Does this help?
",radekg,slackpad
1930,2016-12-09 02:26:02,"Just FYI - I have made a few other enhancements that I think will help this. PR will be in coming shortly. 

TL;DR: Currently consul does not serve back full URL paths in its `Location:` headers when it's doing redirects for the UI, nor does the UI itself append on the correct HTTP origin that accessed it in the first place. These things are necessary to properly support reverse proxies not just on things like port or host but on path as well.

I'll reference back this issue on the PR when I'm ready.

@abhinavdahiya maybe if you could look at it if you'd like and see if we could combine work to have the best of both patches. @slackpad your feedback would be welcome as well.",vancluever,slackpad
1929,2016-04-11 19:31:08,"Hi @slackpad. Thanks for the response. We have limited logs and info because this is occurring from one of the users of our application however here is the info that we know:
- The setup is a 3-node cluster and started with `-bootstrap-expect`
- The user was performing an application upgrade which triggered a rolling deploy
- The following logs are from a client that was connected to the cluster which contains event logs
- After a certain amount of time, if the client is unable to verify sync (by comparing the commit_index and the last_log_index) with the cluster, the client will kill the consul agent and then retry.

Gist: https://gist.github.com/kkelani/97147077b5f1d26cc477c0cbdaca6873

Thanks
@christianang & @kkelani
",kkallday,slackpad
1929,2016-05-11 00:44:57,"Hey @slackpad did the gist help uncover any useful information? We are still experiencing this bug. 
",zankich,slackpad
1922,2016-04-30 03:32:58,"Hi @slackpad!

I'm doing leader election with Consul and I wanted to use a return from `Session.RenewPeriodic` as a signal that the leadership is lost in case it was held. 

I can still achieve the desired behavior if I wrap around the close signal and abdicate before sending the actual close signal to `Session.RenewPeriodic`.
",deadok22,slackpad
1914,2016-04-12 16:01:33,"Hi James @slackpad , thank you really much for your answer;
i still have got troubles for making this wan consul work properly, this is my configuration:



This remote consul server has got in the configuration the bind address configured as lan.

When i start consul on wan client i receive an error that the wan is available only in server mode.
After i switch to server, this is was i receive:



Where i'm lost? in the documentation i cannot find nothing about this issue ;(
",shakisha,slackpad
1914,2016-04-15 00:00:37,"Hello @slackpad , still not have got success on this :-(

Have you got any kinda of update for me? Thank you a lot!
",shakisha,slackpad
1914,2016-04-15 07:21:33,"@slackpad : this is exactly the part of the docs which I didn't get.
on the bind address I have only lan interface because I have got 10 clients in the local lan (datacenter0)

in datacenter ""lon1"" I have the configuration listed above and connection refuse error, but from tcpdump in pretty sure that lon1 server is contacting the server at ""datacenter0"".

should I totally remove bind address and use https://www.consul.io/docs/agent/options.html#advertise_addrs  or put only advertise wan address? 

will be secure keeping only that port with encryption enabled? 

UPDATE:i have tried putting these values in the configuration of datacenter0 and lon1:



but didn't worked, still the same ""getsockopt: connection refused"" (firewalls are disabled on both side).

Also i've tried to remove bind_address, but even with serf_lan,wan and rpc parameters, consul refused to start because of multiple private ip address on the machine.
I'm desesperated
",shakisha,slackpad
1914,2016-04-15 20:05:32,"Hi @slackpad, 



this is very a GREAT idea, but how to do that if vpn is on tun0 interface and i have to listen on both eth1 (lan) and tun0 (vpn)? 
",shakisha,slackpad
1914,2016-12-17 18:19:03,"Hello @sean- and @slackpad ;

thanks for your answers. I explain better my situation so we can make a big step next to enhance this consul version;
@sean- of course, i've seen your reply just yesterday; can you confirm that i can test directly with the 0.7.2 rc?

Actually i have got two datacenters:

DC1 datacenter with only a single consul, wan connected machine.
DC2 datacenter with a 6 consul, lan connected machines and every one with a public ip address.

basically, from DC1 datacenter, i want query the DC2 datacenter to have got a list of pubblic ip addresses of all the DC2 machines (to use it with consul-template, another project from you which i love).

So when running this command on the single consul machine of DC1:

`
or

`
i get in BOTH CASES
>rpc error: failed to get conn: dial tcp IP_ADDRESS_OF_THE_NODE_ON_DC2
>:8300: getsockopt: connection refused

these are the configurations that i used:
(@sean- i'm sorry if i didn't test your way like 
`
but i don't know the exact syntax to put it inside configuration file; i don't like to use the command line :-) )

*CONFIGURATION OF NODE ON DC1*
`

*CONFIGURATION OF NODE ON DC2*
`",shakisha,slackpad
1914,2016-12-17 18:19:03,"Hello @sean- and @slackpad ;

thanks for your answers. I explain better my situation so we can make a big step next to enhance this consul version;
@sean- of course, i've seen your reply just yesterday; can you confirm that i can test directly with the 0.7.2 rc?

Actually i have got two datacenters:

DC1 datacenter with only a single consul, wan connected machine.
DC2 datacenter with a 6 consul, lan connected machines and every one with a public ip address.

basically, from DC1 datacenter, i want query the DC2 datacenter to have got a list of pubblic ip addresses of all the DC2 machines (to use it with consul-template, another project from you which i love).

So when running this command on the single consul machine of DC1:

`
or

`
i get in BOTH CASES
>rpc error: failed to get conn: dial tcp IP_ADDRESS_OF_THE_NODE_ON_DC2
>:8300: getsockopt: connection refused

these are the configurations that i used:
(@sean- i'm sorry if i didn't test your way like 
`
but i don't know the exact syntax to put it inside configuration file; i don't like to use the command line :-) )

*CONFIGURATION OF NODE ON DC1*
`

*CONFIGURATION OF NODE ON DC2*
`",shakisha,sean-
1914,2016-12-22 18:56:39,@sean- doing now ðŸ‘ ,shakisha,sean-
1914,2016-12-22 19:19:04,"@sean-  and if i push in this way i have got:

`

>Error decoding '/etc/consul/conf/config.json': invalid character 'e' after object key:value pair",shakisha,sean-
1914,2016-12-26 14:20:14,"@sean-  should i put these inside the configuration file? 

>>> $ sockaddr eval 'GetInterfaceIP ""eth0""'
$ sockaddr eval 'GetAllInterfaces | include ""name"" ""eth0"" | sort ""type,size"" | include ""RFC"" ""6890"" | include ""flags"" ""up|forwardable"" | attr ""address""' 
>>>


Like 

`

?",shakisha,sean-
1914,2017-02-09 12:29:40,"Thanks @sean- 
ok, two issues now;

1. The ""{{ GetInterfaceIP \""eth0\"" }}'"" takes a strange ip address (10.9.2.0) which is not my eth0 ip.
 
2. from the consul wan machine, ran 
>curl http://localhost:8500/v1/catalog/nodes?dc=de01

and i have got
`

on iptables i have got these rules:

`",shakisha,sean-
1914,2017-02-09 12:55:03,"Basically it seems that consul doesn't listen on port 8300 for the requests from wan machine. 
I cannot find a solution.

@slackpad  have you got an idea?",shakisha,slackpad
1914,2017-02-09 17:40:08,"ok, i have identified the issue and got a workaround;

if i set 
""bind"" to PRIVATE INTERFACE (LAN)
""serf_wan_bind"": ""PUBLIC INTERFACE"",
""serf_lan_bind"": ""PRIVATE INTERFACE"",
**NOTHING WORKS**

but if i set
""bind"" to PUBLIC INTERFACE (WAN)
""serf_wan_bind"": ""PUBLIC INTERFACE"",
""serf_lan_bind"": ""PRIVATE INTERFACE"",

everything works perfectly ( i have at the moment a lot of Refuting a suspect message) but seems everything works.

basically the RPC forwarding is not working as expected.

-serf-wan-bind doesn't allow queries from other consul wan on port 8300 

Why this issue? @slackpad  is this a bug?",shakisha,slackpad
1905,2016-07-18 15:59:33,"agree with @slackpad. i needed the same functionality and i was able to setup something to help me by combining `consul template`, `elastic search` and `elasticui` (an `angularjs` based UI over ES). It's a `quick & dirty` solution - done with minimal coding - within couple of hours. 

https://github.com/awmanoj/consul-search
",awmanoj,slackpad
1904,2016-04-27 18:53:25,"@slackpad This has all the downsides of push based metrics. You never really know when something happened. And beside that, if you have a pull based monitoring system like Prometheus not having any way to pull in metics and having to resort to some kind of bridge make it worse.

I think consul should provide the metrics on some point for pull. See this discussion: https://github.com/hashicorp/consul/issues/817
",discordianfish,slackpad
1904,2016-08-10 20:22:32,"Hi @discordianfish thanks for your thoughts on this. I haven't had any recent cycles to devote to this, but I'll give it another look.
",slackpad,discordianfish
1904,2016-08-10 20:37:30,"@slackpad That would be great! Also see my suggestions in #817 
",discordianfish,slackpad
1903,2016-11-22 17:19:00,Hi @calvn haven't seen any similar reports to this one. Have you seen this again with any of the newer versions of Consul built with newer Go versions?,slackpad,calvn
1903,2016-12-15 05:18:19,"Hey @slackpad sorry for the delayed response, the issue was no longer being reported on our end so it's good to close.",calvn,slackpad
1897,2016-04-13 13:31:48,"Thanks for the feedback, @slackpad - that's a good idea. I'll incorporate that :)
",hairyhenderson,slackpad
1897,2016-07-05 20:21:22,"Thanks @hairyhenderson, appreciate the contribution! I'm going to close this in favor of #1984. I agree with @slackpad that this fits better as a parameter of the check definition.
",ryanuber,slackpad
1888,2016-04-12 20:18:29,"@slackpad Let me rephrase this:
Currently all hosts in my network do resolv lookup via my consul _masters_. If I'll add allow_stale = true to _master_ consul nodes, will this allow them to answer to dns loopup request for the ""max_stale"" period during the ""no leader"" situation? 

By dns loopup request I mean basic glibc one, like ""host nodename.node.consul"".
",Oloremo,slackpad
1888,2016-04-12 20:32:00,"@slackpad Thank you! 
",Oloremo,slackpad
1888,2016-04-13 05:38:13,"@slackpad We do indeed have `allow_stale` enabled on all of our servers, so that would explain the `NOERROR` responses.

Right now, I it appears that the DNS service remains active and will happily return data retrieved from other data centers (where the prefix of the other data center was explicitly specified,) whilst returning `SERVFAIL` only for calls that would otherwise have been serviced within the failed data center.

We're still keen to understand if it would be feasible to devise a method for DNS resolvers to reliably detect when the cluster in a given data center has failed, so as to avoid referring/forwarding DNS traffic to failed servers. Ideally, we'd like the option for the DNS interface to completely disable itself on any server that is no longer authoritative (ie. minority split brain or complete cluster failure.) for its local data.
",markbugejacba,slackpad
1885,2016-03-28 18:56:19,"Sorry @sean- , last question: will this be a correct syntax ?



...and submit it to Consul:


",akamalov,sean-
1885,2016-03-30 18:42:25,"@sean- Sean any feedback or pointers ?
",akamalov,sean-
1885,2016-04-13 16:56:33,"@slackpad Will do James. However, it shouldn't be the reason for 403, right ?
",akamalov,slackpad
1885,2016-04-14 14:33:37,"@slackpad 

Thanks James again. It did work. I went ahead and assigned proper rights to **acl_token** and web UI came up right after. Thanks yet again!
",akamalov,slackpad
1884,2016-04-13 05:06:47,"Hi @mtchavez thanks for the PR! Those retries look pretty reasonable and I've seen those fail from time-to-time as well.
",slackpad,mtchavez
1881,2016-06-01 18:56:34,"@slackpad any thoughts on this?
",BRMatt,slackpad
1871,2016-03-25 03:05:22,"@slackpad thanks for your incredibly fast response!  It will depend on the user whether they are willing to poke these holes in their ACLs, I suspect some will not.  Anyways, the clarification was very helpful.

Cheers,
Amit
",Amit-PivotalLabs,slackpad
1871,2016-04-01 03:04:44,"@slackpad what would you have in mind for WAN semantics to support this use case?  This is something we would be happy to submit a PR for.  Is it a ways away due to complexity, priority, both?

/cc @dieucao @onsi
",Amit-PivotalLabs,slackpad
1866,2016-04-06 14:46:29,"@slackpad -- I have some time this weekend to verify and resolve if you are not working this already. I most likely introduced the issue.
",moofish32,slackpad
1858,2017-02-09 14:07:37,@slackpad @here I got into the same issue. Renamed the datacenter name and restarted the service. But lost access to the cluster. What would be the best steps we can follow to rename the datacenter name without affecting the running cluster? ,gvenka008c,slackpad
1850,2016-03-21 23:30:10,"Hi @ketzacoatl you are correct this currently isn't built-in. You'd have to look at all the edges and filter in your watch script, or we'd have to add some extra controls to the watch.
",slackpad,ketzacoatl
1850,2016-03-22 02:19:40,"AH, very cool, thank you for the reference @slackpad!
",ketzacoatl,slackpad
1846,2016-03-18 20:47:39,"Agree the change looks good, my only concern with this one was what @TeaBough had in terms of further plans. Was this for some Ginkgo-based testing of a project that uses Consul? I'd rather not introduce a testing framework into Consul core without thinking it through a little more first and seeing how it would fit with other HashiCorp products.
",slackpad,TeaBough
1846,2016-03-19 10:02:53,"@slackpad the idea is not to introduce another testing framework into Consul but simply to allow users that use  your testutils to integrate it into their own testing framework (in my case Ginkgo).
",TeaBough,slackpad
1846,2016-03-19 15:56:42,"@TeaBough ok makes sense - thanks!
",slackpad,TeaBough
1845,2016-07-05 19:47:42,"Hey @mssola, sorry for the delay here! I think this could also be avoided by simply enclosing the command to execute in quotes, like:



By automatically inserting double-quotes I think we are opening up the possibility for further unexpected behavior in cases where there may also be double-quotes in the command. Does that make sense?
",ryanuber,mssola
1843,2016-03-17 17:51:35,"Hi @slackpad, i'm using the consul lock command with no flags
",bfloyd89,slackpad
1840,2016-12-14 11:11:30,"Hi @slackpad, I am looking for a way out for the same, I am using the blocking query instead. unfortunately, I am not able to access google servers in my country, could you please elaborate the workaround here? thanks a lot!",hehailong5,slackpad
1836,2016-07-05 19:32:31,"@shaneog sorry about the delay here - this LGTM. Looks like we have a merge conflict but otherwise this seems like a good addition. :+1:
",ryanuber,shaneog
1836,2016-07-05 20:14:18,"I've rebased on master now @ryanuber 
",shaneog,ryanuber
1836,2016-07-05 20:55:07,"Awesome, thank you @shaneog !
",ryanuber,shaneog
1833,2016-03-15 08:43:56,"Hi @slackpad 

Thanks for the fast response.  They may have been WAN joined at some point, I can double-check that.  Do you think this behaviour should only be seen if they have been WAN joined at some point, otherwise this would be unexpected, yes?

Yes, `consul members -wan` shows a fairly eclectic mix.

#### DC1

##### Consul Server 1



##### Consul Server 2



##### Consul Server 3



#### DC2

##### Consul Server 1



##### Consul Server 2



##### Consul Server 3



#### DC3

##### Consul Server 1



##### Consul Server 2



##### Consul Server 3



All the VMs are within the same VPC, all part of the same security group that allows all TCP and UDP traffic within the security group.  Looks like they also had some Network ACLs set up possibly preventing traffic between clusters.  I've deleted the ACLs and restarted the consul processes on all the consul servers.  The `consul members -wan` still shows a mix.

I'm now also trying the following `nslookup`s on all 15 VMs:
- `foobar.service.cf.internal` (resolves on all machines, to the two IPs of the foobar nodes within the respective DC)
- `foobar.service.dc1.cf.internal` (resolves perfectly on all DC1 nodes, I get NXDOMAIN roughly 50-50 on all other nodes, seemingly independent of whether it's a DC2 node or DC3, independent of whether it's a foobar node or a consul server node, and retrying a couple times continues to give random results, different than the first try)
- similarly for the other to dc's. (dc2 works for DC2, but has random success for nodes in DC1 or DC3).

This is just a standard AWS VPC.  What would need to be done to make this less flaky?
",Amit-PivotalLabs,slackpad
1833,2016-03-15 16:48:49,"Thanks @slackpad 

Atlas won't work for us as this needs to work in airtight on-prem networks.

Could you clarify your advice about reducing flakiness?  Does it suffice to have one server in one DC `join -wan` to one server in each of the other two DCs?  Would it somehow make things more robust if every server `join -wan`'d every other server in every DC?

If some consul servers are configured to `-retry-join-wan` some IPs intended for a consul cluster in another DC, and that other DC doesn't exist yet, will the first DC come up and work fine?  I.e. it will keep trying to `join -wan` the other DC, but until the other DC is up it will do it's own thing fine, correct?
",Amit-PivotalLabs,slackpad
1829,2017-02-16 11:32:11,"Hi @slackpad ,

Im also seeing this message in my log:
consul.fsm: EnsureRegistration failed: failed inserting check: Missing service registration

What do you mean by tracing that down? how do I find which service is responsible for this message?

Thanks",cshabi,slackpad
1819,2016-03-24 18:14:24,"@slackpad - Any idea tcp health isn't working for me, I'm running mongo container as per the reference in http://gliderlabs.com/registrator/latest/user/backends/#backend-reference ( consul tcp check ) , but in consul UI i didn't see the health point. Version : 0.6.4. please advise me.
",macbash,slackpad
1818,2016-03-10 01:32:13,"Thanks @slackpad.
",jzohrab,slackpad
1815,2016-03-11 17:16:12,"@slackpad thanks for the reply! To answer your questions and follow up:

No, we do not use Consul agents - just the servers. Unfortunately the gossip protocol really conflicts with our network ACL policy and we couldn't figure out a way to make them work, especially given that we wanted a single logical Consul cluster for our various datacenters. We implemented our own agent that does our deployment work without the gossip protocol and uses the HTTP API for updates and watches.

Is the multiplexing nature of Consul agents owed to the fact that they use the `net/rpc` package to communicate with servers? Is that API intended to be used by clients ever? If not, it seems like it might be very simple to add a GRPC wrapper for those same endpoints, with some established API contract and protos. If this is acceptable to you guys, we may have a PR coming your way.
",anthonybishopric,slackpad
1815,2017-02-16 05:15:33,"Hi @mpuncel I'll pull this forward so we can get it into an upcoming release. I think there's a pretty simple way to address this for KV to optionally send the deltas. We will need a little extra stuff to show that a key was deleted, but if we can figure out a good way to do that, the rest is a pretty simple filter.",slackpad,mpuncel
1815,2017-03-13 16:13:52,@slackpad What if there was an equivalent to the ?keys query that gave additional metadata about each key like modify index? That would make it a lot easier to build a client that watches keys and modify index and then re-fetches the value for keys whose index changed? That sounds like it would be easier to implement,mpuncel,slackpad
1814,2016-03-11 04:02:55,"Hi @tylert thanks for the PR. Can you do a quick rebase? These got reworked at the same time, but your change is still applicable.
",slackpad,tylert
1814,2016-03-11 14:00:24,"@slackpad Most certainly!  Rebase done.
",tylert,slackpad
1812,2017-01-10 15:52:15,"@slackpad which list?
",egidijus,slackpad
1799,2016-03-07 05:15:42,"@slackpad Do you have it in roadmap already with some ETA or it's still not decided? Thanks!
",Ashald,slackpad
1796,2016-03-06 03:47:40,"@ryanbreen you're right.  I'll add docs to match.
",doublerebel,ryanbreen
1791,2016-03-11 07:58:31,"Thanks @slackpad for your answer. Sadly I've fixed the issue a few days ago by restarting the process.
",kamaradclimber,slackpad
1781,2016-11-26 03:04:23,"@doertedev please see this comment - https://github.com/hashicorp/consul/issues/294#issuecomment-98857436 and this stackoverflow answer - http://stackoverflow.com/a/24728298/205585

This is the most common way and for negation we could do ""!"" like it is done in prepared queries or nt-tag query as @slackpad suggested.",senthilkumar-kj,slackpad
1780,2016-03-31 12:20:51,"@slackpad Any updates on this in the meantime? :)
",favoretti,slackpad
1776,2016-03-12 03:36:36,"That would be great @slackpad  - Thanks !
",saswatp,slackpad
1765,2016-02-26 19:30:27,"Hi @romansky can you post whatever you do see in the logs in a gist so we can see maybe where it's getting to when it crashes?
",slackpad,romansky
1765,2016-02-26 20:33:06,"@slackpad sorry to report that after investigation one side of the VPN was not configured to accept traffic from the subnet inside of it, it would pass traffic into it though. It was confusing because the it was working from the other side.. my bad!
",romansky,slackpad
1763,2016-03-10 06:39:35,"Hi @kaskavalci it should show the service health as not passing overall. Here's an example:

![image](https://cloud.githubusercontent.com/assets/673509/13661434/864f1654-e647-11e5-9194-92fc23d3edfd.png)

The fix was to change the status color of the top entry for that host, ""consul-client-nyc3-2"" in the example. @highlyunavailable is correct that some of the specific checks are showing green/stale since the node is dead, but since the `serfHealth` check is applied to the overall service health, the service is marked unhealthy overall for that node.
",slackpad,kaskavalci
1763,2016-03-10 06:39:35,"Hi @kaskavalci it should show the service health as not passing overall. Here's an example:

![image](https://cloud.githubusercontent.com/assets/673509/13661434/864f1654-e647-11e5-9194-92fc23d3edfd.png)

The fix was to change the status color of the top entry for that host, ""consul-client-nyc3-2"" in the example. @highlyunavailable is correct that some of the specific checks are showing green/stale since the node is dead, but since the `serfHealth` check is applied to the overall service health, the service is marked unhealthy overall for that node.
",slackpad,highlyunavailable
1763,2016-03-10 06:50:37,"Hi @slackpad thanks for the explanation, I didn't catch that part. However when we click on a particular service and list instances of that service in the cluster, then it will shown healthy, isn't it? Even though overall health is shown Critical, any watch that checks a particular service health will fail. Am I wrong?
",kaskavalci,slackpad
1763,2016-03-10 16:01:27,"@kaskavalci for that use case you probably want to do a service watch instead of one on the checks - it will do that for you (see the ""Type: service"" section here - https://www.consul.io/docs/agent/watches.html). That watches the health endpoint which takes into account all the node-level checks (like `serfHealth`) in addition to the service-level checks to provide a list of healthy instances.
",slackpad,kaskavalci
1755,2016-03-11 16:40:00,"@slackpad here is a PR that implement this feature: https://github.com/hashicorp/consul/pull/1798

Nothing big - just an optional extra option. Please let me know what you think about the PR.
",Ashald,slackpad
1752,2016-02-24 16:55:16,"Hi @mattwilliamson, @highlyunavailable is spot on in his comments. There are lots of folks using Consul KV from scripts as he described. Here's a working example:

`echo $(curl -s http://demo.consul.io/v1/kv/global/time | jq -r '.[0] .Value' | base64 -D)`

Consul does this so there's no way to break the JSON formatting for the arbitrary values. Tools like [consul-template](https://github.com/hashicorp/consul-template) and [consul-cli](https://github.com/CiscoCloud/consul-cli) also are pretty common in extracting keys and pave over this for you. His comment about lots of first class support for common KV use cases is also very apt. Instead of needing to make KV queries to look for services, for example, many applications can just use Consul's DNS interface and be configured simply with `foo.service.consul` to get a healthy instance.

We will take a look at a raw value (non-JSON) interface for the V2 API as an additional convenience.

Hope that helps!
",slackpad,highlyunavailable
1750,2016-08-11 14:08:55,"@slackpad No problem! I'll take care of this tonight when I get home. I always run go fmt (or goimports) so I'm not totally sure what happened. 

Also thanks @multani, looks like I missed your comment the first time around.
",alistanis,slackpad
1749,2016-03-10 05:23:23,"Hi @csawyerYumaed thanks for the PR! I took your change and made it link to the existing table in the configuration page, and added the Atlas info.
",slackpad,csawyerYumaed
1748,2016-02-23 21:20:26,"@slackpad left minor comments. My biggest question here is what happens with the DNS interface if the tokens are eventually going to go away? It seems very restrictive to only allow the client's global ACL token access the PQ's. I suppose you could handle it by enforcing convention, where e.g. `private-*.query.consul` is hidden from DNS, but you also lose the ability to revoke access by ACL token. Also a bit strange that a user who creates a PQ and can query it from the API might have to jump through hoops to get someone with a management token to enable DNS access for the new query. The DNS interface is probably the most powerful way to use the PQ's so just want to make sure we have thought this through completely.
",ryanuber,slackpad
1748,2016-02-25 00:22:41,"@slackpad  the docs are looking great and nothing stuck out to me - merge when you are ready!
",ryanuber,slackpad
1747,2016-02-23 16:17:56,"@slackpad can you please take a look at #1738 ? I believe it also might be an issue related to ACL resolution.
",Ashald,slackpad
1738,2016-02-25 17:34:16,"@slackpad thanks for confirming the bug. Well I understand the proposed workaround but hope there will be a fix in upcoming release.
",Ashald,slackpad
1738,2016-02-26 04:32:19,"@slackpad can you point me to the place where the issue exists? Maybe I will be able to contribute a PR with the fix.

Btw, are there any plans/schedule for next version release? Just to know whether I need to hurry with PRs etc. :)
",Ashald,slackpad
1738,2016-02-26 04:47:57,"@slackpad ok, I understand - code review, code freeze etc. Although I'll try to do the PR.

Last question: what's the best way to get in touch with Consul developers? I tried IRC channel but it doesn't seem to be very active. I'm working on integrating Consul with our infrastructure and thinking about contributing few PRs with additional features that will make Consul more flexible. So I might need to discuss few things while doing that. Sorry for off-topic and thanks for the answers.
",Ashald,slackpad
1736,2016-02-18 17:28:35,"@jefferai good call - we call build outside of the container but I'll add it there as well to perma-ban any cgo by anything that's built in there.
",slackpad,jefferai
1734,2016-02-26 10:10:52,"Hi @idubinskiy (just saw your IRC note) I didn't forget about this! Hopefully I'll get a little time tomorrow - I  want to look over the RFC and check a couple things before we merge.
",slackpad,idubinskiy
1734,2016-02-26 17:54:58,"@slackpad Thanks!
",idubinskiy,slackpad
1734,2016-03-09 07:14:12,"Hi @idubinskiy I took your PR and make a few small tweaks on the one linked above. Once CI passes I'll merge. Sorry for the delay in reviewing this one and thanks for the fix! I'd like to avoid compression as that puts an additional burden on clients to implement that correctly. Your fix should get at the root of the issue (compression was probably just making things work in some cases), and it doesn't seem necessary to compress on top of this change. We randomly shuffle the results, so even if the user is getting even 1 response back, things should work properly in most cases.
",slackpad,idubinskiy
1728,2016-03-01 21:02:57,"Thanks @mrcrilly - I took your PR and made a couple minor edits, merged under https://github.com/hashicorp/consul/pull/1777!
",slackpad,mrcrilly
1724,2016-03-01 20:19:16,"Hi @kaskavalci thanks for opening an issue. I bet we are getting hit in here - https://github.com/hashicorp/consul/blob/v0.6.3/consul/state/state_store.go#L1306. This pulls all the checks for the node in the inner loop around services. We can profile to confirm but this seems like a reasonable thing to optimize.

Just to double check, are you hitting the health endpoint during your testing above?
",slackpad,kaskavalci
1724,2016-03-02 13:14:00,"Hi @slackpad thanks for your response. In fact we are hitting here https://github.com/hashicorp/consul/blob/v0.6.3/consul/state/state_store.go#L1271 . We used Consul to retrieve a particular service with a given tag. We would like to use ID here but there is no such API for that. Thus, we embedded a custom ID into tags. But this is not practical after few ten-thousand services.

It seems here there is a lookup by ID https://github.com/hashicorp/consul/blob/master/consul/state/state_store.go#L728 but I'm haven't tested its performance. Just to confirm, does `memdb` not let us to perform lookup by ID? 
",kaskavalci,slackpad
1723,2016-09-13 22:30:45,"@polds @slackpad Thanks!
",Vaccano,slackpad
1720,2016-02-17 05:30:32,"Hi @Niks-JJ we don't plan on adding any auth built-in - proxying it with another web server as @polds and @highlyunavailable have suggested is definitely the way to go.
",slackpad,highlyunavailable
1720,2016-08-24 22:16:38,"@slackpad I think serving both UI and API over the same port kinda complicates this, though. 

+1 for even basic auth, it's silly to need to set up a whole proxy just to provide basic access control for what's supposed to be a full-featured cluster orchestration service
",jacohend,slackpad
1718,2016-02-26 17:56:31,"@slackpad https://gist.github.com/kendrickm/2cbe991ed44c30ca7783 

Since the agent had to get restarted to pick up the config option, I can pull the stats again next week after the memory has had time to increase back up.
",kendrickm,slackpad
1718,2016-02-29 17:53:09,"@slackpad I don't know how but in one of my env which have only 50~ agents, consul service takes 1GB of memory, and we currently use it mostly for DNS.
The installed version is 0.6
",panda87,slackpad
1718,2016-03-09 11:15:56,"@slackpad do you have any updates on this issue?
",panda87,slackpad
1718,2016-03-10 22:02:20,"@slackpad pls look me attached graphs for the last 2 weeks goroutines metrics of my consul servers.
<img width=""1260"" alt=""screen shot 2016-03-11 at 12 01 28 am"" src=""https://cloud.githubusercontent.com/assets/3185476/13686046/6aa2c36c-e71c-11e5-93c6-241784f64a3a.png"">
Do you think that the PR above solve this problem?
Do you want to see another metrics?
",panda87,slackpad
1701,2016-02-08 21:50:37,"Thanks @highlyunavailable - agree the error message is super confusing here.
",slackpad,highlyunavailable
1701,2016-02-08 22:53:24,"@highlyunavailable , @slackpad : thank you issue resolved
",mg03,slackpad
1701,2016-02-08 22:53:24,"@highlyunavailable , @slackpad : thank you issue resolved
",mg03,highlyunavailable
1698,2016-06-09 17:06:17,"@slackpad thanks for your awesome work on this! We've been trying to use this feature but unfortunately it seems that it's only available through the DNS interface. What I would really like to see is the appropriately translated address available in the `""Address""` field of the node object when querying through the HTTP API.

I've been chatting with @evan2645 about this, and he thinks that the above should be do-able. I'm ready to start on a patch but wanted to check with you to see if there was any reason this isn't feasible, or if there was any reason it's a Bad Idea. Thanks!
",DWvanGeest,slackpad
1696,2016-02-07 08:36:41,"hi @slackpad , the consul server does not start up at all, am unsure why that is. I configure consul at Packer build time, am thinking maybe am failing to start up the consul service/server, I am using puppet to configure other packages and services at packer build time as well, do I need to configure consul with puppet as well to make it start ?
",CruzanCaramele,slackpad
1694,2016-02-06 17:52:10,"@slackpad Doh. I didn't try the version with a `-`. `--` works and I was too quick with my PR! `-` does indeed work for me (OSX 10.11.3).

Apologies sir.
",jonDowdle,slackpad
1688,2016-03-04 02:19:19,"@justinclayton SIGPIPE is one of the 4 signals that systemd considers as OK when `Restart=on-failure` is set. You could use restart=always here.

https://www.freedesktop.org/software/systemd/man/systemd.exec.html
",joemiller,justinclayton
1687,2016-04-01 01:10:29,"@wuub Agreed, and thank you for that suggestion (I stubbed my toe on this earlier today, in fact).  The default behavior was changed in #1909 .  Where appropriate, we are very receptive to input regarding smoothing out operator and administrator user experience.  Cheers!
",sean-,wuub
1686,2016-02-05 11:54:26,"@blalor Thanks!! This is it!
",imtheghoul,blalor
1680,2016-11-16 19:57:08,"@slackpad great thx ;)
",CpuID,slackpad
1680,2017-02-08 01:45:19,"@slackpad *bump*, I noticed it missed 0.7.3/0.7.4 :)",CpuID,slackpad
1679,2016-02-03 01:38:45,"Perfect, thanks @highlyunavailable and @slackpad!
",Amit-PivotalLabs,slackpad
1679,2016-02-03 01:38:45,"Perfect, thanks @highlyunavailable and @slackpad!
",Amit-PivotalLabs,highlyunavailable
1674,2016-02-13 17:42:51,"Hi @slackpad. My consul info gives back this for two of the machines:



And this for the third:



And the config.json I'm using for the servers is:



I've tried taking out the  ""bootstrap_expect"" option as well as the ""skip_leave_on_interrupt"" but still continue to repro the issue.
",glenwong,slackpad
1674,2016-02-26 17:18:00,"@slackpad You mention that there are similar configuration controls for enabling/permitting stale responses via HTTP endpoints. Sorry for the stupid question, but which settings are those ? I see the DNS-related state configuration settings, but nothing explicitly about HTTP responses. Thanks
",mrwilby,slackpad
1669,2016-02-02 16:07:26,"Ah - thanks @sean- I didn't know it did that. Learn something new everyday.
",darron,sean-
1669,2016-02-02 20:04:01,"The issue is that you end up with hundred of server directives unless I'm mistaken @sean- 
",scalp42,sean-
1661,2016-02-17 07:33:11,"Thanks for fixing this @slackpad and @alistanis - appreciate that!
",darron,slackpad
1661,2016-02-19 21:29:29,"No problem @darron! Thanks for merging it @slackpad! 
",alistanis,slackpad
1661,2016-02-19 21:29:29,"No problem @darron! Thanks for merging it @slackpad! 
",alistanis,darron
1658,2016-01-28 20:18:29,"Hey @slackpad thanks for the response.

There were 3 servers.  It was then scaled down to 1 server, without changing the consul version or enabling TLS, and this was successful as far as I know.  It was then rolled with a new consul version and TLS enabled, remaining at 1 node, and this is what failed.  The plan after that was to scale back up to 3.

This process was done to migrate a 3-node cluster from non-TLS to TLS. We had to do an intermediate scale-down because we can't roll a cluster where one node is expecting encrypted communication and the other two are not.
",Amit-PivotalLabs,slackpad
1658,2016-02-05 02:37:24,"Thanks @slackpad 

On scale down, the nodes leaving the cluster should be doing a graceful leave, removing them from peers.json on all nodes.  What may be happening is if two nodes try to leave at the same time, the other node goes into outage mode, and perhaps the peers.json file on it doesn't get updated properly.
",Amit-PivotalLabs,slackpad
1656,2016-07-07 18:39:02,"@sean- I consider this a bug, because when you connect two DCs together using command you expect it to mean for the entire cluster, this is why @wwalker  had connectivity problems.

Take look at for example Riak's MDC setup (http://docs.basho.com/riak/kv/2.1.4/configuring/v3-multi-datacenter/quick-start/) you just issue a single connection between the clusters it even obtains IPs of other nodes to connect to. It doesn't even matter what happens to the node you issued connections from, the cluster is connected.

Consul has all the tools necessary to accomplish the same thing.

I suppose one can use the configuration file, and that should work, it's essentially offloading work to something else. If it's done by hand is prone to mistakes, if is done automatically you'll need service discovery for the consul itself, plus dealing with special case like not listing own IP there.

Anyway as it is right now the join command line is totally useless. If you have 5 datacenters with 5 nodes won't you need to issue 80 joins to ensure that all nodes are connected with all nodes (5 \* 4 \* 4) so you won't encounter @wwalker's issues and then be on top of that each time a node is replaced (20 joins for a new node)

Edit: referenced wrong person
",takeda,sean-
1646,2016-03-10 07:47:05,"Perfect! Awesome thanks @slackpad!
",doertedev,slackpad
1642,2016-02-02 04:05:01,"@highlyunavailable is right - you have to join each sever to at least one other member of the WAN pool at startup. It's very similar to how the LAN pool works, and it's based on another instance of Serf under the hood, basically. If you can use the Atlas join feature it will join to the WAN pool for your servers - https://www.consul.io/docs/agent/options.html#_atlas_join.
",slackpad,highlyunavailable
1642,2016-07-07 03:39:40,"Thank you @slackpad @highlyunavailable
",tiagoalves83,slackpad
1642,2016-07-07 03:39:40,"Thank you @slackpad @highlyunavailable
",tiagoalves83,highlyunavailable
1640,2016-01-23 09:33:54,"@highlyunavailable Ah, excellent! We still haven't upgraded to 0.6, so we always got warnings on startup if it wasn't set. But then I won't update the PR :)
",carlpett,highlyunavailable
1640,2016-08-18 02:01:08,"Hi @carlpett thanks for the PR (and sorry for the delayed response). Given that we only distribute binaries outside of any packaging, this is probably better done as a separate project. We'd be happy to link to it from the community page.
",slackpad,carlpett
1637,2016-02-02 03:52:42,"Hi @discordianfish this is an interesting idea. One nuance is that the agents are actually the source of truth for service registration, so if the servers modified the central catalog of services then we'd have to add some special-case logic to keep the agent from canceling the configuration. We do have support via `EnableTagOverride` for doing this, just for service tags. One feature I could see that might be simpler is to be able to say ""tag service X for the lock holder with tag Y"". This would let you register the service in the usual way, but add a tag like ""master"" to whoever has the lock.
",slackpad,discordianfish
1637,2016-02-02 11:46:31,"@slackpad I'm not sure I understand the issue with canceling configuration.
I would keep things simple: Add service to local agent if lock is acquired and remove it if lock is lost. No assumptions about how many other services might get registered on other servers.
It's also not just for figuring out the leader within a number of services but also for 'singletons': I want to run only one instance of a service within my cluster and make sure if this goes down, another takes over. From a logical perspective this single instance of my service 'moves' to another host, so it doesn't make sense to have the have a tag on the active one given that all others simply don't exist (until they acquire a lock).
Another thing to consider are the health checks in this case: They will only work once the service is started which requires the lock. If I already register the service and health check even though I don't have a lock, I have a service marked failed in consul..
",discordianfish,slackpad
1637,2016-02-03 02:55:03,"@discordianfish ok this makes a lot more sense and would be simpler than I thought. You'd probably want to point the lock command at some JSON to register when it gets the lock and to deregister when it starts up / attempts to get the lock.
",slackpad,discordianfish
1637,2016-02-03 10:03:31,"@slackpad Yes exactly. I'm using this script as wrapper for now, but it's fragile and something build into consul would be awesome: https://github.com/Jodel/infra-scripts#consul-register
",discordianfish,slackpad
1629,2016-02-02 02:04:45,"Hi @moofish32 thanks for updating these! If you've gotten to test them then we can merge them in case they are useful to others. Only thing I saw from a quick look is that `GOMAXPROCS` doesn't need to be set any more with Go 1.5+.
",slackpad,moofish32
1629,2016-02-02 15:34:15,"@slackpad - I need to go back through and plum the `rhel7` variable and a few others. I will also kill the `GOMAXPROCS`

Thinking about this again though I'll probably call it `centos7`. It will take a couple of days to get the free time, in a bit of the busy season over here (as if there is a non-busy season).
",moofish32,slackpad
1629,2016-02-06 16:41:50,"@slackpad - so this change drifted a little. When I started I was going after just one and then I found a few others. In an effort to slim down I consolidated scripts. If you don't like this, let's just roll it back and I'll add only the rhel7/centos7 piece. I was a little annoyed I had to `subscribe` to use the centos AMI.

I'm looking into build issue with sudo. I may need to back track a bit.
",moofish32,slackpad
1629,2016-02-13 02:04:06,"Hi @moofish32 it looks like you need another rebase. If you were able to test the older scripts then we can update them all, but if not I'd prefer if we just updated the version 7 ones.
",slackpad,moofish32
1629,2016-02-13 14:36:22,"@slackpad rebased to master. A couple quick items:
- Tested - I ran the terraform script for each distro and verified the cluster was up with the right number of members. If there is a better way to test let me know.
- I updated all the Consul versions to 0.6.3, the PR you merged modified many to 0.5.x, was that intentional?
- The ""big change"" here is I refactored the bash installers into one script. IMHO I think it's easier to maintain.
",moofish32,slackpad
1629,2016-02-13 15:21:38,"@slackpad -- I am getting intermittent builds locally and on Travis. Is that new?
",moofish32,slackpad
1629,2016-02-13 16:43:00,"Hi @moofish32 moving up to latest Consul is definitely the right thing - sorry I regressed that with the older PR. We have a few tests that are timing dependent that are a little flaky and we are working on those. Your changes definitely don't interact with the unit tests :-)

I was looking through old issues and found this one that we might want to roll into this PR since you're in here - https://github.com/hashicorp/consul/issues/1304. You definitely want all three (8300 for RPC, 8301 for LAN, 8302 for WAN) to be exposed for servers and (8301 for LAN) for clients, though if things are working perhaps these are getting exposed anyway? The comment about a reboot seems apt, too. Would it be possible for you to take a look at that?
",slackpad,moofish32
1629,2016-02-16 04:32:57,"@slackpad  -- I was officially dominated by the linux distros today. I'll have a fix up in the next couple of days for all the issues you mentioned, but there is just enough difference between upstart in Ubuntu, Centos, and RHEL that I may have to move those back to separate files :( 

I thought about rendering a template inside a remote exec to append to file, but need to kick the tires one more time. 
",moofish32,slackpad
1629,2016-02-20 17:27:14,"@slackpad  -- All four OS variants are now tested and can be restarted. Obviously there is still an anchor dependency on the consul-0 host because that is the default join address. Please review and let me know if you find anything else.
",moofish32,slackpad
1629,2016-02-26 17:40:37,"@slackpad  -- rebased to latest master
",moofish32,slackpad
1629,2016-03-10 06:47:27,"@moofish32 thanks for all the work on this one! Looks good except we should knock this file out :-)

https://github.com/moofish32/consul/blob/update_terraform_rhel7/terraform/aws/terraform.tfvars
",slackpad,moofish32
1629,2016-03-10 14:25:41,"@slackpad  -- great catch, bad miss on my part but it was at least only the names; removed file and rebased.
",moofish32,slackpad
1629,2016-03-10 16:04:05,"@moofish32 thanks for all your work on this one!
",slackpad,moofish32
1616,2016-01-21 15:12:54,"Thanks @slackpad. Any new information on this?
",donaldquixote,slackpad
1596,2016-01-13 22:25:42,"ouch, that was indeed it. Our Kubernetes pod was set to a 256MB limit (which worked on 0.5.2). Now that I've increased it to 512MB, things work as expected.

Sad face for it taking so long for me to post this, as that would've saved me a couple of hours :disappointed: 

Thank you for helping out @slackpad!
",JeanMertz,slackpad
1591,2016-01-13 04:10:49,"Hi @highlyunavailable since this was a totally new API we wanted to be more REST-y, similar to the KV store, but we decided to separate out the create from the update operation since the ID is always generated by the Consul and never passed in when the query is created. It definitely could have been a PUT, but was sort of a style choice.

The API options thing is a bug, thanks for finding that!
",slackpad,highlyunavailable
1590,2016-01-14 02:14:54,"Hi James @slackpad 

I am using the python client for consul.

For example , im doing the following to test:
import consul
conn = consul.Consul(host=""172.31.10.8"",port=""8500"",token=""6678179e-3972-58e3-2ca5-ca4715d77134"")
svc = {""Service"": ""svctestwatch"", ""ID"": ""svc123""}
check1={""Node"": ""node1"", ""CheckID"": ""service:svc123"",""Name"": ""Redis health check"",""Notes"": ""Script based health check"",""Status"": ""passing"", ""ServiceID"": ""svc123""}
conn.catalog.register(""node1"",""1.2.3.4"",service=svc,check=check1) <----this returns true and the ui shows node registered
check2={""Node"": ""node2"", ""CheckID"": ""service:svc123"",""Name"": ""Redis health check"",""Notes"": ""Script based health check"",""Status"": ""passing"", ""ServiceID"": ""svc123""} 
conn.catalog.register(""node2"",""5.6.7.8"",service=svc,check=check2) <------ <----this returns true and the ui shows node registered

i,s = conn.catalog.service(""svc123"")
print s   <---- This is an empty array , this should give me the nodes in the service
",mg03,slackpad
1587,2016-01-18 05:54:24,"Thank you @slackpad . My issue is that ""I want to use consul as a dns server but not with 'service' or 'node' in a full domain"" https://www.consul.io/docs/agent/dns.html  .  How to config ?  
I want to use a domain like 'www.github.com'
",renrenfree,slackpad
1583,2016-02-09 01:53:44,"@fusiondog I think so as well. Do you mind adding a note about this to the docs as well? I'm happy to do that, too - just let me know.
",slackpad,fusiondog
1583,2016-02-09 19:36:27,"@fusiondog Thank you for your PR.  I'm going to take PR and update it so that an administrator can specify an `int` instead of a `bool` to limit the number of addresses returned.
",sean-,fusiondog
1583,2016-02-10 05:07:33,"@sean- Would the int be able to exceed the default 3 results?  The doc update should probably still make a point of the getaddrinfo bug and that using the setting at value 1 is needed to resolve.
",fusiondog,sean-
1579,2016-01-09 00:18:53,"Hi @nbrownus - do you know how close your 0.5.2 setup was to maxxing your machine's memory? If you were close before I could see the fairly large GC behavior differences from Go <1.5 to Go >1.5 causing a marginal situation to blip over and fail. If you weren't even close and it's way different in 0.6.1 that would be surprising.
",slackpad,nbrownus
1579,2016-03-11 06:45:27,"Hi @nbrownus closing this out as we've updated the docs and I think we understand the root cause. Please re-open if you need anything.
",slackpad,nbrownus
1576,2016-01-07 22:10:15,"Thanks @ryanuber. Is there a ballpark ETA for 1.0? I know there is plenty to keep everyone busy. I'm just gathering as much info as I can to present to my managers.

Thanks again.
",donaldquixote,ryanuber
1576,2016-01-07 22:51:20,"Thanks @mitchellh. I personally have confidence in it, but we have a unique case of needing to straddle both the cloud and on-prem worlds, so we will either be redistributing Consul with our software or asking customers to install and run it on-prem, and we have a requirement to target Windows and Linux. Even with a list of large adopters, I can't imagine the customer being happy with ""Windows is not recommended as a Consul server"" printing every time a server goes up.

Anyway, thanks again, and keep it up. I'm excited to start working with Vault over Consul. :)
",donaldquixote,mitchellh
1576,2016-07-01 00:10:36,"Hi again @ryanu, @mitchellh. I following up to see if official Windows support for server is still likely to land in 2016. Our use cases keep piling up :)

Thanks. 
",donaldquixote,mitchellh
1576,2016-07-15 14:00:03,"@ryanu, @mitchellh   I have a client which is mostly windows. We are using AWS. We use packer, terraform already. We have under utilized windows servers I can use to start using Consul and Vault. I used chocolatey packages created by you guys to install consul as a service. I see a warning about lack of production support for consul on windows. A guide for consul on windows along with official support will help for sure. 
",rajinders,mitchellh
1576,2016-09-06 19:14:08,"Just wondering what is the current state of Windows support for the Consul Agent running in Server mode?  Is this a supported and stable configuration for v0.7?  

Is 1.0 still coming out this year?

@mitchellh @ryanuber @slackpad 
",daviddodsworth,mitchellh
1576,2016-09-06 19:14:08,"Just wondering what is the current state of Windows support for the Consul Agent running in Server mode?  Is this a supported and stable configuration for v0.7?  

Is 1.0 still coming out this year?

@mitchellh @ryanuber @slackpad 
",daviddodsworth,slackpad
1576,2016-09-06 19:14:08,"Just wondering what is the current state of Windows support for the Consul Agent running in Server mode?  Is this a supported and stable configuration for v0.7?  

Is 1.0 still coming out this year?

@mitchellh @ryanuber @slackpad 
",daviddodsworth,ryanuber
1572,2016-01-07 20:57:30,"@slackpad yes, I use Catalog API to update tags
One more thing, my consul server already upgraded to 0.6, but my consul client remains at 0.5.2 since lots of clients running
",wyhysj,slackpad
1572,2016-01-08 08:09:34,"@slackpad Thanks for the clarify
today I upgrade everything >0.6.0 and the problem still exists
First I think it's protocol version
As this page [https://github.com/hashicorp/consul/issues/1531](https://github.com/hashicorp/consul/issues/1531) explains it's irrelevant



I use /v1/catalog/register api and my body.json looks like this


",wyhysj,slackpad
1572,2016-01-09 08:57:50,"@slackpad Thanks for such detailed explanation
After changing register service with EnableTagOverride: true
It works great !
",wyhysj,slackpad
1572,2016-07-04 12:02:58,"@slackpad , Thank you from me too.
Can you check if this is correct please?

There are two ways to change the tags of an existing service:
1. By the catalog - v1/catalog/register.
2. By re-registering the service on the agent - v1/agent/service/register.

If you want to use way 1, create the service with  EnableTagOverride: true. Because otherwise the tags will be run over.
If you want to use way 2, create the service with  EnableTagOverride: false (the default). Why? read on.

Advanced note:  It seems that v1/agent/service/register sends the new tags to the catalog regardless of EnableTagOverride. So if you use way 2 yet with EnableTagOverride: true, it will 99% work. The only problem is if you call v1/agent/service/register while the cluster is unavailable; then the registration on the agent will succeed, but it won't send the tag to the server upon re-connection!
",motty-stratoscale,slackpad
1567,2016-01-24 15:32:39,"@slackpad thanks for the comments!

In some very initial toying around, I already discovered that the 1 second `DefaultMonitorRetryTime` is a problem when trying to rolling upgrade, because `consul lock` died really fast.  I don't have the logs in front of me ATM, but IIRC the problem was that consul client was unable to talk to the agent, and thus tried to immediately release the lock which, again, it couldn't do.  I haven't had time to delve in to the source yet (out of round tuits for now :disappointed:) but hypothesized that increasing the retry time might avoid this.

Also, as you pointed out, there are a _lot_ of rough edges that I'm admittedly completely ignoring for now.  I just wanted to start with _something_ as a PoC.
",issacg,slackpad
1565,2016-01-05 21:48:14,"@slackpad  in my case the service is **_sip**, the protocol is **_udp** and we use the subdomain to classify the cluster ( **ppid410** ).  Unfortunately in my use case I do need **_sip** or **_sips** ( for tls) to be there in addition to the protocol ( **_tcp** / **_udp** ).  
",johntdyer,slackpad
1565,2016-01-05 21:49:20,"@slackpad - Its worth mentioning that this is technically working today.... 


",johntdyer,slackpad
1565,2016-01-06 18:12:39,"@slackpad  any thoughts ? 
",johntdyer,slackpad
1564,2016-01-06 06:05:22,"@slackpad Great thanks! Recently we are developing a distribute system using consul as our K/V storage.  
- How about TTL expired? Is it the same as deletion(a 404 response code with X-Consul-Index)?
- Is there any way we can know the previous value if we get a modify/delete/expire action when watch? 

Is there any documentation?
",mqliang,slackpad
1564,2016-01-06 06:53:59,"Sorry I missed your last question. Consul doesn't keep any history of values for KV entries so you'd have to manage that in some other way. 

> On Jan 5, 2016, at 10:05 PM, Liang Mingqiang notifications@github.com wrote:
> 
> @slackpad Great thanks! Recently we are developing a distribute system using consul as our K/V storage.
> 
> How about TTL expired? Is it the same as deletion(a 404 response code with X-Consul-Index)?
> Is there any way we can know the previous value if we get a modify/delete/expire action when watch?
> Is there any documentation?
> 
> â€”
> Reply to this email directly or view it on GitHub.
",slackpad,slackpad
1563,2016-01-05 02:42:40,"Hi @sboily can you try a command like this from that machine to see if openssl can connect:

`openssl s_client -connect scada.hashicorp.com:7223 -tls1_2 -CApath /etc/ssl/certs </dev/null`

There weren't any major SCADA-related changes in 0.6, though Consul keeps that connection open so you may have seen it during the upgrade because it was the first chance to connect in a while.
",slackpad,sboily
1563,2016-01-05 21:15:04,"Thanks for the update, @sboily. Are you ok to close this one down?
",slackpad,sboily
1562,2016-01-04 17:54:31,"Hey @discordianfish, the `consul members` and `/v1/status/peers` output come from different sources; the former being from the gossip layer and the latter being from the Raft layer. That explains why they may be showing different peer sets.

Are the old members fully dead (unreachable)? Were they forcefully terminated, or were they shut down gracefully? A graceful shutdown allows the node to announce its intention of leaving whereas a force shutdown leaves the member in the peer list for another 72h in case it comes back.

Can you share your full configuration and some of the logs from each server at start time? The bootstrap options are important here and this will help paint a more complete picture of what's going on.
",ryanuber,discordianfish
1562,2016-01-04 17:56:08,"To add to what @ryanuber said, it would also be useful to see the /peers output from each of the servers other than 10-1-24-247 to see if they look like they are in healthy state.
",slackpad,ryanuber
1562,2016-01-04 18:23:13,"I suspected something like that, but how is it possible that leader isn't included in peers?

I have a bunch of servers which didn't leave the cluster properly, so it's quite possible that this contributes to this problem (working on this issue right now).  Still, it looks to me like there is also some issue with consul itself leading to the inconsistency between leader and peers.

For the configuration I basically ask the aws api for instances for the instances stack (using cloudformation here). Additionally to that, I use another tag to figure out if an instance is suppose to be a server or now.
All nodes use this config:



...and I just realize that I still explicitly set `-protocol 2` on all nodes.

On servers nodes I start consul with those parameters:



... where the IPs are those of the other instances tagged as server.

On client nodes, I run:



...where again the IPs are those of the server instance _when consul got started_.

@slackpad: Here is the peers output from each server:



Here are a few lines from the log of 10.1.9.157:



And here some of 10.1.29.94:



^- Possibly when I did a rolling replacement of the instances.

Currently I only see the (excepted) serf issues due to the non-gracefully removed instances:



I can also provide the complete log (well those I still have, so only from the currently running instances) if necessary. Just need to spend some time scrubbing them.
",discordianfish,slackpad
1562,2016-01-04 19:18:32,"@discordianfish is it possible that you did a rolling restart of the servers without giving them time to rejoin and become peers again? That might have pushed your cluster into an outage state. If your config file has any use of `-bootstrap` you could end up in a split brain situation like this as well.

In any case, it looks like .157 is in a bad state where it has peers that are gone, and it hasn't added the other two good server nodes. I'd probably make that one leave and add a new server, or restart .157 with a clean data-dir, after making sure you are not using `-bootstrap` in your config.
",slackpad,discordianfish
1562,2016-01-05 09:56:45,"@slackpad It should have waited for the server nodes to successfully join the cluster. Before continuing with the next instance, I run:



That should make sure the node successfully joined.. And as far as I understand, `-bootstrap` should be okay as long as the nodes I point it to are already bootstrapped..
I see how it's simpler to reason about the state if `-bootstrap` is removed, yet that isn't that trivial to automate. 
",discordianfish,slackpad
1562,2016-01-08 22:14:10,"This is slightly off-topic, but since I came here looking for a robust way to wait for a consul cluster to self-assemble (in a context where I know it eventually will) perhaps others will be interested.

Right now I'm attempting to wait with a poll loop that explicitly asks for a lock: `consul lock -n 64 wait-for-consul echo Consul is up`.  It seems that if this command succeeds (in the exit code sense) then I am good to go.  @slackpad How would you rate this tactic vs. polling the peers list?
",phs,slackpad
1562,2016-06-02 15:04:30,"@slackpad We have a similar situation, where the `/v1/status/peers` endpoint shows (besides all current masters) a peer that has been deleted come time ago. `consul members` doesn't show that node. The output is the same for all three master nodes.

The outage recovery document (https://www.consul.io/docs/guides/outage.html) says I can fix that by stopping all masters, editing the peers.json file and starting the servers again. I was wondering if there is also a way to fix this while keeping the cluster alive?

I'd like to prevent downtime if I can. And except for some raft messages saying the peer cannot be found for voting `Failed to make RequestVote RPC`, the cluster seems to be operating fine otherwise...
",amochtar,slackpad
1562,2016-06-02 18:29:04,"@slackpad that worked :)
created a new node with the old IP address, started a new consul agent, joined the existing cluster, then left again and it nicely cleaned the peers list ðŸ‘ 
",amochtar,slackpad
1560,2016-01-05 09:12:05,"@slackpad Thanks for the quick response.
I changed the post-script script to do a request for an inexistent key and check that it returns an empty string (returns 'No cluster servers' and/or 'No cluster leader' ) and it seems to do the job for me... Anyway... I assume that  the KV and the leader API's should have returned the same response... but they don't.. might be some inconsistent leader checks?
",sebi-hgdata,slackpad
1555,2016-01-14 13:33:16,"Hey @slackpad , the idea was all about improving inner-datacenter comunication, you are indeed right.The #1547 PR might solve this.
",migueleliasweb,slackpad
1553,2015-12-29 01:05:29,"Awesome, thanks for the quick merge @ryanbreen.
",peterfschaadt,ryanbreen
1550,2016-01-05 17:49:26,"@slackpad comments addressed, PTAL!
",ryanuber,slackpad
1547,2015-12-24 20:37:47,"@evan2645 things have been a little flaky in Travis since some of our tests are time-dependent. I'll take a look and thanks for submitting this PR!
",slackpad,evan2645
1547,2016-01-15 00:20:08,"Hi @evan2645 - there's a lot of interest in this change!

I've been thinking that it would be good to generalize this a little bit to put us in a good position for more features down the line. If instead of `WanAddress` we added a new member `Addresses` which is a map, keyed by a tag then we could auto-populate it with the tag `WAN` using the logic you have here. On the other side, I think we could generalize `translate_addrs` in the config to be a map keyed by DC with the tag to use to translate for nodes from that DC.

This will set us up to eventually register additional addresses and configure things as needed from the perspective of the other DC, which should be very powerful.

Any thoughts on these changes? I'm happy to help implement if you'd like.
",slackpad,evan2645
1547,2016-01-19 20:43:54,"@slackpad I like the idea of turning `translate_addrs` into a map of DC names. I'll do that.

I'm having a bit of trouble understanding your suggestion on the address configuration though - you're suggesting to add a `WAN` string element to the `AddressConfig` struct, and auto-populate it somehow? Would this take precedence over the pre-existing `AdvertiseAddrWan`, or be disjoint from it?
",evan2645,slackpad
1547,2016-01-19 20:54:08,"Here's the post: http://qnib.org/2016/01/16/consul-ambassador/
@evan2645 @slackpad To me the beatuy of the idea is to put it in a context where the targeted agent (the services within a different DC) is in control which address is given out to an DNS request by a remote agent. A map which is send over and the DNS resolver checks for a default (internal or external address) or an address specified for a given DC.



Just my 2 cents, since I didn't get my hands dirty in the code for now
Christian
",ChristianKniep,slackpad
1547,2016-01-19 20:54:08,"Here's the post: http://qnib.org/2016/01/16/consul-ambassador/
@evan2645 @slackpad To me the beatuy of the idea is to put it in a context where the targeted agent (the services within a different DC) is in control which address is given out to an DNS request by a remote agent. A map which is send over and the DNS resolver checks for a default (internal or external address) or an address specified for a given DC.



Just my 2 cents, since I didn't get my hands dirty in the code for now
Christian
",ChristianKniep,evan2645
1547,2016-01-19 21:09:46,"@evan2645 Ok, not the most complete thought ever written on Github. :)
Maybe more like this:



In which the `dc_specific` would overwrite the default `wan`, if it dares to exists.

The remote agent get this information, checks his DC against the DC of the remote service (since it's remote it's likely to be different :) and if so, he chooses the `wan` address if he can not find his DC in the map of `dc_specific`.
This would make sure that the client is in control who gets what IP address, since he might have special entry-points (loadbalancers) for different regions and this would cover it up.
",ChristianKniep,evan2645
1547,2016-01-19 22:43:51,"ok... what do you think @slackpad? Maybe this is what you meant? Or you also wanted arbitrary tags per DC? The latter doesn't mesh well with the agent-decides-which-address-a-dc-gets approach
",evan2645,slackpad
1547,2016-01-20 06:28:34,"Hi @evan2645 my thought on the addresses list was quite a bit simpler than @ChristianKniep initially, but it would open things up later for features like that if we wanted to expand things. Instead of this:



You'd do this:



Configuration-wise you wouldn't change anything, but you'd put the value you are currently putting into `WanAddress` into `Addresses['wan']`. We don't need to do it now but it gives us a structure to add other address tags later. This seems flexible enough to implement the DC-specific use-case later if people want to organize their tags that way. For now I think letting the agent be in control of which address tags to use is probably the way to go.
",slackpad,evan2645
1547,2016-01-26 18:33:25,"@slackpad I pushed a commit to add an `Addresses` map on the node struct. I was able to consume it nicely from the request side of things.

Note that I was unable to use this structure during node registration, serf tag etc, as the node struct is not present at that time. LMK if you think I'm missing anything
",evan2645,slackpad
1547,2016-02-07 21:51:51,"@evan2645 great work on this! I appreciate you getting this together, and I just realized you also fixed the RetryJoin unit test along the way which has been bugging me for a while :-)

:+1: 
",slackpad,evan2645
1546,2015-12-25 04:55:17,"@slackpad 
so sorry not give the configure informationsã€‚
I use consul as the backend registry of registrator .  and my service is in docker container.  So I set the docker start environment with the following settingsã€‚


",feythin,slackpad
1537,2015-12-22 02:26:29,"@ryanuber good call. We get a ""count"" metric for free with the gauge so no need for two metrics.
",slackpad,ryanuber
1537,2015-12-22 03:11:19,"@scalp42 ah yeah this will make that a little worse temporarily. I don't think this'll make it into the next point release but I'll try to get https://github.com/hashicorp/consul/issues/1241 in the release after that.
",slackpad,scalp42
1534,2016-02-08 06:22:13,"Thanks @slackpad for the analysis. Indeed in this state we found out we cannot write to the KV store.
I had a correspondence on the outage issue with @armon in the past (see here: https://groups.google.com/forum/#!topic/consul-tool/k1ZnMHVwobA ), in which he said that if we restart each of the consul agents with the same flags they had in their previous run, we should be ok - has that changed?
BTW - we added a post-restart code that upon detecting that writes are stuck, it restarts the consul process. Sometimes it takes multiple restarts, but eventually it works. However, that's just a workaround. Appreciate your input on this.
",shimshon-stratoscale,slackpad
1534,2016-02-23 07:10:53,"@slackpad - we caused the crash in our test using an ""ipmi power off"" command, which as far as I understand is not graceful. In addition, our system is configured such that even in a graceful shutdown, we stop consul with SIGKILL, so that we never really leave the cluster (unless we specifically want to have that node leave the culster), so I don't think that's the case here.
",shimshon-stratoscale,slackpad
1531,2015-12-18 19:34:53,"Hi @scalp42 yeah this is a little confusing. Here's a list thread that talked about what's going on:

https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/consul-tool/dGTynOIQ33M/1ioEh-S5DgAJ

> This is correct and sorry it's a little confusing. To make a 0.5.x upgrade easier, we made 0.6 advertise that it speaks version 2 but that it understands version 3. This keeps older versions happy, but when a 0.6 instance sees that another version understands protocol version 3 it will automatically start sending it network coordinates and other 0.6-specific messages. No one will ever claim to speak version 3. 

I'll take this to either update the documentation or make the output of `consul version` a little clearer about the protocol, since several people have been confused about it. Glad to see you upgrade everything to 0.6.0!
",slackpad,scalp42
1531,2015-12-18 19:36:01,"@slackpad got it! 

Thanks for the quick answer :smile: 

Closing and happy Friday!
",scalp42,slackpad
1529,2015-12-18 06:44:23,"Hi @scalp42 this isn't something we've seen before during an upgrade. Can you run `consul info` on each of your three servers and make sure one shows `state = Leader`, two show `state = Follower` and all three have `num_peers = 2`? That'll provide a baseline that the servers are in a working configuration and not in some kind of split brain.

This line is suspicious:

`2015/12/18 03:10:34 [WARN] serf: Failed to re-join any previously known node`

If you run `consul members` on this agent does it show any other nodes in the cluster? Perhaps you need to run `consul join <one of the servers or any other cluster node>` to add it back into the cluster?
",slackpad,scalp42
1529,2015-12-18 19:19:04,"@slackpad thanks for the feedback, I'm not sure what happened to be honest.

Checked `consul info` and it's all looking fine on agents and servers, so going to close.

And open another issue actually :wink: 
",scalp42,slackpad
1528,2015-12-19 06:08:56,"Hi @c4milo sorry about the confusion on this one. I took a look through the DNS mux code and it doesn't look like it exposes a way to hook the default ""failed"" handler - it's all handled by the library and Consul doesn't see it. That's why there's no debug log output for this case. We can summarize that part of the config at startup though, along with the port information most likely.
",slackpad,c4milo
1528,2015-12-19 20:07:29,"It's ok, having the information logged upon startup will do it. Thanks for looking into this @slackpad!
",c4milo,slackpad
1527,2015-12-21 18:09:24,"@slackpad Parsing out the JSON shouldn't be a huge issue. Only that we'll have a couple different services doing it. I've determined that the easiest way of adding in this configuration would be to stick it on the check definition itself (`HealthCheck` in `./consul/structs/structs.go`) so it could eventually get set as an unexported field on `CheckHttp` in `./command/agent/check.go`

TL;DR I agree that solving this from consul's side would add a fair amount of configuration complexity. I personally don't have the bandwidth to dedicate towards a refactor but if there is an opportunity to resolve this in any upcoming work, I would be greatly appreciative :) Feel free to close this issue, unless you want it around for future reference.
",nickmiller-wf,slackpad
1521,2015-12-17 17:45:40,"Hey @sboily, you should be able to use the `CONSUL_HTTP_SSL=1` environment variable to control this. You can also use `CONSUL_HTTP_SSL_VERIFY=0` if you need to skip verification.

Admittedly I had to go code diving for this answer so we should definitely make it easier to find in the docs and CLI usage. Thanks for reporting this.
",ryanuber,sboily
1521,2015-12-17 18:21:29,"Hello @ryanuber, thank you it works :+1: 
",sboily,ryanuber
1509,2015-12-16 15:34:51,"@slackpad you mean that the logs of New leader elected are old logs that were sent to the syslog later?

Yeah, the setup are 5 nodes on each data center(3). After 2 severs died, they rebooted with consul and try to join the cluster. But this never happens and the cluster has no leader either. So all clients turn orphan because there's no leader.
",jimonreal,slackpad
1509,2015-12-17 14:32:13,"@slackpad But when running on bootstrap mode, only one server needs this parameter right?
and if a server goes down, next time it only needs to join, right? there's no need for the bootstrap-expect again.
",jimonreal,slackpad
1509,2015-12-17 14:58:12,"@slackpad and do they all(5 servers of the cluster) need to have this parameter set?
",jimonreal,slackpad
1509,2015-12-17 15:16:15,"@slackpad that's odd. I followed the documentation, and that was not needed but only for the first server. And I did some testing on that, and it worked.
",jimonreal,slackpad
1509,2015-12-18 14:38:11,"@slackpad this is the scenario to replicate the error.
Having a cluster running, and communication with other 3 clusters.
Restart the whole cluster, then there's no communication between the nodes of the cluster restarted.

I had to remove the data dir for the cluster to work again.
",jimonreal,slackpad
1509,2015-12-22 12:06:38,"Thanks @slackpad it was not the issue. But I will take that parameter into account.
",jimonreal,slackpad
1509,2015-12-22 20:26:37,"@slackpad I made the changes, started a new cluster, which connects to the other 2 over -retry-join-wan.

I am getting no cluster leader and the following logs:

docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:20:18 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:20:36 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:20:58 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:07 [INFO] serf: EventMemberJoin: vconsulmaster2wdc.wdc 172.17.0.1
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:07 [INFO] consul: adding server vconsulmaster2wdc.wdc (Addr: 172.17.0.1:8300) (DC: wdc)
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:20 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:22 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:43 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:44 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:46 [WARN] memberlist: Got ping for unexpected node vconsulmaster2wdc.wdc from=172.17.0.1:37051
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:46 [ERR] memberlist: Failed TCP fallback ping: EOF
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:48 [INFO] memberlist: Suspect vconsulmaster2wdc.wdc has failed, no acks received
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:49 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:13 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:32 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:41 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:53 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:56 [WARN] memberlist: Got ping for unexpected node vconsulmaster2wdc.wdc from=172.17.0.1:37379
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:56 [ERR] memberlist: Failed TCP fallback ping: EOF
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:57 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:58 [INFO] memberlist: Suspect vconsulmaster2wdc.wdc has failed, no acks received
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:23:09 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:23:26 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:23:26 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302

The consul is running inside a docker container.
",jimonreal,slackpad
1509,2015-12-23 13:13:00,"@slackpad Here I leave the config file and the command line parameters:

This is the node vconsulmaster1wdc and its the same config for everyone of them

server-config.json:



CLI parameters:


",jimonreal,slackpad
1509,2015-12-29 16:28:59,"after I deleted the data-dir, and started all from scratch it started working even if nodes where disconnected. Thanks @slackpad 

Regarding the data-dir files, which ones must be backed up?
",jimonreal,slackpad
1507,2015-12-21 03:38:35,"Hi @slackpad, I only added some records in `/etc/hosts` to resolve the domain/FQDN.



I don't know whether the DNS resolve library only uses real DNS and skips the `/etc/hosts`.
",subchen,slackpad
1507,2017-02-03 09:13:10,"@slackpad We experience the same issue. It seems `tcpLookupIP` goes to dns server directly and bypasses `/etc/hosts`. IMO this is wrong because you should respect `resolv.conf` in host lookups. This behavior makes Consul to fail connecting other agents in Azure environment. (In our case azure FQDN's are resolved to public IP address from the DNS server, but internal IPs are saved under `/etc/hosts`. When Consul resolves FQDN from DNS, it gets a public IP where it is firewalled and Consul is not bound to. Hence, Consul fails to join.)

Is there a true benefit from performing`tcpLookupIP` instead of `net.LookupIP`? Can we simply ignore that logic and perform go's net package?",kaskavalci,slackpad
1507,2017-02-03 14:48:39,"@kaskavalci ok this makes sense now. We want to keep the behavior of using TCP to get the largest possible list of hosts, but you are right that it breaks `/etc/hosts`. I think the best thing here would be to use Go's lookup and then `tcpLookupIP` and then merge + dedup the lists.",slackpad,kaskavalci
1507,2017-02-03 14:53:40,"@slackpad hmm, wouldn't that include multiple IP addresses for the same host? Assume the following `/etc/hosts` file:



We expect loopback address when we use go's lookup only but `tcpLookupIP` will return google's address too which will cause Join errors.
",kaskavalci,slackpad
1507,2017-02-07 10:29:10,"Hi @slackpad , are you OK with using only go implementation? I can send a PR for that as well.",kaskavalci,slackpad
1502,2015-12-15 17:50:45,"Hi @far-blue that should be everything:



The last release inadvertently had a sub-folder called ""dist"" that we removed for this release:



But the contents are all there, just without that sub-folder. Sorry if that caused some confusion!
",slackpad,far-blue
1500,2015-12-21 16:07:46,"@slackpad @erikdubbelboer here are some more examples:
- https://github.com/sethvargo/terraform-workshop-atlas
- https://github.com/hashicorp/best-practices
",sethvargo,slackpad
1498,2016-01-09 05:02:11,"@slackpad Thanks for the info and link to code. I appreciate the response.

I'll implement using my own watcher process and blocking queries.
",autoric,slackpad
1497,2015-12-16 02:04:45,"Hi @berendt,

Sorry about the issue with the URL.  I have a PR out to get this fixed.  https://github.com/hashicorp/consul/pull/1504

The correct URL for the demo is: https://atlas.hashicorp.com/hashicorp/environments/consul-demo

We will get this corrected in the getting started guide and thanks for creating this issue.
",pshima,berendt
1493,2015-12-11 15:58:08,"Woah, didn't realize we never updated this! Thanks @sethvargo, LGTM.
",ryanuber,sethvargo
1493,2015-12-14 19:43:10,"Thanks @sethvargo (and @tgwizard I fixed that)!
",slackpad,sethvargo
1489,2015-12-10 22:11:21,"Hi @c4milo do you know who's making these API calls?



It's odd there are HTTP requests to deregister it, those would come from some outside source.
",slackpad,c4milo
1484,2015-12-10 00:09:03,"@ryanuber it seems to me that if you don't specify `service` name in check, it will understand it as node-level check and apply to every service on that node. i got `docker` service says `passing 24` because it counts `docker` service itself + `serfHealth` + my own `dnsmasq` check, that doesn't have a `service` defined in the configuration. I am running 8 node cluster with `docker` on every instance. Am i getting it right?
",tpolekhin,ryanuber
1482,2015-12-09 17:37:21,"thanks @slackpad 

the only reference i see on the cluster logs;



I am running the curl on one of the consul cluster node.
",rbrutas,slackpad
1480,2015-12-16 15:02:15,"Thank you for the tip @daveadams . Unfortunately this currently disqualifies the use of the official client https://github.com/Ecwid/consul-api or the puppet module https://forge.puppetlabs.com/KyleAnderson/consul since those do not offer such a way easily. The documentation also states here https://consul.io/docs/agent/checks.html that one is able to specify a name for the check. 
So, is there the idea of adding that? 
",das-vinculum,daveadams
1479,2016-01-09 01:08:49,"Thanks @slackpad!
",lukesteensen,slackpad
1478,2017-03-27 19:34:26,"@sean- awesome, to bad it's not mentioned in https://www.consul.io/docs/guides/bootstrapping.html or https://www.consul.io/docs/agent/options.html",salzig,sean-
1476,2015-12-09 03:22:37,"@slackpad I'll definitely be documenting this as the OOM killer just took out one of my load balancers. This configuration worked flawlessly on 512mb ram prior to introducing Consul. Now even with a 1024mb box consul is able to take the whole node down.
",jmealo,slackpad
1476,2015-12-09 23:03:21,"@slackpad: I upgraded to 0.60 and the problem persists. Here's the output of /debug/pprof/heap?debug=1 after running for 8 hours 38 minutes.

[output.txt](https://github.com/hashicorp/consul/files/57456/output.txt)
https://gist.github.com/jmealo/fbae77eca68cca535fb9

**Output of `free -tm`:**



**Output of `cat /proc/meminfo`:**



**Output of `slabtop -o`:**



**Output of `vmstat`:**


",jmealo,slackpad
1476,2015-12-10 18:20:16,"@slackpad We just hit 92% memory usage again, attached are the output of all of the commands that I've provided before as well as the `ps` output that you requested for consul, nginx, and all processes.

[consul_debug.txt](https://github.com/hashicorp/consul/files/58498/consul_debug.txt)
[free.txt](https://github.com/hashicorp/consul/files/58501/free.txt)
[meminfo.txt](https://github.com/hashicorp/consul/files/58500/meminfo.txt)
[nginx.ps.txt](https://github.com/hashicorp/consul/files/58503/nginx.ps.txt)
[ps.all.txt](https://github.com/hashicorp/consul/files/58502/ps.all.txt)
[slabtop.txt](https://github.com/hashicorp/consul/files/58499/slabtop.txt)
[status.txt](https://github.com/hashicorp/consul/files/58504/status.txt)
[vmstat.txt](https://github.com/hashicorp/consul/files/58505/vmstat.txt)
[consul.ps.txt](https://github.com/hashicorp/consul/files/58506/consul.ps.txt)
",jmealo,slackpad
1476,2015-12-10 18:39:18,"@slackpad: I don't think so, we're not heavily using it right now. We have 7 nodes and 48 health checks total.
",jmealo,slackpad
1476,2015-12-10 18:48:57,"@slackpad Thanks for all of your help/patience. This is what the memory usage looks like, it presents itself like a classic memory leak, however, it doesn't seem to be based on requests or traffic, but rather time.

![screen shot 2015-12-10 at 1 46 32 pm](https://cloud.githubusercontent.com/assets/1066536/11724859/8c3c21be-9f44-11e5-9214-e6e3a9742a15.png)

Due to consul running health checks at regular intervals, that might create enough traffic to influence the graph.
",jmealo,slackpad
1476,2015-12-15 00:12:49,"@slackpad: It certainly seems like it is raft using up the memory (see output below). I'm not sure why `pmap` is the only tool that knows that it is consul consuming the memory. I will dump telemetry if I'm able to sanitize it easily.


",jmealo,slackpad
1476,2015-12-15 00:22:38,"@slackpad `kill -s USR1 $(pidof consul)` doesn't seem to work for me when syslog is enabled in the consul server config file. Do I need to run the process in the foreground or pipe `stderr` to a file to dump telemetry?
",jmealo,slackpad
1476,2015-12-16 01:26:58,"@slackpad: It's been 1 day 20 minutes since I disabled consul on my cluster and we've experienced no memory issues. Prior to disabling consul I had to reboot the servers every 6 hours to clear memory. I'll rest easier if we let it go another couple of days, but, this configuration worked for 2-3 months without Consul and removing it seems to immediately solve the problem, so I can say with some certainty that Consul is the issue.

I don't know why only the load balancers have this issue, the only difference in their configuration is the allowed number of open files is significantly higher, which could possibly be allowing something to leak handles.

To me the `pmap` output makes it clear that raft.db is using a significant amount of memory. Perhaps log compaction is leaking memory?

If it helps at all this happened in 0.5.x and 0.6.x so the large changes in 0.6.x probably don't have anything to do with it.
",jmealo,slackpad
1476,2016-01-08 20:39:09,"@slackpad Thank you for following up. As excited as we were about consul we ended up reimplementing everything we needed from it in Node in about a day and have had zero infrastructure issues since we got rid of Consul.

My only update is that Consul was the cause of the OOM issues.

I guess it's safe to close this ticket; however, the problem exists and causes catastrophic failures that could take every node in a cluster down one-by-one within a few minutes of each other if consul is started at the same time on each node where this condition is present. This would obviously be bad but also likely require the user to redo the bootstrap process.

That might be a good thing, because if the cluster goes down and comes back up and consul isn't working, it won't take down the cluster again.

We sunk a couple of weeks of troubleshooting and hours of downtime in production into this and I hope that nobody else goes down that rabbit hole.

If you think of it whenever the problem is finally solved or encountered on your end please ping me :-)
",jmealo,slackpad
1476,2016-01-08 20:56:09,"I'm glad you found a solution @jmealo. If you ever get around to it we'd love to look into this further with you but if you're happy with your current solution its best to leave it as-is.

We work personally (1-on-1) with a handful of the largest websites that exist that run gigantic Consul clusters and in the past we have found memory leaks we've fixed straight away (none recently to my knowledge). These clusters generally run with a long uptime and their memory usage is stable. They use every feature of Consul (at least prior to 0.6, folks are still adopting 0.6 features) and have never experienced memory issues.

None of this means that you didn't have a real issue, but I'm confident that in the general case Consul is extremely stable and memory is well under control. There may have been something unique about your setup we missed through the back and forth here, though. I think @slackpad overall was correct and I mirror his view that all your debug output seems to point to Consul using a very reasonable amount of memory. So we must be missing some data somewhere.

Good luck and let us know if we can help in the future.

(EDIT: sorry ""james"" in GitHub for pinging you with this, I meant @slackpad)
",mitchellh,slackpad
1476,2016-01-08 21:19:41,"@mitchellh I'd really like to see this fixed. My node solution simply parses my consul health checks and runs them using Node instead of Consul. The health checks are unchanged except for one that checked a socket.io server by requesting `/socket.io.js` which is 170kb uncompressed and seemed the likely cause of the issue.

I can say with high confidence that the health checks were not the issue as they are running from Node without issue. As part of our consul troubleshooting, the socket.io test was disabled without relief.

The issue at hand here is consul/go-raft/go was causing a memory leak that:
1. Consul's telemetry doesn't know about
2. Every ""normal"" way of checking memory and shared memory allocation in Linux provided no insight into the cause of the issue

My primary concern is that another enduser will go absolutely bonkers trying to figure this out. I myself was convinced that consul was not the issue based on our troubleshooting. I went to DigitalOcean, KVM, linux-kernel NGINX, OpenResty, consul trying to figure out the memory usage issue to no avail. 

If I can get a box setup and recreate the conditions can you delegate engineering time to work on this?I'm not sure if I can reproduce it without the other 7 nodes in the cluster but it might be worth a try.

The stack that caused this will be open sourced in the not so distant future (a year tops). I may be able to provide bootstrap scripts for an entire cluster identical to this one at some point if you want to test it internally.

Thanks,
Jeff

EDIT: Additional info on largest health check response and wording.
",jmealo,mitchellh
1476,2016-04-07 01:09:03,"@slackpad @mitchellh From the looks of it this was a kernel leak caused by non-process code (which is why the memory could not be attributed to a process).

That being said, using OpenResty and consul together can reproduce the issue. Using either in isolation does not.

The issue did not happen when running vanilla NGINX with consul. The only difference is that OpenResty is serving 1-2k connections and NGINX was in the low hundreds. Since both the primary and failover load balancers would both fail after a set amount of time regardless of connection or load, I think it's safe to say that the network traffic has nothing to do with it. 

In the interest of saving everyone time (unless someone wants to learn how to diagnose kernel memory leaks in KVM on a cloud provider) I'd be willing to give it another go when Ubuntu 16 LTS is released.

**Does that sound like a good plan?**
",jmealo,mitchellh
1476,2016-04-07 01:09:03,"@slackpad @mitchellh From the looks of it this was a kernel leak caused by non-process code (which is why the memory could not be attributed to a process).

That being said, using OpenResty and consul together can reproduce the issue. Using either in isolation does not.

The issue did not happen when running vanilla NGINX with consul. The only difference is that OpenResty is serving 1-2k connections and NGINX was in the low hundreds. Since both the primary and failover load balancers would both fail after a set amount of time regardless of connection or load, I think it's safe to say that the network traffic has nothing to do with it. 

In the interest of saving everyone time (unless someone wants to learn how to diagnose kernel memory leaks in KVM on a cloud provider) I'd be willing to give it another go when Ubuntu 16 LTS is released.

**Does that sound like a good plan?**
",jmealo,slackpad
1472,2015-12-09 12:59:20,"@pearkes thank you for the detailed explanation - it's helpful in planning the mentoring and the process to make this code merge-able.

> The current automated tests are very shallow and don't cover a ton of the use cases. Upgrading and testing changes would require a lot of knowledge about UX for this UI and comparison with a full active instance of it. Something like http://demo.consul.io shows a set of the various states, but still lacks certain features (locks, ACLs).

Having some automated tests is helpful. We'll aim to not modify the HTML output to make it possible for you to run your test suite to verify the application. We're going to add acceptance tests to the application, so you'll have more tests when we're finished but it'll require manual checking on your part when we're finished.

> This UI is relied upon for critical infrastructure changes so there's not a lot of room for error and iteration â€“ we can't push breaking changes to things like k/v, full stop

We can keep this project fairly low risk and aim to have code ready for you to review. Your team can use the new app when you're ready.

> The packaging and dist scripts for our current release process are not npm backed, which might be a headache

This should be fine. We'll copy the Ember App code into a new EmberCLI project. With EmberCLI, we can run `ember build` which will generate 2 files: `vendor.js` and `application.js`. The only change that you'll need to make will be to copy the files into the main repo and link to these new files. 

> We have some bandwidth and Ember folks internally who can spend time reviewing this, but we can't make it a priority unfortunately, so timelines might be long there.

Our goal will be to upgrade the application to use all of the latest best practices in a new EmberCLI project. We'll speak to the demo API(likely via a proxy). You should be able to test the application by setting up a more complete cluster and point to it's API.

> Just wanted to be up front that this requires a lot of Consul understanding and has some hidden complexity

It would be difficult to go all the way with this project without your team being onboard to work with us, so we'll just do what we can.Refactoring the app into the latest best practices on EmberCLI seems like a fairly straight forward project. We can aim to have all of the features implemented that are currently visible on the demo site. The result will be a repo that'll build the app and talk to the demo API. At that point, you can take that code and integrate into your application when it becomes a priority.

What do you think?
",taras,pearkes
1468,2015-12-07 11:36:19,"Hi @slackpad, I was thinking of doing this with a check scripts indeed but I came across this in the consul documentation about HTTP checks: 

> This type of check should be preferred over a script that uses curl or another external process to check a simple HTTP operation.

In my scenario, I have services that depend on other services to function properly. Registering a check script to check via HTTP something that is already checked and available to the consul cluster seems wrong. But maybe I am trying to achieve too much out of the tool? 

Actually, stretching this idea even further, the ideal thing would probably be to be able to register dependencies on other nodes health checks or service checks that are within the cluster don't you think?
",hadrienk,slackpad
1467,2015-12-04 05:30:46,"Awesome - thanks @meirish!
",slackpad,meirish
1467,2016-01-14 23:59:22,"@slackpad where are you seeing this? on demo.consul.io I see the SVG icon in Chrome, but the old icon in Safari - any chance I'm just hitting a server running older ui code in Safari?
",meirish,slackpad
1466,2015-12-22 13:14:29,"@slackpad That's helpful! Thanks.
",tongda,slackpad
1465,2016-09-29 11:06:56,"@slackpad The question is about two things. 

> is that completely hidden because of the container wrapping?

I think this information is hidden from the environment of the guest (container), because this is exactly the point of the abstraction layer - transparent resource isolation. From the isolation standpoint, there is no sense to expose the information on how ports are mapped on a different level to the virtualized env.

> Is it possible for memberlist to become aware of the mapped ports by any direct means

Acquiring this information is possible, yet it is not very easy. The starter environment inside of the container may be organized by any means to obtain this information from the Docker daemon (requested mapping), host conntrack/nat configuration (Get-NewNATSession/StaticMapping) or any other way available; and then it should pass gathered info on mapped ports to the consul server agent start command line. And there are may exist other levels of indirection. Organizing all this is not very pleasant.

Personally, I would prefer MemberList to be able to detect miss-advertised ports automatically based on the stats of the incoming UDP traffic. The thing is the wrong port advertisement can be detected only from the outside of the container network host environment, so memberlist could reuse additional knowledge to at least detect such a cases.
",sitano,slackpad
1465,2016-10-01 16:34:36,"@slackpad I wanted to share another thought

This NAT issue is not a _BUG_. The bug is an error in implementation or environment. But a cause of this flapping behaviour is not an error, but wrong ports configuration. It's not a fault of the Consul, that it awaits properly declared ports to be available in advance. The fact of mismatching of advertised ports and mapped ports results into the situation where one side\or both of membership protocol does not see ping's acks.

Flapping behavior, in that case, is also normal, due to how MemberList is working. Suspect nodes can successfully refute its deadness. There is also a separation of MemberList operations between active and passive (ping ack is passive, refuting and resync is active).

Flapping is possible when behind a NAT, there is a still partial visibility (some ports are accessible and known, others dont) and is, due to the protocol best effort.

Maybe this issue (and all related) could be closed then, because the only way to organize valid networking for the Consul, is to know your ports, and not to advertise wrong ones. We run it on Linux docker like that:


",sitano,slackpad
1460,2015-12-01 23:19:54,"@slackpad  Than you so much for your help.  This came down to a subnet issue.  I am not sure why it would get a 200 back at all if it was on the wrong subnet, but it did.  I have since resolved the issue by creating another load balancer and placing it on the right subnet.  
",sflint,slackpad
1452,2015-11-29 04:47:58,"@slackpad we may as well. It's a small change but should drop the memory foot print noticeably.
",armon,slackpad
1448,2015-12-21 23:19:56,"Hi @gozer - would you mind sticking the address at the end of the log message and using the new log functions from memberlist, so these will all look the same? Here's an example: https://github.com/hashicorp/consul/blob/master/consul/rpc.go#L86. There's a `LogAddr` function that should work for your use case here. Thanks!
",slackpad,gozer
1448,2015-12-22 23:29:22,"@gozer sorry I didn't realize that. In that case, it should be good enough to stick it at the end as `""... from=%s""` to match the memberlist format. Agree it's not worth converting to an address.
",slackpad,gozer
1448,2015-12-30 20:41:28,"@slackpad done as suggested
",gozer,slackpad
1448,2016-01-05 04:59:31,"@gozer thanks for the update! One other thing - I think your `split()` call will mangle IPV6 addresses - since it's just a string I'd probably just print it with the port number.
",slackpad,gozer
1448,2016-01-05 16:52:04,"@slackpad, you are absolutely correct, that address splitting had bothered me from the start, to be honest. Removed as suggested.
",gozer,slackpad
1439,2015-12-17 14:30:17,"@ryanuber sorry for the late reply.
i am using docker setup from https://github.com/gliderlabs/docker-consul/blob/master/0.6/consul-server/Dockerfile 

> > Running consul
> > docker run test  -bootstrap -ui-dir /ui
> > ==> WARNING: Bootstrap mode enabled! Do not enable unless necessary
> > ==> WARNING: It is highly recommended to set GOMAXPROCS higher than 1
> > ==> Starting Consul agent...
> > ==> Starting Consul agent RPC...
> > ==> Consul agent running!
> >          Node name: '23f87bf86c12'
> >         Datacenter: 'dc1'
> >             Server: true (bootstrap: true)
> >        Client Addr: 0.0.0.0 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
> >       Cluster Addr: 172.17.0.6 (LAN: 8301, WAN: 8302)
> >     Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
> >              Atlas: <disabled>

==> Log data will now stream in as it occurs:



==> Newer Consul version available: 0.6.0

> > inside the container 
> > curl  localhost:8500
> > <a href=""/ui/"">Moved Permanently</a>.

but if i ran curl  -L localhost:8500 , i am getting the output.

> > outside the container http://172.17.0.6:8500/ is not working , where 172.17.0.6 container ip 

i am able to see ui folder inside the container 

> > bash-4.3# ls /ui
> > index.html  static
> > 
> > docker ps
> > CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                  NAMES
> > 23f87bf86c12        test                ""/bin/consul agent -s""   8 minutes ago       Up 8 minutes        8300-8302/tcp, 8400/tcp, 8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp   sharp_wright
",hridyeshpant,ryanuber
1432,2016-07-06 23:09:33,"@slackpad Thank you for response. This is quite demanded feature and everyone is too excited.
",t3hk0d3,slackpad
1432,2016-07-07 06:33:51,"Great! @slackpad let us know if we should rebase & fix this pull request to match the current master head
",adamdubiel,slackpad
1432,2016-08-08 09:04:03,"@sean- Thanks for the response. I like your suggestion about changing the api as it's more human-friendly and unified for all types of checks. I'll have a look at the fresh source code of Consul and probably make some bigger rebase / refactor of this PR - please, give me some time for that.
I've noticed that my change doesn't affect the check registration at `/v1/catalog/register`, should it be promoted to the catalog api?

By the way, If anyone is interested, we've developed a custom tool for the Mesos/Marathon environment that does the automatic service (de)registration - https://github.com/allegro/marathon-consul.
",dankraw,sean-
1432,2016-08-12 20:43:12,"@slackpad Awesome, I'm very happy to hear that! :) 
Maybe it'll be even better to start from scratch as `deregisterCriticalServiceAfter` property suggest a better / cleaner solution for service removal. A single job wiping out critical services should do better, so there will be no mess in the code responsible for ""check update"".
",dankraw,slackpad
1423,2016-01-07 18:01:56,"@slackpad Awesome, great work by the way!
",Kr1sso,slackpad
1419,2016-03-05 02:59:59,"@slackpad I don't think we want to do that. In the case where you have tons of ACL tokens, you probably don't want to pre-load them all, and the cache is a pretty huge performance win. Given that the logic is already there, I don't see a compelling reason to remove it.
",armon,slackpad
1419,2016-03-05 05:20:49,"@armon are you thinking we'd still replicate the full un-compiled policy set from the servers but retain the cache of compiled policies (so you could still look up any ACL in the event of a partition)?
",slackpad,armon
1419,2016-03-07 03:04:59,"@slackpad I'm not exactly sure what you mean, but I meant this would act as a second cache tier, and would not affect the existing caches.
",armon,slackpad
1419,2016-03-07 03:11:10,"@armon I think the main thing I'm stuck on is what subset of ACLs would you use to warm the cache?
",slackpad,armon
1419,2016-03-07 04:26:34,"@slackpad I think there is basically 2 different caches. Cache 1 is the existing LRU/2Q of fixed size. Its keyed on the actual token and cannot be disabled. Cache 2 would be new, keyed on the hash of the id, and would contain the _full_ ACL set.

The idea is ACLLookup(token) -> Cache1(token) || Cache2(hash(token)) || ACLResolve(token)
",armon,slackpad
1414,2015-11-15 01:56:23,"@mitchellh agree this is weird to fix at the state store level but I couldn't find any clean place to put these up in the HTTP layer without doing a bunch of post-filtering up there (some of these are nested inside other structures). I looked at the JSON marshaling and didn't see a good way to hook it in there (though that would have changed the API on other ways because we do have some `null` arrays in the JSON). I think it'll be the common case that we are going to fill these slices anyway (we were already `append`-ing onto a nil which kind of sucks since we don't know the sizes beforehand) so this won't be too bad.
",slackpad,mitchellh
1414,2015-11-15 05:09:17,"LOL @mitchellh your spidey sense was right with this one.

The failing test was due to a slice weirdness when I converted KV to be consistent. When a unit test tried to use the same reply object multiple times we ended up getting the underlying arrays pointed incorrectly. Looking into this I realized that KV already dealt with nil slices up at the HTTP layer, so I just changed the other endpoints to match. It was dirty to enforce the HTTP interface via the state store, and we were just getting lucky before because we did things and different layers.
",slackpad,mitchellh
1408,2016-03-19 05:11:27,"@slackpad  The functionality we needed (rotating encryption keys) is not available in the HTTP API.  In https://github.com/hashicorp/consul/issues/1368 we were told that RPC interface was not internal.
",rosenhouse,slackpad
1408,2016-03-22 19:24:19,"@slackpad speaking on behalf of @rosenhouse we would prefer to only interact with consul over HTTP if that were possible. We were only using the RPC client out of necessity.
",ryanmoran,slackpad
1407,2015-11-12 11:17:57,"@slackpad: Thanks! Email sent with the log file.

Re: hashicorp/vault#679; How do I check how many keys I have under `/vault/core/leader`?

Whenever I try to do a query like curl 'http://consul01:8500/v1/kv/vault/core/leader?recurse', it times out and causes the Consul server to crash.
",msabramo,slackpad
1400,2015-11-12 02:52:37,"@ryanuber that is exactly what I want
",JeffChien,ryanuber
1400,2016-03-30 22:01:10,"@ryanuber Any updates on this?
",aanm,ryanuber
1397,2015-11-20 07:37:05,"Hey @captainill this is looking awesome!

Running this locally and clicking around I had a few questions for you.

###### You probably need to rebase. A ""Prepared Queries"" section will get added to this nav:

![image](https://cloud.githubusercontent.com/assets/673509/11294102/8e3ba64a-8f15-11e5-9782-c8baa35d6044.png)

###### I'm seeing one 403 for a Typekit-related resource:

![image](https://cloud.githubusercontent.com/assets/673509/11294127/bcfd7a26-8f15-11e5-8a51-6623693669ca.png)

###### What do you think about anchoring the ""edit this page"" link to the bottom? When I first landed on this page I thought ""oops this is a placeholder"". It looks fine for long pages but a little funky for short ones:

![image](https://cloud.githubusercontent.com/assets/673509/11294145/f110b0b2-8f15-11e5-9c8c-15454ab13866.png)

###### Not sure if it is related to the 403 error, but these headings on the main page ended up super light:

![image](https://cloud.githubusercontent.com/assets/673509/11294155/0a9f6fd2-8f16-11e5-8db5-01f77effd634.png)

(same for the Key Value Storage heading that follows this one)
",slackpad,captainill
1397,2015-11-20 20:59:40,"@slackpad Thanks for looking over!

-I'll do the rebase
-The failed to loaded resource 403 is on the live site so it'll be good to fix that anyhow. Not sure what the story is there
-Ah! I actually anchored it in the other sites as I was doing this but I missed it here. Good call.
-I think that the header issue (super light font color) is just a selector issue but I'll fix whatever it is
",captainill,slackpad
1397,2015-12-04 06:49:41,"@captainill any chance you can make a pass through here again before we ship 0.6? Thanks!
",slackpad,captainill
1397,2015-12-20 19:27:10,"@slackpad Along with 'by HashiCorp' logo in the header being correct now I

-merged maste into my branch
-pinned the EDIT THIS PAGE link to the bottom
-made the H2 headings on the homepage readable

I had to reach out to Typekit about the 403. As far as I can tell typekit is configured correctly (the correct domain is listed for usage and the embed code is right) so I'm not sure what the deal is. I can report back when I get that sorted but if the rest checks out I would merge this and i'll circle back with a 403 fix when I've got it.
",captainill,slackpad
1396,2015-11-09 19:17:52,"Hey @saromanov, thanks for the pull request. The best way to control the result of the health check is by using exit codes. Consul's health checks are Nagios-compatible, so exit codes 0 == passing, 1 == warning, and anything else is critical. I would recommend using the exit code instead.
",ryanuber,saromanov
1395,2015-11-09 17:34:21,"Thanks @highlyunavailable - this wasn't intended so I'll get a fix in and look through the other endpoints. 
",slackpad,highlyunavailable
1394,2015-11-09 16:25:41,"Hi @saromanov thanks for making a PR, though I think this would be kind of an unexpected behavior for the `rtt` command (we were trying to make it feel a little like a `ping`. Did you have a specific use case in mind?
",slackpad,saromanov
1389,2015-11-17 06:45:43,"@armon For the Sort option, with the failover options also using RTT it seemed too confusing/crazy UX-wise. I plumbed it as a Source parameter to the endpoint so it works like all the others with a `?near=` argument over HTTP (like all the other coordinate-aware endpoints), but his does preclude it over DNS since there's no way to activate that. It's an advanced feature that's possible to use if you are building on the HTTP API, but not part of the DNS response anymore.

It seems very tricky to use via DNS properly (no load balancing and the agent you are sorting based on can be unclear if you are proxying Consul's DNS, recursing, etc.) so WAN-only use of RTT seemed like the clear winner and less of a foot shooter. I'm definitely open to adding it back in the query definition if you think it's useful for DNS as well. It would be a minor change, might even be doable as an agent option. It might even be clearer as an agent option so it can be explained as ""if I serve a prepared query, sort the results relative to me"".
",slackpad,armon
1389,2015-11-17 16:02:03,"@slackpad looking good, I left some minor feedback and questions throughout.
",ryanuber,slackpad
1388,2016-09-30 04:56:22,"@slackpad any chance this PR can get some love now that v 0.7 is out? cheers
",DanyC97,slackpad
1387,2016-08-11 02:12:45,"@slackpad I'm not so sure they're related, the issue I had was related to the node acquiring leadership, then losing it straight away (within a second, when running with quorum of 1). The buffer thing was separate to that.

Either way, I haven't seen this recently, so could be worth closing, unless others are also experiencing it?
",BRMatt,slackpad
1383,2016-09-22 15:40:43,"thanks for letting us know @slackpad !
",claudio-viola,slackpad
1382,2015-11-05 07:07:16,"Thanks @highlyunavailable ! That was very helpful.

In case it helps anybody, I applied your workaround in HAProxy like so:


",kvz,highlyunavailable
1380,2015-11-18 21:08:38,"Yep this should be fixed by https://github.com/hashicorp/consul/pull/1341 - once we roll out 0.6.0 (very soon) this will be fixed. Thanks for reporting this @yoshuawuyts and your help @highlyunavailable. Sorry we can't push it sooner but we don't want to confuse people with the docs for 0.6.0. 
",slackpad,highlyunavailable
1379,2016-01-08 01:32:48,"Hi @saromanov thanks for the PR. I think we'd want to do some more up front design work before adding this system - there's a lot to think about such as how to rotate logs, should requests fail if auditing is not possible, etc. We can work this under #414 once we put auditing on the roadmap, but I think we will hold off for now.
",slackpad,saromanov
1374,2015-12-03 19:37:02,"@slackpad - I've been thinking that it would be great expose an HTTP agent endpoint at /v1/status/info and perhaps another at /v1/status/members that would provide the info currently emitted in difficult to parse format from `consul info` and `consul members`.

I'd be happy to contribute a PR for this type of change if there is some agreement that it makes sense/would prove useful.
",trumant,slackpad
1374,2016-06-08 01:21:20,"@slackpad or @sean- do either of you have any updates on this issue?
",CpuID,slackpad
1368,2015-11-03 20:01:24,"@highlyunavailable We're attempting to create fakes in order to unit test consumers of the `agent.RPCClient`. The problem we have now run into is that `agent.RPCClient.InstallKey()` returns a `keyringResponse` which is unexported. It seems like significant portions of the `RPCClient` (really, any of the various methods around keys) are actually unexported and therefor not necessarily suitable for 3rd party use.
",zaksoup,highlyunavailable
1358,2016-07-26 15:56:28,"@slackpad seems like #1430 is dead, should we create a new one or is there something that you're not satisfied with?
",amenzhinsky,slackpad
1358,2016-08-22 15:45:31,"@carlpett you can always wrap it in `/bin/sh -c`.  You would not need to put it in a separate script.
",mfischer-zd,carlpett
1358,2017-02-27 05:31:45,"@slackpad your comment aligns with a recent breaking change in [consul-template v0.18.0](https://github.com/hashicorp/consul-template/blob/master/CHANGELOG.md#v0180-january-20-2017)
> A shell is no longer assumed for Template commands. Previous versions of Consul Template assumed /bin/sh (cmd on Windows) as the parent process for the template command. Due to user requests and a desire to customize the shell, Consul Template no longer wraps the command in a shell. For most commands, this change will be transparent. If you were utilizing shell-specific functions like &&, ||, or conditionals, you will need to wrap you command in a shell, for example:)",steve-jansen,slackpad
1343,2015-10-27 16:18:08,"LGTM @diptanu @slackpad Can we make sure the website docs get updated for this change as well
",armon,slackpad
1343,2015-10-27 16:18:08,"LGTM @diptanu @slackpad Can we make sure the website docs get updated for this change as well
",armon,diptanu
1343,2015-10-27 21:55:17,"@diptanu it looks like this change broke some of the BSD targets (from a full `make`):


",slackpad,diptanu
1336,2015-10-26 15:10:05,"@slackpad once I get all the sites updated, I'm going to move the fastly logo into middleman-hashicorp and compress it there :smile: I just didn't feel like doing it 8 times, and I can't do it until all the sites are updated :smile: 
",sethvargo,slackpad
1333,2016-04-13 20:43:05,"@slackpad can confirm, removing everything from `/var/lib/consul/` seemed to fix a service that was registered by registrator. We ran registrator against the local consul-agent, so I'm assuming moving it to hit the consul-cluster instead may fix the issue...
",josegonzalez,slackpad
1326,2015-10-22 20:34:06,"@ryanbreen Yep! Fixed by #1318 
",armon,ryanbreen
1311,2016-02-05 22:46:57,"Hey @slackpad 

Thanks for following up.  Yes, we're still having this issue.  We [guarantee data persistence when scaling up from 3 to 5](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L80-L100) whereas we [only guarantee the cluster is functional after scaling up from 1 to 3](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L28-L46). @ryanmoran and @zankich spoke with @mitchellh and some HashiCorp folks when they visited our office, sounded like this is something we have to live with for now.
",Amit-PivotalLabs,slackpad
1311,2016-02-13 22:44:18,"Hey @slackpad 

Those were two separate issues.  We've had users running a 3 node cluster, whom we've migrated to a 3 node TLS cluster, via a scale-down => turn on TLS => scale-up.  The scale-down can go south and requires manual intervention (usually blowing away data and starting from scratch, once we're wedged in an ""outage"" state)

Separately, we have continuous integration for our consul service that tests that it can be scaled up, down, and rolled in various ways.  One particular test deploys a 1-node cluster from scratch, then scales up to 3 by adding one node at a time.  Given the way we orchestrate this, we can't guarantee data from the 1 node persists on scale-up.
",Amit-PivotalLabs,slackpad
1302,2016-03-22 08:54:00,"@slackpad please reopen
",rtoma,slackpad
1299,2016-08-12 19:03:40,"@ross I think you are hitting the current behavior - the configured key is designed to be an initial one only - https://www.consul.io/docs/agent/options.html#_encrypt:

> Specifies the secret key to use for encryption of Consul network traffic... The provided key is automatically persisted to the data directory and loaded automatically whenever the agent is restarted. This means that to encrypt Consul's gossip protocol, this option only needs to be provided once on each agent's initial startup sequence. If it is provided after Consul has been initialized with an encryption key, then the provided key is ignored and a warning will be displayed.

Consul does this because there are commands to update the keys later and users won't want to revert to the initial key when restarting. You probably want your CI pipeline to blow away that state before baking an image.
",slackpad,ross
1291,2015-10-20 06:19:39,"@armon and @ryanuber all the outstanding comments have been addressed so please take another look.

I'm going to leave the TODO in `PrefixWatch.Notify()` for now since it's an existing bug and clean that up on another PR if I have time. I think it'll need a periodic sweep kind of cleanup, or else the notify groups will have to be able to tell the parent `PrefixWatch` once they have become empty.
",slackpad,armon
1291,2015-10-20 19:32:30,"@slackpad this all looks super solid! We should also remove the entry in the FAQ that mentions Consul's use of LMDB. I wasn't able to get a diff of the changes on the state store from where I left off and you picked up (because they are so large), but I perused the file and things looked sane. :+1:
",ryanuber,slackpad
1290,2015-11-17 02:14:39,"@slackpad I've seen this before in normal operation - if the server that the agent is connected to dies, the agent freaks out and loses all sessions. I know I commented on it somewhere in github but the search doesn't find it.
",highlyunavailable,slackpad
1288,2015-10-13 00:47:52,"@talwai We will fix this for the Consul 0.6 release, but currently build 0.5 against Go 1.4
",armon,talwai
1284,2015-10-08 22:10:09,"Thanks a lot @nbrownus :+1: 
",scalp42,nbrownus
1284,2015-11-03 18:48:51,"Any chance to look at this @slackpad following @nbrownus PR ? Would be greatly appreciated.
",scalp42,nbrownus
1284,2015-11-16 22:58:28,"Hi @nbrownus - thanks for this! Once we get 0.6 rolled out I'll work with you to review this so we can get it into the following release.
",slackpad,nbrownus
1284,2016-01-26 15:30:33,"@slackpad Aside from the merge conflict, is there anything stopping this PR from being merged? I have some time this week and could having a shot at rebasing it if @nbrownus is busy.
",BRMatt,nbrownus
1284,2016-01-26 15:30:33,"@slackpad Aside from the merge conflict, is there anything stopping this PR from being merged? I have some time this week and could having a shot at rebasing it if @nbrownus is busy.
",BRMatt,slackpad
1284,2016-01-30 00:25:33,"thanks a lot again @nbrownus much appreciated
",scalp42,nbrownus
1284,2016-02-01 14:19:32,"Thanks @nbrownus! :heart: 
",BRMatt,nbrownus
1278,2015-10-08 20:27:30,"@armon could we add chunk=true to delete endpoint so that recursive deletes will be done in smaller chunks, sacrificing the atomicity of the overall delete for performance?  For me I saw a 7.8 X performance improvement doing 10 separate 10,000 key deletes serially (8.5 seconds each, total time 84.6 seconds) versus doing a 100,000 key delete (660 seconds).   Then I ran 10 deletes of 10,000 keys each in parallel, and the last of them finished within 17 seconds.

So if the system did chunks in separate go routines, at the sacrifice of overall DELETE atomicity, could provide 40X improvement.  I could look into writing this,but only if it has a chance of being accepted :-) 
",wwalker,armon
1278,2015-11-19 04:48:44,"I like @mitchellh's idea of providing some kind of paging in the APIs. That would allow tools to delete in chunks and it would be obvious that atomicity is not guaranteed across the entire set.  The paging could possibly be useful for other uses too if it applies to GET and not just DELETE. I'm imagining some kind of key browser like the Consul UI for instance. In fact, the Consul KV UI started timing out like crazy when I had millions of keys, so it could probably benefit from being able to do queries with paging. 

I would think that it would be very, very good if Consul could refuse to delete more than a certain number of keys, say 1000 or something. That way if you have millions to delete, you would be forced to use paging and wouldn't be able to hang yourself like @wwalker and I did by attempting to mass delete millions in one query. 
",msabramo,mitchellh
1278,2016-01-04 16:00:39,"@slackpad is the patch above part of 0.6.0?

I just got hit with this again (1.6 M vault/core/leader/\* entries....)
",wwalker,slackpad
1274,2015-12-01 19:38:12,"I would like to finish it up. I think that always generating the file is better for early catching build errors. But I can implement it either way. Lets see what @ryanbreen and @slackpad have to say.
",rgl,ryanbreen
1274,2015-12-01 19:38:12,"I would like to finish it up. I think that always generating the file is better for early catching build errors. But I can implement it either way. Lets see what @ryanbreen and @slackpad have to say.
",rgl,slackpad
1274,2015-12-01 19:51:37,"Yeah I'd go with @ryanuber's suggestion and just check in the go file - adding Ruby/bundler to the default build path is pretty heavy so this'll keep things fast and simple for most people who aren't updating the web UI.
",slackpad,ryanuber
1274,2015-12-01 20:03:19,"Seems fair. As the @ryanuber branch already has that done, I'll retract this PR.
",rgl,ryanuber
1265,2015-10-13 04:15:45,"Hi @spheromak sorry for the delay on this, and thanks @armon. Your change in #1296 looks good but iirc there were no health checks for these services. Looking at the code I'm surprised there's not an n^2 loop over services so I'm not sure this alone will fix it.
",slackpad,armon
1265,2015-10-13 12:29:20,"No agent checks. We were planning on doing http callbacks for service
status.

On Mon, Oct 12, 2015 at 9:15 PM James Phillips notifications@github.com
wrote:

> Hi @spheromak https://github.com/spheromak sorry for the delay on this,
> and thanks @armon https://github.com/armon. Your change in #1296
> https://github.com/hashicorp/consul/pull/1296 looks good but iirc there
> were no health checks for these services. Looking at the code I'm surprised
> there's not an n^2 loop over services so I'm not sure this alone will fix
> it.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1265#issuecomment-147597716.
",spheromak,armon
1265,2015-10-13 12:34:50,"This may have been causing the slowdown. I am traveling this week but will
try to get a test run with the patch
On Tue, Oct 13, 2015 at 5:29 AM Jesse Nelson spheromak@gmail.com wrote:

> No agent checks. We were planning on doing http callbacks for service
> status.
> 
> On Mon, Oct 12, 2015 at 9:15 PM James Phillips notifications@github.com
> wrote:
> 
> > Hi @spheromak https://github.com/spheromak sorry for the delay on
> > this, and thanks @armon https://github.com/armon. Your change in #1296
> > https://github.com/hashicorp/consul/pull/1296 looks good but iirc
> > there were no health checks for these services. Looking at the code I'm
> > surprised there's not an n^2 loop over services so I'm not sure this alone
> > will fix it.
> > 
> > â€”
> > Reply to this email directly or view it on GitHub
> > https://github.com/hashicorp/consul/issues/1265#issuecomment-147597716.
",spheromak,armon
1264,2015-10-06 06:42:28,"@highlyunavailable I think we should improve the documentation for `force-leave` then
",omribahumi,highlyunavailable
1254,2015-09-28 21:50:57,"@highlyunavailable What would be the recommendation for persisting that data, and in the case of a cluster outrage what would be the recovery process? Would it be pointing the new server nodes' `-data-dir` to the old data directory that was backed up in one way or another (e.g. a persistent volume that was mounted to the old instance)?
",calvn,highlyunavailable
1254,2015-10-05 19:07:03,"Interesting topic. We are currently backing up our dockerized Consul servers using [Convoy](https://github.com/rancher/convoy), but it appears that this will cause issues if we were to restore this data onto a new Consul server on a machine with a different IP address, as @highlyunavailable noted. We followed this as recommened by @armon in this [Google Group topic](https://groups.google.com/forum/#!msg/consul-tool/cbe_W_SClog/u3PhFlDlyaAJ).

We know that [Consulate](https://github.com/gmr/consulate) exists, but we are striving for a service-agnostic back up solution, which is why we settled with Convoy. 

Our main goal was to backup the K/V store. Is there a subdirectory we should be backing up instead of the `/data/` directory in its entirety?
",djenriquez,highlyunavailable
1254,2015-11-03 18:40:46,"Sorry for the late reply on this one. The snapshots contained in the data-dir should be useful for providing you a good state checkpoint in the event of a disaster, but as @highlyunavailable noted, the peers list would probably need surgery and there's no consistency guarantees for the Raft log post-snapshot, so that data could be lost (if it was corrupted you'd probably have to delete it and/or zero it out). Also, the frequency of snapshots is hard to control so it's hard to control the amount of data that's exposed.

We are going to look into adding a new snapshot API and/or CLI that would let you kick out a snapshot so you could have a known restore point. The Raft log post-snapshot would always be at risk, but at least you could control when the snapshot occurs.

Not sure which release this would be targeted for, but will update this ticket once it's slotted on the roadmap.
",slackpad,highlyunavailable
1249,2015-09-21 18:17:41,"Hi @macb - thanks for opening this. I think we are going to take a look at doing something along these lines across more than just Consul, so you should probably hold off on ""going rogue"" :-) We will update this once we've got a plan.
",slackpad,macb
1249,2015-09-21 20:43:01,"Awesome @slackpad, looking forward to it.
",macb,slackpad
1249,2016-02-02 10:19:36,"@slackpad if you can come up with a recommendation (I'm personally a fan of [logrus](github.com/Sirupsen/logrus)), that might be the kind of thing a community contributor could tackle.  I'm personally irked by the logging output of consul-template, consul, and vault; if you could settle on a framework across all your products, that'd be a really great experience for us ops-y folk!
",blalor,slackpad
1249,2016-02-02 18:32:45,"Thanks for that recommendation @blalor.  It's something that has come up several times internally and isn't a resolved issue yet.  Stay tuned.
",sean-,blalor
1247,2015-09-22 09:14:04,"Hi @slackpad - Thank you for your considering with my questions. I just running a consul cluster without consul-template. As I have registered about 400 services and checks, I suspect whether the 400 checks cause the problem. Each of my checks registered with a interval as 2 seconds by the HTTP method. Now I will try to register my services and checks randomly into the cluster and enlarge my cluster with more servers. Thank you very much. I'm looking forward to a more powerful version of consul.
",zhouzhongmi,slackpad
1245,2015-09-18 17:55:39,"Yup, @highlyunavailable  traffic is open both ways for ports 8300, 8301/udp, 8301, 8302/udp, 8302, 8400, and 8500.



I tried adding a timeout, but as far as i know, netcat's lowest timeout is 1 second, which passes everytime for all ports in both directions...
",djenriquez,highlyunavailable
1245,2015-09-21 17:43:10,"Looks right, I think. :stuck_out_tongue_closed_eyes: 

us-west-2



us-east-1



I appreciate your time on this @slackpad.
",djenriquez,slackpad
1245,2015-09-23 18:10:55,"Ah, I don't remember @slackpad, sorry.

I noticed that the consul DCs attempt to join each other, then give up for a period of time and then retry again later. I came to this conclusion because when I navigate to 10.179.3.152:8500, there are periods of time where US-EAST-1 does not appear in the datacenter list, then it'll eventually come back. Maybe 8300 wasn't showing up because I dumped the session when one of these cases was happening?

In no case does clicking on that datacenter load successfully.

Are there any scenarios you would like me to capture? I would post all of the tcpdump in here, but theres just a ton of records.
",djenriquez,slackpad
1245,2015-10-02 21:47:14,"@slackpad Is there a way to ""cancel"" the `join -wan` command? Since this isn't working for us at the moment, i'd like Consul to just stop trying to join. Its been trying to join for a little under two weeks now!
",djenriquez,slackpad
1245,2016-11-09 19:18:41,"Hi, @slackpad. Could you please elaborate leave process for the WAN pool in details?
I also need to disjoin datacenters.
You mentioned two ways to do it.

### Issue  'consul leave' or 'consul force-leave' command and restart Consul.

If I do this, I suppose that I need to do it on each node and it is hard to do it by a script in an automated way since I need to restart Consul.

Even if I do this manually, will this leave just WAN protocol but keep LAN protocol as it were before joined to another datacenter?

### Cut off the traffic and let Sert declare them dead.

Does this mean I need to update some configuration for raft or consul?
For example, take out serf_wan from consul.conf?



I would appreciate your answer in advance.
",hosunghwang,slackpad
1244,2015-09-16 11:27:57,"@sethvargo just to be clear, what we do for all requests except for the first one is to set the `index` query param to the value of the `X-Consul-Index` of the previously received response, indicating that we are interested in receiving a response only if something has changed since that specified index. AFAIK this is  straight from the Consul Http API docs.
",agemooij,sethvargo
1244,2015-09-17 10:54:42,"Hi @slackpad and @sethvargo, we ran some tests and this is the current situation:
- we checked several services and their health checks and we can verify that their health checks consistently and continuously produce exactly the same responses (i.e. the same status and the exact same http entity).
- we can see that **all (!)** indexes, or at least all the ones for all `/v1/health/service/<service>` and `/v1/catalog/service/<service>` endpoints for all our services are being incremented almost continuously. this includes the ones for which we have verified that their health checks are returning idempotent responses.

The big question is therefor: what could be triggering index increments for those two endpoints for every single service we have running? Especially if we can verify that their individual health checks do in fact return idempotent responses.

Just to be sure, does Consul guarantee that each individual service has its own index and that changes to one service don't trigger an index increment to another service?
",agemooij,slackpad
1244,2015-09-17 10:54:42,"Hi @slackpad and @sethvargo, we ran some tests and this is the current situation:
- we checked several services and their health checks and we can verify that their health checks consistently and continuously produce exactly the same responses (i.e. the same status and the exact same http entity).
- we can see that **all (!)** indexes, or at least all the ones for all `/v1/health/service/<service>` and `/v1/catalog/service/<service>` endpoints for all our services are being incremented almost continuously. this includes the ones for which we have verified that their health checks are returning idempotent responses.

The big question is therefor: what could be triggering index increments for those two endpoints for every single service we have running? Especially if we can verify that their individual health checks do in fact return idempotent responses.

Just to be sure, does Consul guarantee that each individual service has its own index and that changes to one service don't trigger an index increment to another service?
",agemooij,sethvargo
1244,2015-09-21 08:37:00,"Thanks @slackpad for the update. A fix to make the granularity of updates match with expectations and documentation would be very much appreciated. 

We are actively looking for all sources of non-identical health check responses and we have already found some obvious sources; mostly of health checks running against software we don't control, like Cassandra and Prometheus. Those services have timestamped health check responses. In my experience this is quite common behavior so finding out that Consul is not compatible with such situations is troubling. 

I think a lot of people using consul-template or other forms of watches might be running into this same problem, probably without even noticing except for some mysteriously high loads on their Consul clusters.

It seems some subtler, more configurable behavior is probably called for here. Perhaps some way of either ignoring or semi-interpreting the health check responses?
",agemooij,slackpad
1244,2015-09-22 14:43:27,"@mbroome as far as I understood the granularity of writes is cross-service at the moment. I'm not exactly sure where the granularity borders of these ""tables"" are but in practice for us this means that any write for service X on any Consul endpoint (catalog, health, etc.) will also trigger all watches for all other services on all other endpoints.

@slackpad It would be great if we could get a better insight of the current granularity of writes/watches. An initial high-level generalization would already be very helpful. 
",agemooij,slackpad
1244,2015-09-22 14:47:10,"@slackpad I agree that interpreting health check responses would be the last possible choice I expect you guys to make. I simply threw it into the discussion as an extreme alternative.

If the granularity of writes would increase, the side-effects of a chatty/flappy service would be greatly reduced. Next to that I agree that ""writes per minute"" or something similar would be a very helpful metric to have for a service so you can quickly debug problems like this.
",agemooij,slackpad
1244,2015-09-24 09:19:13,"@mbroome for us watches do still ""work"" but only because both consul-template and out own watches always compare the new response to the old response and only trigger reconfiguration when something has actual changed. The main impact we are seeing is the load produced by all these watches constantly being triggered and then resubscribing. This is not practical unless you have an extremely stable environment that hardly ever changes.

@slackpad Great news! Glad to hear it is on your list.
We are talking to some teams at other companies we know about the impact of this issue on their systems. We expect that a lot more people will have made the assumption that watches will only be triggered by writes to the service they are watching and that the impact of this assumption has so far been relatively low for most teams only because they either have more stable clusters or because the load/request spikes have not been spotted or correctly identified. We only found out ourselves because its turns out our cluster was extremely chatty due to registrator so the load spikes were big enough to trigger us to dive into it.
",agemooij,slackpad
1244,2016-06-20 15:57:47,"@jhmartin : We've tracked down index churn to 2 distinct causes. First one is related to failed health checks for non-running services on Windows, where the text message of failed check would vary between 2 messages. One is a timeout message and the second one is connection refused message.
Second cause of index churn is more interesting. In our setup we use ACL tokens for service registration, which are passed with registration request as a query string parameter. We also have configured consul to deny registrations without ACL token by default. What seems to be happening in this case is when agents do a periodic entropy sync, they try to read the catalog and the read request gets denied access to all services except 'consul' service, and the agent writes to catalog, because services returned from catalog and its state don't match. Each agent does this once a minute, and given enough agents this causes pretty frequent index churn. The workaround was to include a token with ""read"" access to all services in each agent's configuration.
",Loushu,jhmartin
1244,2016-10-18 09:25:58,"@slackpad any updates on delivery? version ? The problem exists on 0.7 but less often than 0.6.4. I wonder what has been changed.
",rohitjun,slackpad
1241,2015-09-14 21:54:06,"Hi @scalp42 it doesn't look like that's exposed via any Consul configuration right now. Unless that gets added, you'd have to make a mod here and build Consul:

https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L572
",slackpad,scalp42
1241,2015-10-08 17:51:44,"Having the hostname in the metric kill us and it ends up duplicating a shit ton of metrics (vs datadog where you would pay per host for example).

@slackpad any chance we can see @nbrownus ported to consul as well?
",scalp42,nbrownus
1241,2015-10-08 17:51:44,"Having the hostname in the metric kill us and it ends up duplicating a shit ton of metrics (vs datadog where you would pay per host for example).

@slackpad any chance we can see @nbrownus ported to consul as well?
",scalp42,slackpad
1238,2015-11-04 03:24:54,"@slackpad what's the latest on this one? I would really like to adopt Consul, but can't put it into production until we're able to prevent remote execution via this method.
",arobson,slackpad
1237,2015-09-24 12:46:49,"@slackpad so we've been running with the above config for a while now on Kubernetes.

When a container stops, it starts again with the same name (but a different IP).

We now see logs like these:



`consul members` shows the correct IPs, but `peers.json` has the above mentioned _wrong_ IPs _on top of_ the correct IPs.

Does this mean we'd have to write a script that fetches the current node IPs and puts those in `peers.json` before starting Consul?
",JeanMertz,slackpad
1236,2015-09-11 19:16:15,"Cool, makes sense.  @scalp42, if you want to update the PR to restrict the changes to errors in comments and docs, it'll be safe to merge.
",ryanbreen,scalp42
1235,2015-09-17 09:55:50,"@slackpad 

> Want to take a crack at preventing multiple reloads as well?

I'm pretty sure `handleReload()` is only called from `handleSignals()`, and AFAICT handleSignals is fully synchronous (https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L797) and as such doesn't need a mutex to prevent multiple reloads.  (/cc: @ryanuber ?) 

It seems that all the interference was caused by `handleReload` and `antiEntropy` fighting with each other NOT multiple configuration reloads running simultaneously.  It's just easier to trigger a Pause/Resume conflict with `antiEntropy` if you force consul into contant reload mode by spaming SIGHUP for a while. 
",wuub,slackpad
1233,2015-09-10 21:56:33,"Thanks @slackpad ! That's what I get for not running the full set of tests at the end.
",ryanuber,slackpad
1232,2015-09-11 05:32:13,"To expand on what @armon said, in the vast majority of cases, there's a Consul agent on the same host as your code that will communicate with the Consul servers on your application's behalf. This means that usually, the scenario where the ""agent goes down"" means that the specific host that is running the code that created the Client is also down. Further, some of the calls in the client API are agent-specific (everything in `Client.Agent()`, e.g. the list of services on the local agent) so in my opinion it would be bad API semantics to have some sort of ""fallback"" agent that might return a completely different set of services, health checks, etc.

If you want to have a fallback Client if for some reason you cannot run a Consul agent on the same server as your application, I'd suggest creating a slice or map of Clients and handling failover between them in your application logic - this will ensure that you can handle any edge cases caused by calling Agent APIs against a remote agent in an appropriate way.
",highlyunavailable,armon
1232,2015-09-11 15:15:48,"> To expand on what @armon said, in the vast majority of cases, there's a Consul agent on the same host as your code that will communicate with the Consul servers on your application's behalf.

I don't think having an agent on the same (and every) host where your app is running is a realistic architecture in most places. Even if it were, there is no way I can have rolling upgrade of Consul servers without bringing my entire application down. At least won't be able to bring down the consul agent without bringing down the application on that node.

> If you want to have a fallback Client if for some reason you cannot run a Consul agent on the same server as your application, I'd suggest creating a slice or map of Clients and handling failover between them in your application logic

Yes - this is definitely possible at the application side. But I believe for a critical system like consul which is used often as the infrastructure backbone and should be having high availability, it makes sense to have this made available in the standard API itself.
",anoopengineer,armon
1231,2015-09-21 18:16:45,"@slackpad that isn't a bad option. I'd probably need someone's assistance to make that happen though. 

However my only counter comment is that we could make the `local` tag configurable and change it to something like `local-agent` by default, something that has a low probability of being used already. 

This method just leaves all the existing conventions as is, but if you or someone else can/will help with the path you suggested, I'm all for it.

I just really need a way to get the IP/port into for ""local"" services to the agent and I think there is a pretty good use case in general for it.

Thanks!
",ekristen,slackpad
1231,2015-09-21 19:17:04,"@slackpad thanks! My golang experience is limited (as evident by the PR) but if you can make this work, or you need my help, please let me know.
",ekristen,slackpad
1231,2015-09-28 16:36:15,"@slackpad any progress on this by chance? Thanks!
",ekristen,slackpad
1230,2015-09-10 21:43:31,"Picked this up when @sfncook rebased and built #1187 - @ryanuber I think we missed a couple spots:


",slackpad,ryanuber
1230,2015-09-10 21:57:43,"@slackpad - Actually I hadn't done a rebase/merge from the master branch for a while.  Just did so and pushed to my PR #1187 It's building now.
",sfncook,slackpad
1226,2015-09-09 05:54:52,"Yep, what @slackpad said is what you could easily do.

Note that the HTTP API by default only binds to loopback, so if you want to run HTTP queries, you'll need to [rebind the HTTP address](https://www.consul.io/docs/agent/options.html#addresses).

I'm not sure what the port in the SRV record would be though for the `consul` service, but you could just assume it's on 8500 by default.
",highlyunavailable,slackpad
1226,2015-09-09 06:01:35,"Interesting detail @highlyunavailable - the port for the built in Consul service is set to the internal RPC port, not the HTTP server, so you're right you'd have to assume it's 8500 (or whatever it's configured for), or put it in KV, etc.

https://github.com/hashicorp/consul/blob/master/command/agent/agent.go#L170
",slackpad,highlyunavailable
1225,2015-09-09 00:21:39,"Hi @scalp42 are you running `dig` against the server node or a node running an agent? I believe the DNS TTLs are added in by the agent that services the DNS request and don't come from the server's configuration.
",slackpad,scalp42
1225,2015-09-09 00:32:31,"Hi @slackpad 

I'm running `dig` locally against the node agent (`dig @127.0.0.1 -p 8600`).

I see the TTLs only when `dig` is pointed at our Consul server nodes (`dig @consul.example.com -p 8600`) :



In this case does it mean that the local agent **cannot** get stale data ?

Correct me if I'm wrong but it would make any downstream caching impossible if TTLs are not specified.
",scalp42,slackpad
1225,2015-09-09 02:38:24,"@slackpad sorry for the delay:



I see the service TTL being `null`, this is interesting.
",scalp42,slackpad
1225,2015-09-09 02:40:37,"@slackpad just found the issue. So we've always been reloading consul instead of restarting it.

Looks like a restart actually fixed it. Is it expected that `consul reload` does not actually pick up the `dns_config` part when changed?
",scalp42,slackpad
1225,2015-09-09 05:47:56,"Wow totally missed that (and also means we've been pushing Chef changes for ""nothing"" trying different values etc when it was just not applied due to reload).

Thanks a lot @slackpad for the feedback and the issue opened :smile: 
",scalp42,slackpad
1224,2015-09-09 14:55:39,"Hi @slackpad, Consul is already emitting configuration-specific metrics here:
https://github.com/hashicorp/consul/blob/master/consul/health_endpoint.go#L101

As for the PR from @ophiradi, we are interested in graphing historical health-check passes/failures from consul's perspective on a service-by-service basis. It would be another source to alert from when our failures go above a certain rate or to be able to see another measure of quality over time.
",victortrac,slackpad
1212,2015-09-09 06:48:35,"@slackpad Sorry for the late response! Pinging between the three AZs in us-west-2 is roughly 1.3ms.

Nothing interesting is happening in the logs or being reported in Sysdig. Our nodes are pretty under-utilized right now, but the highest traffic belongs to Consul and Consul-template with an average rate of about 7 KiB/s, spiking to 20KiB/s about every 30 seconds. Our nodes are reporting an average rate of 7KiB/s, so yea pretty much all Consul traffic.
",djenriquez,slackpad
1212,2015-09-16 23:23:07,"@slackpad Yes sir.
",djenriquez,slackpad
1212,2015-10-02 02:53:18,"Thanks @slackpad.

Hi @skippy, yes this issue actually was born in the Google group. As far as the flapping nodes, I'm having a hard time justifying allocation an m4.large, especially 5 of them for Consul. Sysdig shows that Consul uses an average of 40 KiB/s network traffic, with some spikes to 70 KiB/s, but thats it. This is in a cluster of ~30 nodes /w ~40-50 services between the nodes. 

Now, maybe larger/stronger instances can increase stability, but why? Smaller instances, even t2.micros should be more than capable of handling that kind of network traffic.

How does one set up service/node stale caches? Is this a feature in Consul that I enable? This is a setting I have not yet fiddled with, maybe it can help. I'm not using Consul DNS at all.

I had someone else just yesterday recommend `--net=host`. I've transitioned the server containers to use that option and am slowly transitioning the agents to use that as well. Its too soon to report whether its helping, I feel that it has, somewhat, but I have noticed some nodes with `--net=host` still flapping. 

Once I transition all agents to use that option, i'll report back. Thank you!
",djenriquez,slackpad
1212,2015-10-02 16:05:53,"@blalor, are you using t2.small within the same AZ or spanning AZs?  

@djenriquez great point about moving to m4.  The challenge with AWS is there are lots of other variables; how many azs are being spanned, which region are you in, etc.  And then lots of guessing (are the t2 and m4 families on better internal network hardware?)

@djenriquez here is part of a sample json config that may help:



you'll see some of these settings on https://www.consul.io/docs/agent/options.html#node_ttl
",skippy,blalor
1212,2016-01-08 02:10:49,"Looks like you're doing some work to closing out some issues @slackpad. I've tried to replicate this flapping in 0.6.0 and have fortunately, been unsuccessful. Looks like all the network optimizations in 0.6.0 did the trick.

Closing, and hoping this stays closed.
",djenriquez,slackpad
1212,2016-01-08 03:31:36,"@slackpad I'll have more time next week to dig into the consul consensus.  After I dig into it I'll get back in touch.
",sstarcher,slackpad
1212,2016-01-11 20:18:30,"@slackpad thanks for the quick response! I did notice this morning when one of the servers went down that I couldn't ssh in so that makes me think this may be an EC2 problem as well. I am getting some network and consul metrics set up now. Will report back.
",MrMMorris,slackpad
1212,2016-01-12 17:21:12,"@slackpad I have determined that it is a cron.daily task that is causing high disk io. Might be logrotate, still looking into it.

<img width=""879"" alt=""screen shot 2016-01-12 at 12 15 57 pm"" src=""https://cloud.githubusercontent.com/assets/1494248/12270882/51e8a572-b926-11e5-9424-3d4508b72fc2.png"">

**However**, I am experiencing a different issue now. On the same server, I have been seeing these logs since 9:30am UTC (not when cron.daily is run). Any idea why this is happening and how to prevent or have it recover automatically? or does it require manual intervention with a peers.json edit?


",MrMMorris,slackpad
1212,2016-01-13 05:52:01,"@slackpad scratch that last issue. It was due to some port not being open, although I'm not sure which.

This is my SG for Consul Servers. What am I missing that would cause the previous election timeouts?

<img width=""759"" alt=""screen shot 2016-01-13 at 12 49 28 am"" src=""https://cloud.githubusercontent.com/assets/1494248/12286183/d2ba2626-b98f-11e5-9012-80d0f4cee2cd.png"">
",MrMMorris,slackpad
1212,2016-01-20 15:37:58,"@slackpad After relaunching all of our consul servers on larger nodes we are still seeing significant problems.  Would you like me to create a new ticket or document it here.  An overview is as follows
- AWS EC2 - m3.medium
- 5 Servers
- 100 Clients
- Consul running in a docker container with --net=host - Docker 1.9.1
- Ubuntu 14.04
- DNS forwarding is setup on our DNS servers to forward requests for *.service.consul to our 5 servers
- Vault is in use, but running on separate servers.  

Config



Our logs show the following over the past 12 hours.  Certainly below over the past 12 hours only one server has had failed to reconnect problems and it's possible that, that node is having issues, but over the next 12 hours I suspect I'll see other servers have issues as has consistently been the case.  Over the past week I have moved the servers from t2.micros to t2.mediums and now to m3.mediums to see if it was any performance problem.  The CPU utilization is 15% on the servers.




",sstarcher,slackpad
1212,2016-02-02 02:40:34,"@slackpad I have documented several times what my server load is.  The load on the server nodes is pretty much non-existent.  The only role of those boxes are to be consul masters.  We ship logs off the box and collect metrics, but that's it.
",sstarcher,slackpad
1212,2016-02-02 02:53:43,"@slackpad Thanks for the clarification.  We don't currently use consul template.  We do use vault, but only in a very minimal sense and our vault usage is newer, but the flapping issue has been around for a very long time.  We use consul for service discovery, the cache TTLs are all around 5 seconds I believe to eliminate excessive load.

I'm currently testing our consul servers on CoreOS to see if they exhibit the same flapping problem.
",sstarcher,slackpad
1212,2016-02-02 03:24:45,"@slackpad After migrating the nodes to CoreOS if the flapping continues I will run everything outside of docker and report back.  I do run with --net=host which is why I have kept running in docker, but it could still be related.
",sstarcher,slackpad
1212,2016-02-26 18:12:30,"@romansky there's a debug log level that might help there -https://www.consul.io/docs/agent/options.html#_log_level.
",slackpad,romansky
1212,2016-02-26 18:25:39,"@slackpad thanks, I already have `debug` set, does this take effect during monitor? I don't seem to see any messages with `[debug]` prefix. If the process is indeed crashing will it produce any relevant logs?
",romansky,slackpad
1212,2016-02-26 18:31:05,"@romansky yes `consul monitor` can set the log level to debug, though if it looks like the process is crashing you might want to set that on the Consul agent itself and observe its output directly - the `consul monitor` command is doing an RPC call to the agent so it might miss any final logs related to a panic, etc.
",slackpad,romansky
1212,2016-02-26 19:06:11,"@slackpad so if the config file is set with the following-



Is this enough?
",romansky,slackpad
1212,2016-02-26 19:09:18,"@romansky your issue is probably worth splitting off into a new Github issue since it's not related to the flapping others are seeing here. That'll help keep the noise down since there are quite a few threads going on this one.
",slackpad,romansky
1212,2016-02-26 19:13:31,"@slackpad rgr
",romansky,slackpad
1211,2015-09-01 20:22:46,"@ryanbreen Sure, I will update soon. I did just copy and paste from the source project. :/

I will came back later with a better title! 

Thanks
",kikitux,ryanbreen
1211,2015-09-01 20:51:42,"@ryanbreen done it. Thanks for checking this
",kikitux,ryanbreen
1207,2015-09-01 02:05:40,"Thank you @slackpad , that resolves the problem.
",wyhysj,slackpad
1202,2015-08-28 00:45:13,"This is on our roadmap for a V2 API where we can redesign some of the assumptions of V1. As @highlyunavailable said, the DNS perspective makes it very difficult. That said, we have some ideas as to how to tackle it, but we are probably a few Consul versions away from this.
",armon,highlyunavailable
1200,2015-08-31 22:14:06,"Hi @ryotarai - code looks good. Can you please also update https://github.com/hashicorp/consul/blob/master/website/source/docs/commands/lock.html.markdown as part of this change?
",slackpad,ryotarai
1200,2015-09-01 02:02:37,"Hi @slackpad 
Thank you for reviewing. I updated the doc: https://github.com/ryotarai/consul/commit/b2755d026e25071f645c76a071069c242ab2a800
",ryotarai,slackpad
1193,2015-08-28 16:37:05,"@slackpad Thanks, I think you saved the day. `-join` docs mention how many times it will be tried at all. My expectation from this sort of distributed software was to have `-retry-join` as the default behavior.

![image](https://cloud.githubusercontent.com/assets/159209/9551800/36776b0e-4d68-11e5-8bf9-c53a77334b0b.png)
",ahmetb,slackpad
1191,2016-12-01 16:27:44,"@slackpad sorry, but i try to do that by multiple ways, i think we need in consul normal DNS interface. Cannot work with service discovery with normal way. We need full DNS functional.",westsouthnight,slackpad
1187,2015-09-10 21:32:37,"@slackpad @ryanuber - Thanks for the review, guys.

@slackpad - I have added a couple test cases in TestAgentAntiEntropy_EnableTagDrift.  But perhaps you can see in this conversation that the Travis failing with errors that don't appear to be related to my updates.  I'm not sure why they are failing - they seems to be complaining that an interface is being used. (in code that I did not modify)  Perhaps you guys have seen these errors before?  Known issue?

Travis errors:
command/maint_test.go:48: not enough arguments in call to a1.agent.EnableServiceMaintenance
command/maint_test.go:53: not enough arguments in call to a1.agent.EnableNodeMaintenance
",sfncook,slackpad
1187,2015-09-11 01:07:28,"@slackpad - Thanks so much for the thoughtful and thorough review!  I will make these updates tomorrow.
",sfncook,slackpad
1187,2015-09-11 16:36:43,"@slackpad I just pushed updates in response to your comments.  (thank again)  Note that the title of this pull request and branch still refer to the old config item name ""EnableTagDrift"", though the code has been updated per your request.
",sfncook,slackpad
1187,2015-09-11 22:27:06,"@slackpad Awesome, just pushed those changes.  Thanks.
",sfncook,slackpad
1186,2015-08-19 00:53:30,"@armon I see. Is there a location on the filesystem where the ACLs are stored, or do I have to query it via the API and export like like so?

On a separate, but related question, if I were to decommission dc1, would I have to restore KV's too? What if they were already replicated to dc2 and dc3 with consul-replicate?

What other data do you suggest exporting, raft or serft from the `data-dir`?
",calvn,armon
1186,2015-08-19 01:39:33,"@armon One last thing, what would be the correct procedure to migrate the ACLs? It is like so:
1. Export ACLs on dc1
2. Write exported ACLs to dc2
3. Change `acl_datacenter` on all server nodes from dc1 to dc2 (including dc1 itself?)
4. Shut down dc1 cluster
5. ???
6. Profit

On step 2, `acl_datacenter` on dc2 still points to dc1, so would there be a conflict there? Also, on step 3, once dc1's `acl_datacenter` is changed to dc2 would there be a conflict (although it wouldn't matter so much in this case since it's going to be taken down)?
",calvn,armon
1186,2015-08-19 15:39:19,"Edit: This question is throughly answered in https://www.consul.io/docs/internals/acl.html

@armon You mentioned that dc2 would end up forwarding to dc1, are you talking about requests that needs ACL tokens for permissions, or the ACL tokens themselves? If it is the former, what would happen during an outrage on dc1? Would dc2 just not able to perform anything if its under a deny-by-default policy? Or does it have the ACLs cached locally so that accessing the KV store and service registration is still possible?

In other words, what is the actual flow for checking if the ACL is valid in clusters where it's not the `acl_datacenter`? Does dc2 (or dc3) asks dc1 every time a request is made to check whether the ACL token used is valid?
",calvn,armon
1186,2015-08-19 17:55:16,"@armon If the dc1 was to be decommissioned, what would be the process of moving clients that are currently part of dc1 to dc2? Would that imply cluster merging issues and other weirdness along the way?
",calvn,armon
1186,2015-09-11 17:14:32,"@armon In the case of doing the `acl_datacenter` swap, is it safe to assume that the services that have been registered before in dc2 with with a particular ACL token will not disappear? Is it just that I can no longer use ACL to register new services?

What would happen if I disable ACLs on dc2 entirely? Would service still be able to register regardless of whether `?token` parameter is provided? Ideally I would want zero downtime on services that are registered to dc2. How would this ACL migration process affect services (whether on dc1 or dc2)?
",calvn,armon
1186,2015-09-11 18:47:18,"@armon Cool! What do you mean by 'issues' during the time between enabling ACLs and importing the old tokens? Is it actions that require ACLs such as new service registration and KV queries? I think I can live with that temporarily as long as I am not taking down existing services.
",calvn,armon
1184,2015-08-25 23:49:55,"That's a good point @ryanbreen - even headers brings to mind complexity around supporting multiple, etc. I'll change this to thinking for now, because we don't want to introduce a bunch of complexity. If there are a few extra options that are highly useful, it might make for a better experience, but we don't want a `curl`-level of stuff for sure.
",slackpad,ryanbreen
1177,2015-08-17 20:48:48,"Hi @slackpad, no, I did not build consul, it is getting downloaded from mitchellh's bintray (https://dl.bintray.com/mitchellh/consul/)

see: 



if it is any help:
`fc35735a636f0d5c9d62ae1c537c8b2e2ed1960fb34fe810f6b9431f7646e9f1  /usr/local/bin/consul`


",feniix,slackpad
1177,2015-08-17 23:09:54,"@slackpad sadly, I forgot to run an strace before and now when I run it with or without strace it does not do it any more. Otherwise I would have more info.
",feniix,slackpad
1173,2015-08-26 15:11:28,"@wuub thanks that would be great! Just for science can you run 0.5.2 on another node just to make sure I'm not missing anything and it shows the problem, too? Looking at the diff 0.5.1->0.5.2 doesn't seem to have anything related but it would be good to be sure. Then I'll give you a patch (or patched build if you like) of 0.5.2 that locks out the server updates during the pause for a reload. Running 0.5.2 along with other 0.5.1 nodes should not be a problem.
",slackpad,wuub
1173,2015-08-27 08:43:36,"@slackpad we are now on 0.5.2, I'll try to confirm that the problem still occurs ASAP.

I'll can build a debug binary myself, just point me to a commit/branch :)
",wuub,slackpad
1173,2015-09-11 16:27:02,"Hmm this is interesting - so it's basically looking like sending another HUP before the first reload is done triggers this behavior. I think we could also guard this by using a `sync.Mutex` in `handleSignals` so we can be sure we only process one at a time. It seems a bit chaotic to have two config reloads going at the same time. Thanks for all the detailed information @wuub! I'm marking this as a bug, and I think the fix should be pretty simple. We'll get this in for 0.6's release!
",ryanuber,wuub
1173,2015-09-11 16:35:10,"@ryanuber  two config reloads should be guarded against as well, but during the investigation I did today I was able to trigger deregistration even with a single, well behaved SIGHUP. 

I'm pretty confident that I got to the bottom of this, and AFAICT #1235 fixes the root cause of the problem we are experiencing. 
",wuub,ryanuber
1173,2015-09-11 17:43:19,"Thanks for nailing this down @wuub - nice work! I'll take a look over your PR, and I'll double check my original patch to see if there's anything in there worth saving since that never made it to master.
",slackpad,wuub
1167,2015-08-20 17:16:53,"@railsguru this looks good, sorry for the delay! If we can just add the test case for the option, as well as update the CLI and HTTP documentation I think we can merge this.
",ryanuber,railsguru
1167,2015-09-01 21:44:34,"@railsguru, this needs to be documented here: http://www.consul.io/docs/agent/options.html.  Can you update `docs/agent/options.html.markdown` to cover this?
",ryanbreen,railsguru
1167,2015-09-02 04:30:34,"@ryanbreen ah missed that cue, done!
",railsguru,ryanbreen
1159,2015-12-31 20:24:16,"Even with the new tomography features in 0.6, I think this feature still has its place where specific fallback is desired.  However, I'd be interested in your thoughts @armon...
",bacoboy,armon
1159,2016-01-03 19:45:58,"@bacoboy Our goal is that prepared queries would be the solution to this, in a more generic way. As @slackpad said, you can use the tomography for a ""zero touch"" failover configuration, but you can also specify the specific fallback order if you care to.
",armon,slackpad
1159,2016-01-09 03:18:11,"I agree that the queries allows control from the `client`, but in cases where I don't want the client to know anything other than the local consul agent (because updating a zillion client configurations would be bad), the crux of this request is to move this fallback logic to the consul agent configuration.  

Yes, tomography allows server side fallback if you want ""closeness"" to be your fallback mechanism, but that not what I want.  I want a server-side way of saying which way to go if not found.  @armon you said:

> but you can also specify the specific fallback order if you care to

Are you referring to the client side query again or is there a configuration server-side I'm unaware of to specify fallback?  I looked again, but didn't see anything.
",bacoboy,armon
1157,2015-08-11 14:05:40,"Hey @ryanuber,

Unfortunately I thought the same thing and tried these approaches already.  The problem is a chicken and egg issue.  You can't register a check to a service if that service doesn't exist yet, you will get an error.

I also tried to register the ""maintenance mode"" check by using the naming convention when the service itself is registered, but those values are ignored and a new checkId is generated for it when combined in the service registration.  The only way I was able to accomplish was the method I mentioned earlier about the TTL.
",hopperd,ryanuber
1154,2015-08-05 22:15:31,"@darron Hmm this is odd. I haven't seen that before. @slackpad is looking into this.
",armon,darron
1154,2015-08-06 01:30:33,"@darron What version of Consul are you guys running? Two things are odd here. A blocking query is capped to 10m on the server side, but the fact that no query is going through and ""failed to start stream"" is being logged means we are blocking trying to open a new stream to the server (single TCP stream, multiplexed per-request). 

We apply back pressure on new streams to prevent overwhelming the servers, and it seems like the clients are waiting for a new stream to be available. This is causing the blocking query to go for a very long time.

Not sure yet why clients are blocking. Do you see anything odd on the servers around those times? Specifically the leader is likely to be the culprit.
",armon,darron
1154,2015-08-06 01:47:59,"@darron Could you also check  the value of /proc/sys/net/ipv4/tcp_keepalive_time
",armon,darron
1154,2015-08-07 04:11:53,"A thorough review of the receive side in the server hasn't found any smoking guns, so my current working hypothesis is that you are seeing TCP connectivity issues and this known mode with the client is causing things to hang. I think the next thing on my side would be some stress testing to try to get it to repro without messing with the TCP stream.

@darron it would be super useful to get some `tcpdump` for Consul RPC traffic from the agent to the server during one of these events (preferably showing things working properly and then into the failure) - would something like that be possible? Also, I think we could make this a lot better behaved with write timeouts on the client side - would it be possible to run a slightly patched agent in your environment?
",slackpad,darron
1154,2015-08-10 22:00:32,"@slackpad Do you need anymore tcpdumps? either:
1. Working to non-working.
2. Non-working to working.

Let me know - I have both types of nodes right now that I can grab data from. All server nodes.
",darron,slackpad
1154,2015-08-10 22:14:06,"@darron I think I'm pretty good with what you've sent so far. Your last round of pcap files led to #1165, which I don't think will actively harm anything but will create a small flurry of network traffic and probably some extra load on the servers when it happens (spins up 3 goroutines per connection, etc.).

If it's easy to get a two-sided pcap of a good to bad transition that would be useful, but I don't want to take too much of your time trying to get that if it's a hassle.
",slackpad,darron
1154,2015-08-11 07:58:26,"We're seeing the same behaviour at our cluster. One of the nodes doesn't respond anymore, calls to /agent are fine, but to /catalog just hang forever. Our cluster is much smaller, but we're querying the API quite a bit. We're running [Prometheus Consul exporter](https://github.com/prometheus/consul_exporter), which polls the API quite often, and our own gateway, which is using Consul as well.

I turned on the debug level, but the only thing I could see is that the health checks via http are not being processed anymore. 

Let me know if I can help debugging this! @darron, could it be that you're also using the Prometheus Consul exporter?
",bastichelaar,darron
1154,2015-08-14 23:12:27,"Hi @bastichelaar thanks for offering to help debug this (and sorry for the late reply)! Here's what we know so far:
1. Through @darron's data drops we realized that yamux (the library Consul uses to multiplex RPC requests over a single TCP connection) had the potential to stall on the client or server side. There was coupling between the send and receive loops due to the way it can try to send window updates to apply back pressure or send replies to ping requests during reads. We cleaned these up and added a fallback timeout here - https://github.com/hashicorp/yamux/pull/9.
2. We also realized that heavy RPC traffic during TCP connects would create a ton of new connections and kill off all but one, we fixed that here - https://github.com/hashicorp/consul/pull/1170. This wasn't directly involved in the stalls but it wasn't helping anything and created a bunch of useless network traffic at a critical time.

I merged those fixes, along with some minimal cherry picks to get the build working, to a branch based on the 0.5.2 tag, which is here - https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches. I ended up rolling back both memberlist (6025015f2dc659ca2c735112d37e753bda6e329d) and serf (668982d8f90f5eff4a766583c1286393c1d27f68) to versions near the 0.5.2 release date since there are protocol version bumps that you definitely don't want in there, so a build in this configuration is very close to 0.5.2, but includes the above fixes.

@darron is doing some testing with this new binary and it is behaving better (shorter stall periods), but alas it's hitting the new timeouts we added so there's still something we need to figure out.

If you'd like to try out this binary and/or send some logs from this happening in your configuration you can email support@hashicorp.com and CC me at james at hashicorp.com and I'll give you the build. We will keep this issue posted with what we find and with the fix once we figure it out.
",slackpad,darron
1154,2015-08-20 18:52:57,"OK - to summarize where this particular issue is at - we've now had a 24 hour period where no nodes have gone deaf, couldn't communicate with the master and needed to be bounced. We haven't seen that for a long time given we're at 900 fairly busy nodes - busy with services, DNS lookups and KV traffic.

A key understanding for me was recognizing that:
1. Server nodes were all of a sudden unable to talk to the leader.
2. As a result, all of the client nodes that were talking to them were effectively cut off as well.

Bouncing the server would resolve it for all the nodes - but that's an unsustainable strategy.

There have been 3 things that have changed this status and helped to hopefully solve it:
1. [The Yamux patch for deadlocks](https://github.com/hashicorp/yamux/pull/9) - we're running that on the server nodes.
2. [The Consul patch for connection throttling](https://github.com/hashicorp/consul/pull/1170) - we're running that on the server nodes.
3. Making sure the server nodes were immune to the ""Rides the Rocket"" Xen/EC2 networking bug. For future reference - this is what did it for us:

`/sbin/ethtool -K eth0 tso off gso off sg off`

1 and 2 helped a ton - but what seems to have made it much more consistent is 3.

We had thought we had fixed the Xen/EC2 bug - but it was an incomplete solution on the Consul server nodes and only came to light through some excellent ""reading-the-pcap-leaves"" by @slackpad. 

Basically - the leader was sending things to the server nodes that it never got - and so that put it into a strange state that took a while to come out from.

There's [another patch to yamux](https://github.com/hashicorp/yamux/pull/11) - but we're going to give this current state a week and then think of changing out the Consul binary cluster wide.

I'll update this next week after I'm done traveling and we have more data to back up the current conclusion.
",darron,slackpad
1154,2015-08-20 19:04:33,"Same here: we also applied the ""Rides the Rocket"" Xen/EC2 fix and we build a new version of Consul using the deadlock fixes branch (https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches). The cluster is stable now, and the /v1/catalog API endpoint doesn't become unresponsive anymore. We're still monitoring the cluster, but it looks good! I'll keep this issue updated if we encounter any issues. 

Thanks @darron and @slackpad for your help!
",bastichelaar,slackpad
1154,2015-08-20 19:04:33,"Same here: we also applied the ""Rides the Rocket"" Xen/EC2 fix and we build a new version of Consul using the deadlock fixes branch (https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches). The cluster is stable now, and the /v1/catalog API endpoint doesn't become unresponsive anymore. We're still monitoring the cluster, but it looks good! I'll keep this issue updated if we encounter any issues. 

Thanks @darron and @slackpad for your help!
",bastichelaar,darron
1154,2015-08-28 15:40:46,"@slackpad It looks like those patches have pretty much solved this problem for us.

In the last 8 days we have had a single instance of things going deaf - but it was short and corrected itself:

http://shared.froese.org/2015/0hrr9-17-16.jpg

I wonder if we need to try the other [Yamux patch](https://github.com/hashicorp/yamux/pull/11) - but pretty happy with where we are at the moment.

Worth a 0.5.3 release?
",darron,slackpad
1154,2015-08-28 16:27:26,"@darron thanks for the update. If things are performing well you probably don't need that last patch as that was kind of a catch all for any TCP errors; you've got a high enough request load that one of your streams is likely going to try to send a header and time out (the patch will time out even if it's not trying to write a header) As for 0.5.3 I think at this point we should focus on 0.6 which will have the performance fixes, too. Are you ok running the patch release for a little while longer?
",slackpad,darron
1154,2015-08-28 18:25:13,"Yeah - it should be OK. I will build a package and install across my cluster.

Thanks for all your help @slackpad - really appreciate it.
",darron,slackpad
1154,2015-08-28 18:28:20,"@darron my pleasure - I totally appreciate all your efforts repro-ing this and mechanizing and supplying the debug data - you put in some major effort to track this down!
",slackpad,darron
1152,2015-08-05 02:13:03,"@armon thanks for answering, will consul support small-granularity invalidation in future version?
",half-dead,armon
1152,2015-08-10 09:41:47,"@armon Have you ever benchmarked the '/v1/agent/check/pass/xx' endpoint? It seems that it will trigger all server node's disk write, right?
",half-dead,armon
1150,2015-08-06 03:32:16,"@slackpad That may well be it. It was our cluster that showed the elections as I said, I dont remember nodes leaving and joining every minute but they well could of been joining and leaving.

@armon More details, it was a 0.5.2 cluster with 3 nodes running m4.medium's one in each az zone. We rolled out consul-template to 100+ nodes and consul never recovered.

First thing we noticed was that one our nodes ran out of open files, consul had something like 5000+ open files when we ran lsof. Most of them looked like connections from clients requests the consul template data.

We recycled the node and turned off consul template but that node never seemed to recover, with the other nodes often complaining of timeouts to that one (500ms or more).  

At that point we recycled the entire cluster and kept consul-template turned off, it appears stable.

The debug logs were not much help unfortunately, they showed little more than what we had above. Again, this broke a huge amount of things in our setup, so I grabbed what I could before completely redoing the cluster.
",evanccnyc,armon
1150,2015-08-06 03:32:16,"@slackpad That may well be it. It was our cluster that showed the elections as I said, I dont remember nodes leaving and joining every minute but they well could of been joining and leaving.

@armon More details, it was a 0.5.2 cluster with 3 nodes running m4.medium's one in each az zone. We rolled out consul-template to 100+ nodes and consul never recovered.

First thing we noticed was that one our nodes ran out of open files, consul had something like 5000+ open files when we ran lsof. Most of them looked like connections from clients requests the consul template data.

We recycled the node and turned off consul template but that node never seemed to recover, with the other nodes often complaining of timeouts to that one (500ms or more).  

At that point we recycled the entire cluster and kept consul-template turned off, it appears stable.

The debug logs were not much help unfortunately, they showed little more than what we had above. Again, this broke a huge amount of things in our setup, so I grabbed what I could before completely redoing the cluster.
",evanccnyc,slackpad
1150,2015-08-11 18:10:01,"To build on what @armon said - we were never able to run Consul Template with service queries across our cluster reliably once we hit around 100 nodes. Leadership transitions over and over that were really unstoppable.

If you can build the template on one of the server nodes - running under `consul lock` - and put the result into the KV store - a [simple JSON watch](https://gist.github.com/darron/7dcacaedf0793f3dc38c) on each node can easily pull it out and reload haproxy.

A few things to watch out for:
1. Be careful you're not reloading a blank config file if something goes wrong with the CT build.
2. Make sure to add a ""wait"" to Consul Template so that it can't happen every second if something's flapping - that can be painful.
3. Build a ""stop"" mechanism so you can freeze the KV from being updated automatically - push out a known good one by manually updating the KV - and then fix the automatic process.
4. Add some external logging so that you can see when it's updating and the changes. We are throwing an event and a diff at Datadog so that we can see precisely what's changing and when.
5. We are also checksumming the version that is created and then syslogging the checksum that we write on each host - [it's pretty fast](https://gist.github.com/darron/885c5056d0e88e0a6dcb) and the addition of that data helps to make sure it's happening properly.
",darron,armon
1150,2015-09-03 15:49:59,"I am fairly certain that I just ran into this case with around 35-40 nodes, but also making attempts to use Consul Template pretty heavily. Normally the cluster has handled it well up until yesterday where the cluster of 3 was never able to be queried and all the log output made it appear that networking issues were the culprit. It has since sorted itself out with lower traffic, usage, and fewer nodes up.

@darron a few questions for you if you are able to answer:
1. What kind of templates are you building with Consul Template? Are you doing larger files with multiple queries, using ranges, or a lot of smaller template files with few key queries?
2. Are you building all templates for all nodes in your data centers on your consul server nodes? 
3. In [your example watch](https://gist.github.com/darron/7dcacaedf0793f3dc38c) what is the `consulkv get hostsfile/data` utility you are using to get the values?
4. Are you using any prefix queries? Does a watch on a prefix have any difference in performance over using Consul Template with a range query over a directory?
",mtchavez,darron
1145,2015-07-30 16:23:44,"@jrgarcia Can you trim the prefix itself so that it fixes both lock and semaphore?
",armon,jrgarcia
1145,2015-07-30 16:25:06,"@armon Sure thing
",jrgarcia,armon
1145,2015-07-30 16:43:03,"@jrgarcia Can you move it to line 103? The issue is that this is in `setupLock` which means the bug affects `setupSemaphore`. Moving it into `main` fixes it for both cases (e.g. -n > 1)
",armon,jrgarcia
1145,2015-07-30 16:45:31,"@armon Gotcha, I understand what you meant by that now. Thanks!
",jrgarcia,armon
1143,2015-07-29 21:31:53,"@ryanbreen Could you add a test to verify the behavior is as we expect?
",armon,ryanbreen
1138,2015-10-02 15:35:08,"@ryanuber thanks for clarifying here. So services cannot be deregistered from many nodes in a single call, is this the same for key/value pairs or no?
",bhurlow,ryanuber
1136,2015-07-30 04:39:25,"@porterjamesj @armon This does give a proper error in master now. Feel free to reject this if the proper error is good enough (see b5f6451). I couldn't find a way to test this given the tests you have for the `lock` command, because they use `touch` and it will work properly with a leading slash. I'm open to suggestions of how to test given the testing facilities that are already in place.
",jrgarcia,armon
1133,2015-09-23 12:49:09,"@armon We were debating with our colleagues what would be the correct way to mark a consul service check in case the node disappears, and it seems to us that the most appropriate thing to do is to mark the service check as unknown(similar to Nagios behaviour). It avoids any confusions for users and it is the actual state of that check.
",nustiueudinastea,armon
1133,2015-12-31 15:33:26,"Hello!

@armon ""The health of a service is transitively defined by the health of the node it is running on.""

If service's health is transitively defined by the health of its node, why the services related to a 'critical' node aren't marked 'critical' (or 'unknown', as suggested) too?

I can see the same behavior with the 0.6.0 compilation, and it took me hours to detect it running Ansible contrib/inventory/consul_io.py script, that depends on the health of a service to tell if it is up or down - but don't check the health of the node itself.

Can I consider a mistake of that script to not check the node's health? (I'll do it by now for my current needs.)

Thank you, and a Happy New Year!
",raitech,armon
1132,2015-07-28 09:41:38,"@armon Some of the telemetry output I don't understand, do you have any documents? 
",half-dead,armon
1132,2015-07-30 17:38:37,"@ryanuber Are there any documents for the telemetry output? some of those I don't quite understand, like below:
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.udp.received': Count: 19 Min: 22.000 Mean: 26.684 Max: 33.000 Stddev: 5.121 Sum: 507.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.tcp.accept': Count: 2 Sum: 2.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.tcp.sent': Count: 2 Sum: 2058.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.msg.alive': Count: 2 Sum: 2.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.udp.sent': Count: 19 Min: 20.000 Mean: 27.263 Max: 33.000 Stddev: 6.252 Sum: 518.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.serf.queue.Event': Count: 10 Sum: 0.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.serf.queue.Query': Count: 10 Sum: 0.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.serf.queue.Intent': Count: 10 Sum: 0.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.memberlist.gossip': Count: 50 Min: 0.008 Mean: 0.021 Max: 0.076 Stddev: 0.012 Sum: 1.058
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.memberlist.probeNode': Count: 10 Min: 1.042 Mean: 1.738 Max: 4.459 Stddev: 1.076 Sum: 17.380

And another question, how can I measure the max latency when a new service registerd on one client, I mean, how long does it take to sync this service to all server nodes.

Many thanks!
",half-dead,ryanuber
1130,2015-07-23 21:35:21,"I'm particularly not in love with the naming either.  @armon can I ask why a UDP health check doesn't make sense?  It does support UNIX sockets too BTW.
",pdf,armon
1130,2015-07-23 22:39:48,"Hey @pdf,

UDP checks wouldn't entirely make sense because of the connectionless nature of the protocol. You would need to send packets and wait to receive packets in order to determine a successful transmission, which would require specialized logic on the remote end.

We should still be able to check IP4/IP6. Looking at the [`net.Dial`](http://golang.org/pkg/net/#Dial) function, you can see how passing either format of address is accepted.
",ryanuber,pdf
1130,2015-07-24 17:50:00,"@pdf This is looking great. Would you mind updating the documentation as well? I think that is all that is missing.
",armon,pdf
1126,2015-07-22 20:01:18,"@fraenkel This should go away, it can happen sometimes when a new leader takes over. Does this message persist forever?
",armon,fraenkel
1126,2015-07-23 01:40:46,"@armon We have seen the Skipping message appear when the leadership changes.
The only time I have truly seen it go away was when we leave and join after rolling updates.
In theory, nothing should have changed.

Now that we have simplified our config and removed all the auto-join behavior, we haven't seen these messages for at least 1 day.
",fraenkel,armon
1125,2017-02-06 21:38:59,"@ryanuber @slackpad Any thoughts on this? We're now in need of a solution here as well.

Would it make sense to create a DNS A record in, say, the `.private.consul` domain to represent the service IP, then make the SRV answer point to that A record?",mfischer-zd,slackpad
1125,2017-02-06 21:38:59,"@ryanuber @slackpad Any thoughts on this? We're now in need of a solution here as well.

Would it make sense to create a DNS A record in, say, the `.private.consul` domain to represent the service IP, then make the SRV answer point to that A record?",mfischer-zd,ryanuber
1125,2017-02-06 22:05:44,"@mfischer-zd that went out in 0.7.1, but had an issue we just fixed in 0.7.4 that released today (https://github.com/hashicorp/consul/pull/2695).  I think you might be right that this is a dup of https://github.com/hashicorp/consul/issues/1228 (at least solution-wise).",slackpad,mfischer-zd
1125,2017-02-07 19:36:10,"I'm a coworker of @mfischer-zd. I downloaded Consul 0.7.4 and tried to reproduce the problem.  I registered a service like:



and then did a SRV lookup.  As desired, the SRV lookup returned a record that resolved to the service IP, rather than the Node IP.



So as far as I can tell, this issue is fixed in 0.7.4. ",jonmoter,mfischer-zd
1123,2015-07-22 20:22:44,"@gmr This should be happening already! At the bottom of the stack, it ends here: https://github.com/hashicorp/memberlist/blob/master/memberlist.go#L156
",armon,gmr
1120,2015-07-22 20:15:13,"@highlyunavailable It's not documented or available through the HTTP API since its a bit of a highly nuanced dance to get it to work. There is a lot of API calls due to the streaming nature of responses that makes it hard to package as a single convenient API call. That said, it _is_ possible, we are just using the API under the hood, so take a look at the exec code. It's just not simple.
",armon,highlyunavailable
1120,2015-07-22 21:26:58,"@highlyunavailable As a heads up, we do want to improve the performance of the system by allowing output to stream directly to the client instead of via KV. This will probably shift some things, but the current stuff should continue to work for backwards compatibility.
",armon,highlyunavailable
1120,2015-07-22 22:07:28,"@armon I'm actually rebuilding the entire remote exec system in C# as part of my [Consul API](https://github.com/PlayFab/consuldotnet) so that I can do remote execution from an administration web site without the admin server having to set up direct connections (e.g. PowerShell remoting) to service instances, so any pointers on how you'd design it to be more performant without going through KV would be interesting.
",highlyunavailable,armon
1120,2015-07-22 22:09:18,"@highlyunavailable The idea is that the Consul agent would setup a temporary TCP listener and send that address as part of the exec payload. Then clients can connect and stream results back directly. Alternatively, a server based approach allows servers to act as brokers without going through K/V and using Raft.
",armon,highlyunavailable
1120,2015-07-22 22:12:10,"@armon Ah okay, so that would be part of the Consul agent and would be handled entirely through it rather than leveraging the event system + storage like the current method does. I assume there'd be some sort of endpoint on the agent that the `consul exec` command would connect to in order to stream down the output from the TCP connection as well, or would you be setting up the TCP listener in Go directly inside the `consul exec` command?
",highlyunavailable,armon
1120,2015-07-22 22:19:23,"@highlyunavailable Likely it would be through the agent as you are saying. The exec process would not do the listening.
",armon,highlyunavailable
1116,2015-08-31 13:32:40,"Hey @armon,

I got somehow a similar remark. I would like to make the deployment agnostic to the underlaying docker machines and therefore I thought having
- an inter-machine DC (dc1) for which all consul ports are pinned to the physical eth0 address
- an intra-machine DC (vmX) which is comprised of the  containers running on top of the physical machine. 

Registrator exposes all internal services to all the other nodes in the dc1-cluster. And the internal containers are able to access services exposed on different machines, by accessing the dc1 namespace.
So far, so good.

![screen shot 2015-08-31 at 15 31 30](https://cloud.githubusercontent.com/assets/1420201/9579791/6724b952-4ff5-11e5-9d1f-62299f0351d2.png)

But the consul servers (the green once), expecting to talk to the DC ontop of the other machines as well.
The log from consul ontop of VM2.



The internal consul server is hooking himself in - all good.
But...



... kibana4 was started on vm1, I would have expected that a consul server only listens to his own datacenter and the DC of his WAN server.

But maybe that's the problem, that the agent listens to **all** DCs of the WAN server?

Cheers
Christian

**UPDATE**:
Hmm.. looking at the memberships they present themself different:
- **VM1** seems only to care about itself (as I would expect).
  This bugger is bootstraped.


- **VM2** is also looking out for the first VM-DC.
  This one joins the first one.



Is there a way to prevent agents to look beyond there own and a common DC?
I also skipped the `registrator` w/o a change in behavior.  The second dc1-consul sees the local containers, the first one doesn't. :(
",ChristianKniep,armon
1113,2015-07-17 17:03:33,"Definitely agreed - we should hide token existence from prying eyes. Thanks @gmr!
",ryanuber,gmr
1110,2016-12-02 14:26:44,"@cruatta / @jness / @bof : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,cruatta
1107,2016-09-15 10:29:26,"@armon Is this still a target for 0.8 as you mentioned it might be above?
",jhickson,armon
1105,2015-07-13 19:11:44,"@ryanuber Ah ok! that makes sense :+1:  so the `force-leave` is an outlier :stuck_out_tongue_closed_eyes:  

Is there any plan to incorporate something like ""control any node from every node"" from the API perspective?

Thanks.
",aj-jester,ryanuber
1104,2015-07-17 17:50:01,"@ryanuber I understood that. The thing is, because Consul will be used for address allocations, this limits the time the software (that is in charge of renewing the sessions every <1h) maintenance windows to a maximum of 1h.
Also, a good practice in address allocations is not to immediately re-use a recently freed subnet. This also limits the grace period to 1h.

I think this shouldn't be limited to such a small value, unless there's a performance reason for this.
",omribahumi,ryanuber
1104,2015-08-02 12:39:03,"@armon any chance this could be in the next consul release?
",omribahumi,armon
1102,2015-07-13 19:40:18,"Interesting approach. @armon do you think this would basically just be a flag to disable tag sync during anti-entropy altogether? Sounds like the easiest way might be to just sync the tags if we are doing a registration, but not if we are ensuring later on.
",ryanuber,armon
1102,2015-07-14 01:25:12,"@ryanuber I think the flag would just nil-out the tags for the purpose of checking if the two service entries are the same. This way if the service registration is missing, then the client side tags are used. Otherwise, the service side tags are used.
",armon,ryanuber
1097,2015-07-09 14:52:03,"@ryanuber There is actually a [check](https://github.com/hashicorp/consul/blob/master/consul/session_endpoint.go#L44-L54) to determine both min and max TTL.

There is no explicit cap on _session lifetime_, but there is a cap on _TTL length_.
",highlyunavailable,ryanuber
1097,2015-07-09 15:32:12,"@ryanuber I see. I missed the release/delete part.

What about having higher TTL values, for those cases you just want to ""create a key with a TTL"".
Also, would I be able to rewrite that key with a new session, without a prior release?
I'm thinking about that the app (flannel in this case) might be killed and lose its session. Will I have to wait for the TTL to expire prior to re-acquiring it?

Again, the use-case here is https://github.com/coreos/flannel/blob/master/subnet/registry.go#L95
",omribahumi,ryanuber
1097,2015-07-09 15:53:17,"@highlyunavailable thanks!

I think this should be pointed out in the documentation.

As for the options you suggested, 1 is problematic because, theoretically, the address pool might be re-assigned to another node during the time it's deleted.
About the session TTL, having it limited to 1h limits the maximum node downtime possible. The current etcd implementation uses 24h, which makes sense in this scenario.

Why was the 1h value chosen?
",omribahumi,highlyunavailable
1096,2015-07-09 10:36:06,"@tgwizard No it doesnt work
",avinashkolluru,tgwizard
1095,2015-07-17 17:20:32,"Hey @lra, This is an unfortunate panic. Consul internally checks for this potential deadlock scenario and bails in this way if a transaction can't be started. Usually this is because of a leaked transaction which will never close. The timeout is pretty conservative at 30 seconds, so you are definitely hitting this nasty little bug. I would expect that this could be worse on systems which perform poorly. Fortunately, we plan to mitigate this by moving the state store into a pure in-memory store for Consul 0.6, so this type of issue should be completely gone once that lands.

Thanks for the detailed report, and let me know if I missed anything.
",ryanuber,lra
1095,2015-08-21 23:34:47,"@lra yes, definitely soon, though there is not a firm date at this point. 0.6 aims to be a massive performance and stability improvement release. It is odd that you are hitting this deadlock so often, though, and we haven't heard many reports of it happening in the wild. Anything unusual about your setup(s)?
",ryanuber,lra
1092,2015-07-16 07:22:05,"@fraenkel Do you just mean when a client has sync'd all the services/checks or do you mean when a server has sync'd the Raft transactions? I don't think we expose the client sync state, but you could always query the agent info with `/v1/agent/services` and then cross-check with `/v1/catalog/node/` to ensure they match. For the Raft transactions, using `consul info` to check the `last_log_index` is the easiest way.
",armon,fraenkel
1092,2015-07-16 11:43:35,"@armon When we roll an upgrade, we are trying to determine when it's safe to move to the next server. We have noticed that if we roll too early, we either lose quorum (very bad), or we maintain quorum but lose data (bad).
Currently we are watching the consul service on a given node and when we see the Tags go from nil to [], we know the Synced service 'consul' message has appeared and it seems to be safe to move on.

If we can compare the last_log_index with the commit_index, then I would go with that. Just trying to find a safe and sane way to automate install and upgrades.
",fraenkel,armon
1092,2015-07-22 22:33:50,"@fraenkel Oh yeah, I would use the `last_log_index` and `commit_index` between the existing leader and the new nodes to check.
",armon,fraenkel
1089,2017-01-30 17:04:42,"@ryanuber 
I would also like to see the option to attach a custom TXT record and support RFC 2782 at the *domain* level, i.e. answer to look-ups of _<service>._<protocol>[.service][.datacenter]<.domain> for SRV and _<service>[.service][.datacenter]<.domain> for TXT.

The use case in mind is for a [kerberized cluster using only DNS](http://web.mit.edu/Kerberos/krb5-1.5/krb5-1.5.4/doc/krb5-install/Hostnames-for-the-Master-and-Slave-KDCs.html) for realm and service discovery.",sodre,ryanuber
1089,2017-01-30 18:58:28,"PR #2690 adds support for SRV queries at the datacenter level. @ryanuber, can you review is and see if it is okay?",sodre,ryanuber
1088,2015-07-23 06:08:30,"Hi @armon, 

Make sense, it's a big change. Ping me if you need help I can spend time on this + QA time. 

Regards
",eloycoto,armon
1088,2016-04-14 22:38:11,"@slackpad that's too bad. It will make the DNS SRV less useful. Is the support on the road map? I guess the workaround is not to use DNS but use http, and create tags to store ""weight"", etc. information. 
",gfrankliu,slackpad
1088,2016-11-15 00:16:16,"@slackpad any update on this? I'm guessing there hasn't been any progress in this area.
",thehydroimpulse,slackpad
1085,2015-07-23 15:18:32,"@armon I understand the confusion that this solution may cause in particular, but we need to address this problem in some form. The idea of nodes being marked critical before running checks causes severe problems on startup if you have long check intervals, as per #954. Perhaps there could be a configuration option for which ""initial"" state nodes are put in. 

I'd be happy to open a new ticket with an outline of that suggestion, if you'd like. 
",siddharthist,armon
1085,2015-07-23 20:43:43,"@siddharthist Agreed, could you make a ticket for the initial state in that case?
",armon,siddharthist
1085,2015-07-23 20:56:36,"#859 actually should solve this case by allowing the ability to provide the check status when registering the check. The confusion is probably that we forgot to document it on the web docs, so we can probably just create a ticket for that instead. @siddharthist does that satisfy your use case?
",ryanuber,siddharthist
1085,2015-07-23 21:38:35,"@ryanuber It does, thank you for pointing that out! I'll comment with the same pointer on issue #954 for reference, and then both this and that are probably ready to close. 
",siddharthist,ryanuber
1084,2015-07-06 16:01:37,"Thanks for your response @ryanuber. I share your concern regarding the individual environment variables. Maybe I go with the wrapper script approach. I didn't consider that before. 

`service.port` was a mistake on my side. I mean the ports for the service registration. That could be as well handled in a wrapper script.
",i0rek,ryanuber
1083,2015-07-07 02:43:17,"@ryanuber thank you. I get it.
",juaby,ryanuber
1082,2015-07-07 02:42:41,"@armon thank you very much. next time I'll read doc more carefully
",juaby,armon
1081,2015-07-13 17:52:15,"@ryanuber hmm...,I did it with chrome inspector,then modified the scss files,thought It would be easy for you compiling and run,well ,It would be good to have screenshots,I just didnot noticed at that time.next time maby....
",bung87,ryanuber
1078,2015-07-13 16:14:38,"@mfischer-zd thanks for opening this, makes sense to me. We use environment variables for a few other things, including the HTTP address and RPC address. I'm thinking we should do the same for the token with a `CONSUL_TOKEN` environment variable.
",ryanuber,mfischer-zd
1076,2015-07-13 16:05:58,"@ashish235 what @highlyunavailable described is accurate. It's reasonable to add an authentication proxy layer like Apache or Nginx in front of Consul. It sounds like your needs are very basic, so keep in mind that there are also HTTP basic auth modules that work in the same way that the oauth modules do.

Hope that helps!
",ryanuber,highlyunavailable
1076,2015-07-15 05:24:31,"Thanks @highlyunavailable  and @ryanuber. Cheers!
",ashish235,ryanuber
1076,2015-07-15 05:24:31,"Thanks @highlyunavailable  and @ryanuber. Cheers!
",ashish235,highlyunavailable
1075,2015-07-02 05:29:15,"@highlyunavailable Sweet that worked great! thanks. Also While I got you here may I ask for a feature request? Can we have a flag on put to write the data to consul regardless if there's a change? (right now it will only update if the value is different.)
",ThomasAlxDmy,highlyunavailable
1075,2015-07-13 16:09:02,"Thanks for fielding this one @highlyunavailable!
",ryanuber,highlyunavailable
1073,2015-07-02 07:24:13,"Hi @slackpad ,

To add to what @VaradDeolankar mentioned, 

We are planning to use Consul as an distributed service discovery mechanism within our infrastructure.
To make this happen, we want to modify the way consul responses to service requests. We can write our API/Code that overrides the way consul responds to service discovery requests.

Does consul provide any interface that we can implement to override default behavior?

We simply want to know the place in consul code which we need to modify or where we need to plugin our APIs.

Thanks
Pratik
",pratikbatua,slackpad
1073,2015-07-02 12:09:45,"You could still achieve that by wrapping the responses from Consul in another service, as @slackpad says.  There's no need to modify Consul itself to achieve that, and you're signing up for more of a development burden if you try to accomplish this by rolling a custom version of Consul.
",ryanbreen,slackpad
1073,2015-07-04 08:52:42,"thanks for your response @highlyunavailable .

Yes you are right. We have considered the DNS approach as it best fits our requirement.
Only concern I have is about support and ease available around https vs dns.

We have clients across multiple languages - java/c#/c++/kdb etc.. and may have more clients on other technologies as well.

As http end point is easy to implement and support is available across each language/technology in the market hence we preferred http over dns.

Thanks
",pratikbatua,highlyunavailable
1072,2015-07-01 19:22:32,"Hi @ketzacoatl - you are right, we should beef up the documentation to make this more clear. I found this thread which gives some info about the format of the token from @armon:

https://groups.google.com/forum/#!topic/consul-tool/lN3jZRbS2-g

> If the `acl_master_token` is not supplied, then the servers do not create a master token. If they did,
> there would be no way to programmatically provide it safely. When you provide a value, it can be
> any string value. Using a UUID would ensure that it looks the same as the other tokens, but isnâ€™t
> strictly necessary.
",slackpad,ketzacoatl
1072,2015-07-01 19:49:06,"Thanks for the assistance @slackpad!
",ketzacoatl,slackpad
1071,2015-07-09 23:36:12,"@darron hmm, this is interesting, the service discovery ACL's shouldn't affect this, and I couldn't reproduce this locally. Did you ever figure out what was going on? If you have a config I can reproduce with, then I'll definitely get this fixed before a new release.
",ryanuber,darron
1071,2015-07-09 23:49:10,"I think I've actually seen this before now that I look at it closer. If you aren't using a token while browsing around the UI, the javascript code still tries to send the `?token` parameter, and javascript's `undefined` value gets passed. Thus, when trying to look up the `undefined` token, Consul responds with an error that it can't find the token. Not sure if what you were seeing is the same thing.

@darron can you share any of the other ACL issues? Consul 0.6 is going to have a number of ACL enhancements, so if we can catch any bugs early on that would be great!
",ryanuber,darron
1071,2015-12-16 21:54:10,"@oswell @darron @slackpad I can confirm that this worked for me.  I updated my application.min.js locally on a single node (both under /var/lib/consul/ui/application.min.js and /var/lib/consul/ui/static/application.min.js), restarted consul on that node, and able to see the UI as expected.  Updating my token key in my local session data from empty, to an invalid token properly gives me a 403, and setting a correct token under this key provides me with the access I expect from my acl.
",pauzed,slackpad
1071,2015-12-16 21:54:10,"@oswell @darron @slackpad I can confirm that this worked for me.  I updated my application.min.js locally on a single node (both under /var/lib/consul/ui/application.min.js and /var/lib/consul/ui/static/application.min.js), restarted consul on that node, and able to see the UI as expected.  Updating my token key in my local session data from empty, to an invalid token properly gives me a 403, and setting a correct token under this key provides me with the access I expect from my acl.
",pauzed,darron
1062,2015-08-25 08:38:27,"Hi, sorry for such late update. But since creating this ticket I was able to clear this issue that affected our setup. 
So after digging into consul source code I decided that the easiest approach would be to momentarily stop some of the affected nodes wait for the issue to clear up and then restart them.

tl; dr I'm pretty sure the issue is too small `recentIntent` buffer size that is checked in this [method in Serf](https://github.com/hashicorp/serf/blob/master/serf/serf.go#L1481) 

IIRC there were around 220 distinct messageJoinType messages passed around in the cluster and the default length of recentIntent buffer is 128 so given enough hosts communicating with each other it seems possible that it would cause for such messages to be rebroadcasted indefinitely. 

I thought about increasing the recentIntent buffer length and deploying modified consul to affected hosts but since it was a dev cluster so I could just stop them for the required time.

PS
@slackpad all nodes were running consul 0.5.2 at that time
",pchojnacki,slackpad
1062,2015-12-14 23:32:31,"Notes on a possible solution from @armon: move the intent data to be stored with the node records instead of a shared pool. Need to use care with join intents and uncertainty in node joining and message timing (might need a shadow node or something).
",slackpad,armon
1058,2015-06-25 16:11:24,"Hi @siddharthist,

Characters allowed in services as well as tag names can include any alpha-numeric characters as well as dashes. You can use other characters to do registrations, but they won't work with the DNS interface. I've added a small documentation section on the service definitions page to make this more clear in 6290cb9. The Consul agent should also throw a warning in the logs if a non-compliant name is registered.

Let me know if I missed anything!
",ryanuber,siddharthist
1058,2015-06-25 17:13:43,"@ryanuber That looks awesome. Thank you!
",siddharthist,ryanuber
1056,2015-06-26 14:58:14,"Agreed with @highlyunavailable.  I'm going to close this because I don't see a need to burden Consul with this, but I'm happy to be overridden if others disagree.
",ryanbreen,highlyunavailable
1051,2015-06-25 16:18:13,"@highlyunavailable I'm confused on how I can use it that way. Isn't <-leaderCh going to block until the locks returns? What I really need to do is execute some operation while I'm holding the lock and then releasing it when I'm done. 
",ThomasAlxDmy,highlyunavailable
1047,2015-06-19 16:31:30,"What @highlyunavailable suggests should work nicely, good idea!
",ryanuber,highlyunavailable
1046,2015-06-30 00:57:37,"@ryanuber Left some comments, but LGTM!
",armon,ryanuber
1045,2015-09-28 11:20:25,"I'm also seeing similar behaviour on our Kubernetes infrastructure.

@slackpad: you say `force-leave` would work, but in our scenario:
- we have five consul servers running
- I kill one server on purpose
- kubernetes brings a new one online, using the same name as the killed one
- the new server joins the cluster, and works as expected
- other servers correctly see the new server, using the old name but a new IP address
- however, they also start to log every ~20s:
  
  
- at this point in time, there doesn't seem to be a way to let them forget about this node, because `force-leave` requires a node name, but that name is already working again, it's just the old IP in `peers.json` that should be forgotten.
",JeanMertz,slackpad
1041,2015-09-11 18:39:34,"@rboyer Sorry about the delay. Could you please add a test case?
",armon,rboyer
1036,2015-06-16 02:36:42,"I think the answer @ryanbreen gave probably _is_ the universal answer, at least currently. Consul uses a simple fork/exec mechanism to run script-based health checks, so the child process is spawned as the same user who started Consul. We could add something to this effect in the health checks documentation.
",ryanuber,ryanbreen
1036,2015-06-16 02:37:17,"@siddharthist yeah, please do!
",ryanuber,siddharthist
1033,2015-06-16 06:03:50,"@ryanuber Thanks for your reply. I've read the issue you referred to. It helps a lot.

So I'll just close this one.
",jiangshengwu,ryanuber
1030,2015-06-14 06:10:54,"Oh good - we definitely want to run these for each test run. Thanks @gogolok!
",ryanuber,gogolok
1019,2015-06-11 02:54:17,"Hi @ryanuber , thank you for your reply.

But I mean how could I create a `HA` consul cluster. The `HA` means services dns lookup will not be affected by whichever consul agent down.

For example:

I registry a service through any one of the consul agent, like below:

`curl -X POST -d service.json 10.0.0.4/v1/agent/service/register`

Expect:

I could nslookup through other consul agent when `10.0.0.4` is down.

Actual:

I couldn't nslookup through any of other consul agent.

BTW, I checked the API doc, and I found `/v1/catalog/register` could work like what we expect. But in the doc, it recommends to use `/v1/agent/service/register`. But `/v1/agent/service/register` says Registers a new **local** service. local??? I'm confused, why it is local? How to register a distributed service?

> Note: it is usually preferrable instead to use the agent endpoints for registration as they are simpler and perform anti-entropy.

The service configuration which register by `/v1/agent/service/register` is sync by serf protocol. So why not other node handle over the services dns when the agent which handle `/v1/agent/service/register` is down?
",feiyang21687,ryanuber
1019,2015-06-11 08:16:25,"@ryanuber Thank you very much.

So what's the best practice to deploy that consul cluster? Run client agent on every **service** machine, is that right?

But I have some worries:

A: DNS lookup performance. I check the code, dns lookup request will be hand over to the client which hold the service. If there are many client agent, like thousands, will dns lookup performance be affected?

B: Server agent workload. If there are many client agent, will server agent sync heavily?
",feiyang21687,ryanuber
1017,2015-06-10 15:57:03,"@discordianfish We already to this internally! The protocol negotiations allow a Consul 0.1.0dev instance in our fleet (so we won't judge) to still talk with the 0.5.2 masters.
",armon,discordianfish
1017,2015-06-10 16:10:24,"@armon So there is a internal consul version doing that, just not the public / open source one? Or did I miss something?
",discordianfish,armon
1017,2015-06-10 16:26:10,"@discordianfish I mean the public version should be doing this already. There should be no interoperability issues. Are you running into a problem with something currently?
",armon,discordianfish
1017,2015-06-10 17:57:39,"@armon I did, I tried to upgrade the cluster to #971 and ran into this issue (other nodes were running 0.5.0). Unfortunately I ended up destroyed the cluster and can't verify. Are there integration tests to test this compatibility?
Beside that, should this also work for downgrades / rollbacks?
",discordianfish,armon
1017,2015-06-10 18:31:04,"@discordianfish it sounds like you built from master and picked up the pending protocol bump to v3 in the process. There's a change in there that adds a new TCP ping mechanism that required a change to the protocol.

This sounds like a regression because v3 only extends v2, so it should allow a v2 node to join a v3 server, but it currently does not:



I'll take a look.
",slackpad,discordianfish
1012,2015-07-31 19:38:53,"@highlyunavailable this is very clever. A couple of questions.
1. How do you determine the endpoint names like `/recomendation/`? Are those the consul service names?
2. What if some services are private? Do you tag the specific ones you want to expose as ""public"" in the consul service registration?
",ray-,highlyunavailable
1008,2015-06-09 11:59:27,"@highlyunavailable Ahh got it! That is subtle indeed, but it does the trick! Thanks!
",armon,highlyunavailable
1007,2016-02-03 17:47:40,"@slackpad I have Consul 0.6.3, I have created a post on this issue [here](https://github.com/eBayClassifiedsGroup/PanteraS/issues/182)
",kopax,slackpad
1006,2015-06-09 02:19:29,"So @highlyunavailable hit this exactly dead on. The semaphore implementation does not have the lock-delay while the lock does (by design). The simplest approach was to just wait 5 seconds but I agree this is a bit heavy handed.
",armon,highlyunavailable
1004,2015-06-05 17:35:01,"Hey @i0rek, I took a quick look through what you have so far and I think you're on the right track. We are missing a few things. See my comment above. We will also need to add the new config fields to the `Merge` method in a *Config, so that the new config options may be specified in any configuration file and not just the first one on the list.
",ryanuber,i0rek
1004,2015-06-06 05:27:36,"Thank you very much for the suggestions @ryanuber! I will take care of them beginning next week.
",i0rek,ryanuber
1004,2015-06-08 16:00:46,"@ryanuber I think I added everything you suggested. Still have to test it though.
",i0rek,ryanuber
1004,2015-06-08 20:29:38,"@i0rek this is looking good. Ping me when you feel it is complete and I'll give it another once-over!
",ryanuber,i0rek
1004,2015-06-09 12:32:24,"@ryanuber I added RPC to the mix, because that was missing. I also added a little bit of documentation, not sure how you handle that. I was planning to rebase a last time after you looked at it so that you have a nice commit you can merge. I am not sure how you handle that either.
",i0rek,ryanuber
1004,2015-06-12 18:56:21,"@i0rek this looks good, just some minor notes about test coverage but overall this is really close! The documentation looks right. Also, no need to rebase this, since it can be cleanly applied against master in its current state.
",ryanuber,i0rek
1004,2015-06-13 22:40:29,"Thanks for the review @ryanuber. I added the tests.
",i0rek,ryanuber
1004,2015-06-14 00:42:18,"Great! Will review again soon!

On June 13, 2015 3:40:35 PM PDT, Hans Hasselberg notifications@github.com wrote:

> Thanks for the review @ryanuber. I added the tests.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/pull/1004#issuecomment-111757900

## 

Sent from my Android device with K-9 Mail. Please excuse my brevity.
",ryanuber,ryanuber
1004,2015-06-23 17:46:28,"@ryanuber any progress on this? Seems ready to merge to me. Thanks
",i0rek,ryanuber
1004,2015-06-23 18:01:27,"@i0rek sorry for the delay! It's been busy. Left a super-minor comment but otherwise let's get this merged. Great work!
",ryanuber,i0rek
1004,2015-06-23 19:24:14,"@ryanuber no worries. I changed the typo!
",i0rek,ryanuber
1002,2015-06-05 05:26:18,"@sathiyas it's definitely not related to your changes. Unfortunately Consul has a hard time with its unit tests on Travis-CI sometimes.
",ryanuber,sathiyas
1001,2015-06-04 15:54:08,"Hey @blalor, this sounds like it could be a regression. I'll crack into this one very soon. Thanks for reporting it!
",ryanuber,blalor
1001,2015-06-05 18:03:41,"@blalor I remembered wrong, we were never restoring the previous status up to this point. I've started a branch for this. I think it will need to be optional and off by default so as to not disrupt clusters which depend on the current functionality. I'll update here when I'm closer to having something usable.
",ryanuber,blalor
1001,2015-06-08 16:39:30,"@blalor the above merged PR should fix the TTL checks and restore their status on later agent start. No config option needed for this case since it is only the TTL checks that get this new behavior.
",ryanuber,blalor
997,2015-06-03 17:01:04,"Hi @armon thanks for your answer. Great hearing about that decision. I am just curious, how you would integrate that by still having valid DNS names. Is there any idea for that already? 

Thanks!
",brommer,armon
997,2015-06-04 07:51:34,"@armon Ok, great, thanks.
",brommer,armon
993,2015-06-09 22:14:28,"@slackpad Apologies, I've updated the comment above with the other 2 logs.
",reversefold,slackpad
993,2015-06-10 01:39:08,"@slackpad is correct here. @reversefold when you delete the entire data directory, you are also deleting the raft log entirely, which is why you get the error about the voting terms not matching up (servers with data joining a leader with no data). Editing the peers.json file and leaving the raft data intact is the current best practice for recovering in outage scenarios, and the `null` is described in #750, TL;DR being that it is purposely nulled out during a graceful leave for safety reasons.
",ryanuber,slackpad
993,2015-06-19 18:16:05,"@slackpad thanks, I somehow missed that. I figured it was probably somewhere in the docs and I was just missing it.
",orclev,slackpad
993,2015-07-02 06:53:58,"@slackpad 
can you give a patch build to fix this issue instead of manually fix it since it is almost impossible to mannually fix something on production env?
",juaby,slackpad
993,2015-07-06 20:29:27,"Perhaps we should always start with --bootstrap-expect=1.  That way we would work around the bring up problem.  The remaining servers will join subsequently, so in the end we'll get our redundancy back.  I believe joining servers need to nuke their raft data.  I know this is not recommended but in our case, manual fiddling with descriptors is not an option. @slackpad do you see any issues with this approach?
",elephantfries,slackpad
992,2015-06-02 18:59:20,"@phinze, thanks for asking, I should have mentioned it, RHEL AMIs are HVM based and do not take m1 instances. 
",sathiyas,phinze
992,2015-06-02 19:01:44,"@sathiyas ah okay - can you go t2.micro instead then? we want to keep the defaults in the examples relatively cheap :grinning: 

Ideally we can switch the ubuntu AMIs to HVM as well just to keep it simpler.
",phinze,sathiyas
992,2015-06-02 19:58:38,"@phinze , thanks for quick review, I made changes to reflect latest AMIs for HVM for both ubuntu and rhel6 and tested both.
",sathiyas,phinze
990,2015-06-01 11:30:57,"@armon yeah, it was a quorum issue which I could see from the logs. But I don't get this my one node (consul server) was always up, so in that case it should have elected itself as a leader and other nodes should join it later. This was my understanding but I think I am missing something here. But  can you confirm that if only one server is running it can be elected as a leader.

I think I need to find some way to find the new leader and join it instead of joining a failing server. 
",ashish235,armon
990,2015-06-01 16:05:45,"Hi @highlyunavailable, cool Thanks for the awesome response. My queries are answered. 
",ashish235,highlyunavailable
988,2015-06-01 20:39:15,"@rafikk we generally recommend against using any non-DNS compatible characters in service names. That said, as long as it's allowed in Consul, the UI should support it too. @pearkes any thoughts on this?
",ryanuber,rafikk
988,2015-06-02 21:55:22,"@rafikk This _should_ be fine to merge but I think @ryanuber is just waiting on me double checking Ember won't mind. Will do that shortly and give a :+1:.
",pearkes,ryanuber
988,2015-06-02 21:55:22,"@rafikk This _should_ be fine to merge but I think @ryanuber is just waiting on me double checking Ember won't mind. Will do that shortly and give a :+1:.
",pearkes,rafikk
988,2015-06-02 22:06:37,"Sounds like this is G2G, so I'm going to merge this in. Thanks, @rafikk!
",ryanuber,rafikk
985,2015-06-26 09:55:04,"@highlyunavailable Thanks for finding this! My guess is there is a channel blocking somewhere as well in the tear down path. I've tagged this as a bug. As it should just kill the child process in scenario 3.
",armon,highlyunavailable
985,2015-06-26 09:57:58,"@sean- If the client is partitioned off from one of the servers, who happens to be the leader, then things should still work. Clients pick a random server to talk to for RPCs for load balancing, and then the servers do internal request forwarding if they are not the leader. Given some time, the client should detect that server as partitioned via Serf and remove it from the list of eligible servers. So when the client makes an RPC call, it will be to one of the non-partitioned servers and that server should be able to forward to the leader. At least, thats how it should work :)
",armon,sean-
985,2015-08-05 10:01:57,"@armon So is the behaviour that highylunavailable described in scenario 1 the intended one? Meaning loss of the leader and election of a new one implies loss of all locks?
",jeinwag,armon
982,2015-06-03 07:14:54,"@artushin it's hard to say without a bit more context on your scenario. Could you provide any details on what happened during the service registration, if the check was registered separately, what version of Consul you are running, if you are running any custom patches, etc? Some debug-level logs would also go a long way in helping us diagnose the problem.
",ryanuber,artushin
982,2015-06-03 21:32:49,"@ryanuber We're on v0.5.2 on 5 servers and 66 agents and v0.5.0 on 30 other agents. This started happening when we switched from http status checks to ttls and got some other issues. In the end, we switched back but this INFO log still occurs and load looks like its higher than it was before. 

Here are the debug logs from a single host starting with a few of the messages and ending in the same messages (they come in groups). Nothing seems out of the ordinary. I've dropped our service names but each request was for a different service.

Is EnsureRegistration called only when a service is attempting to register? I'm just worried that we have some kind of flapping registration we're not seeing.


",artushin,ryanuber
982,2016-04-13 05:40:41,"@artushin I'm going to close this out since this code path was completely rewritten in Consul 0.6.0 (it looks from the debug log that the state store got corrupted). Please re-open and/or let us know if there's any lingering part of this issue.
",slackpad,artushin
977,2015-05-27 01:43:09,"@ryanbreen yeah, tend to agree, it's kinda horrible to condense comparisons into a single case statement. reverting that bit...
",sdboyer,ryanbreen
976,2015-05-28 19:52:16,"@ryanuber nice trick! Although, I was thinking more in being able to monitor RDS instances from Consul. 
",c4milo,ryanuber
976,2015-05-28 20:03:19,"@c4milo I use TCPing to do just that:

`/bin/tcping -t 1 rds.hostname.goes.here 1433`
",highlyunavailable,c4milo
976,2015-05-28 20:12:06,"What @highlyunavailable suggest should work too! Both commands would take a hostname and port, which should allow you to do exactly what you need.
",ryanuber,highlyunavailable
972,2015-05-26 15:40:38,"@highlyunavailable thanks for the tip!
",MrMMorris,highlyunavailable
971,2015-06-05 02:06:34,"@discordianfish I build consul 0.5.2 with this patch and removed my ""search ec2.internal"" from /etc/resolv.conf along with setting only a single nameserver of 127.0.0.1.

Even with compression turned on I still get ""FATA[0000] Get https://registry-1.docker.io/v1/repositories/library/busybox/tags: dial tcp: lookup registry-1.docker.io on 127.0.0.1:53: cannot unmarshal DNS message"" from docker
",sstarcher,discordianfish
971,2015-06-05 14:32:04,"I have not been able to craft a decent test that validates this fix as I cannot get the test DNS server to reliably return a response that is too large. We have been using it without issues but it sounds like @sstarcher still sees some.

@discordianfish do you believe miekg/dns#216 will fix that issue as well? 
",epipho,discordianfish
971,2015-06-05 14:59:10,"@discordianfish  I'm sure I compiled turbine's compress-dns branch
""./command/agent/dns.go:    m.Compress = true
./command/agent/dns.go: m.Compress = true
./command/agent/dns.go:     r.Compress = true
./command/agent/dns.go: m.Compress = true
""

I also checked the version of my binary it was something along the lines of 0.5.2.#####

I will re-attempt on monday.
",sstarcher,discordianfish
971,2015-06-08 14:24:46,"@discordianfish I again rebuilt it using the compress-dns branch from turbine and I still get 
`FATA[0000] Get https://registry-1.docker.io/v1/repositories/library/busybox/tags: dial tcp: lookup registry-1.docker.io on 127.0.0.1:53: cannot unmarshal DNS message`


",sstarcher,discordianfish
971,2015-06-08 17:01:35,"@miekg suggests to set the compress flag in consul, not wait for him to change this upstream.
@armon Can we get this merged soon? Even if it's not fixing the issue for all, it's definitely a pretty clear bug which breaks everyone using docker and consul as recursor.
",discordianfish,armon
971,2016-01-27 15:21:50,"@slackpad indeed. Sorry I had github notifications turned off and didn't see it.  I just merged 0.6.3 into my fork and am doing testing to make sure there are no regressions.
",epipho,slackpad
971,2016-05-31 17:37:14,"@slackpad I've been doing some testing as I'm hitting this same docker + consul bug. I don't think the DNS library makes the compressed state of the incoming message available.
",alexjh,slackpad
971,2016-05-31 17:45:42,"No it doesn't because compression is hop by hop so it doesn't make sense to
relay this when you are a proxy.

I don't get why consul just compresses everything. Compression has been in
the DNS standard since 1984.
On 31 May 2016 7:37 p.m., ""Alex Harford"" notifications@github.com wrote:

> @slackpad https://github.com/slackpad I've been doing some testing as
> I'm hitting this same docker + consul bug. I don't think the DNS library
> makes the compressed state of the incoming message available.
> 
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/hashicorp/consul/pull/971#issuecomment-222762646, or mute
> the thread
> https://github.com/notifications/unsubscribe/AAVkW_3zhBkwprX1sN0VSn7gdJW6QZhVks5qHHHigaJpZM4Elqx3
> .
",miekg,slackpad
971,2016-05-31 22:34:44,"@epipho:

> Compress udp messages that come in that are already over 512 bytes (non-conforming server?)

Like miekg said, it makes sense to compress everything. I think that would be a good start and would fix the docker bug that a lot of people are seeing.

@ryanuber: I don't think tests for compression are needed as that's already covered by the tests in the dns library.
",alexjh,ryanuber
970,2015-05-22 18:17:23,"@artushin Looks like its coming from LMDB, hopefully this class of issue goes away with 0.6
",armon,artushin
968,2015-05-22 03:11:09,"@highlyunavailable The ""behavior"" of a session affects what is done during invalidation of a session to any keys associated (""locked"") by that session. So I guess the confusion here is between the behavior of a key ""lock"" in Consul vs the `api.Lock` client library.

The `api.Lock` will create the key if it does not exist, and in either case attempts to associate or ""lock"" the key with a session. On `Unlock` the client dis-associates the session (""unlock""), but does not delete the key. The `api.Lock` exposes a separate `Destroy` operation instead. The intended use case for that library was for locks that are longer lived than the sessions. For example, multiple services contending for the same lock as a leader election mechanism.

That said, you can get the behavior you want by doing the lock with a session with `delete` behavior, acquiring the lock, and then doing an explicit session invalidation. The session invalidation will cause the lock to be deleted / released without it lingering.
",armon,highlyunavailable
968,2015-05-22 17:52:19,"@highlyunavailable I agree. The downside of overloaded terminology and complex systems. But I'm happy to help clarify!
",armon,highlyunavailable
964,2015-05-20 20:18:24,"Hi @sathiyas - thanks for this contribution!

I think the `egress` rule confusion is just a matter of using the latest version of Terraform. In 0.5.0 we changed the behavior of security groups to avoid the implicitly created egress rule, so it needs to be in the config now.

As for the provider variables, it's actually important to leave those out of the module definition to support users who are configuring their provider via environment variables.

I think the name tag is a good idea though. Can you re-push this PR with just the name tag stuff?
",phinze,sathiyas
964,2015-05-20 20:28:46,"Sure @phinze,will do shortly
",sathiyas,phinze
964,2015-05-21 00:41:38," @phinze, modified, tested and submitted. Thanks for quick review
",sathiyas,phinze
964,2015-05-26 15:00:07,"Looks good - thank you @sathiyas!
",phinze,sathiyas
964,2015-05-26 17:47:02,"Answering a question from @sathiyas here for public record.

> I have question on why you think the Provider info is not needed to run the stack.
> Without the follwowing block in my TF file, I cannot run the stack.

There are two ways to configure the provider without a `provider { ... }` declaration inside the module.

**One**: provider config inherits into modules, so you can simply configure the provider in the place where you invoke the module.



**Two**: provider config can be provided solely via environment variables, so you can completely omit any `provider { ... }` blocks and simply set these environment variables:



Either of these methods should work for you.

The important thing is that we omit the provider config from _inside_ the official Consul Terraform module, so that callers can choose which provider config style they prefer.

Hope this helps to clarify - let me know if you have any further questions!
",phinze,sathiyas
956,2015-05-19 22:28:56,"@sean- Can you tell if its hung or just migrating? Our own servers took like 90 seconds to finish the migration. Or did they just sit there forever?

/cc: @ryanuber any ideas why it would be hanging?
",armon,sean-
956,2015-05-19 22:33:03,"That is interesting - the migration utility only uses the Raft interfaces, so I'm not sure where this might be stemming from. @sean- how large is the original LMDB data directory?
",ryanuber,sean-
956,2015-05-19 22:43:44,"@ryanuber For the upgrade utility, can we have it output incremental process (e.g. 5%..10%...) so that it's clear something is happening at least?
",armon,ryanuber
956,2015-05-19 22:54:34,"@armon, yeah I think we can update some counter after each raft log is converted over. I'll take a stab at that.
",ryanuber,armon
956,2015-05-20 01:08:59,"@armon the total size was ~1MB, it should have been tiny.  I `truss`'ed the process and it was working, but not doing anything.  It looked like it was spinning in place forever.  I see it was opening have the `truss` logs available.



and this continues for a while, but then it stops and the output changes:



And the process basically loops forever.  I still haven't chased this in to code, but this is what I recorded before employing the workaround.
",sean-,armon
956,2015-05-20 02:46:15,"Yeah this definitely sounds like a problem - 1MB should have flown through very quickly. I've added progress indication to Consul's master branch, which might help to understand which phase the migration hangs at. It will dump some output like this:



@sean- correct me if I'm wrong, but it looks like you are using FreeBSD? In the meantime, I'm going to set up a FreeBSD machine and give the migrator a test.
",ryanuber,sean-
954,2015-07-23 21:53:08,"@onnimonni Solution posted in issue #1085:
""[#962] actually should solve this case by allowing the ability to provide the check status when registering the check. The confusion is probably that we forgot to document it on the web docs, so we can probably just create a ticket for that instead. @siddharthist does that satisfy your use case?""
",siddharthist,siddharthist
949,2015-05-20 06:20:08,"Turned out it was competing versions on the global bin path. Shit behind the keyboard, sorry.

@armon Thank you for this project; looking forward to using it more.
",haf,armon
948,2015-05-19 22:38:08,"@tiwilliam My only concern now is Windows. I have a suspicion it will not play nice... 
",armon,tiwilliam
948,2015-06-29 21:57:46,"@highlyunavailable Thank you! I wonder if it works with the Windows Loopback Adapter installed.
",tiwilliam,highlyunavailable
948,2015-06-30 12:27:10,"@highlyunavailable Good catch, I've added `127.0.0.0/8` and we now treat it as a private block, which I think in this case is perfectly fine.

I guess you can change address of your Windows Loopback Adapter manually to 127.0.0.1 if you really want that?
",tiwilliam,highlyunavailable
948,2015-09-02 14:45:05,"It doesn't look like the 169.254 case is a problem since Consul will [bail out](https://github.com/hashicorp/consul/blob/iface-down-fix/consul/util.go#L255) if it is presented with multiple private IPs.

This could only be a problem if the machine a. has 1 APIPA-addressed DHCP adapter b. public IP adapter(s) - this would mean that consul would try to auto-bind to the APIPA adapter, but that's already a thing - Consul won't bind to a public IP. I'm fine with how it works in Windows right now as well.

if @armon approves it would be cool to get this merged - there are multiple open bugs that this would fix it looks like: #934, #928.
",highlyunavailable,armon
947,2016-09-16 06:45:50,"+1 would love to have this in :)

@slackpad _bump_ :)
",CpuID,slackpad
946,2015-05-16 05:01:52,"@tgwizard I think we could also remove the datacenter from the node name when listing WAN members, now that we have a column dedicated to that.

![](https://cldup.com/DJPGFOzAbH.png)
",c4milo,tgwizard
946,2015-05-16 10:22:43,"Hmm, @c4milo I don't think that is the datacenter but part of the actual node name. If I run it locally I get


",tgwizard,c4milo
942,2015-05-15 21:03:09,"@c4milo perhaps using the `-detailed` flag would be good enough?
",tgwizard,c4milo
942,2015-05-15 21:57:26,"I submitted a PR to add this. @c4milo I'm very sorry if this was something you wanted to do and I just rushed into this :/
",tgwizard,c4milo
942,2015-05-15 22:11:05,"@tgwizard how dare you :)
",c4milo,tgwizard
942,2015-05-15 23:14:25,"@ryanbreen Good problems to have :)
",armon,ryanbreen
939,2015-05-15 01:23:48,"@armon everything looks great, just one untested method. Otherwise LGTM!
",ryanuber,armon
939,2015-05-15 01:32:28,"@ryanuber Added test!
",armon,ryanuber
938,2015-06-02 22:19:13,"@rafikk Agreed about the nested scrolling, but unfortunately it's for performance. In large clusters (thousands of services/nodes) the UI chokes without ember listview.
",pearkes,rafikk
938,2015-06-02 22:45:16,"@pearkes Does that mean removing ListView is a non-starter? Is pagination an option?

Is there a good way for me to test the UI against such a cluster?
",rafikk,pearkes
938,2015-06-03 13:02:07,"@rafikk Best way to test the UI is to replace the JSON endpoint to a json file on disk (the ui dir serves a directory, so you can just copy a file in there). Then give the file a fake response of some 1000s of nodes. That's the best way I remember. Proper fixtures would be nice though. Ember has a come a long way since this UI was made, so there are a number of ""better"" tools now as well.
",pearkes,rafikk
937,2015-05-18 21:26:44,"Hey @cruatta,

For checks which apply to the system as a whole (like memory or cpu utilization, etc), these should actually just not be associated with any service. If they are associated with the node only, when they start failing, all services on that node are considered ""unhealthy"" and are not returned from the service catalog when using a passing filter, and will also not be returned from the DNS interface. Using node-scoped checks for general system-level tests should allow deduplicating most things.

Does that help?
",ryanuber,cruatta
933,2015-05-18 22:51:54,"@highlyunavailable That is what the `Destroy` command is for!
",armon,highlyunavailable
932,2015-05-12 20:15:37,"@highlyunavailable I think this is okay actually. Lock makes use of the `?acquire` operation which may be affected by a lock-delay, while semaphore uses `?cas` which does not have the same sort of deferral mechanism. 
",armon,highlyunavailable
924,2015-06-03 23:43:12,"@mainframe thanks for reporting this. This is happening in the gossip layer. After reading the code, it appears this is intentional. The gossip layer uses logical time only in its state which makes it more resilient to clock differences between the agents. My best guess at why the timers aren't restored is to avoid writing the local system time into the agent state to make this behavior more predictable. @armon can probably clarify here for us.

As for the peers.json file, that is intentionally left populated. You can read more about these types of failure scenarios in [this guide](https://consul.io/docs/guides/outage.html). Of particular interest here is the section on failed servers, which explains how this scenario may be recovered from.

I think the TL;DR is that this is working as intended, but I'll leave this open for now in case I missed something.
",ryanuber,mainframe
924,2015-06-04 06:04:26,"@ryanuber - correct me if Im wrong - but outage guide deals with recovering consul cluster and restoring the quorum after full outage. I have no problem with restoring the quorum and getting consul cluster working again - once enough nodes for quorum are up again. I have a problem that consul cluster members list is changed/reduced after outage recovery - when not all nodes are back up again. 

But let me illustrate the problem with the real use case - and why Im thinking its a problem:

1) Lets say we have 3 node consul cluster



2) Now the full poweroff / outage happened
3) Lets say that after outage we manage to boot-up / recover nodes 1 and 2 - and node3 still stays down
4) Consul cluster forms with nodes 1 and 2 - quorum reached and cluster is operable - BUT nodelist is reduced/changed now to this (after reaping the node3 when node1-2 form the quorum):



5) Our problem is that we are running Ceph cluster on top of consul cluster - and we are using consul member list in order to provide local host resolution (and generated configuration) to it. There would be no problem if after outage consul cluster would recover with nodes 1 and 2 up only - and members list would look like this (providing correct status overview of a cluster - with the member list as it was before outage):



6) Ceph cluster would recover perfectly when node3 is still down yet present in members list (in failed state) - but it fails to recover when we are loosing node3 from nodelist/host resolution.

You could say that coupling local host resolution and ceph with consul members list is our problem :) But why Im thinking its a more generic problem for everyone? Because currently after outage and consul cluster auto-recovery you will end up with totally NEW cluster (changed member list) - in case enough nodes for quorum are up - but not all previous server nodes are up. I would expect that I will get OLD cluster status with failed nodes after outage - like it is also normally presented in case of node(s) failure (when still having quorum) - ie after outage I would expect to see this as members list (if node3 is still down):



Bottom line - I think if outage re-defines my cluster topology - its very wrong :) That basically means that we cant auto-recover stuff on top of consul cluster from outage.
",mainframe,ryanuber
924,2015-06-04 09:12:39,"@mainframe I think the problem is that the node reaping is ""best effort"" in Serf. We do not persist the failed nodes, and their 72h grace period is only in memory. This means during a full cluster shut down, that state is lost. When the cluster comes back online the ""failed"" nodes are gone and so they are immediately reaped.
",armon,mainframe
924,2015-06-04 09:18:53,"Thank you for explanation @armon. Would it be possible to make it persistent in the future releases or its by design?
",mainframe,armon
916,2015-05-08 02:12:49,"Thanks @armon, that's great info.  We'll look into overriding the serfHealth check association and TTL-based sessions.  And enabling telemetry.

Here's a few examples of log snippets:










",Amit-PivotalLabs,armon
916,2015-07-12 09:26:17,"@Amit-PivotalLabs @armon 

I can confirm we see the same frequent membership loss issue in AWS. I will try to get some logs.
",aj-jester,armon
916,2015-07-22 22:49:50,"Thanks @armon.

/cc @fraenkel @ematpl @luan see above comment from @armon re UDP routing issues.
",Amit-PivotalLabs,armon
916,2015-07-22 22:54:07,"Thanks, @armon and @Amit-PivotalLabs!
",ematpl,armon
916,2015-08-26 19:26:21,"Hi @ematpl, @armon  and @Amit-PivotalLabs did you finally find the root cause of this error? we are seeing the same error in our systems, also having 3 consul servers (one of them on-prem) in different AZ. Same errors appear in AWS hosts as well as in on-prem consul server. Is there any way to increase Timeout. 
Checking the logs, it is almost happening every hour in each client in our case. So, it's ""frequent"" enough.

We are seeing same errors in our logs:


",bruno-loyal3,armon
916,2016-01-25 15:14:06,"Running 0.6.3 on AWS as well (using Docker 1.9.1) and see serf membership leaving/joing such as has been described throughout this post. Does the 0.6.3 version of Consul ""expose low-level tunable of both Raft and Serf"" @armon ?
",draxly,armon
916,2016-01-26 02:20:30,"@armon I would love my issue to be a configuration issue.  I have been running the cluster for over a year and it has been a consistent low level of annoyance.  Over the weekend it went 2 days without any flapping, but lost connection on sunday evening.
",sstarcher,armon
916,2016-01-26 18:26:22,"@armon I'm using docker with --net=host to remove the ARP problems.  My servers are highly over provisioned and run at 15% CPU for Consul.  I do see sporadic jumps in CPU every day or so randomly.   I was hoping my issue was #1592 , but after upgrading to 0.6.3 I still see issues, but it's starting to look like the issue is less often.
",sstarcher,armon
916,2016-01-26 19:08:06,"@armon in the past 24 hours I have 2,907 occurrences of `EventMemberFailed`, but the large majority of these are members and not the 5 leader nodes.

On just my 5 leader nodes I have 253 occurrences of `EventMemberFailed` At one point in time in the last 24 hours every leader node has had someone report that EventMemberFailed for that node.

4 of the 5 nodes have reported at certain times that every other node has `serf EventMemberFailed`  Only a single node has no entries for EventMemberFailed.

This does raise an interesting point the 4 nodes that are complaining about each other are complaining about each other within 30 seconds of each other.

Jan 25th 19:50:43, 23:08:55, 23:09:11, 23:10:00
Jan 26th 00:17:09
",sstarcher,armon
916,2016-01-26 20:09:57,"@slackpad I see `no acks received` in a handful of occurrences, but never around a leader election issue.

The issue with the leaders is always related to `Failed to contact` In the below log 10.0.20.175 was the current leader it loses leadership and reaquires it.



On a node it failed to contact.


",sstarcher,slackpad
916,2016-01-27 09:04:29,"@armon, thanks for the pointers on how to look for potential errors.
Regarding using Docker, I have now tested to run Consul (both server and rest of agents) without Docker and experience the same problem. :/

A, perhaps unrelated question: On one of the servers, I saw a one-time message that I have not seen before:
[ERR] memberlist: Failed TCP fallback ping: read tcp 10.7.1.9:58713->10.7.1.224:8301: i/o timeout
Does this imply that TCP is used as fallback when UDP checks fail (I believe I have seen that mentioned somewhere as well)? If that is the case, shouldn't I see this regurlarly in my logs when encountering serf issues? Before a server is considered dead I mean?
",draxly,armon
916,2016-03-21 07:50:24,"@slackpad, I believe I have verified that by using netcat on both servers and seeing that tcp and udp connections are successfull. 
Also, this problem occurs a couple of times per day for the entire environment (10 servers) so it is a pretty infrequent problem. I'm starting to believe it might be something with the network between the Amazon EC2 instances but not sure how to verify this.
",draxly,slackpad
916,2016-08-22 03:17:09,"@jhmartin Thanks for the reply. If that's the case, I would guess that a specific node or set of nodes would appear to be frequently marking random other nodes as failed/dead, but we aren't observing any patterns among the nodes that are doing the marking (i.e. those logging messages like ""memberlist: Marking {host} as failed, suspect timeout reached""). Does that sound like it rules out any issue related to an overloaded machine performing a check?
",paladin8,jhmartin
911,2015-05-06 18:19:24,"@kaelumania The explanation given by @highlyunavailable is dead on. The peers file is only ever edited during an outage, which is defined as a loss of quorum for Consul. This means a majority of servers are offline or cannot communicate. In that case, the cluster cannot safely make changes to the peer set because it is unable to coordinate. Typical operation of adding/removing servers does not require that process.

Closing the ticket, but please re-open if you have an issue!
",armon,highlyunavailable
911,2015-05-06 19:41:21,"@armon @highlyunavailable thank you very much. Can you say something about my second comment?
",kaelumania,armon
911,2015-05-06 19:41:21,"@armon @highlyunavailable thank you very much. Can you say something about my second comment?
",kaelumania,highlyunavailable
911,2015-05-06 20:03:22,"Any ""server"" can serve a read, but depending on how consistent you require your read to be, there may be round-trips needed to `N/2+1` members of the cluster to verify the value is current. Check out the [HTTP API](https://www.consul.io/docs/agent/http.html) docs, specifically the ""Consistency Modes"" section.

The short answer is: The leader is involved in ""default"" and ""consistent"" level reads though it may not directly service the read. The ""consistent"" mode involves N/2+1 servers, one of which must be the current leader. The ""stale"" consistency mode allows any server immediately service a read. In other words, yes, all non ""stale"" consistency mode reads will eventually talk to the leader though other servers may actually be servicing the request (that is, actually have an open TCP connection to the client).

Watches are a special case - as I understand them (and correct me if I'm wrong, @armon), the state change events are what trigger watches to complete, so the act of writing to the local state machine as part of replicating an update across the cluster will cause the server to send out the data - this is not the same as a request to the leader and a response from the leader.
",highlyunavailable,armon
911,2015-05-06 22:10:05,"@kaelumania The explanation by @highlyunavailable is almost perfect. Watches actually aren't a special case, and are just like normal reads and even will respect the consistency modes. Raft is implemented like the paper, and the Serf/Gossip data is not used for replication.

In the ""default"" read mode, all reads are serviced by the leader. The ""consistent"" read mode forces an additional heartbeat round trip on read. The ""stale"" mode allows any server to service the read, and thus does load shedding from the leader.

Hope that helps!
",armon,highlyunavailable
911,2015-05-07 07:28:33,"@highlyunavailable thanks once again. If I understand you right, any server can answer a request, but internally checks the value with the leader?

@armon Does that mean that if I have 1000 nodes with each 2 watches (via `consul watch`) there are 2000 blocking queries to the leader node? Further for stale reads how is decided which server answers the request or does the client address a specific server? For example, when a read request is send out via serf and arrives multiple servers. How is ensured that only one server answers or is the client responsible for de-duplication? How do I configure watches to use stale consistency mode?

Thanks.
",kaelumania,armon
911,2015-05-07 07:28:33,"@highlyunavailable thanks once again. If I understand you right, any server can answer a request, but internally checks the value with the leader?

@armon Does that mean that if I have 1000 nodes with each 2 watches (via `consul watch`) there are 2000 blocking queries to the leader node? Further for stale reads how is decided which server answers the request or does the client address a specific server? For example, when a read request is send out via serf and arrives multiple servers. How is ensured that only one server answers or is the client responsible for de-duplication? How do I configure watches to use stale consistency mode?

Thanks.
",kaelumania,highlyunavailable
911,2015-05-08 08:22:07,"@armon thanks, it might be useful to add an article to the consul documentation about which parts use serf and which parts use raft etc. Do you think 2000 blocking queries to the leader might be problem?
",kaelumania,armon
904,2015-05-05 01:05:32,"@josephholsten this looks much better, thanks! RE: command naming, I think `configtest` is fine. I left some minor comments, and it looks like we are missing the middleman documentation, so if you want to add that feel free. Otherwise, we can also take care of it after a merge.
",ryanuber,josephholsten
904,2015-05-05 18:14:59,"@ryanuber care to review the code again? I'll get the middleman doc ready
",josephholsten,ryanuber
903,2015-05-04 19:14:51,"Hey @josephholsten,

I think we can test the configuration relatively easily by making just a single call to `ReadConfigPaths` from the `agent` package. You can basically just pass it an arbitrary path, so I think the CLI could even just accept a `[]string` for the args, and we can directly pass it into `ReadConfigPaths`.

This shouldn't require any code copying or anything like that. Make sense?
",ryanuber,josephholsten
903,2015-05-04 19:31:30,"@ryanuber please check #904, it's free of code copying.
",josephholsten,ryanuber
900,2015-05-04 00:04:38,"@ryanbreen feel free to merge this and move the link to the section you feel fits best
",ryanuber,ryanbreen
899,2015-05-04 04:01:57,"@ryanbreen that is a neat approach! Automatically mirroring git commits into Consul via a webhook is a very interesting idea.
",rhelmer,ryanbreen
897,2015-10-26 08:15:04,"@ryanuber: I just ran into this one as well.. it was fixed in #1127 but that commit has not made it to the website yet.
",robinroestenburg,ryanuber
895,2015-04-29 20:34:30,"Yep, comments would be great. Thanks @ryanuber!
",grantr,ryanuber
893,2015-05-03 23:21:25,"Hi @ryanuber 
- [this is the link to the chocolatey package](https://chocolatey.org/packages/consul)
  - the comments (scroll down) are what I'm talking about.
- I _think_ the package source is https://github.com/sitano/chocolatey-packages, and I would guess community-provided.
  - this is the maintainer: https://chocolatey.org/profiles/mirthy

However, the chocolatey package lists @mitchellh and @armon as authors, so I assumed it was owned by Hashicorp.

I've used the package to bootstrap my use on Windows nodes - it saved me needing to figure out a service wrapper and so forth.
",petemounce,ryanuber
892,2015-05-07 18:59:59,"It should persist past refresh, that would be a bug. It's saved in local storage.

The only conceivable way to share it would be to tack it on to the query param, which as @armon noted would be pretty unsafe. But it's an option and doable.

Otherwise, don't know how you could share.
",pearkes,armon
886,2015-04-29 23:11:51,"@ryanuber Thanks, this feature will be much appreciated.

For anyone's interested: atomicity can also be achieved in the watcher handler level with an implementation close to the following:

Consider that there are N keys we would like to update atomically, at once: 
Create each key value in the following format:
`<value1>:1:N:<uuid>`
`<value2>:2:N:<uuid>`
`...`
`...`
`<valueN>:3:N:<uuid>`

Where `<valueN>` is the actual value of the Nth key in the bulk and `<uuid>` is a unique identifier we assign to the bulk to differentiate it from other bulks.

The watcher handler keeps a map of uuids to a list of KVs.
When a KV update occurs, the handler peeks at it's value and seeks for the format mentioned above.
In case there's a match: it will add the KV to list of KVs which is mapped by the 'uuid'.
It will then check if this list reached the size of N (the handler knows what N is since its part of the above format as well).
If the list reached the bulk size then we can safely execute some action (in our use case it was a curl command which sends the the entire KV list in one bulk to a web server endpoint).
",mikeys,ryanuber
882,2015-04-29 04:52:36,"@jsternberg this involves both serf and the even lower-level memberlist package. As @armon mentioned the changes required will be deep and involved, so before starting any work it would be best to start brainstorming in a Google Docs document about the design, as there are certainly a very large number of considerations to make here.
",ryanuber,armon
882,2015-06-25 14:41:23,"Please include me (@armon), @ryanuber and @slackpad. 
",armon,armon
882,2015-06-25 14:41:23,"Please include me (@armon), @ryanuber and @slackpad. 
",armon,ryanuber
880,2015-04-23 10:22:21,"@armon Great, thanks! I think this should be documented? I'd say this is a concern everyone who is replacing nodes in the cluster automatically has. But I'm good, so feel free to close this ticket if you want.
",discordianfish,armon
876,2016-01-27 02:31:42,"@armon, has this been implemented in 0.6.0?

We have a unit test that tries to call api.client.KV().Acquire() twice, expecting the first to succeed and the second to fail. This is the behavior seen in agent v0.5.2, but agent v0.6.0 allows the 2nd Acquire() to succeed.

How exactly has the semantics of Acquire() changed?
",chnrxn,armon
875,2016-06-21 15:36:58,"@slackpad - Would love your feedback on the above PR! I could also use advice on inconsistent test failures that I'm seeing in Travis - all tests are passing consistently in my local dev environment. 
",tshak,slackpad
866,2015-11-18 16:51:35,"Hi @slackpad, 

It's actually (just?) 100G, which is all raft.db.

Using strings tells me that it seems to be full of KV data and consul-replicate statuses. We are writing about 20 numeric values into the KV every 20 seconds and doing peer-replication with another consul DC.

Snapshots are really just 60k.

$ ls -lh /var/lib/consul/raft
total 100G
-rwxr-xr-x  1 consul consul  107 Oct 12 08:26 peers.json
-rw-------  1 consul consul 100G Nov  4 04:10 raft.db
drwxr-xr-x 17 consul consul 4.0K Nov  4 04:12 snapshots
$ ls -lh /var/lib/consul/raft/snapshots
total 60K
",chnrxn,slackpad
866,2016-01-11 05:09:30,"@slackpad, not any more after I cleared those huge ones and restarted Consul. (and those happened 2 out of maybe 30 machines).
",chnrxn,slackpad
866,2016-02-02 05:23:59,"@slackpad, if I understand you correctly, I could just have an external process control (e.g. daemontools) stop Consul, remove the Raft DB, and restart Consul (of course one host at a time)?
",chnrxn,slackpad
866,2016-02-02 07:28:57,"@slackpad how can I tell when a snapshot has been taken, or when a compaction has been done? Is there anything in the logs I can watch out for, or something?
",chnrxn,slackpad
866,2016-10-07 21:14:52,"@slackpad couldn't I just remove server one by one from cluster, delete the entire data directory, then add back the particular machine back into the cluster.

We are facing a similar issue and need to resolve this quickly.
",myusuf3,slackpad
866,2016-10-10 21:16:46,"any ideas here, other than deploying new cluster? @armon 
",myusuf3,armon
866,2016-10-10 21:48:07,"@slackpad well I am not convinced that's how it works, I recently had to replace a server and introduced it to the cluster and now its raft.db is just as big as the others, it was a new server with clean data directory. 

What is exactly the process you are describing? Also is there a way to know when I snapshot was completed other than grepping logs and waiting?

Do you mean to say new servers added won't have this bloat? If so how do you explain new server I recently added to the cluster. 

Lastly, by data directory, you mean parent folder containing raft.db and snapshot directories?
",myusuf3,slackpad
866,2016-10-10 22:07:53,"@slackpad hmm. logs incoming.
",myusuf3,slackpad
866,2016-10-10 22:23:25,"@slackpad anything specific we are looking for here? there are quite a few logs!
",myusuf3,slackpad
866,2016-10-10 22:29:38,"@slackpad also getting this on the leader since the 6th 


",myusuf3,slackpad
866,2016-10-11 00:11:55,"@slackpad possibly our health checks are comprehensive, so removing box from cluster one by one deleting data directory `consul/data` and adding them back to the cluster should reclaim disk usage? Wouldn't we see behaviour like we just saw for the newly added node? 
",myusuf3,slackpad
866,2016-10-11 14:18:58,"@slackpad on leader? quite often
",myusuf3,slackpad
866,2016-10-11 14:19:41,"> @slackpad possibly our health checks are comprehensive, so removing box from cluster one by one deleting data directory consul/data and adding them back to the cluster should reclaim disk usage? Wouldn't we see behaviour like we just saw for the newly added node?

More interested about this though ^^
",myusuf3,slackpad
866,2016-10-11 15:45:21,"@slackpad well those machines have been running for over a year and I would image that this isn't issue atm, but totally possible but I would imagine I would have seen this issue earlier. Regardless how do I fix this issue without taking out production since it seems like cluster seems to be replicating the large raft.db to new machines
",myusuf3,slackpad
866,2016-11-13 23:26:12,"@slackpad cool! so we upgraded to Consul 0.7 and have removed consul 0.5.\* from our system completely. As you mentioned adding new machines to the cluster and having it have a clean `raft.db` wasn't true in consul 0.5.\* but it is true for Consul 0.7. When we would previously add machine it would copy the entire `raft.db` or what looks to be the entire thing to the new box. 

Anyways that was an observation ^^

The issue I am seeing now is that `raft.db` for the old boxes that was at 70% disk usage isn't going down and I would like to clear that up since it's dangerously close to full. 

Is it safe to remove the node from cluster `rm -rf /data/` and restart consul add it back to the cluster? Then repeat for all the remaining servers to reset disk usage or not?
",myusuf3,slackpad
862,2015-04-18 00:06:00,"@ryanuber I'm not sure I understand, this looks like it will pass through the CNAME but won't actually resolve it.
",armon,ryanuber
862,2015-04-18 00:23:29,"@armon so maybe we were thinking two different things. If a recursor is provided in Consul's configuration, the recursor handles resolving the CNAME as it should. However, when Consul crafts the DNS reply, it currently returns only the first CNAME, and the resulting A or AAAA record, so the response ends up looking something like this:



Notice that the above CNAME chain is broken because we are missing the intermediate CNAME's. It was my understanding that this is what was breaking the clients. After patching, we get the full chain:



Were you thinking that Consul would act as its own DNS recursor if none was configured?

One other thing I was going to ask about was the limit on # of records. I am guessing that it was to make DNS responses smaller if many A records are returned, but in these cases this might be limiting, which is why I bumped it slightly to 5. Any thoughts on that?
",ryanuber,armon
862,2015-05-04 22:19:13,"@ryanuber I see. Makes sense!
",armon,ryanuber
861,2015-04-13 19:45:35,"@fraenkel I've left some feedback, I think a more minimal change is possible and avoids additional nesting.
",armon,fraenkel
861,2015-04-14 02:33:32,"@artushin I couldn't quite figure out what you changed but I do now use the lockSession instead.
@armon I went with your approach but had to play some variable declaration games so no new variables were introduced.
",fraenkel,artushin
861,2015-04-14 02:33:32,"@artushin I couldn't quite figure out what you changed but I do now use the lockSession instead.
@armon I went with your approach but had to play some variable declaration games so no new variables were introduced.
",fraenkel,armon
861,2015-04-14 03:10:04,"@artushin I would expect ErrLockHeld to be returned if it's already held. What is the issue? I may just not be understanding. Maybe a diff only gist would help clarify?
",armon,artushin
861,2015-04-14 03:50:32,"@artushin I understand what you are saying now. I would suggest a separate PR which will also need a new test case since you are adding new behavior that I don't believe is currently covered.
",fraenkel,artushin
859,2015-04-13 19:47:41,"@Heuriskein We should not allow ""unknown"" as it is being deprecated. It is already mostly on the way out, but the constants are left for backwards compatibility.
",armon,Heuriskein
859,2015-04-13 21:14:15,"Removed unknown.

On Mon, Apr 13, 2015 at 12:47 PM, Armon Dadgar notifications@github.com
wrote:

> @Heuriskein https://github.com/Heuriskein We should not allow ""unknown""
> as it is being deprecated. It is already mostly on the way out, but the
> constants are left for backwards compatibility.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/859#issuecomment-92475777.
",Heuriskein,Heuriskein
859,2015-05-11 23:43:19,"@Heuriskein Thanks! Sorry about the delay!
",armon,Heuriskein
857,2015-04-11 02:33:44,"@ryanbreen not all of them, actually. We still use an in-memory only LMDB for Consul's state store, so for example, the FAQ entry about virtual memory size should be left intact until we completely remove it in 0.6. Anything specifically about the Raft log + LMDB can be updated though.
",ryanuber,ryanbreen
855,2015-04-10 17:01:45,"@fraenkel Good call, that should be an easy enough check! Tagging as bug
",armon,fraenkel
854,2015-06-04 18:59:33,"@armon Just FYI, we (Docker) just changed the registry dns name to a CNAME which means this bug (or netgo but, see my linked issue) is breaking everyone using docker and consul with recursor right now.
",discordianfish,armon
854,2016-08-05 16:53:16,"@slackpad Hi.  Is there a resolution for this one in the works?
",tmichaud314,slackpad
854,2016-08-17 22:38:38,"@slackpad Are these fixes in the master branch?
",tkambler,slackpad
852,2015-04-10 05:15:52,"This is definitely something we plan on pinning down in a v2 API. We are planning this internally, but it's not on our roadmap at this point for near-term work. @fraenkel is right on the money on this one.

I'm going to close this because we can't change the v1 API response format at this point. Thanks for the report, and watch for a v2 API in the future.
",ryanuber,fraenkel
852,2015-04-10 18:09:40,"@fraenkel You're correct, the response isn't technically malformed. I should have said that the response content-type was incorrect and that it should have been `application/json` for consistency.

@ryanuber Fair enough. I'll keep an eye out for when the v2 API is released for this bug fix.
",mtougeron,ryanuber
852,2015-04-10 18:09:40,"@fraenkel You're correct, the response isn't technically malformed. I should have said that the response content-type was incorrect and that it should have been `application/json` for consistency.

@ryanuber Fair enough. I'll keep an eye out for when the v2 API is released for this bug fix.
",mtougeron,fraenkel
851,2015-04-17 18:15:16,"I think it may make sense to support a `?persist` flag to flag the persistence off on a per-service registration. Thoughts @jefferai @ryanuber?
",armon,jefferai
851,2015-04-17 18:15:16,"I think it may make sense to support a `?persist` flag to flag the persistence off on a per-service registration. Thoughts @jefferai @ryanuber?
",armon,ryanuber
851,2015-04-17 20:34:11,"Tagged as an enhancement, thanks @jefferai!
",ryanuber,jefferai
849,2015-04-08 22:13:32,"Thanks for the quick answer @ryanuber! That's all I wanted to know ;-)
",abronan,ryanuber
843,2015-04-27 20:28:14,"@ryanbreen @dpurrington this is definitely in the crosshair for 0.5.1 (the next release of Consul), which should be on its way out in the coming weeks. The release won't go out the door without this.
",ryanuber,ryanbreen
841,2015-04-06 17:36:45,"@armon This happened for quite some time (several minutes at least) after all nodes were up and running, so it wasn't just, as expected, during the initial bootstrapping. Once I started the cluster one-by-one, things worked as expected.
",discordianfish,armon
840,2016-09-21 18:09:38,"@slackpad May I ask how txn solves this? You can only do PUTs in a txn, so how do I combine a PUT (to unlock) and DELETE?
",fraenkel,slackpad
840,2016-09-21 18:17:06,"@fraenkel with the /v1/txn endpoint you PUT a JSON structure with a list of operations to perform - you would PUT a structure like this:



These are done atomically, so if the unlock succeeds it will delete the key as part of the same request.
",slackpad,fraenkel
840,2016-09-21 18:18:13,"@slackpad The docs say PUT is only supported which is why I asked. Ah, so that meant you PUT /v1/txn but any verb is supported.
",fraenkel,slackpad
838,2015-04-02 16:39:30,"@discordianfish this is a symptom of #457. There is a bit more to it since the node IP addresses are persisted on other members of the cluster as well, but we are very aware of this. Let's track this in #457. Thanks for reporting!
",ryanuber,discordianfish
836,2015-04-10 16:13:02,"@armon thanks that worked
",sge-babrams,armon
835,2015-04-02 16:42:20,"Thanks @ryanuber!
",grantr,ryanuber
834,2015-06-02 22:27:14,"Hey @apoydence,

Since this change is actually in the KV code, I'm not sure it would fix the 301 on the HTTP endpoint side.
I'm also not sure about the utility, since a client can follow the redirects and still succeed in doing the PUT. Let me know if I'm missing something here.
",ryanuber,apoydence
834,2015-06-05 02:17:39,"@ryanuber If the key name ends with a '/' then it messes up the URL that's built.
",apoydence,ryanuber
834,2015-06-05 22:23:55,"@apoydence ah this is a client modification. I read it as a server change for some reason. Thanks!
",ryanuber,apoydence
831,2015-04-28 21:44:32,"@ryanbreen I don't think you are missing anything. If the port is configured, the HTTPS server should start, and the HTTPS address field is just there to allow changing what it binds to.
",ryanuber,ryanbreen
831,2015-05-05 21:45:30,"Closing, this seems to be done. Thanks @ryanbreen 
",armon,ryanbreen
829,2015-03-30 22:18:32,"Hey @apoydence, currently you can do this in two ways:
1. Use `consul watch` and invoke a script based on its output
2. [Configure a watch in consul](https://consul.io/docs/agent/watches.html) with a script handler to invoke the API.

There is no in-built way to automatically query the internal API, but using watch handlers you should be able to do just about whatever you want to in a few lines of code.
",ryanuber,apoydence
829,2015-03-30 22:21:43,"Hey @ryanuber, I might have missed it, but I didn't see anywhere in the linked document to do this any other way besides the first way (script based).
",apoydence,ryanuber
829,2015-03-30 22:25:32,"@apoydence you are correct that you would still need a script. You can use the command-line `consul watch` to create a watch as an external process, or you can configure Consul with internal watches, which fire the handler script that you configure. This helps reduce the number of moving parts.
",ryanuber,apoydence
829,2015-03-31 14:52:31,"@ryanuber Are there any plans to expand the functionality of watches? Meaning, in the future will we be able to do it programmatically?
",apoydence,ryanuber
829,2015-04-01 00:38:12,"@apoydence I'm not sure what you mean. Watches are just a convenient abstraction around doing blocking queries programatically. Those are the underlying API that enables watchers. See the ""Blocking Queries"": https://consul.io/docs/agent/http.html
",armon,apoydence
829,2015-04-01 01:32:28,"@armon Ah, I didn't notice that the service endpoint had noted to have blocking queries.  I will look into those. Thanks!
",apoydence,armon
829,2017-01-30 23:08:02,@apoydence I've a question around the usage of watches. I'm new to Consul and started looking at the documentation to use it for our use cases. I see the maximum time a blocking query can wait is 10 mins. Is there a reason for this upper cap? We were planning to use watches for job completion notifications where the job could take more than 10 mins. Are blocking queries the right ones to use or Consul offers any other functionality? ,cthumuluru,apoydence
828,2015-04-06 21:23:46,"@apoydence The sample format you used is for config files, but it looks like you guys figured out the correct API format. Closing!
",armon,apoydence
827,2015-03-30 22:20:49,"Mmm, good point @highlyunavailable.  If the tests pass, I'll compact the code and update the PR.
",mfischer-zd,highlyunavailable
827,2015-04-01 01:24:59,"Thanks, @mfischer-zd. We do already have some handling for SIGTERM [here](https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L694-L758). The behavior of SIGTERM is configurable. If what you're after is a graceful leave, you can set the `leave_on_terminate` config option, which should cause Consul to invoke the same code path as SIGINT.
",ryanuber,mfischer-zd
827,2015-04-01 15:53:56,"@ryanuber, this patch corrects behavior of `consul lock` and other tools - it's not related to the behavior of Consul in agent mode.  See #797 for further discussion.
",mfischer-zd,ryanuber
827,2015-04-01 16:58:52,"@mfischer-zd ah that makes sense then, merging this in. The test failures are definitely unrelated to this change. I'll address those separately.
",ryanuber,mfischer-zd
822,2015-03-27 22:07:17,"@ryanuber I can definitely provide those. Someone in IRC suggested I use this flag:

`consul members --rpc-addr=10.0.1.5:8400`

and that worked on the servers that were experiencing the error. Is there something I can add to the config so it Just Works without the flag?

10.0.1.5:

logs:



config:


",MrMMorris,ryanuber
820,2015-11-25 02:33:04,"This should now be a non-issue, as we've completely replaced the LMDB-backed state store with an in-memory index so we never need to touch the disk. @fraenkel I know this ticket is old but are you still seeing this? Trying with the newest Consul RC might give you significantly better results.
",ryanuber,fraenkel
820,2015-11-25 02:35:47,"@ryanuber Nope. I will close it.
",fraenkel,ryanuber
819,2015-03-26 22:20:32,"@fraenkel this sounds like it could be a startup race. The error message `Missing node registration` indicates that the node is not yet registered in the catalog. Are you attempting to create a session immediately after starting Consul, in a script or similar? If so, you might need to allow Consul some time to initialize and sync the node registration to the catalog.
",ryanuber,fraenkel
818,2015-05-14 19:34:03,"@ryanuber thank you for looking.  Deleting the data is in fact what I did do to get back to square one.  I eventually found that the state was being caused by chef runs.  Every time the nodes converged, the consul recipe scheduled a restart.  Over time, all 3 servers convergence would eventually line up and cause a down state.  If did the manual recovery steps, it would come back.

Far as the health checks.  It was also a chef recipe bug that would hork up the service check, sometimes.  

I've fixed our recipes now so they only install consul and don't modify and the bugs as well.  Since I've done that, the cluster has been happy.
",alpduhuez,ryanuber
817,2015-03-26 17:00:24,"@armon Yup, Prometheus is about ""pull"" as well, so it's a bit the odd one out in `go-metrics`. But if you want to keep it to a JSON format, then you'll need custom code, yeah. The question would then be whether it'd also be possible to expose it as Prometheus metrics on some other endpoint (or via content-type negotiation on the same endpoint).
",juliusv,armon
817,2016-04-26 01:26:24,"@armon Did you think about this any more? It came up here again and I would like to solve that somehow. You said that in the rpc layer you access the metrics already but it seems like the metrics there are difference and the only way (I know of) to get metrics state out of go-metrics is via the prometheus sink or a new sink. So I'm happy to implemented that, but it's a bit unclear to me how it's suppose to work.
Right now the simplest option seems to use the Prometheus sink. If that works for you, I can submit a new PR for that. It still has the problem with only support for flat metrics but everything else would lead to redundant metric code or require heavy refactoring of go-metrics.
",discordianfish,armon
817,2016-04-27 00:39:11,"@armon Here is a new branch: https://github.com/hashicorp/consul/compare/master...discordianfish:fish/add-prometheus-sink
I've decided against using the existing api listener because people usually bind that to 127.0.0.1 where the metric listener needs to be reachable from other hosts.
This also depends on https://github.com/armon/go-metrics/pull/30 or consul might crash if service tags are used.

Even though it already helps me a lot to debug our ongoing consul issues and I'm not very happy with the resulting metrics for two reasons:

a) They are not named very well. Even if you don't want to adopt the prometheus format, maybe you are up to adhere to some prometheus best pratices that are IMO universal: https://prometheus.io/docs/practices/naming/

b) They are flat. I'll submit another PR to go-metrics to make the resulting metrics a bit 'better', but ultimately if the interface of go-metrics only supports flat metrics we won't be able to solve this properly. What are you thoughts about that? Have you considered refactoring the metrics to support multidimensional ones? The Datadog support also looks a bit hackish in that regard: https://github.com/armon/go-metrics/blob/master/datadog/dogstatsd.go#L60 
",discordianfish,armon
816,2015-05-04 22:40:23,"@pepov Sorry about the epic delay! Not sure how this slipped through. This looks great, merging!
",armon,pepov
815,2015-03-25 18:05:23,"This is an interesting idea. I think if we were to support setting custom DNS records, we would want to have a first-class API for doing CRUD operations on them. I agree with @armon, there are going to be numerous edge cases we should think about.
",ryanuber,armon
811,2015-03-24 23:52:36,"@discordianfish definitely not - the DNS interface should only return healthy results. Please do let us know if you see otherwise.
",ryanuber,discordianfish
810,2015-03-25 17:45:23,"thx @armon, you can close ticket.

out of topic:
You have mentioned that

> The problem is that many (most) Consul deployments actually do depend on the A records.

Might be, that we are doing something wrong here, thats why ask for more details :), so sorry for being so picky. Can you just tell me how **only** A record is being used for Consul deployments? I thought that **only** SRV is needed since it contains a important couple of real IP and PORT?
",sielaq,armon
807,2015-05-29 17:52:05,"@frankfarmer In this case they were both co-occurring.  As @armon mentioned this was likely caused by the lack of connection reuse, which may have in turn triggered excessive file descriptors being used.  We addressed the cause (fixed our dns lookups) so we haven't had the urge to replicate it again. 
",primal-github,armon
805,2015-03-20 15:06:34,"@ryanbreen Like this?
",discordianfish,ryanbreen
803,2015-03-24 21:23:16,"@ryanuber Any feedback about the previous comment?
",Amit-PivotalLabs,ryanuber
803,2015-03-25 17:33:43,"@ryanuber @Amit-PivotalLabs Primarily the check was done in a few places for defense in depth. I think it's probably fine to leave just a single check for min/max values in the session create path on the server. The state store checks can probably be reduces to a very basic sanity check instead of bounds check.
",armon,ryanuber
802,2015-03-19 23:02:28,"@sethvargo this seems reasonable to me - perhaps an additional field in the health responses with an aggregate status would do the trick so existing clients continue to work normally. Nice example :+1:
",ryanuber,sethvargo
802,2016-09-15 14:30:08,"Could we dump this in a milestone for scheduling @slackpad. Seems high-value with little effort ðŸ˜„ 
",sethvargo,slackpad
798,2015-08-20 19:04:38,"@armon Is there some doc or an example showing how to specify a per-service `acl_token`? Do I just add an `acl_token` parameter to a [service definition](https://consul.io/docs/agent/services.html) when defining it in configuration?
",tillig,armon
795,2015-03-23 14:08:41,"@armon Sorry for the delayed response. Yes, multiple server nodes are available in the case I described - I created a cluster of three server nodes, each one a separate Docker container; consul1 is the leader in the scenario, the other two start as followers but one is promoted to leader when ""docker pause"" is applied to consul1. Other than pausing the leader, it's a normal three-node server cluster, implemented as containers.

If the issue is an arbitrarily long or indefinite TCP timeout, wouldn't this problem also occur if a network partition occurred in a real-world environment? Specifically:
1. consul1 loses connection to the cluster
2. consul_client1 tries to register a service before it learns that consul1 is down
3. consul_client1 waits, possibly indefinitely, for consul1 to respond
4. consul_client1 blocks on all HTTP API calls until it's restarted or the network partition is resolved

Let me know if you need any more information about the test case.
",ghicks-rmn,armon
795,2016-01-15 08:59:21,"@slackpad : I am running Consul 0.5.2 currently, but I will test with the latest Consul 0.6.2 today and keep you posted. Thx for the lead !
",xakraz,slackpad
795,2016-01-20 17:53:58,"Hi @slackpad ,

I finally managed to test consul 0.5.2 vs the latest 0.6.3 and you are right, it has been fixed (at least in the latest version).

So I guess I will have to update all my servers know :p

### Consul 0.5.2



### Consul 0.6.3


",xakraz,slackpad
795,2016-02-09 12:37:46,"@slackpad Have you some other feedbacks about the issue ?

From my point of view the update to Consul 0.6.3 solve it.
",xakraz,slackpad
792,2015-03-17 20:08:11,"@mfischer-zd At that point, it means the attacker also has access to the keys of the certificate authority as well. Access to just the client side public/private keys are not enough to forge a new key signed by the CA.
",armon,mfischer-zd
792,2015-03-17 20:17:44,"@mfischer-zd The same certificate authority would be used that exists now. The `ca_file` configuration currently allows you to specify the CA used to validate the certs. https://consul.io/docs/agent/options.html#ca_file

So the only real change is that outgoing requests to servers would validate the hostname against a specific pattern.
",armon,mfischer-zd
792,2015-03-18 20:47:08,"+1 on the severity of this, and the reluctance in adopting consul for a security-conscious environment.

@armon, A question to clarify on the CA/TLS proposal, would it be possible to validate the server/client certs independently, or is this an illusion of security?

I also like the idea of having separate shared secrets for server-to-server vs agent/server communication (servers would have both keys, agents would not have the key used for server to server configuration). Does this make sense to consider?
",ketzacoatl,armon
792,2015-03-18 21:19:31,"+1 and thanks @armon for raising the issue and all the discussion.
",fazy,armon
792,2015-03-18 21:22:22,"@ketzacoatl I'm not sure quite what you mean by the server vs client cert validation. Both must be signed by a trusted CA (or multiple different CAs). The difference is that server certificates would contain additional data to distinguish them.

I'm not sure where this additional shared secret would come into play? Do you mean in the gossip protocol layer?
",armon,ketzacoatl
792,2015-03-18 21:43:53,"@armon. On my certs question, I think you answered it with _(or multiple different CAs)_.

On the shared secret, the thought is for there to be separate secrets used for servers who pass around updates to the directory, and agents which just read the directory.
",ketzacoatl,armon
792,2015-03-18 22:51:36,"@ketzacoatl I'm not sure the shared secret adds any more security here, but just additional complexity for the user.
",armon,ketzacoatl
792,2015-03-19 00:42:09,"@armon, If it is optional (servers could have same secret as agents, or a unique secret), the user is not inhibited. If an agent is compromised, they need to get the server secret (along with generate a cert with the right CA) before they can impersonate a consul server. What do you see that is not reasonable? 
",ketzacoatl,armon
791,2015-04-12 18:31:36,"Tokens should no longer appear in the monitor or logs after ee56598.

@tummychow I'm not sure if it makes sense to do that in the API package. The client made the request, so it must already know about the token. We do plan on enhancing and unifying the response formats in a v2 api in the future, but we haven't started on that project yet.
",ryanuber,tummychow
780,2015-09-23 09:48:21,"@armon are there plans to implement this in the foreseeable future, or would you accept a pull request for this? In the latter case: can you give me an indication of how hard it is to implement this in Consul?

@iconara did you find a workaround for the missing `-try`/`-timeout` flags in your setup? If so, can you share that?
",marceldegraaf,armon
780,2015-09-23 09:48:21,"@armon are there plans to implement this in the foreseeable future, or would you accept a pull request for this? In the latter case: can you give me an indication of how hard it is to implement this in Consul?

@iconara did you find a workaround for the missing `-try`/`-timeout` flags in your setup? If so, can you share that?
",marceldegraaf,iconara
780,2015-09-28 08:47:14,"Thanks @slackpad. If you're open to a PR for this, and can point me to how that would work in the Consul code base, I'd be glad to submit one.
",marceldegraaf,slackpad
780,2015-12-09 11:03:12,"@armon @slackpad any updates on getting this functionality into Consul?
",marceldegraaf,armon
780,2015-12-09 11:03:12,"@armon @slackpad any updates on getting this functionality into Consul?
",marceldegraaf,slackpad
779,2015-03-13 17:19:52,"Hey @darron, thanks for the report. This is sounding like it might be a keep-alive issue. Is the server you are talking to configured with a keep-alive timeout of < 30s? The default Go HTTP client uses a 30s keep-alive. We probably need to adjust this on the Consul side, but I just want to nail the issue down further before going down that road. Also, if you could provide the check configuration in its original JSON form, and the curl command you used, that would be helpful.

Tagging as a bug, Thanks!
",ryanuber,darron
779,2015-03-13 17:51:43,"@ryanuber We should just disable keep-alive, it seems sane for doing localhost checks to just re-dial.
",armon,ryanuber
779,2015-03-13 17:53:08,"@armon +1
",ryanbreen,armon
779,2015-03-13 19:04:21,"It's a really standard nginx container - I'm just away from my laptop and
will get full config when I get back.
On Fri, Mar 13, 2015 at 11:53 AM Ryan Breen notifications@github.com
wrote:

> @armon https://github.com/armon +1
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/779#issuecomment-79187084.
",darron,armon
779,2015-03-13 19:56:46,"FYI - @ryanuber - this is the config:

https://github.com/octohost/nginx/blob/master/nginx.conf - 15 second keepalive timeout.

Was setting this JSON:

`{""ID"": ""interactions-49155"",""Name"": ""interactions"",""Port"": 49155,""Tags"": [""http""],""check"": {""http"": ""http://10.132.82.182:49155"",""interval"": ""15s""}}`

With this command - $2 is the JSON that's passed:

`curl -s -X PUT -d ""$2"" ""localhost:8500/v1/agent/service/register?token=anonymous""`

It goes from here: https://github.com/octohost/octohost/blob/master/bin/octo#L421

To here: 

https://github.com/octohost/octohost-cookbook/blob/master/files/default/consulkv#L39-L41

I have all sorts of containers though - so likely what @armon and @ryanbreen +1'd would be the best - it would be a bit of a futile process to make sure everything had a long enough keepalive.

Thanks for taking a look at this!
",darron,armon
779,2015-03-13 19:56:46,"FYI - @ryanuber - this is the config:

https://github.com/octohost/nginx/blob/master/nginx.conf - 15 second keepalive timeout.

Was setting this JSON:

`{""ID"": ""interactions-49155"",""Name"": ""interactions"",""Port"": 49155,""Tags"": [""http""],""check"": {""http"": ""http://10.132.82.182:49155"",""interval"": ""15s""}}`

With this command - $2 is the JSON that's passed:

`curl -s -X PUT -d ""$2"" ""localhost:8500/v1/agent/service/register?token=anonymous""`

It goes from here: https://github.com/octohost/octohost/blob/master/bin/octo#L421

To here: 

https://github.com/octohost/octohost-cookbook/blob/master/files/default/consulkv#L39-L41

I have all sorts of containers though - so likely what @armon and @ryanbreen +1'd would be the best - it would be a bit of a futile process to make sure everything had a long enough keepalive.

Thanks for taking a look at this!
",darron,ryanbreen
779,2015-03-13 19:56:46,"FYI - @ryanuber - this is the config:

https://github.com/octohost/nginx/blob/master/nginx.conf - 15 second keepalive timeout.

Was setting this JSON:

`{""ID"": ""interactions-49155"",""Name"": ""interactions"",""Port"": 49155,""Tags"": [""http""],""check"": {""http"": ""http://10.132.82.182:49155"",""interval"": ""15s""}}`

With this command - $2 is the JSON that's passed:

`curl -s -X PUT -d ""$2"" ""localhost:8500/v1/agent/service/register?token=anonymous""`

It goes from here: https://github.com/octohost/octohost/blob/master/bin/octo#L421

To here: 

https://github.com/octohost/octohost-cookbook/blob/master/files/default/consulkv#L39-L41

I have all sorts of containers though - so likely what @armon and @ryanbreen +1'd would be the best - it would be a bit of a futile process to make sure everything had a long enough keepalive.

Thanks for taking a look at this!
",darron,ryanuber
779,2015-03-15 20:36:06,"Hey @darron - I just pushed 952ec28, which should disable HTTP keep-alive's. If you have a minute, give master a test and see if the issue persists. I'll leave this open for now until we confirm the fix. Thanks!
",ryanuber,darron
769,2016-03-03 02:09:49,"Ah gotcha, thanks for the clarification @ryanuber.

Do you know what the reasoning is for making it fatal for config files?
",tonglil,ryanuber
768,2015-03-07 14:41:49,"@armon So if you have 3-5 active servers and 100 clients, if one of the active servers kicks the bucket, a client won't step up to take the place of an active server?
",iamthemuffinman,armon
768,2015-03-07 14:43:40,"That is correct.  Consul agents are either servers or clients.  There's not
currently a facility for a client to become a server automatically.

On Sat, Mar 7, 2015 at 9:41 AM, Robert Deusser notifications@github.com
wrote:

> @armon https://github.com/armon So if you have 3-5 active servers and
> 100 clients, if one of the active servers kicks the bucket, a client won't
> step up to take the place of an active server?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/768#issuecomment-77691807.
",ryanbreen,armon
768,2015-03-07 15:03:51,"@ryanbreen Is there a branch to add this feature?
",iamthemuffinman,ryanbreen
768,2015-03-07 15:13:45,"I don't believe so.  It may be something the team is considering, but to my
knowledge it's not an immediate roadmap item.

On Sat, Mar 7, 2015 at 10:03 AM, Robert Deusser notifications@github.com
wrote:

> @ryanbreen https://github.com/ryanbreen Is there a branch to add this
> feature?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/768#issuecomment-77692756.
",ryanbreen,ryanbreen
768,2015-03-09 20:57:59,"I think @ryanbreen perfect answered this. There is no plans to support that feature in the short term, so you must dedicate server nodes in advance. I'm going to close this as I think the question is answered.
",armon,ryanbreen
767,2016-01-17 23:46:51,"@armon love your product, but your getting started for consul sucks.
",RongxinZhang,armon
766,2016-01-12 14:23:35,"@ryanuber how do prepared query improve this? Can you elaborate please?
",raphink,ryanuber
766,2016-01-12 14:24:34,"@armon so you're saying instead of namespace, make it so that consumers can only see some nodes? What if I want to configure an haproxy for multiple services that share the same name with a different namespace?
",raphink,armon
766,2016-01-18 07:51:13,"@armon I get the idea, but it doesn't allow to have multiple services with the same name on a given proxy.
",raphink,armon
758,2015-03-05 22:57:36,"@highlyunavailable Please go for it: your NSSM setup is cooler than our WinSW config. :smile:
",ryanbreen,highlyunavailable
758,2015-09-23 20:59:49,"@armon Just want to let you know that we are working to build a MSI package with NSSM and consul.exe running as an automatic build at AppVeyor. I'm sure I can get this open sourced very soon.
",StefanScherer,armon
758,2015-11-05 17:02:21,"Not quite as nice as @highlyunavailable but we've got a similar Deploy.ps1 script for our Octopus Deploy rollout:



We use a separate deployment step to set the environment var `GOMAXPROCS` as until I saw this issue, I was unaware we can set it on NSSM on a per service level...
",megakid,highlyunavailable
758,2016-01-14 19:37:07,"@carlpett @StefanScherer I would be interested in seeing both these packages. I'm in the process of configuring consul agent on a Windows server. 
",vLifeOfBrian,carlpett
758,2016-01-20 20:12:11,"@vLifeOfBrian @carlpett I was allowed to open source parts of our MSI build process. I've put it into an extra repo that can build the MSI package and deploy it as GitHub release as an example. All done at AppVeyor CI. Have a look at https://github.com/StefanScherer/consul-agent, an AppVeyor build badge is also there to see what happens in CI.
",StefanScherer,carlpett
758,2016-01-22 16:48:55,"@carlpett Thanks for sharing! Looks pretty good.

Our setup with the `package.json` where we read many values from it comes from building MSI packages for Node.js microservices. We stripped that down to put Consul in a very similar MSI.

I also have removed the code signing steps we have to sign both the `consul.exe` as well as the final MSI file. This might be interesting for an official MSI build to suppress the ""unknown publisher"" Windows warnings.

A missing step are some tests with the MSI. I plan to add some at work and share them as well in the public repo soon.
",StefanScherer,carlpett
758,2016-02-10 16:29:39,"@carlpett - this is a great setup!
Thank you for sharing!

In my team we need a custom consul.json with a specific local bind_addr in place of the loopback advertise_addr.
Do you think it is better to fork off your repo or to use it as a submodule in our repo?

Thanks,
Vassil
",vassilvk,carlpett
758,2016-02-11 13:59:26,"Thanks, @carlpett.
And @StefanScherer, thank you for open sourcing your WiX setup - this is really solid stuff!
",vassilvk,carlpett
751,2015-03-04 00:12:37,"@ryanuber Some minor comments but looks great!
",armon,ryanuber
751,2015-03-04 00:18:43,"@ryanbreen I see what you mean, yeah we do switch between ""the value is opaque to Consul and it does't care"" and ""the value is opaque to the client, and don't attach semantics to it"". I guess that is unclear which direction the opaqueness exists. I'm not sure if there is anything we can do except clarify more.
",armon,ryanbreen
750,2015-03-04 00:21:20,"@pepov It has to do with the semantics of leave. With a leave you are basically telling Consul ""please announce to the cluster your intention to leave, and do not re-join this cluster again unless explicitly told to."". As part of that, the node leaves the raft replication group and broadcasts a gossip message with its intent to leave. When we leave the raft group, the peers are purposely set to `null` to avoid bothering the existing cluster on restart. Does that make sense?
",armon,pepov
750,2015-03-04 05:11:13,"@armon I understand you, but confused because I thought I'm explicit by setting the start_join in the config. Why the gossip layer is allowed to join together and only the raft peerset is handled differently in this case? Is there a config flag I should use to avoid this, or simply avoid leaving for server nodes? 
",pepov,armon
750,2015-03-05 01:49:27,"@pepov The gossip layer is simpler since joins are idempotent and there is no issues of data safety. The raft layer is much more sensitive, and hence a little more challenging to work with. Typically, you avoid this by never having servers leave. It's rather strange operationally to have servers come and go.
",armon,pepov
750,2015-06-17 21:52:08,"@awheeler If you shutdown the servers gracefully they will leave the cluster and not re-join when you restart. You'll need to `join` each new server as it comes up with the new version of Consul (or follow the process discussed in #993 by fixing up the `peers.json` file if you accidentally have all 3 nodes leave simultaneously).
",slackpad,awheeler
750,2015-07-23 00:45:31,"@armon I see.  I think my/others confusion comes in because of incomplete documentation.

I didn't realize ctrl-c took a node out of the cluster in a deep sense.  But the design makes sense to me.

My confusion came in when I see things like ""Graceful shutdown""----> which I took to imply a possibility for a ""Graceful startup"" and rejoining of the cluster even if all nodes were brought down.

So for upgrades and resets we should be sending a different signal to the Consul process?

I think this signal, or all of the signals Consul expects and the outcomes of those signals should be very well documented somewhere.

Maybe a table listing the signals and Consul states post-signal?
",theonewolf,armon
750,2015-09-11 02:03:33,"Yes, and it's covered in #993 -- you manually populate the peers.json file.  See @slackpad 's example there.
I've used it several times since I read that and it makes the whole situation a non-event.
",awheeler,slackpad
750,2016-03-10 13:02:52,"Hi @slackpad , i think i figured this out, by adding some parameters that say ""do not gracefully leave in any case, hard/soft kill"" , don't remember exactly, but problematic configuration BEFORE i found that solution was: 

{

  ""acl_datacenter"": ""dc-main"",
  ""acl_default_policy"": ""deny"",
  ""advertise_addr"": ""22.22.22.22"",
  ""advertise_addr_wan"": ""11.11.11.11"",
  ""bootstrap_expect"": 3,
  ""ca_file"": ""/zzzzz"",
  ""cert_file"": ""/zzzzzz"",
  ""data_dir"": ""/var/consul"",
  ""datacenter"": ""dc-new"",
  ""disable_remote_exec"": true,
  ""domain"": ""my.domain.consul"",
  ""enable_syslog"": true,
  ""encrypt"": ""zzzzzzzzzz"",
  ""key_file"": ""/zzzzzz"",
  ""log_level"": ""INFO"",
  ""server"": true,
  ""start_join"": [
    ""x.compute.amazonaws.com"",
    ""y.compute.amazonaws.com"",
    ""z.compute.amazonaws.com""
  ],
  ""start_join_wan"": [
    ""zzz.compute.amazonaws.com"",
    ""yyz.compute.amazonaws.com""
  ],
  ""syslog_facility"": ""LOCAL5"",
  ""ui"": false,
  ""verify_incoming"": true,
  ""verify_outgoing"": true
}
",Dmitry1987,slackpad
749,2015-03-04 00:24:06,"@ryanbreen Looks great!
",armon,ryanbreen
747,2015-03-03 02:48:10,"@ryanbreen Thanks!
",armon,ryanbreen
747,2015-03-04 00:24:11,"@ryanbreen Thanks!
",armon,ryanbreen
743,2015-03-02 03:06:23,"@highlyunavailable If you want to whip up a PR, I'll be happy to review it.  Otherwise, I can take a crack at adding coverage of negative caching to dns-cache.html tomorrow.
",ryanbreen,highlyunavailable
743,2015-03-02 07:33:42,"Wow, it helps if I actually make the pull request to the root repo. Anyway, @ryanbreen I've made some docs on it.
",highlyunavailable,ryanbreen
742,2015-03-23 21:09:10,"@armon +1 on sharing some details on the known issue. We can start throwing ideas once we have a basic understanding of what's going on :)
",rotatingJazz,armon
742,2015-05-12 04:47:05,"Hi @armon, thanks for the reply. I don't think I 'm restarting containers rapidly. Also I had tried  ""conntrack -F"" for clearing the ARP cache. 

Can you provide me some pointers on where to dig the issue? 

I 've stopped the consul container on the Host where my application + consul agent was running and after that it seems the discovery is stable. 

Was it because of some NAT issue? that two containers (consul, consul agent) can't run on the same host ? My consul had all the port exposed and mapped while my consul agent only had the application port exposed and mapped. 

Kind of in middle of some confusion with the utility of consul server and consul agent. 
",ashish235,armon
742,2015-05-29 20:24:46,"@armon Sounds like a good idea! :+1: Do you think this can hit in 0.6? This issue is a roadblock for using it in production (at least, for me, I'd love to hear how others deal with it).
",rotatingJazz,armon
742,2015-05-29 20:42:38,"Talked to @armon a bit today and we are going to try adding a TCP fallback for pinging peers, with a warning in the log if this actually confirms the existence of the peer. This should help the misconfigured client discover the correct state of the world and not introduce bad information into the cluster via the anti-entropy mechanism (which also uses TCP), while still being obvious to operators that there's a networking problem.
",slackpad,armon
740,2015-03-04 00:29:45,"@blalor So I am a bit confused, I think this is already possible right?
",armon,blalor
740,2015-03-31 06:11:06,"I was looking into this and the issue is the way ServiceDefinition is defined. 





ServiceDefinition takes a slice of CheckTypes rather than full blown HealthDefinitions so you don't get fields like ID and Name. You could add ID and/or Name to CheckType and I think that would solve this but then you might as well just have a slice of HealthDefinitions inside of ServiceDefinition. The way I am currently avoiding this problem is just defining a Service in one file and then in a separate file defining a list of checks that are all associated with that one service which makes config management easy. It's not as elegant as what @blalor suggested but it works. 
",cruatta,blalor
740,2015-07-13 18:59:48,"@aconrad the endpoint `/v1/health/checks/<service>` does currently exist. Does it not function how you would expect?

I looked at this a while back and found exactly the same as @cruatta did - the changes actually go pretty deep to support passing in the CheckID, which is unfortunate. I would probably just use a file with separate definitions like some have hinted at above, all in a single file for each service, like this:



This is going to be a somewhat low-priority enhancement since we have a reasonable work-around, but we definitely want to get it fixed for the embedded definitions.
",ryanuber,cruatta
740,2015-07-13 20:28:19,"@ryanuber the endpoint works (and I'm using it) but I have no way to know which check item in the list of checks is the one I care about since I can't identify them by name -- so as I explained, I try to detect the check I care about by parsing its output.
",aconrad,ryanuber
740,2015-07-14 18:38:59,"@ryanuber ah got it. The person that manages our cluster applied the work-around, works great. Thanks!
",aconrad,ryanuber
737,2015-02-26 00:48:12,"@armon Thanks for the comments.

As for motivation... I've had to solve this once before, but I'm working on a new project that has a fixed size cluster that I'm addressing into hash-ring style.  The simplest example is probably a cluster of cache machines where each key lives on node `hash(key) % numNodes`.  With caches in particular, allowing numNodes to change is really dangerous because it allows for keys to migrate from one node to another.  You can easily end up with a single key being present on multiple nodes with _different_ values when nodes fail, etc.  So, it's more reasonable to just fix numNodes and have empty standbys ready to jump in when nodes fail, etc., but the important part is that a given key always maps to the same virtual node.

Protip: Probably use Redis Cluster if you're facing this issue for caching, they handled key migration during cluster resizing :smile: Alas, I'm working on something that has a similar problem but isn't a cache.

Anyway, back to the Semaphore.  `map[string]int` would certainly work, I can make a pass at implementing it that way if you'd like.  We could also take it a step further and maintain a list of available slots along side the holders map, which would let us avoid the empty slot search.  It's a little more bookkeeping, but since everything is synchronized it shouldn't be hard to get it right.

I'll think a bit more about compatibility.  It would be a shame to have to introduce `SlottedSemaphore` and deprecate `Semaphore`.
",justinrosenthal,armon
732,2015-03-26 12:15:06,"@armon it seems like this PR fixes a build problem [1] which I encounter while packaging 0.5.0 for Gentoo Linux.

Do you think it possible to release a 0.5.1 version with at least this fix in a near future ? I'll remain stuck on 0.4.1 otherwise for now.

Thank you.

[1] https://travis-ci.org/hashicorp/consul/builds/51879912
",ultrabug,armon
732,2015-03-26 16:55:04,"@ultrabug If you build everything against master it should compile! You will have an issue if you are using the Consul 0.5.0 code base with the master of Serf.
",armon,ultrabug
732,2015-03-26 17:24:00,"@armon yes I know mate, that's exactly what I was saying. But this thus defeats the packaging of 0.5.0 hence my request for a new tag please.
",ultrabug,armon
732,2015-03-26 17:53:37,"@ultrabug Ah. We are hoping to cut that release in a few weeks.
",armon,ultrabug
732,2015-03-27 08:40:28,"@armon fair enough, good thing I was late in packaging it ;) thanks mate
",ultrabug,armon
731,2015-02-23 19:02:41,"@lyrixx I understand. We are actively migrating away from LMDB because of issues like these. The next major release will not use LMDB for data storage.
",armon,lyrixx
731,2015-02-24 09:25:30,"@armon I'm happy to hear that ;) What are you going to use?
",lyrixx,armon
731,2015-02-24 15:01:04,"@ryanbreen Thanks ;)
",lyrixx,ryanbreen
731,2015-03-04 11:15:21,"@armon I guess I was looking for the more general - how many LMDB-specific issues have you encountered. But now I see you were on 0.9.11 for a long time. Your issue #509 sounds like our ITS#7815 that was fixed in 0.9.12. Still, we would have investigated if you had let us know you were having problems.
",hyc,armon
729,2015-02-24 06:46:13,"That solved the problem, thanks @armon. 
",rosmo,armon
728,2015-02-23 16:19:03,"Hello @sethvargo 

Thanks so much, I got it working now.
I tried random/live or random/prod before but didnt know the syntax was `atlas_userid`/`cluster_name`

Thanks so much and really cool stuff
",oba11,sethvargo
725,2015-03-16 20:08:05,"@armon I just want to mention a use case that may not be entirely clear here: We at ungleich are running an infrastructure for customers that consists solely of machines with public ip addresses and safe firewall settings - they are all managed by configuration management (cdist in our case).

At the moment we have to include the individual public ip address in the configuration, which kind of reverses the purpose of consul (which is able to discover things, but before discovering, we need to manually discover the node's ip address).

In short: we do have a use case in which we want consul to bind and announce on any address. I would expect consul to do so by issuing -bind=0.0.0.0, however that results in the infamous error message also seen in #789.

If your point of view is that this is insecure by default, then I suggest to add a flag to consul like -allow-insecure-bind or -allow-non-private-bind, but still allow to bind _without_ specifying the public ip address.
",telmich,armon
725,2015-03-19 04:43:25,"@armon I understand the problem in regard to consul now - I wasn't aware that the IP is not taken from the IP packet itself, but is contained as data.

I will try to find a way around it by writing cdist types that query for the address of ethX.

I wonder, would it be a smaller change to consul to support something like -bind-interface to select the ip to be used? Almost all of our machines are running on opennebula and thus the interface is eth0 in most cases, so being able to use -bind-interface eth0 would at least make the situation easier for the moment.

I would however appreciate support for ""no configuration required"" in case of having only official ip addresses mid term - either way (multiple ip support, using the source ip in the ip packet, ...)
",telmich,armon
725,2015-08-07 19:29:20,"@armon I do agree with @staticglobal in the sense that consul should not make any difference regarding rfc1918 ips and any other IP. If there is only one IP, it should use it. If there are multiple IPs, it cannot know what to advertise and should fail with ""Multiple IPs detected - please specify the IP to announce"". Even better solution would be to select a preferred interface and if that also has multiple IPs, consul can fail again.

However, distinguishing rfc1918 and public IPs makes the life harder for everyone - I never understood your design decision in this regard.
",telmich,armon
725,2016-12-02 17:55:37,"@sean- that looks awesome - will give it a try next week!
",telmich,sean-
724,2015-02-23 18:32:25,"@ryanuber Can you make sure the docs get updated for this?
",armon,ryanuber
724,2015-02-23 18:45:35,"@armon done in 84f04ff and 2c3995b
",ryanuber,armon
724,2015-02-23 18:46:07,"@ryanuber :+1: 
",armon,ryanuber
721,2015-02-20 19:41:23,"@blalor shared some debug logs with me, which included this raft log:



Looking at the raft code, it's obvious why this log causes this problem. Need to look into how we get into this state to begin with. Perhaps a graceful leave on a single-node cluster is how we get here(?).
",ryanuber,blalor
721,2015-02-23 17:24:55,"@blalor I haven't been able to get a repro case on this. I tried starting up a 0.4.1 single-server cluster with 1 client and then upgrading it to 0.5, but things worked normally, so the upgrade by itself doesn't seem to be the problem. Are there any steps you've been able to reproduce this with?
",ryanuber,blalor
721,2015-02-23 18:31:43,"@blalor The simplest fix is to just blow away the data dir. There was a regression in 0.4.1 that changes how single node clusters worked, which is why the 0.4.0 -> 0.4.1 and the 0.4.1 -> 0.5.0 transitions have been problematic.
",armon,blalor
721,2015-02-23 18:50:44,"@blalor What may be possible is to actually start another server (no bootstrap), then edit the peers file to have both of the servers.
",armon,blalor
721,2015-02-23 19:11:09,"@blalor You cannot have a cluster with partial encryption, it's sort of all-or-nothing.
",armon,blalor
720,2015-02-20 21:42:47,"@armon @ryanuber this is something that has come up in almost all of our projects at least once. I think we could build something into middleman-hashicorp in the frontmatter or some type of common annotation that we use.
",sethvargo,armon
720,2015-02-20 21:42:47,"@armon @ryanuber this is something that has come up in almost all of our projects at least once. I think we could build something into middleman-hashicorp in the frontmatter or some type of common annotation that we use.
",sethvargo,ryanuber
720,2015-02-20 22:50:12,"Yea, I think @sethvargo has a good point in that we can just build this into middleman-hashicorp. 

Design wise, a subtle `> v0.5` underneath the doc title or w/e would be a good approach and not clutter things too much IMO.
",pearkes,sethvargo
720,2015-02-20 22:51:03,"But yea, I also agree with @ryanuber that if we do it inline full width across the text it could get tiresome/distracting. Need something a little quieter.
",pearkes,ryanuber
719,2015-02-20 03:14:16,"@blalor so this is tricky. The problem you are facing is that any given node will _only_ send messages using the primary encryption key. We don't encrypt replies based on the the key used from the requestor. Since your 2nd node never knew about the new key, it was unable to decrypt the response sent to it from the original node, and therefore could not join. Normally a key rotation should happen when all nodes are available to receive the new key, and not during a deploy. I'll think more about how we can make this nicer.
",ryanuber,blalor
719,2015-03-04 02:29:56,"@blalor makes sense, I'll see if we can do something more intelligent for the initial keyring persistence. For the time being, you could work around it by removing the data directory if the initial start-join fails.
",ryanuber,blalor
718,2015-02-20 02:44:47,"@blalor ah, re-reading the message now it does sound a little ambiguous (**what** is it ignoring?). I'll clarify.
",ryanuber,blalor
718,2015-02-20 02:53:19,"@blalor the message should now read:



Thanks for the report!
",ryanuber,blalor
717,2015-07-07 02:12:53,"@armon any thoughts on this? I'd really love to get our ACL definitions in source control!
",colinrymer,armon
717,2015-07-07 16:14:16,"@colinrymer It's now possible with some of the changes in Consul 0.5.2, but wasn't previously. It's on our roadmap, but no definitive timeline yet. It should be pretty easy to whip up a script using our API currently to scan files in a dir and hit the API.
",armon,colinrymer
714,2015-02-19 22:46:03,"@highlyunavailable this is exactly what i needed, thanks a lot!
",hoffoo,highlyunavailable
711,2015-02-19 00:53:38,"@ryanuber I think we can actually re-write most of the API to use the shared query() / write() methods. It just started to get too far out of scope for this PR.
",armon,ryanuber
711,2015-02-19 00:54:55,"@armon makes sense to me. Have to draw that boundary somewhere.
",ryanuber,armon
709,2015-10-13 17:13:35,"@blalor if you can get that data, that would be a better serial, yes. I didn't see anything that let you access the consul index for consul-template.
",highlyunavailable,blalor
709,2015-10-13 19:11:49,"@highlyunavailable using the UNIX timestamp does generate a legal zonefile that will meet the DNS requirements for a higher serial number, but it's not strictly speaking a `+=1` increment which seems to be the original intent... In any case the unix timestamp has been my goto solution for the same issue as well so I'm not alone.

Would storing the DNS zone into a consul KV pair be one possibility?
",nathanisaac-s,highlyunavailable
709,2015-10-14 07:42:43,"@awheeler this fails if you have dots in the service names..... I ended up using the ID field, like that 

{{range services}}{{range service .Name ""any""}}
{{.ID}} 60 A  {{.Address}}{{end}}{{end}}

but maybe there is a more elegant solution to introduce dots (I have no choice but to do this ) ?
",alexinthesky,awheeler
708,2015-02-20 19:30:48,"Thanks, @zoli! Since we support multiple recursors, it would be nice if the `-recursor` flag was repeatable. You can see an example of how to do this with the `-config-file` argument.
",ryanuber,zoli
707,2015-02-17 20:20:10,"@ryanbreen the call to `UpdateCheck` will only update the in-memory status of the check and its output, not the check definition itself. So this should give the desired functionality.
",ryanuber,ryanbreen
697,2015-03-11 21:16:39,"@armon Can you post that other ticket's ID?  I am interested in following that effort, and seeing if I can contribute to it.
",pccowboy,armon
695,2015-02-13 01:03:06,"@ryanbreen So the code for it is here:
https://github.com/hashicorp/consul/blob/master/command/agent/session_endpoint.go#L105

But @sethvargo recently showed me that Golang time.ParseDuration does not allow a value without a suffix, so this may be a non-issue.
",armon,ryanbreen
693,2015-02-13 06:02:55,"1.I register a service in consul agent:



And, I exam the result use `http://192.168.2.71:8500/v1/health/service/innosql`



2.I create a session like this:



result is:



and use session/info api: `http://192.168.2.71:8500/v1/session/info/fa9599ae-f4e4-8015-6325-cc9e1c83581e` 



3.I reload the consul agent.



4.Use session/info api: `http://192.168.2.71:8500/v1/session/info/fa9599ae-f4e4-8015-6325-cc9e1c83581e`  again.
return _null_

Is that normal? Thank you for your answer!@armon
",ahjdzx,armon
688,2015-02-17 21:56:47,"We just had the same issue. Great that it's fixed! @armon could you please link to the commit or PR that fixes it?
",tgwizard,armon
688,2015-02-18 00:16:04,"@tgwizard Here it is: https://github.com/hashicorp/consul/commit/d92e5d37e3b83dc05c6504861041bd8c294fb844

It was actually a revert of the commit that caused the regression.
",armon,tgwizard
688,2015-04-20 15:51:07,"@armon I'm running on Ubuntu 14.04.1 with consul 0.5.0 and seeing the same error message as at the top of this issue.  what other information would be helpful to you?  for now I just increased the allowed open file count and rebooted the box.
",cglewis,armon
688,2015-04-20 17:34:39,"To make sure I understand this - The standing issue is that Consul floods the logs when file handles are exhausted, not that Consul itself is leaking resources, correct? It sounds like @armon has fixed @dpkirchner's resource leaking problem, but if any program exhausts file handles Consul fills the disk with logs.

@cglewis are you just redirecting consul's log output to a file? If you use a syslog server, most often times there is a coalescer built in (like rsyslog's [message reduction](http://www.rsyslog.com/doc/rsconf1_repeatedmsgreduction.html)).
",ryanuber,armon
688,2015-04-20 17:40:53,"@ryanuber so I only have two things running on that machine, and the former has been running fine for months without file handle issues, but only after adding consul agent to it has it started to have this issue.  I don't care as much about the logs filling up, as that can easily be filtered, I was more concerned that Consul seems to be the culprit for the resource leak, though I can't verify that specifically, as I haven't isolated it yet.
",cglewis,ryanuber
688,2015-11-17 00:53:43,"@ChrisMcKenzie are you still experiencing this? The issue of aggressive logging when file handles are exhausted still exists, and it's a difficult-to-detect situation from inside of the application. The solution for now is to set high limits for ulimit, or using a syslog server to leverage its log throttling abilities, such as rsyslog. The latest release should contain the fixes mentioned above by @armon so this should be less of a problem now.
",ryanuber,armon
680,2015-02-08 19:56:51,"Hey @lalyos, thanks! We will probably want to check if there is a pre-release flag set, so in the case of a final release number we don't end up with `x.x.x-` (empty pre-release field).
",ryanuber,lalyos
680,2015-02-09 07:23:52,"Ohhhh @ryanuber you are just destroying my single character PR ;) 
fixed that.
",lalyos,ryanuber
680,2015-02-09 08:08:49,"LGTM, thanks @lalyos!
",ryanuber,lalyos
679,2015-02-08 19:16:54,"@blalor unfortunately that's not always possible.  For example, I'd register the service from the Mesos executor process, this process could get OOM killed (since it runs inside a control group) and then I'd be unable to clean up the service definition.

What we're doing now is using etcd to add a key for the service with a TTL, and constantly refresh the TTL.  If the TTL expires the key is deleted.  There's no other process that needs to run to clean up stale etcd keys, which really makes operations much more simple.

It'd be interesting if something like this is possible, or if we need to write cron jobs that can somehow reconcile stale service definitions with services that should actually exist?  The latter seems really lame.
",ajf,blalor
679,2015-02-28 16:37:23,"@armon exactly right.
",ajf,armon
679,2015-07-08 23:49:58,"is it still planned @armon by any chance ?
",scalp42,armon
679,2015-07-10 00:20:09,"@scalp42 Yes, it is still planned
",armon,scalp42
679,2015-08-01 19:31:27,"@ajf and @armon We can really use this as well. 

Perhaps a new boolean attribute called deregisterService. By default value for deregisterService is false for backward compatibility. If deregisterService is true and after TTL is breached the service is deregistered from the catalog. 
Json example.
{
  ""check"": {
    ""id"": ""web-app"",
    ""name"": ""Web App Status"",
    ""notes"": ""Web app does a curl internally every 10 seconds"",
    ""ttl"": ""30s"",
    ""deregisterService"":true
  }
}
",brycechesternewman,armon
679,2015-08-06 20:12:27,"Not sure if this is what you're already thinking this @armon. If service/register supported the `acquire` parameter, the service could be deleted when it's session ttl expires, the way ephemeral keys currently work.
",cablehead,armon
677,2015-02-08 20:10:12,"Hi @jhmartin, this is likely consul receiving the HUP before the signal handler is registered. We might be able to move the handler registration earlier in the process, but that only improves our chances of catching the signal (not guaranteed). 

This is easily reproducible with the following command:



Adding a sleep before `kill` demonstrates the handler catching the signal if given a chance to register. I'll see if moving it earlier in the startup helps at all.
",ryanuber,jhmartin
677,2015-02-08 20:32:11,"@jhmartin I just experimented with this a bit, and I don't think we'll be able to do much better. You can see my example program [here](https://gist.github.com/ryanuber/368a7b8b63e76d967759). You might want to keep a very short sleep on the end of the command, or in your init script to guard against this.
",ryanuber,jhmartin
677,2015-07-13 03:17:47,"@ryanuber Could the startup order be reworked to prevent consul info from being successful until after initialization is complete?
",jhmartin,ryanuber
668,2015-02-04 18:55:53,"@nicholascapo I think the main thing is just making sure that there are no races, so if we did end up keeping HealthUnknown or some other status, we would need to modify any place where we apply health filters (probably `dns.go` and `health_endpoint.go`). I don't recall if there was any other reason we stopped using HealthUnknown aside from the race conditions it caused initially. @armon thoughts?
",ryanuber,armon
668,2015-02-05 18:56:33,"@armon @ryanuber Can't we deprecate unknown health and just provide initial status while registering a check? Or with less granularity, while registering a service? It seems that initial status depends on the semantics of the service.
What consul 0.5 currently do with zero checks for a service?
",salehe,armon
668,2015-02-05 18:56:33,"@armon @ryanuber Can't we deprecate unknown health and just provide initial status while registering a check? Or with less granularity, while registering a service? It seems that initial status depends on the semantics of the service.
What consul 0.5 currently do with zero checks for a service?
",salehe,ryanuber
663,2015-01-31 18:36:18,"@ryanbreen this looks great! Just one comment about a small mistake, but otherwise this looks merge-ready.
",ryanuber,ryanbreen
660,2015-01-30 07:34:47,"@gkze the build failing isn't from your changes, so no worries on that front.

This is great! You might want to take a peek at the master branch since there are a number of new commands and arguments going in to the 0.5 release.
",ryanuber,gkze
660,2015-01-30 08:12:28,"@ryanuber thanks for the heads up! Added
",gkze,ryanuber
654,2015-02-04 18:35:35,"@arnaudbriche Thanks! Could you also add the appropriate doc updates? If you don't have time, I'll eventually swing back around to this
",armon,arnaudbriche
654,2015-02-06 07:03:36,"@arnaudbriche I'm going to merge this in and make the documentation changes. I'll link you to the commit after. Thanks for taking care of this!
",ryanuber,arnaudbriche
654,2015-02-06 07:36:58,"@arnaudbriche you can find the adjustments I made [here](https://github.com/hashicorp/consul/compare/45097f9f3d...5c2a764cbe). I had to adjust a few of the tests as well, but nothing major. Thanks!
",ryanuber,arnaudbriche
653,2015-01-29 10:56:38,"@ryanbreen I like this. Nice work.
",ceh,ryanbreen
652,2015-01-28 22:40:14,"Looks like a bug in Consul. I'll take a look at this shortly. Thanks @ryanbreen !
",ryanuber,ryanbreen
647,2015-01-27 18:06:00,"@ryanuber  Thanks, that seems to have been the problem, the server had a different datacenter name specified than the config for the agent. 
",byllc,ryanuber
646,2015-01-26 22:14:17,"Hey @darron, this actually seems correct. If the node has gone offline, it is likely not running the checks any more, and definitely not submitting them to the catalog. Since the check is a script + interval type, the only thing that ends up marking the check as failed is when a bad return code is observed when the agent runs the script, and the result submitted to the catalog. I can see how this could be a little confusing when looking at the UI. 

As a side note, the node in the output you've provided actually **should** be excluded from any queries for the `bunk` service with passing filters enabled. Reason being is that `serfHealth` is failing, and is attached directly to the node. If any node-level health checks go into a failed state, then all services from the node should be excluded from the typical DNS or API `/v1/health/service/bunk?passing` interfaces.
",ryanuber,darron
645,2015-01-26 18:15:40,"@hoffoo probably not with the Makefile, since we ensure from there that all of the deps are available. You might be able to build using plain old `go build` in the consul directory, but YMMV.
",ryanuber,hoffoo
644,2015-01-28 05:49:10,"@foostan this LGTM! I merged before I read your question about adding tests, so I added them in 58eba95. Thanks for the fix!
",ryanuber,foostan
640,2015-01-24 21:18:09,"Hey @foostan, thanks for the PR! We have definitely noticed the various inconsistencies we have in Consul's API around allowed methods, response codes, etc.

By doing `GET /v1/agent/service/deregister/`, I don't see the behavior you mention where all services become deregistered. Only if a service ID is specified does it actually deregister anything.

Although it seems silly to use GET to deregister a service, we accept that method currently, and we don't state anywhere in our HTTP docs which methods are allowed/disallowed for deregistering services. We want to avoid breaking existing clients as much as possible.

For these reasons, we've started to tally up things we want to address in a `/v2` API set. We'll post a public GitHub issue once we have our initial set of goals laid out, and we likely won't start working through these until at least post-0.5 release.

I'm going to close this for now, but I've taken an item down to address this globally in all of Consul's API methods for `/v2`.
",ryanuber,foostan
640,2015-01-24 21:18:43,"@foostan if I missed anything or misunderstood you, let me know and we can re-open this. Thanks!
",ryanuber,foostan
639,2015-01-24 21:22:56,"@ceh I agree that this would be really nice to have. I think we also want artifact generation for various platforms while using cgo to make our releases less manual, its just not something we've been able to invest in yet.
",ryanuber,ceh
637,2015-01-25 04:32:49,"@ryanuber 

Moved the implementation into util_GOOS.go and made the function take an integer pid instead of a `os.Process` to make it more useful.

Kept `syscall.Signal` in the Windows function signature to keep 'em identical, plus, Go might add support for interrupts on Windows in the future.

Please take another look.
",ceh,ryanuber
633,2015-01-23 23:14:46,"@hoffoo are the servers running different versions of Consul? It sounds from the logs like the leader is newer than the follower(s) being replicated to, and is attempting to replicate the `TombstoneRequestType`, which was recently introduced in Consul 0.5.0rc1. If that is the case, upgrading the other servers in the cluster might be the only way to get the followers to accept the data again, unless I am missing something. @armon what do you think?
",ryanuber,armon
633,2015-01-23 23:14:46,"@hoffoo are the servers running different versions of Consul? It sounds from the logs like the leader is newer than the follower(s) being replicated to, and is attempting to replicate the `TombstoneRequestType`, which was recently introduced in Consul 0.5.0rc1. If that is the case, upgrading the other servers in the cluster might be the only way to get the followers to accept the data again, unless I am missing something. @armon what do you think?
",ryanuber,hoffoo
633,2015-01-24 09:31:46,"@armon @ryanuber doesn't this break consul's compatibility promise? 
",wuub,armon
633,2015-01-24 09:31:46,"@armon @ryanuber doesn't this break consul's compatibility promise? 
",wuub,ryanuber
633,2015-01-24 21:40:14,"@wuub the protocol compatibility is not affected by this. The issue of not being able to apply new items from the Raft log on older versions of Consul should only come up if a partial upgrade of the server pool is performed (say, 1/3 of them), and normal operations are resumed while this inconsistency exists. There should not be problems during the upgrade process, but generally running multiple versions of Consul servers together in a cluster during normal operation is not ideal.

Since this particular case involves older server nodes being unable to apply certain operations replicated to them from newer servers, we will likely need to publish a note about upgrading from pre-0.5 releases.

@armon any other thoughts on this?
",ryanuber,armon
633,2015-01-24 21:40:14,"@wuub the protocol compatibility is not affected by this. The issue of not being able to apply new items from the Raft log on older versions of Consul should only come up if a partial upgrade of the server pool is performed (say, 1/3 of them), and normal operations are resumed while this inconsistency exists. There should not be problems during the upgrade process, but generally running multiple versions of Consul servers together in a cluster during normal operation is not ideal.

Since this particular case involves older server nodes being unable to apply certain operations replicated to them from newer servers, we will likely need to publish a note about upgrading from pre-0.5 releases.

@armon any other thoughts on this?
",ryanuber,wuub
633,2015-01-25 22:01:54,"I've clarified the backwards compatibility in f53bd94. 
@wuub the short answer is kind of. The servers cannot be mixed with 0.5, but the clients can. The clients are largely where this promise matters, as it's very hard to coordinate the upgrade of thousands of nodes. We try very hard with the servers as well, but it can be extremely challenging to be forward and backward compatible in all cases. With 0.5 there is a 15 minute time window before you will have any issues, which is reasonable enough to handle a 3-5 node rolling upgrade.
",armon,wuub
633,2015-01-27 01:54:08,"@wuub Let me try to clarify:

1) The 15 minutes comes from the servers periodically issuing a new `TombstoneRequest`. This is an internal detail, but it basically allows Consul to cleanup some keys in the background after a configurable TTL. The default value of the TombstoneTTL (not configurable currently) is 15 minutes: https://github.com/hashicorp/consul/blob/master/consul/config.go#L242.

Basically, 15 minutes after a 0.5.0 leader is elected, it will issue that command to followers. Older versions will append to their Raft log, but then panic when they attempt to apply it. This is by design, since we don't know if its safe to ignore a command (future compatibility), we log a message and then hard panic. This is to avoid potential state corruption given that the command is not understood.

2) As above, it will hard panic / stop processing. Stale reads will not affect this since the server will just crash.

3) Correct! The issue stems from trying to process the `TombstoneRequest` internally.

4) Yep! This command is purely internal to the cluster, and does not get issued between clusters.
4a) I highly doubt it. That would be a logistical nightmare that we would work very hard to avoid.
",armon,wuub
633,2015-01-27 09:20:17,"thank you @armon , everything is clear now
",wuub,armon
629,2015-01-23 06:17:32,"@darron was this working before? I do not see where a config_dir was supported in the code. Previously consul would have silently ignored this, but in 0.5.0 we are adding a more strict config checker which catches unknown config keys.
",ryanuber,darron
629,2015-01-23 06:20:44,"@darron related: #71 
",ryanuber,darron
628,2015-01-22 21:13:52,"@ryanuber quite the opposite actually

Right now, if we (someone who has commit to hashicorp/consul) push a branch (like f-new-feature) to hashicorp/consul, a Travis build is triggered. Next, when we open a PR for said branch, **another** build is triggered. As such, for each commit we push beyond the original PR, **two** builds will happen - one because we pushed to a branch that is in the repo and two because we pushed a commit to an open PR.
",sethvargo,ryanuber
628,2015-01-28 12:37:20,"@sethvargo OS X is in beta and can be enabled according to http://docs.travis-ci.com/user/multi-os/

Updates #639.
",ceh,sethvargo
628,2015-01-28 16:23:25,"@ceh ^
",sethvargo,ceh
619,2015-01-20 20:15:35,"@armon This looks great! Only minor nit-picks added. Otherwise this LGTM. Glad to see a SIGTERM attempt before SIGKILL in here, too!
",ryanuber,armon
619,2015-01-20 20:42:46,"@armon added one more question about `RenewPeriodic()`.
",ryanuber,armon
619,2015-01-21 23:59:28,"@sean- the `-n` value actually is encoded in the key used for the semaphore! This allows additional clients trying to use the semaphore with a conflicting `-n` value to detect this and exit immediately. The code that does the check was actually part of a different PR [here](https://github.com/hashicorp/consul/blob/master/api/semaphore.go#L208), which extended the API client with a bunch of helper methods, including both the lock and the semaphore. This PR wraps those extra methods nicely into the base consul CLI. Agreed though, we could probably add a note that using `-n` with a conflicting value will result in an error.
",ryanuber,sean-
619,2015-01-22 01:35:38,"@sean- Clarified the documentation in d478f78. You will get an error if -n conflicts. 
",armon,sean-
617,2015-01-18 01:42:20,"@blalor i think we are definitely interested in having auto generated docs. This was just a fairly easy split of the existing docs that makes them much easier to navigate and easily fits into the existing consul website.
",ryanuber,blalor
616,2015-01-18 02:26:05,"Thanks, @ceh! Are two `-f`'s required in the `go get` command?
",ryanuber,ceh
612,2015-01-20 15:04:10,"@ryanuber @armon  I wish you guys had included me in the discussions before unilaterally changing this around. Both of these are bad changes. I would appreciate if you reverted these and included me in the discussion.
",jefferai,ryanuber
612,2015-01-20 16:18:02,"Hey @jefferai 

I am sorry if you feel like we went behind your back. That was certainly no one's intention. We discussed the changes at length as a team and we decided that many of the behaviors introduced were not in parallel with the [Principle of Least Surprise](http://en.wikipedia.org/wiki/Principle_of_least_astonishment) or other tools in the industry. Please allow me to elaborate further.
- When listening on a socket in nginx, nginx will create the socket as the same user:group the nginx processes is running as. If you need particular permissions for the socket, you must run nginx as a different user (or more commonly a different group) so that other services can read/write to the socket. We decided to take a similar approach with Consul. Furthermore, the standard description of a unix socket is `unix:/path/to/socket`. We did not feel comfortable coalescing the unix socket descriptor with the permissions on the socket file itself.
- We did not think it was the appropriate UX to automatically delete the socket. If the socket was persisted on disk, that means Consul was unable to shut down cleanly (something bad happened), and a human being should make a decision of whether it is safe to remove the socket file and restart Consul or if more intervention is needed. Other tools (like postgres and nginx) both follow this paradigm.

If there are specific issues I did not cover in my response, please let me know comment on the appropriate lines in the diff of this PR and we can definitely revisit the decision(s).
",sethvargo,jefferai
612,2015-01-20 16:54:50,"Hi @sethvargo @ryanuber @armon 

First off, I want to point out that this is an example of being a _terrible_ upstream. The syntax was proposed on the mailing list. Nobody, including Consul team members, objected. Ryan asked about it on the previous pull request, then after I explained my rationale, he thanked me for it and expressed no reservation.

You guys could have had a further discussion with me on the previous PR. You could have expressed concern and asked for community input on the mailing list. You could have poked me in email or on IRC. You could even have gotten me to make needed changes prior to you merging them so that my time wasn't wasted coding them in and writing tests for them only for you guys to waste your time reverting them less than 24 hours later.

That sucks.

So let's go over the problems with these changes.

1) nginx is not the only game in town. Many other services -- for instance, dovecot, clamav, _and_ your own later example of postgres -- allow you to specify the (usually) user and (definitely) group and mode you want to use, to make it easier and -- crucially -- more secure for other services to interoperate. That way you don't need to have the primary group you are running consul under be the group that everyone else uses to communicate with it. Removing that capability reduces both flexibility and security.

2) You can't simply get around this by making a directory and creating the socket in that directory and having it inherit permissions. I don't know what man page you're looking at, but `man 7 unix` on my Ubuntu 14.04 system says nothing of the sort. And I just verified that using netcat -- permissions of the parent directory have nothing to do with anything, so the workaround you guys suggest isn't actually a workaround. Proof:



3) Rather than removing the user/group/mode altogether, you could have simply expanded the configuration language, as Ryan and I discussed in the previous PR. As I said there, nobody expressed any issue with the configuration language since the original RFC, and if people didn't like the coalesced syntax the right thing to do would be to modify configuration to support sockets properly. You guys picked the nuclear (and time-wasting) option instead.

4) Leaving aside the point of what a user would do with a dead socket if Consul died in an unclean fashion, I don't know where you got your intel about removing sockets and postgres, but it's wrong. If postgres dies and you restart it, something in postgres wipes the socket and recreates it. I don't know what does it, but I _can_ tell you that it's not Ubuntu's init script. It's one of the pg tools, or it's the daemon itself. I just tested this -- on unclean shutdown the socket remains, and upon restarting the socket is removed and recreated, which I can tell because the inode changes:



Here's another example, using everyone's favorite netcat:



As a contrast, let's see the workflow with nginx:



I don't know where you guys got your intel, but it's wrong. You care about principle of least surprise...so do I. The least surprise solution is not to leave a dead socket lying around that the user can't do anything with anyways and then fail to start because of it. That will just leave users pissed off when a simple restart of consul fails to work. The least surprise solution is to do what everyone else is doing, and remove the socket and then re-create it.
",jefferai,ryanuber
612,2015-01-20 16:54:50,"Hi @sethvargo @ryanuber @armon 

First off, I want to point out that this is an example of being a _terrible_ upstream. The syntax was proposed on the mailing list. Nobody, including Consul team members, objected. Ryan asked about it on the previous pull request, then after I explained my rationale, he thanked me for it and expressed no reservation.

You guys could have had a further discussion with me on the previous PR. You could have expressed concern and asked for community input on the mailing list. You could have poked me in email or on IRC. You could even have gotten me to make needed changes prior to you merging them so that my time wasn't wasted coding them in and writing tests for them only for you guys to waste your time reverting them less than 24 hours later.

That sucks.

So let's go over the problems with these changes.

1) nginx is not the only game in town. Many other services -- for instance, dovecot, clamav, _and_ your own later example of postgres -- allow you to specify the (usually) user and (definitely) group and mode you want to use, to make it easier and -- crucially -- more secure for other services to interoperate. That way you don't need to have the primary group you are running consul under be the group that everyone else uses to communicate with it. Removing that capability reduces both flexibility and security.

2) You can't simply get around this by making a directory and creating the socket in that directory and having it inherit permissions. I don't know what man page you're looking at, but `man 7 unix` on my Ubuntu 14.04 system says nothing of the sort. And I just verified that using netcat -- permissions of the parent directory have nothing to do with anything, so the workaround you guys suggest isn't actually a workaround. Proof:



3) Rather than removing the user/group/mode altogether, you could have simply expanded the configuration language, as Ryan and I discussed in the previous PR. As I said there, nobody expressed any issue with the configuration language since the original RFC, and if people didn't like the coalesced syntax the right thing to do would be to modify configuration to support sockets properly. You guys picked the nuclear (and time-wasting) option instead.

4) Leaving aside the point of what a user would do with a dead socket if Consul died in an unclean fashion, I don't know where you got your intel about removing sockets and postgres, but it's wrong. If postgres dies and you restart it, something in postgres wipes the socket and recreates it. I don't know what does it, but I _can_ tell you that it's not Ubuntu's init script. It's one of the pg tools, or it's the daemon itself. I just tested this -- on unclean shutdown the socket remains, and upon restarting the socket is removed and recreated, which I can tell because the inode changes:



Here's another example, using everyone's favorite netcat:



As a contrast, let's see the workflow with nginx:



I don't know where you guys got your intel, but it's wrong. You care about principle of least surprise...so do I. The least surprise solution is not to leave a dead socket lying around that the user can't do anything with anyways and then fail to start because of it. That will just leave users pissed off when a simple restart of consul fails to work. The least surprise solution is to do what everyone else is doing, and remove the socket and then re-create it.
",jefferai,sethvargo
612,2015-01-20 17:42:05,"@jefferai @ryanuber @sethvargo Okay, so how about the following:
- Consul should perform a delete + re-create on the socket if it already exists. This allows it to recover from a crash by simply restarting. I don't see any reason to not just delete the socket, since this way we can re-bind to it.
- I think if we split the UNIX domain socket configuration into multiple configuration variables it will be much clearer. Namely, we should still use the ""unix:path"" syntax to switch from a TCP to domain socket listener, but new configurations for `unix_socket_user`, `unix_socket_group` and `unix_socket_perm` should be added to explicitly specify the other variables. We can sanely default those of to that of the running agent, and the permissions to match the parent folder.

Thoughts?
",armon,jefferai
612,2015-01-20 17:42:05,"@jefferai @ryanuber @sethvargo Okay, so how about the following:
- Consul should perform a delete + re-create on the socket if it already exists. This allows it to recover from a crash by simply restarting. I don't see any reason to not just delete the socket, since this way we can re-bind to it.
- I think if we split the UNIX domain socket configuration into multiple configuration variables it will be much clearer. Namely, we should still use the ""unix:path"" syntax to switch from a TCP to domain socket listener, but new configurations for `unix_socket_user`, `unix_socket_group` and `unix_socket_perm` should be added to explicitly specify the other variables. We can sanely default those of to that of the running agent, and the permissions to match the parent folder.

Thoughts?
",armon,ryanuber
612,2015-01-20 17:42:05,"@jefferai @ryanuber @sethvargo Okay, so how about the following:
- Consul should perform a delete + re-create on the socket if it already exists. This allows it to recover from a crash by simply restarting. I don't see any reason to not just delete the socket, since this way we can re-bind to it.
- I think if we split the UNIX domain socket configuration into multiple configuration variables it will be much clearer. Namely, we should still use the ""unix:path"" syntax to switch from a TCP to domain socket listener, but new configurations for `unix_socket_user`, `unix_socket_group` and `unix_socket_perm` should be added to explicitly specify the other variables. We can sanely default those of to that of the running agent, and the permissions to match the parent folder.

Thoughts?
",armon,sethvargo
612,2015-01-20 17:46:32,"@armon That's fine -- as I said in the other pull request, changing configuration is the ideal option. I can see arguments as to why you'd want to be able to specify user/group individually for each socket (since RPC and HTTP have different APIs, and AFAIK not all things can be done on each). Maybe that's too advanced, but this might be the best time to implement something along those lines.

Unfortunately, the ""best"" solution that I can think of would require deprecating or changing `-addresses` to have sub-objects instead of sub-strings. Otherwise it'd be to add a separate option along the lines of `-unix-addresses` but then you have to have a war between which one takes precedence when both are set.
",jefferai,armon
612,2015-01-20 17:49:49,"@jefferai Is this a use case you guys have currently? (Having distinct permissions per-socket). If it isn't then I'd prefer to keep is simple and just have a single set of `unix_*` configuration. If it is a use case, then I think we can have sub-objects within a different block. e.g.


",armon,jefferai
612,2015-01-20 17:54:17,"@armon It's not a current use-case, no, although I can't speak for everyone here. But, I was simply figuring that if that might be useful to anyone down the road, easier to change things before people use them than after. :-)
",jefferai,armon
612,2015-01-20 17:56:35,"@armon @sethvargo  @ryanuber BTW, since nginx is a common example for you guys, nginx uses `unix:/path`, but most other utilities that I've seen -- including actual languages -- prefer the full URL syntax with `unix:///path`. Just FYI. I'm a big fan of nginx, but not of all of their decisions...
",jefferai,armon
612,2015-01-20 17:56:35,"@armon @sethvargo  @ryanuber BTW, since nginx is a common example for you guys, nginx uses `unix:/path`, but most other utilities that I've seen -- including actual languages -- prefer the full URL syntax with `unix:///path`. Just FYI. I'm a big fan of nginx, but not of all of their decisions...
",jefferai,ryanuber
612,2015-01-20 17:56:35,"@armon @sethvargo  @ryanuber BTW, since nginx is a common example for you guys, nginx uses `unix:/path`, but most other utilities that I've seen -- including actual languages -- prefer the full URL syntax with `unix:///path`. Just FYI. I'm a big fan of nginx, but not of all of their decisions...
",jefferai,sethvargo
612,2015-01-20 18:08:49,"@armon I'm guessing you meant ""rpc"" and ""http""; there's no reason for DNS to be over Unix sockets. (Or rather, not for the same reasons that drove this implementation.)

But yes, that looks great.
",jefferai,armon
610,2015-01-17 00:46:31,"@dave-tucker LGTM! Thanks!
",ryanuber,dave-tucker
608,2015-01-18 02:17:18,"@imkira good catch! We can see in go's `http.Client` `Do()` method, which is what's getting called under the hood, that it either returns `nil, err`, or `resp, nil`, so IMO it is probably safe to assume we would never do anything with the response body if err is not nil. I agree though that it wouldn't hurt to just check if the response struct is nil, and if not, at least close the Body to prevent leaking handles. Maybe this belongs in `requireOK`, which will also ensure that future uses of that method get the same protection.
",ryanuber,imkira
608,2015-01-19 02:55:38,"Thank you @ryanuber .
I also agree that, like http.Client.Do, closing all resources on error (in this case resp.Body) is the right approach.
I am sending a new commit to attempt to fix this issue.
Please let me know if it looks good.
",imkira,ryanuber
606,2015-01-15 20:45:07,"@sethvargo I do think in this context that PUT is the correct verb, because the resource we are updating is the maintenance state of the given service or node, and not the service as a whole. If we do use PATCH at some point, I'd suggest we do that in a v2 API, since the current set of methods all use PUT in v1.
",ryanuber,sethvargo
606,2015-01-20 22:22:13,"Looks really good. Minor feedback, could we also add the API client updates for this too? One thing worth discussing is a potential CLI command to easily toggle the node/services. It seems like it would be useful.

@sethvargo @mitchellh thoughts?
",armon,sethvargo
606,2015-01-20 22:42:23,"@armon CLI tool seems useful. Is that something you envision in consul itself or a plugin of sorts?

I'm thinking it should be a separate project. If I'm using a monitoring service, I probably just want a CLI with some auth flags as opposed to all of Consul.
",sethvargo,armon
606,2015-01-21 19:12:05,"@armon added the API endpoints and modified the endpoint. You can see the diff [here](https://github.com/hashicorp/consul/compare/d89af51eb6...e088240c95).
",ryanuber,armon
605,2015-09-23 17:21:54,"@phobologic @ryanuber When you use ASG to maintain the desired number of servers, do the new servers increase the quorum? Let's say you start with 5 servers, so the quorum is 3. If two servers are lost and two new ones are brought back up by ASG, does the number of known servers (at least for the first 72 hours) become 7 and the quorum becomes (7/2)+1? If the quorum is not static, and you go trough two more iterations within 72 hours the quorum will be (11/2)+1=6, but the number of servers will be 5 so it will be in an unhealthy state. In other words, I would like to know if new server nodes joining would increase the quorum.
",calvn,ryanuber
605,2015-09-23 18:01:18,"@highlyunavailable Thanks for the prompt reply! So there is a chance that ASG (if no `leave` or `force-leave` is issued) will cause an outage in the case where it spins up servers to the point that the quorum is above the desired/max amount set on ASG. I guess I will do something similar to what @petemounce mentioned and use SQS + AutoScaling SNS to signal a `force-leave` on the old instances.

Edit: Is there a way to query the quorum? `consul info` does not seem to provide that information.
",calvn,highlyunavailable
603,2016-01-15 12:14:06,"Thanks a lot, @slackpad . This would certainly reduce the number of requests necessary when using `consul-template`. But unfortunately we do not currently have it deployed in production yet. 
IMHO it is not so straight forward to get notified about changes via filesystem (`inotify` would definitely do it though), since we intend to watch changes of services instead of configurations.

In this case, if we go the straight way, primary concern would be that if every worker process must send individual watch requests via HTTP to local agent, there will sure be lots of them (several thousands or more on some node), and I doubt whether that could work in real world with heavy traffic.
However, if we can somehow merge watch requests, there will only be few connections established at the same time.
",tesseract2048,slackpad
598,2015-07-06 23:07:05,"@slackpad thanks. Test cluster. Yes, the node I captured on was experiencing the issue at the time.
",petemounce,slackpad
595,2015-01-12 21:23:38,"Looks good! @ebroder could you add a test for this behavior?
",armon,ebroder
594,2015-01-10 18:12:35,"@armon I left 1 comment, but otherwise everything LGTM! Super awesome.
",ryanuber,armon
592,2015-01-12 20:02:38,"I think is a good idea. @blalor it's possible this was rejected early on, but I've had a change of heart on it. 
Some feedback I have:
- Any 2XX status code should be treated as OK
- Let's use 429 ""Too Many Requests"" for WARN
- Anything else is critical. 
- Tests for the new functionality would be great :)
- Super pedantic, some log statements are missing the appropriate ""agent: "" prefix.
",armon,blalor
592,2015-01-12 20:58:33,"I agree with @armon on using a 429 for warnings. It also agree with @sean- that writing the response into the output field would be helpful, and it's probably not too complicated to implement. Looking good!
",ryanuber,armon
592,2015-01-12 20:58:33,"I agree with @armon on using a 429 for warnings. It also agree with @sean- that writing the response into the output field would be helpful, and it's probably not too complicated to implement. Looking good!
",ryanuber,sean-
591,2015-01-12 21:40:56,"@armon Hm, yeah I think that is the case. We could modify the code path to continue passing the single `.Check` field through to preserve compatibility, but there would still be this weird gap if a client restarted using the newer `.Checks` field instead. I think advising in the upgrade documentation is probably the most reasonable thing to do. Should we do this in the release notes when 0.5 is cut?
",ryanuber,armon
591,2015-01-14 19:23:03,"I've made a few adjustments in here after some experimentation. What we have now should be compatible with older versions of Consul by using `Check` instead of `Checks` when there is only a single check for a service (which would be the case on older Consuls).

We also solve the issues @armon mentioned earlier by batching service sync operations with check syncs where appropriate. Basically, if a check is to be synced, and is associated with a service, we attach the service to the `RegisterRequest` if it is out of sync or doesn't exist. This requires scoping the `RegisterRequest` to a single service and its associated checks, which is handled in `syncChecks()`.

One final change is that we batch all checks which are not associated with any service together to reduce the number of RPC requests required to perform anti-entropy.
",ryanuber,armon
591,2015-01-15 07:12:16,"@armon I ended up reverting `syncChecks` back to its original `syncCheck`, and instead modifying `syncService` so that it searches for any out-of-sync checks and piggybacks them along with it. Reduced complexity quite a lot. I think this is ready for a once-over.
",ryanuber,armon
588,2015-01-09 21:54:21,"Thanks, @tiwilliam. I'll take a look at that.
Another note to self: This one has come up on occasion:


",ryanuber,tiwilliam
588,2015-01-22 00:56:45,"@armon I think so. I looked into Terraform to see what we were doing for tests and updating deps, and we aren't taking the same approach there. I t seems fair to get test errors if you try running the tests with outdated deps.
",ryanuber,armon
587,2015-01-12 20:13:25,"@jefferai The tests passing as often as master is a good sign. I do still think we need some general testing around some of the functions that are going in here though. For example, `populateUnixSocket` and `adjustUnixSocketPermissions` seem like fairly generic functions which we could have some unit testing for individually. We could use the runtime to figure out if we are running on Linux/UNIX, and skip if we are not with `t.SkipNow()`.
",ryanuber,jefferai
587,2015-01-13 14:10:19,"@ryanuber Sure. I haven't had time to get to new tests yet, just fixing the one regression I had against old tests and running over and over to determine what's likely to be a problem and what's just test brokenness. New tests are next.
",jefferai,ryanuber
587,2015-01-13 18:26:45,"@jefferai sounds good, just let us know when you think its ready and we'll take another look!
",ryanuber,jefferai
587,2015-01-13 20:15:19,"@ryanuber @armon in agent.go, in Create, a configuration is passed in; this configuration is then ignored by the agent.setupServer and agent.setupClient calls, which means my adjustments to the config to have it listen on Unix sockets have no effect (on either the server or client).

I'd like to change setupServer and setupClient to honor config.Addresses if set to something other than the defaults. This feels slightly intrusive, but I don't see any other way. Comments?
",jefferai,armon
587,2015-01-13 20:15:19,"@ryanuber @armon in agent.go, in Create, a configuration is passed in; this configuration is then ignored by the agent.setupServer and agent.setupClient calls, which means my adjustments to the config to have it listen on Unix sockets have no effect (on either the server or client).

I'd like to change setupServer and setupClient to honor config.Addresses if set to something other than the defaults. This feels slightly intrusive, but I don't see any other way. Comments?
",jefferai,ryanuber
587,2015-01-13 22:36:50,"@jefferai Not sure why they would be impacted? Since the HTTP listener is in the agent level and not at the Consul level.
",armon,jefferai
587,2015-01-14 19:54:47,"@armon @ryanuber I believe this is now ready for review. Also, let me know if you'd like me to squash these into either one or two (code in one, tests in the other) commits, or leave as-is.
",jefferai,armon
587,2015-01-14 19:54:47,"@armon @ryanuber I believe this is now ready for review. Also, let me know if you'd like me to squash these into either one or two (code in one, tests in the other) commits, or leave as-is.
",jefferai,ryanuber
587,2015-01-14 22:24:37,"@jefferai I'll take a look at this in just a bit, thanks!
",ryanuber,jefferai
587,2015-01-15 00:29:20,"@jefferai I went through and added some comments about various things. Overall looking really good!

I am wondering about the format of the UNIX socket URI since it includes `;[user];[group];[mode]` at the end. I might be missing something here. Is this a typical UNIX socket path, or are we inventing some syntax here? Maybe you could elaborate on why we are taking that path here.
",ryanuber,jefferai
587,2015-01-15 14:38:11,"@ryanuber OK, I've gone through the issues above.

A typical UNIX socket path is unix:///path/to/socket/file. The user/group/mode are necessary parts of the specification though. The reason it's in that form is compatibility with the current configuration, which is a string. Most other applications have the owner/group/mode as separate configuration items.

The only way to do it the ""normal"" way would be to change the configuration file format, or at a minimum add several more values for each of the rpc and http addresses, either in a sub-object or as extra optional keys.

When I proposed this on the mailing list (https://groups.google.com/forum/#!topic/consul-tool/9m4iKt6PTgE) I got no indication from either armon or other users that this method was unsatisfactory, and it retains compatibility. I'm fine with a change to the configuration syntax instead, but that would require a separate discussion with more parties involved, I think.
",jefferai,ryanuber
587,2015-01-15 23:37:28,"@jefferai I've read through the comments, thanks for elaborating on the implementation. I'm going to merge this in and update a few minor stylistic things, but I think the functionality is there. I'll link you to the changeset afterwards. Thanks for doing this! :+1:
",ryanuber,jefferai
587,2015-01-16 22:38:39,"@jefferai I pushed #612 as a follow-on to this PR. See the description there for details on what changed and why. Again, thanks for tackling this, we appreciate it!
",ryanuber,jefferai
583,2015-11-25 17:41:11,"@cskksc  @ryanuber thanks!
",marcellodesales,ryanuber
581,2015-01-07 18:48:33,"@ryanuber any idea why the tests are failing?
",sethvargo,ryanuber
581,2015-01-07 19:14:56,"@sethvargo normally we see failures on Travis due to some timing issues, but these look a little scarier. I'll look back and make sure nothing on our end is causing this.
",ryanuber,sethvargo
581,2015-01-07 19:16:55,"@ryanuber okay. I'm just wondering if there's a recursive dep or something weird (like we already had a package named ""api"" from somewhere else)
",sethvargo,ryanuber
579,2015-02-27 23:32:45,"@oliora Good idea! Tagging for enhancement.
",armon,oliora
575,2015-01-05 22:07:42,"Hey Thordur,

Feel free to PR the comment changes and doc updates! I still do think shuffle should be done with
the full list just to prevent clients which access only index 0 from causing issues.

Best Regards,
Armon Dadgar

From:Â Thordur Bjornsson notifications@github.com
Reply:Â hashicorp/consul reply@reply.github.com>
Date:Â January 5, 2015 at 12:45:04 PM
To:Â hashicorp/consul consul@noreply.github.com>
Cc:Â Armon Dadgar armon.dadgar@gmail.com>
Subject:Â  Re: [consul] DNSConfig EnableTruncate to true by default. (#575)  

@armon, thanks for the clarification, but I have a small objection if you'll allow me:

The current EnableTruncate behaviour breaks RFC conformity (RFC2181, Section 5.1) but I can see why breaking it might be beneficial given your 99.9% argument.

Documenting this better might be very beneficial, and I'll see if I can cook something up.

Any objections to the other two commits ?
I'll resubmit a PR for those, apologies for mixing commits in this PR.

â€”
Reply to this email directly or view it on GitHub.
",armon,armon
573,2015-01-05 19:18:56,"Ah, tricky! @armon makes sense, will adjust this.
",ryanuber,armon
571,2015-01-06 18:43:39,"@darron oh are you saying that the watchers compound over time? e.g. a new set of 50 watchers is added on each reload?
",armon,darron
571,2015-07-29 22:20:59,"@ryanuber what is `Ltime`?
",joelmoss,ryanuber
571,2015-08-10 14:46:53,"@armon Do you still plan to add the flag to the watches (to turn off fire-on-create)? If so, any plans when this is going to be available?
",BjRo,armon
567,2015-01-01 21:40:34,"@ryanuber That stale example is testing that you can set either ?stale or ?consistent, but not both.
",thorduri,ryanuber
567,2015-01-01 22:33:46,"@thorduri I just pushed a basic test for pretty-printed responses in e9615c5. If you rebase against master and add one more test (or expand the `TestPrettyPrint` test), we can then merge this in. We want to test that both forms (`?pretty=1` and `?pretty`) work as intended so we don't break any clients.
",ryanuber,thorduri
567,2015-01-02 08:19:28,"@ryanuber Done. Hopefully the test refactor is OK.
",thorduri,ryanuber
565,2015-01-06 18:38:07,"There are many customers running in EC2 classic, so it's not an EC2 issue. My guess is that the security groups / iptables are causing some type of havoc. This is a really high error rate, and as @ryanuber said, at very low levels of the system. 

I'd check dmesg and maybe a little bit of tcpdump to see what is happening. My guess is network configuration issues.
",armon,ryanuber
565,2015-01-14 18:35:56,"@lyrixx What kinds of disk are you using? Is it possible that you are experiencing some extremely slow or contested IO?
",armon,lyrixx
565,2015-01-27 19:49:08,"@armon thank you very much for your answer. I was planning on testing 0.5, but I was hoping skipping rc1 and going directly to the final release :) Do you know when that would be?
",eolamey,armon
565,2015-01-27 19:52:56,"@armon also, what value would you recommend for GOMAXPROCS? Does it depend on the number of concurrent requests, or the number of cores available?
",eolamey,armon
562,2015-01-02 19:58:25,"@armon that's great; looking forward to it landing!
",petemounce,armon
561,2014-12-30 02:37:53,"I agree with @blalor on this one. I think we could disambiguate the current responses by returning an empty list with a 200-range response while listing an empty keyspace, since the keyspace does exist and just happens to be empty, which is different than it just not existing to begin with.

The thing is though, there could be (and likely are) clients depending on the current functionality, so any changes like this would need to go into a `/v2` api.
",ryanuber,blalor
560,2015-01-02 21:58:45,"@armon I have just joined -wan one server of the ungleich-init7 dc from hetzner-rz16.

I assumed (seems incorrectly) that all servers are informed about the other datacenter via gossip in the local datacenter?

If it is necessary to join -wan to every other server in the datacenter, I would have to repeat the step for every server in the other datacenter every time the node reboots?

I.e. having 3 servers in ungleich-init7, 3 servers in hetzner-rz16 and 3 servers in our upcoming dc, every server would have to join 6 other servers?

I think what makes me mostly puzzled is that I assumed that the information (view) of the cluster should be eventually consistent -  did I assume wrong here?
",telmich,armon
557,2015-01-02 16:42:43,"@armon Is the only behavior we can do in this case to panic? Is there a way we can gracefully fail out somehow. And, in either case, perhaps we just make it configurable as an ""advanced case"". 
",mitchellh,armon
557,2015-01-03 03:00:54,"@telmich from my understanding, we have to use a timeout because a routine we call from the LMDB C code gets ""stuck"" on occasion, and rather than blocking forever (essentially causing an undetectable/unrecoverable condition), we set a conservative upper limit on execution time and bail if we aren't done by the deadline.

@armon is that correct? Do we have an open issue upstream yet by chance?
",ryanuber,armon
557,2015-04-06 19:42:11,"@ryanuber will this be fixed with BoltDB backend?
",c4milo,ryanuber
555,2015-01-02 16:35:41,"@blalor Thanks for tackling this! The Apiary docs do look really good. I bet we can get pretty close to that by improving the docs generation we have now, instead of needing to link in an external service.

@sethvargo Thoughts? Any extensions to middleman we can use to make it more like Apiary and make the API doc experience nicer?
",armon,blalor
555,2015-01-02 20:16:44,"@armon I would like to move to standardized, versioned documentation for all our projects, but it's not something I have had time to research much.
",sethvargo,armon
555,2015-01-11 04:59:43,"@blalor Awesome :+1: :beers: 
",rotatingJazz,blalor
553,2015-02-03 13:58:27,"@armon I made a separate issue as it is confusing to discuss this here. #667
",derekelkins,armon
551,2014-12-31 07:05:47,"Hey @ceh thanks for the solid work as always. I also realized these changes would violate the api compatibility for the v1 endpoints and paused there to figure out the right way to go about it. We might need to go the v2 route to avoid breaking any clients.
",ryanuber,ceh
550,2015-01-05 20:04:46,"@ryanuber I have a config file for the container stuff:



Consul is properly starting with it.

@armon I understand. I will look into how to advertise the RPC port. Maybe you have some pointers for me what needs to be considered. 

Is there anything I can provide to help identify the bug regarding the self-doubts of the node?
",i0rek,armon
550,2015-01-05 20:04:46,"@ryanuber I have a config file for the container stuff:



Consul is properly starting with it.

@armon I understand. I will look into how to advertise the RPC port. Maybe you have some pointers for me what needs to be considered. 

Is there anything I can provide to help identify the bug regarding the self-doubts of the node?
",i0rek,ryanuber
550,2015-01-05 20:36:57,"@armon Thank you so much for looking into this! :beer: Happy new Year! :beers: 
",rotatingJazz,armon
550,2015-01-05 22:35:25,"@i0rek Take a look at consul/server.go setupSerf(). Basically the ""port"" value we gossip out is the RPC port, which currently is setup to the real port. I guess there could be a new AdvertisePorts configuration that would allow a different port value to be gossiped out which would be set there.
",armon,i0rek
550,2015-01-05 22:38:43,"@i0rek with respect to the self-suspect, a dump of ""consul members"" and ""consul members -detailed"" would be useful. Looking through the memberlist code, not sure how this is possible.
",armon,i0rek
550,2015-01-05 22:44:23,"@armon this is what I see when I start consul in the container: 



and after a minute or so:


",i0rek,armon
550,2015-01-06 10:54:45,"@ryanuber you were right and I was wrong. I got the configuration option wrong. Consul doesn't start anymore now that I am using the right one.


",i0rek,ryanuber
550,2015-01-06 18:08:26,"@i0rek I pushed #576 yesterday which should help us avoid this confusion in the future. As for `advertise_addr`, I don't think we can just accept the port number on the end of the address in `ip:port` format, since we use it to set up two separate gossip agents and the RPC advertise address. I think as @armon said the way to go would be to have some new config option, maybe like:


",ryanuber,armon
550,2015-01-06 18:08:26,"@i0rek I pushed #576 yesterday which should help us avoid this confusion in the future. As for `advertise_addr`, I don't think we can just accept the port number on the end of the address in `ip:port` format, since we use it to set up two separate gossip agents and the RPC advertise address. I think as @armon said the way to go would be to have some new config option, maybe like:


",ryanuber,i0rek
550,2015-01-06 18:38:55,"@ryanuber I've tried that, it only works when all the nodes have the same ports, which defeats the purpose. We need to be able to advertise the port along with the address.
",rotatingJazz,ryanuber
550,2015-01-06 19:10:28,"@ryanuber thanks for #576!
Re `ports`: thats not enough as @rotatingJazz said. 
Re `advertise_addrs`: I will give it a shot and let you know once I have something to look at.
",i0rek,ryanuber
548,2015-11-25 01:58:01,"@sethvargo have you seen this since you reported it? I haven't noticed it thus far and not sure how to reproduce it.
",ryanuber,sethvargo
546,2014-12-18 02:59:11,"@ryanbreen there is also a function in util, `randomStagger()`, that should help with this. Check it out [here](https://github.com/hashicorp/consul/blob/ce4aa7beb5dc9434e19a93e04902520a7114386f/command/agent/util.go#L36). It can probably plug right into the interval.

Otherwise I think this is a good idea!
",ryanuber,ryanbreen
546,2014-12-18 03:08:28,"Agreed with @ryanuber! Also some tests for this would be good :)
",armon,ryanuber
546,2014-12-18 03:30:59,"@ryanbreen Probably enough to ensure the check is run within a timely manner (e.g. <= Interval).
",armon,ryanbreen
546,2014-12-18 06:48:16,"@ryanbreen I left a few comments, but looking good!
",ryanuber,ryanbreen
546,2014-12-18 14:02:22,"Great feedback, thanks @ryanuber!  Let me know if this doesn't address those points adequately.
",ryanbreen,ryanuber
546,2014-12-18 20:46:50,"@ryanbreen LGTM, Thanks for doing this!
",ryanuber,ryanbreen
544,2015-05-07 00:13:40,"@c4milo Were the nodes dead when you did a ""force-leave""? Do they show up in ""consul members"" at all?
",armon,c4milo
544,2015-05-07 01:14:35,"@c4milo Hmm force-leave should push them into the ""left"" state. Nodes are not reaped until they are in failed for 72h or in the left state. Did ""force-leave"" not cause them to go to ""left""?
",armon,c4milo
544,2015-05-12 17:40:00,"@armon I just ran into this again, here is a video: https://asciinema.org/a/bd1apr97vc45f4syahet3dxig. Should I open a separate issue for this?
",c4milo,armon
544,2015-05-12 18:14:35,"@c4milo Everything looks fine in that video, the nodes are in the left state. ""force-leave"" just moves a node from the ""failed"" -> ""left"" state. They are not removed from the members list for 24 or 72h.
",armon,c4milo
544,2015-05-12 18:49:08,"I see. I'm going to need more sleep. Thanks @armon. 
",c4milo,armon
544,2016-08-15 15:44:02,"@slackpad For me, the problem that this causes is that /v1/catalog/service/service endpoint, still shows services from failed nodes, for me it makes more sense, once it's failed, the services get removed.
",lucaswxp,slackpad
543,2015-02-11 13:18:32,"Hi @armon 

It seems this pr is not deployed yet.

Could you deploy it ?

And BTW, I(t) may be stupid, but IMHO a link to https://github.com/hashicorp/consul/tree/master/api for the Go part could be useful ;)
",lyrixx,armon
542,2014-12-16 11:25:06,"@ryanuber tests are added.
",lalyos,ryanuber
542,2014-12-17 00:36:42,"@lalyos great tests! Thanks for filling those in. Merging on in.
",ryanuber,lalyos
541,2015-01-02 20:42:09,"@sethvargo Hey! How often do you update consul.io? This change is still not present :sweat_smile:
",carlanton,sethvargo
541,2015-01-02 21:35:59,"@carlanton it is live now
",sethvargo,carlanton
541,2015-01-04 12:59:35,"Thanks!

On Friday, January 2, 2015, Seth Vargo notifications@github.com wrote:

> @carlanton https://github.com/carlanton it is live now
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/541#issuecomment-68564607.

## 

Mvh
Anton

Sent from my iPhone
",carlanton,carlanton
541,2015-01-04 17:23:13,"@carlanton actually had to roll this back because we have docs on not-yet-released-features. It will go out with Consul 0.5
",sethvargo,carlanton
539,2014-12-16 05:26:32,"That's great @i0rek :+1: 

I have some other things that are more time sensitive to work on now, but I'll get back later to this issue to update on success or problems found.
",Scorpiion,i0rek
534,2014-12-13 12:42:09,"@armon I understand what you are saying. I don't think our case is pathological if you think of load balancers like HAProxy where few servers generate high load. But consul-template is probably a better way to archive our goal in that case.
",i0rek,armon
533,2014-12-15 12:17:12,"@armon - I believe the problem is not the ""."" but simply because the DC name in this case with uppercase is registered unormalized while DNS resolution being generally case insensitive is enforced at https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L311 . This is a problem as well as it looks to me as the HTTP API is case sensitive. Maybe you could consider enforcing semantics and canonicalization outside the different interfaces to ensure consistency.
",alouche,armon
533,2014-12-15 21:52:09,"@alouche They should both be case insensitive since the internal indexes normalize for that. I do agree that datacenter name is not currently normalized which could cause issues. Probably need to down-case it everywhere, but it will be backwards incompatible change in some cases.
",armon,alouche
532,2015-02-02 21:23:23,"@jhmartin The interim solution is to disable exec support until the ACL framework covers it
",armon,jhmartin
532,2015-05-27 07:08:35,"@armon I would also like to see a feature, where we can decide which commands are whitelisted, e.g. block `rm -rf /`. The proposed interim step by @jhmartin sounds reasonable good to me. That way we can decide, if the command gets really executed or is being blocked by the node. A similar way would be to add a configuration option to the agent, which describes which command should be used to execute the command given by the exec request, e.g. `{ ""exec_engine"" : ""/usr/local/bin/secure_bash"" }` and maybe the exec carries only the parameters to this command.
",kaelumania,jhmartin
532,2015-05-27 07:08:35,"@armon I would also like to see a feature, where we can decide which commands are whitelisted, e.g. block `rm -rf /`. The proposed interim step by @jhmartin sounds reasonable good to me. That way we can decide, if the command gets really executed or is being blocked by the node. A similar way would be to add a configuration option to the agent, which describes which command should be used to execute the command given by the exec request, e.g. `{ ""exec_engine"" : ""/usr/local/bin/secure_bash"" }` and maybe the exec carries only the parameters to this command.
",kaelumania,armon
526,2015-02-23 18:58:23,"Thanks @armon.  I think the other component to this was that the serf local snapshot had marked the servers as having left.  This was due to me misreading ""gracefully leaving"" as being something that you would want to do when shutting down a server.  I assumed this was the preferred way -- that the server would come back up just as gracefully when restarted.
",dellis23,armon
526,2015-04-20 05:18:38,"@armon With my testing, whenever the peers.json file is empty (shows a value of ""null"" in the file), deleting the folder, then starting up each server again seems to bring the servers back to state of quorum. I have not seen other files other than the peers.json file in the rafts folder though. 

Is it also not advisable to only delete the peers.json file when it is null, as it seems that the servers discover each other correctly once this is done. I am on consul 0.5.0
",thedjEJ,armon
526,2015-04-24 09:52:13,"Thanks @armon . I think I understand this better now and nuking the directory is DEFINITELY not a good idea. Not leaving gracefully is the issue though and I will look into not letting the servers do this, especially when they might once again join the cluster.
",thedjEJ,armon
516,2014-12-05 08:48:26,"@mtchavez thanks for this PR. I made a note above about `globalRPC`. Could you try wrapping the test in a `WaitForResult`? That would be a more reliable fix if this is in fact a timing issue.
",ryanuber,mtchavez
516,2014-12-05 18:04:50,"@mtchavez You have the right idea - I should have explained a little better. Since many of Consul's tests are sensitive to timing, we actually have a method built for exactly this purpose called `WaitForResult`. You can see an example of its usage [here](https://github.com/hashicorp/consul/blob/master/consul/server_test.go#L201).

Basically what this does is the exact same thing you pasted above, just on a shorter interval. We just brute force checking a result, and give up if the condition still isn't met after some time.

Does that make sense?
",ryanuber,mtchavez
511,2014-12-04 08:40:31,"@catsby good catch, thanks!
",ryanuber,catsby
509,2014-12-03 19:12:22,"@lyrixx thanks for the report. Just looking over the MDB source I'm not exactly sure how this happens.

[This comment](https://github.com/armon/gomdb/blob/master/mdb.c#L6465) suggests that this should not happen, so perhaps this could be an upstream bug. Again, not sure though.

@armon thoughts?
",ryanuber,lyrixx
509,2014-12-03 19:15:21,"@lyrixx any additional information about the cluster you can volunteer would also be useful here.
- Which version of Consul are you running? `consul -v`
- Any other known problems on the host which had the error?
",ryanuber,lyrixx
504,2014-12-01 02:31:36,"This is actually because `Check` is specified with a capital `C`. Technically we document this configuration in all lower-case in the [service definition docs](https://consul.io/docs/agent/services.html). Mapstructure does accept the capitalized form, though.

81d4e5c fixes this by searching service definitions for any check occurances regardless of case and fixes them up. Might be better to eventually only allow the expected configuration (i.e., all lower-case).

@armon this shouldn't affect persisted services, since marshaling a `time.Duration` just writes it out as a number instead of a string.
",ryanuber,armon
490,2014-11-21 18:43:40,"@andrewwatson Sure! Want to open a PR?
",armon,andrewwatson
490,2014-12-01 22:59:30,"This seems mostly related to `go build` and not Consul itself, so I'm closing this for now. If there is some reason that Consul specifically does not support static builds, feel free to re-open.

@andrewwatson open up that PR if you get something working!
",ryanuber,andrewwatson
485,2014-11-20 16:24:46,"Hi @lyrixx 

Thank you for the bug report. Those links are actually designed to be ""linked"" to, which is consistent among all our products. I definitely see your point about the link being misleading, so I'll work on getting something into [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp).
",sethvargo,lyrixx
479,2014-11-21 18:13:46,"@hoffoo this is fixed in master and will be in the next release!
",ryanuber,hoffoo
479,2014-11-21 18:33:11,"very cool, thanks @ryanuber !
",hoffoo,ryanuber
478,2014-11-17 23:08:04,"@amalaviy This is looking good. I've left a few minor comments above. Other than that, if we can get some tests and comment all the methods in here, we will be in good shape!
",ryanuber,amalaviy
476,2014-11-20 19:58:36,"Thanks @armon.  It'll be some days before I can get us upgraded to 0.4.1 but I will most def. report back.
",ctro,armon
476,2015-03-23 17:37:30,"Same issue as @francois here, playing around with Consul (0.5.0 now) in a Vagrant environment. 

@armon I had a look at the outage guide, but the problem is that the content of the peers.json file on all three nodes is the string ""null"". Removing the file didn't seem to make a difference, nor did restarting the server agents with or without -bootstrap-expect - they simply won't elect a leader without wiping my data directory.
",AirbornePorcine,armon
476,2015-03-23 17:52:47,"Great, thanks @armon !
",AirbornePorcine,armon
476,2015-04-28 17:14:35,"@plombardi89 
Well, that took me forever :)
I just upgraded our consul boxes to 0.5.0.  Bringing up 3 new 0.5.0 nodes to join the old cluster worked.
Simply `consul leave`ing on each of the ""old"" nodes successfully transferred leadership to one of the ""new"" nodes.  Yipee :)

@armon, at this point I'll leave closing this issue up to you...
",ctro,armon
475,2014-11-23 08:37:12,"@armon 

> Would it be possible to support IPv6? Not sure what is involved for that.

Actually it involved me reading RFC about ipv6 as i never used it before. But the hardest part was to find an environment to test ipv6. Kudos to **digital ocean**.

To refactor the PR to support ipv6 actually took replacing 5 lines with 2 ;) ( see [commit](https://github.com/sequenceiq/consul/commit/d583bc2ccb5375ff4cb53681f82508d718fd3fd8) )

The digital ocean test setup/result are documented in this [gist](https://gist.github.com/lalyos/1fff88c2511abd4716d5)
",lalyos,armon
475,2014-11-23 08:43:49,"I made the FQDN resolution to include the datacenter name. But it might be useful to be it configurable.
Maybe under the `dns_config` object something like `reverse_lookup=fqdn/nodc` with fqdn as default.

@armon  does it makes sense?

But it should go into a new PR once this got merged.
",lalyos,armon
475,2015-09-02 15:10:20,"@armon - what do you think of @lalyos' suggestion to make this configurable? This feature is currently making it hard for us to use Consul DNS, because we use our internal DNS for stuff still. Specifically, we run a service, and it currently registers itself with a home-grown service discovery system. As part of that, it takes the IP address of the host VM, does a reverse lookup, and uses that domain name to register itself.

When I enabled Consul as the default DNS resolver, the service started registering itself like ""deals.domain.net.node.flex.consul"". This is correct as this feature is defined (nodename matches, ""flex"" is the datacenter name, etc), but this address is not addressable by services that don't yet have Consul running. Since we need to roll out Consul in stages, we need some way to have the reverse lookup configurable so that on specific nodes it just uses the recursor DNS servers to do the reverse lookup. 
",robreinhold,armon
475,2015-09-02 15:10:20,"@armon - what do you think of @lalyos' suggestion to make this configurable? This feature is currently making it hard for us to use Consul DNS, because we use our internal DNS for stuff still. Specifically, we run a service, and it currently registers itself with a home-grown service discovery system. As part of that, it takes the IP address of the host VM, does a reverse lookup, and uses that domain name to register itself.

When I enabled Consul as the default DNS resolver, the service started registering itself like ""deals.domain.net.node.flex.consul"". This is correct as this feature is defined (nodename matches, ""flex"" is the datacenter name, etc), but this address is not addressable by services that don't yet have Consul running. Since we need to roll out Consul in stages, we need some way to have the reverse lookup configurable so that on specific nodes it just uses the recursor DNS servers to do the reverse lookup. 
",robreinhold,lalyos
475,2015-09-02 20:59:32,"Thanks for the reply, @armon. I think I may have cluttered up my point talking about our internal service discovery.

Maybe a better way to say it is that, when doing a reverse lookup on an IP that happens to have a Consul agent running on it, we were not expecting to get back a Consul address, we were expecting to get back the DNS address that our upstream recursors would return. 

What I'm proposing is a config value like:
reverse_resolve=recurse/consul (or something better, I'm no good at naming)

The way it works right now, Consul is basically clobbering a reverse lookup of the local IP on VMs/servers that have Consul agents setup as the DNS resolver. This was not what I expected, and it breaks name resolution for anybody consuming the Consul name (node.dc.consul) that doesn't yet have Consul configured as their resolver. So this would work great on a distributed system that's not using DNS names yet, or where IPs are used exclusively, but would be very difficult for us to adopt.

I'm willing to do the dev work and get you a pull request, I was just wondering how it would be received. Any chance this config option would be looked at and potentially merged?
",robreinhold,armon
473,2016-01-10 09:33:42,"@blalor I'm inferring from your original post that you run consul in docker with --net=host.

I think there is a workaround if you use --net=bridge:
- you can bind consul -client=0.0.0.0 to all interfaces (inside the net-container-space)
- map 8400/8500/8600 to your bridge0 (172.42.17.1) on the host
- map 8300-8302 to your private-network ip on the host
",tgeens,blalor
470,2014-11-13 19:23:29,"@ryanuber that all makes sense.  You may want to clarify that in the documentation since it says that latter values ""override"" earlier ones (which could be interpreted as one array replacing the other).

Thanks for the suggestion that appears to work better.  One question -- are those settings which can be provided whether or not we are actually initializing the cluster vs. re-starting from existing state? Ideally I'd like one configuration I can spin up regardless of condition.

Another question -- if I use `bootstrap-expect=N` must I have exactly N peers or is that a lower bound?  I'd like the freedom to spin up additional peers if needed so I don't want to have the exact number encoded in configuration.
",sfitts,ryanuber
468,2014-11-21 19:30:52,"@armon - should not have happened, but changing compile environment might have affected it.

LMDB 1.0 will break 0.9 compatibility, yes. The on-disk data layout will change. It has not (intentionally) changed so far.
",hyc,armon
468,2014-11-21 20:14:28,"> Do you think you could provide @hyc with copies of the raft/ data directory after running it with each version? That may be of use in determine what changed.

Yes. Since he doesn't have a public email address I'll mail it to you, @armon.
",webcoyote,armon
460,2014-11-10 22:26:29,"@armon: In the case of needing to do discovery using DNS, this means that my own app/code needs to be instrumented to talk to Consul specifically instead of just 'some http endpoint' no? 

The beauty of the HAProxy option to me, is that it just works in dev where the actual services are available at localhost at the specified port, whereas in prod you just switch those out for a HaProxy, no code changes needed, and no leak-in of (to me) devops stuff like Consul. Consul-Template seems to be exactly what I'm looking for in this regard, thanks.

BTW: appreciate the email, that clarifies things a lot. I especially got the notion that consul is pretty heavy in operation, while that doesn't seem to be the case. Of course the proof is in the pudding, so I'll have a crack at it tomorrow. 

Lastly, I intend my entire stack to run on CoreOs, which with Etcd seems to partially overlap functionality with Consul. Although that may be the case, I'm pretty sure they don't have to bite eachother. Do you have any experience in this regard?
",gebrits,armon
459,2016-09-21 17:02:56,"I'm going to close this down per @armon's comment above - this would be hard to do properly without introducing a lot of complexity in Consul itself.
",slackpad,armon
457,2015-02-24 00:16:55,"@blalor Can you provide the DEBUG level logs from the machine and maybe one other machine? This looks slightly different than the issue of this ticket. The ticket is that the Raft peers cannot handle an IP update of a server, while this looks like a different issue (Join/Fail) not converging.
",armon,blalor
457,2015-02-24 19:56:06,"@blalor It looks like consul-001 is unable to ping (directly or indirectly) consul-000:



This could mean there is some network issue preventing UDP packets between them, which is causing the flapping. Could you investigate possible network issues?
",armon,blalor
457,2015-12-01 16:21:01,"I'm determined to introduce ip change support in Consul.

I've hacked the code to allow that and it seems to work. I'd like to agree with you on the design of the final solution so that, possibly, my pull request could be integrated with mainline Consul.
@armon Please let me know your comments and concerns.

The requirements:
- allow ""old-style"" behavior - identification of nodes by their IP address
- allow identification of nodes by some unique (cluster-wide) identifier;
- it is not required to provide online IP change support (i.e. you need to at least restart agent to use new IP)

OK, so here's the idea:
- use node name as a ""node address"" (consistency with serf, web API etc.)
- keep this node address in RaftLayer and in serverParts
- use serf-based node address resolver in RaftLayer::Dial and ConnPool::getNewConn to resolve node address to proper IP when creating a new connection

Please note that no reverse resolution (IP->node address) is required.

Correctness:
Obviously, there is a question whether such approach is correct.

Assumptions:
- Raft algorithm doesn't require reliable network (i.e. network delays,
  partitions, packet loss, duplication, re-ordering is allowed)
- after code inspection I believe hashicorp's Raft implementation doesn't require reliable network either
- consul doesn't identify message sender by remote address (which is by nature IP); instead the sender node identification is passed in messages (if needed); in general, the messages are valid or not regardless of who sends them - it is their content that matters
- nodes are identified (in Raft, for RPC) by their address, but there is no requirement that this is a TCP address. Thus, it can be arbitrary node address without affecting Raft/consistency.

Observations:
- If there is a property that IP address is not re-used the approach is correct, because effectively IP change is seen as a transient network problem.
- if IP address is re-used after some reasonably long time, the scenario is reduced to transient network problem as well.

This is good enough for me, because that covers real-world scenarios I need to handle.

However, I believe than even in case of rapid IP addresses changes the approach stays correct. The new case to consider is when messages reach different destination then intended because serf data is not up-to-date. Still, because it is message content that matters, and not the sender, all invalid requests will be dropped (even now there must be a support for handling stray or delayed messages). There is a risk that some valid requests are dropped, but this affects only efficiency, but not correctness.

Obviously, this is hardly a _proof_ of correctness. I do not intend to perform formal verification though. Is it good enough for you?

I've looked over web API and I think this change doesn't affect it. I hope I haven't broken anything.
",jakubzytka,armon
454,2014-11-21 21:27:52,"Very interesting @armon! Thanks for the explanation.
",i0rek,armon
454,2014-11-23 11:27:33,"@armon What about being able to specify the expected quorum size ? It is up to the user to use a correct value, like it is for `bootstrap_expect`
",adrienbrault,armon
454,2015-05-12 02:36:27,"@ryanbreen That didn't help. Here is what i did
- Started first node in bootstrap mode ( this node will self-elect as leader, creating a basis for forming the cluster.)
-  Started second and third node in non bootstrap mode which i call a normal server
- I wanted each server on equal footing so I did shutdown the bootstrapped consul instance and then re-enter the cluster as a normal server.

Everything looks good at this point.

I forced the cluster to lose quorum by restarting 2 of the 3 nodes at same time. Nodes came back online but leader was not selected on its own.

I want to know what should be my next step here.

Should i again start node 1 in bootstrap mode and re-execute the steps mentioned above?
",mohitarora,ryanbreen
454,2015-05-12 04:13:03,"Thanks @ryanbreen .

-bootstrap-expect is better than -bootstrap, I will start using that but both these are used when cluster is initialized.

I still need the steps for recovery once quorum is lost. In my case no leader was selected once all nodes came back to life after quorum loss.
",mohitarora,ryanbreen
454,2015-05-13 00:11:59,"@highlyunavailable What if all three go down at once? How do I restart then?
",saulshanabrook,highlyunavailable
454,2015-07-28 21:52:26,"Hey @armon

I think there may actually be a bug here though, no?  In order to fix the issue I have to:
1.  Stop consul on all 3 server nodes.
2.  Rewrite /var/lib/consul/raft/peers.json with the correct contents.
3.  Start consul on all 3 server nodes.

The issue with peers.json is the actual contents seem to be written as ""null"".  (Aka the string ""null"").
",jwestboston,armon
454,2015-07-29 22:40:34,"@armon Ahh .. yes .. that does make sense! :-) Thanks for the clarification.  The peers.json file is a list of folks actually, expected to be in the cluster at the current time.  Stopping consul == gracefully exiting the cluster == removal from that list across the cluster.

So really, indeed, things are operating as designed.  And all we need (maybe? perhaps?) is an easier experience for cold restarting an existing Consul cluster.
",jwestboston,armon
454,2016-02-25 09:52:46,"@armon 
I'm having a cluster of 3 nodes on an environment, which is subject to be stopped and restarted in an automated manner.
Since I had trouble with getting the consul cluster up and running again I was looking for the reason why no leader could be elected. 

Regarding your post this seems to be an expected  behaviour. Thanks for your clarification at this point!

Is there any way to prepare the consul cluster for such restarts - like shutting down 2 of 3 instances before stopping the instances?
Beside of telling the nodes that they should not leave gracefully - since the master would have been selected manually in a complicated way (stopping the running service, forcing bootstrapping on this node, starting the service, stopping the service, removing enforced bootstrap, starting the service again)

Is there a feature planned to be implemented in future releases?

Cheers,
Âµatthias
",mwiora,armon
454,2016-09-12 22:18:17,"@slackpad 

I have the good fortune to be able to actually rebuild from scratch without losing any critical data, and yes I'll definitely be using the latest version of Consul to do it. When I get fully rebuilt I will be simulating this same scenario and documenting the results. I'll make sure and update this thread when I do with a step by step guide.
",ljsommer,slackpad
452,2014-11-05 18:14:30,"@iconara Sounds like you guys theory is correct based on the data. Looks like they mistakenly left the ports open and the attempts to heal a failed node managed to merge the clusters. Besides network rules, and encryption we also have an open ticket to avoid merging clusters if the dc's don't match which should add another layer of protection.
",armon,iconara
449,2014-11-07 05:09:40,"@carlanton this should be fixed now in master. Thanks for reporting it!
",ryanuber,carlanton
446,2014-10-31 23:05:00,"Excellent, makes sense, thanks for taking the time to answer my questions @armon!
",c4milo,armon
445,2015-02-21 04:16:58,"As @i0rek mentioned, normally to get file-based logging, you redirect stdout to a file. You can also achieve this by forwarding messages to a syslog server, allowing it to do what it is good at and redirect your logs wherever you want them to go. I'm going to close this, because I don't see us adding this as a core consul feature. Thanks!
",ryanuber,i0rek
443,2014-10-30 20:40:32,"@lra This might just be a bug with how our UI works. The UI is trying to determine if the ACLs are enabled, but since the UI is on the client without `acl_datacenter` it's detection is failing. In this case ACL's are enabled and enforced by the server, but the UI is just mis-reporting as disabled due to how it does it's simple check.

In terms of the ""Access Denied"" message, that is expected. Since you must use a management token to manipulate ACLs, you will need to provide the `acl_master_token` to the UI in the preferences.
",armon,lra
440,2014-10-30 16:37:11,"@lra gossip encryption status should now show up if you build against the latest Serf. I'll leave this open so we can look at doing ACL's as well.
",ryanuber,lra
440,2015-05-18 22:44:19,"@lra There is no way to tell from `consul info`, but you can check the `ACLDatacenter` in /v1/agent/self
",armon,lra
436,2014-10-27 02:26:25,"@sethvargo LGTM, merge away!
",ryanuber,sethvargo
435,2014-10-27 04:28:01,"@sethvargo I had no idea that Google honored these tags, but after looking it up this LGTM!
",ryanuber,sethvargo
434,2014-12-11 19:32:57,"@armon I was seeing it even with fresh data directories iirc. On the initial start it's fine, but after restarting (and preserving the data directory created by 0.4.1), I saw this behavior.
",vito,armon
431,2014-10-24 07:56:06,"@xla This is looking great! I think you've pretty much got it. We aren't breaking backward compatibility, and the implementation is very simple and to the point. It's outside of the scope of this ticket, but it's looking like we need an analogous `checks`-type option to match.

My only recommendation is to add the new `services` config option to `website/source/docs/agent/options.html.markdown`, but I'd be happy to do that after a merge if you prefer.
",ryanuber,xla
431,2014-10-24 19:01:44,"@ryanuber Going to refactor the test and happy to incorporate the documentation changes as well.

Adding another PR for `checks` after sounds like a go way forward.
",xla,ryanuber
431,2014-10-26 18:50:44,"@xla I'm going to merge this in and make the adjustments so we can all start profiting from this. Thanks again, great work!
",ryanuber,xla
431,2014-10-27 18:14:57,"@ryanuber You beat me to it. Thanks for the quick responses on this one.
",xla,ryanuber
427,2014-10-27 18:31:04,"@blalor blah. Sorry - I just saw this. Soooooooooo (prepare), we use a custom middleman extension called [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp). He is open source, but highly customized to our MM installations.

One of the magical things he does is, given a list with a code element in the first:



This automatically gets converted to a named link (so we can link to a specific config item in the documentation).

I **think** that is screwing up your links. Our middleman installation also auto-generates named-header-links (TOC data), so you shouldn't need to manually create them.

This is most likely a bug in middleman-hashicorp, but looking at what you're trying to do, I think it also opens room for new magic.

What we really want to do is have a TOC at the top - I think middleman-hashicorp could be extended to auto-generate that table and links from the H\* tags.
",sethvargo,blalor
427,2014-10-27 18:47:56,"@blalor:



And then browse to `http://localhost:4567`. Note: you need to have a Ruby environment installed and setup as well. 
",sethvargo,blalor
423,2016-02-03 10:22:22,"@armon Has there been any progress on this?
",maticmeznar,armon
421,2015-01-20 16:22:46,"@ryanuber this is done now, correct?
",sethvargo,ryanuber
421,2015-02-20 17:06:16,"@blalor not currently, no. We basically just support setting the address of the HTTP server to `unix://x/y/z` to listen on a domain socket rather than TCP. Could you elaborate on your use case a bit?
",ryanuber,blalor
417,2014-10-21 22:23:16,"@sethvargo The ""HashiCorp Tools"" and ""Community Tools"" headers look... jank. Do we have better styling for those? 
",mitchellh,sethvargo
417,2014-10-21 22:23:31,"@sethvargo I looked around and I guess not. :|
",mitchellh,sethvargo
417,2014-10-21 22:23:46,"@mitchellh yea - that's the standard `<h2>` styling :frowning: 
",sethvargo,mitchellh
416,2014-10-21 20:34:06,"@armon we just kicked off the deploy, but sure :smile: 
",sethvargo,armon
416,2014-10-21 20:34:30,"@armon do you think it would make sense to aggregate all these ""tools"" into their own download page (instead of a separate one for each)?
",sethvargo,armon
416,2014-10-21 20:38:11,"@sethvargo Yeah I think a tool page would be nice. I think we should have a HashiCorp tools page and a community tools page, since there are others we should link to (confd, crypt, consulate, diplomat, some other things)
",armon,sethvargo
414,2016-11-22 19:35:29,@armon has consul auditing been put on the roadmap? We have a requirement for this and looking into options.,fromonesrc,armon
410,2015-05-11 18:21:27,"@ctheune Please send a PR! Happy to review and merge
",armon,ctheune
399,2014-11-25 03:48:16,"Hey @josephholsten, the linked page seems relatively inactive, not having any posts since early October. GitHub is much more visible to us in our daily routine, and responses would likely be a lot faster by opening up a GitHub issue. Between GitHub/Google Groups for async help, and IRC for real-time, I think we have this pretty well covered.

I'm going to close this for now, but if the community on SO fires up again, feel free to let us know! Thanks!
",ryanuber,josephholsten
393,2014-10-12 02:15:27,"I might be somewhat confused here. I think the behavior that @claco is asking for is already available with `-bootstrap-expect`. Once all the servers are online, the leader election is done automatically without having to select a single bootstrap node manually.

@claco Maybe you are referring to the behavior prior to 0.4? We've since changed how bootstrapping is done to simplify.

New method: http://www.consul.io/docs/guides/bootstrapping.html
Old method: http://www.consul.io/docs/guides/manual-bootstrap.html

@ryanuber I think we have a separate ticket open for mDNS. mDNS can be used to remove the ""consul join"" interaction, but the leader election according to `-bootstrap-expect` would be unchanged.
",armon,ryanuber
393,2014-10-25 14:05:38,"@mainframe If that works, cool, and I owe you a beer. :-)
",claco,mainframe
372,2014-09-30 01:41:30,"@armon Thanks for the reply. You are right. The parameter for start cluster is not correct.



should be replaced with



After that it works fine.
",tiw,armon
371,2014-11-28 17:46:30,"The problem is, I don't know how to reproduce this state. Once it has happend on an ec2 cloud.

I tried to reproduce by `consul leave` or `force-leave` a node, but this way the node is listed by `consul members`. The same happens with 0.4.0 and 0.4.1.

If I kill a node, its still listed as _failed_. Somhow we should reach a state whenn `consul members` doesn't lists a node. @armon how long a node stays in _failed_ state? Does it gets removed after a specific time?

@wallnerryan can you reproduce this error?
",lalyos,armon
371,2016-09-21 01:48:24,"@slackpad yep, that was it. Thanks!
",mapa3m,slackpad
368,2014-09-26 03:54:35,"@mfischer-zd the answer actually does look authoritative for the zone, considering the `aa` in the response flags. Dig's `AUTHORITY` field is actually a simple counter for the number of entries in the authority section, and not a true/false type indicator. This isn't clear in the documentation but is easy to spot in dig's source code.

My understanding of stub-zone vs. forwarders is limited, but to me it sounds like the forwarder is actually the more correct configuration in this case since the authoritative servers are known and relatively static.
",ryanuber,mfischer-zd
368,2015-02-09 16:58:45,"@mfischer-zd were you able to configure unbound for consul? If so, could you share your forwarding configuration, can't get it to work myself. Thanks in advance.
",wunki,mfischer-zd
355,2014-09-22 16:34:06,"@drnic The ""nodes"" type watch maps to the ""/v1/catalog/nodes"" endpoint, which does not reflect health information, just a list of the known nodes. Nodes that are in the left/failed state are still in the catalog until they are reaped (~72h).

So you wouldn't expect that view to change, since none of the data in it is. I think there probably should be a /v1/health/nodes endpoint that does include the health data however.

I'm closing the ticket, but let me open a new one for the /v1/health/nodes endpoint!
",armon,drnic
355,2014-09-22 16:47:07,"Thanks @armon !
",drnic,armon
352,2014-09-19 19:29:07,"@imkira This looks like an issue with UDP messages not being properly delivered. This pattern of suspected failure / re-join flapping continuously is exactly what is expected if the client is not handling the UDP messages. Verify that the UDP messages are going through on the UDP port (8301 by default)
",armon,imkira
352,2014-09-24 03:06:54,"@armon thanks for the prompt reply.

The weird part is that, if I were to have any firewall setting problem, it shouldn't go away even if I restart the client consul, right? (By ""restart"" I mean the process itself, not the machine where it runs) But the problem does go away, in fact. I have also noticed that this problem happens not after ""1 day of operation"" like I guessed before, but rather when I put my dev machine to sleep.

Anyway, this is my dev machine and it shouldn't happen (I suppose) in production. I am using docker for running consul1,2,3 (servers) and exposing 8300 8301 8302 8400 8500 8600/udp. Docker is running on top of boot2docker (since I am running it on OSX) and the client agent is running on the host machine itself. I have no firewall settings blocking docker vm (boot2docker) or docker instances to host. Also, host is able to contact docker instances at the exposed ports specified above. It appears I should have 8301/udp listed as you said, but that doesn't seem to be the root of this problem since it runs fine for hours until I put the machine to sleep.

I haven't looked at the implementation part where you are ""handling the UDP messages"", but I am assuming client agents listen to 8301/udp and wait for gossip messages (?) If that is true, might be the case the udp server running on the client agents is getting somewhat ""confused"" after awaking from sleep?
Any other ideas on what may be going wrong?
",imkira,armon
352,2014-11-05 17:00:08,"@outrunthewolf these messages come from way down in the gossip layer (memberlist), indicating a network problem between nodes. If nodes aren't able to successfully send ping/ack messages to one another over UDP, then you will likely see members flapping between dead/alive state.

I would try the suggestions above from @arthurbarr and @dennybaa and see if you can get any mileage out of either solution, or as @armon suggested if you are doing rapid teardown/startup of docker networking, you might want to add a pause in between.

Let us know if you are still having trouble!
",ryanuber,armon
344,2014-10-15 02:23:35,"@armon I've been exploring this a bit today. I noticed that consul itself is what is registering the ""consul"" service. I've been able to also get the service registered in the agent with a few simple lines. I think we can probably take the registration out of consul itself now and let the anti-entropy handle it. The question now is how we get any guarantee that the anti-entropy has run. Right now, `l.changeMade()` is just called from the `AddService()` method on `localState`, so if that runs immediately after starting the server (likely before any leader is elected), I'm not sure it will work reliably. This definitely creates problems for the tests as well.

Any ideas on how to better approach this?
",ryanuber,armon
343,2014-09-19 13:04:48,"@tiwilliam Nice!
",pearkes,tiwilliam
342,2014-09-15 21:25:46,"@hoffoo There is no way currently, but this seems to be common feedback which we will try to address with a parameter to suppress the initial callback.
",armon,hoffoo
341,2014-10-20 18:40:04,"Thanks, @ryanuber. I'm using the /v1/health/service REST API since the /v1/catalog/service doesn't expose information about health checks. 
",plorenz,ryanuber
341,2014-10-20 19:23:19,"I've separated this into another issue after @armon's comment - I have reproduced this and will look into it. @plorenz have a look at #413, we will track it there.
",ryanuber,armon
339,2015-01-02 09:26:36,"@ryanuber Sorry not working with Consul anymore so no I haven't
",failattu,ryanuber
336,2014-09-22 16:30:32,"@ryanuber Oh since using the event on the WAN won't rotate the remote LAN's?
",armon,ryanuber
336,2014-09-23 06:59:10,"@armon yeah exactly. Initially I was thinking we would just have new keys gossiped to all of the nodes and a collective response returned, which seems desirable from the operator's perspective. The alternative is to have like a `-datacenter` flag and a `-wan` flag, and require the operator to run the key rotation for each datacenter plus the wan keyring. I was going to give the former a shot first to see how feasible that ends up being. Let me know if there is a better way of doing this that I'm not thinking of.
",ryanuber,armon
336,2014-10-02 07:05:29,"Thanks, @armon! Always appreciate your code reviews. I left a few comments inline above regarding the generalized `globalRPC` method. Let me know if it makes sense, and I'll address the other suggestions tomorrow.
",ryanuber,armon
336,2014-10-09 17:45:09,"@armon I think this is better now! There are just a couple of things I want to run by you.
1. Anyone currently using the `-encrypt` flag, and rebooting their clusters to change keys will have broken workflows after their next upgrade. Starting with the `-encrypt` flag will work as they would expect, but changing the `-encrypt` value and restarting the agent would not have the same effect as before.
2. I noticed that the WAN keyring is the slowest to respond to keyring queries. I can get a fast response from all LAN pools (~10-15ms total on 10-DC local cluster), but the WAN pool, even on a completely local cluster with multiple DC's, can take up to ~400ms on its own. I though this might have something to do with the timing values being different for the WAN pool, but thought I'd run it by you to see what you think.
3. `globalRPC` simply forwards to all nodes, including the local DC. I used `forwardDC` for this since `forward` skips the local DC and also checks if we can tolerate stale reads and does leader forwarding, which doesn't seem applicable to the `globalRPC` method.
",ryanuber,armon
327,2014-10-09 21:15:54,"@awheeler exec can be disabled via config, so I guess only a config to disable script based checks would be necessary.
",armon,awheeler
327,2015-05-27 07:12:21,"@awheeler @alexhudson See my comment in https://github.com/hashicorp/consul/issues/532, there I propose a mechanism that makes `exec` more safe. Further one could add something like a `checks_engine` option to the agents config. Then you would have all the flexibility to handle a secure exec (in your own terms) on your own.
",kaelumania,awheeler
327,2015-06-01 13:11:14,"@armon SSH provides a similar solution, for example see http://binblog.info/2008/10/20/openssh-going-flexible-with-forced-commands/
",kaelumania,armon
320,2014-09-05 02:42:40,"Hi, @armon 

Under etcd, When I watch and wait a directory like this:



And I update the file `/dir/sub/file2`

The ""blocking query"" will just return one kv pair which was changed.



But under consul, when I use `recurse&index=xx`, the query always returns all of the nodes.

Regards.
",yzprofile,armon
320,2014-09-06 14:32:05,"@armon Do you plan on supporting this eventually? I've been looking at using Consul as my main cross-cluster synchronization/messaging mechanism(service A updates state, service B discovers change and applies it to its own state), but since the entire tree that I am watching is relatively big, getting it all at once is impractical.
",dalegaard,armon
314,2014-09-02 17:05:41,"@drnic I think your version of Serf is out of date. Did you try ""go get -u ./...""
",armon,drnic
307,2014-08-29 00:41:50,"@josephholsten That is correct!
",armon,josephholsten
307,2014-08-29 00:55:07,"@josephholsten Thanks! Fixed in master.
",armon,josephholsten
305,2015-02-21 05:10:39,"@blalor good catch. We actually _do_ have the proper anchors and links, but I think this is a regression. I opened hashicorp/middleman-hashicorp#6 for this. Thanks!
",ryanuber,blalor
300,2014-08-25 06:50:35,"Hey @armon thank you for the prompt support!
I got the latest source and ran consul but it doesn't seem to address the bug I am reporting.

Sorry for not putting it together as a test.go file, but here is a gist that reproduces the bug.

https://gist.github.com/imkira/f40e64d00583160c0c9f

As initially reported, I get two bug patterns:
- len(Checks) between calls to health/service differs (0 vs 1, 1 vs 2, ...)
- number of Checks matches but newly registered service status doesn't (unknown vs passing)

Let me know if you can fix this.
Thank you in advance.
",imkira,armon
300,2014-08-25 18:03:00,"@imkira I am unable to reproduce the error with you test code running against master. Can you verify you re-built against master? Also a gist of the error output could be useful.
",armon,imkira
298,2014-08-22 11:57:15,"Great work @armon!
",tiwilliam,armon
294,2014-11-19 17:31:41,"@i0rek The problem is a tag could be ""foo.bar"", which is hard to disambiguate from ""foo"" and ""bar"" or just ""foo.bar"".
",armon,i0rek
294,2014-11-19 20:59:13,"@armon it already is a problem, no? service ""foo.bar"" VS service ""bar"" and tag ""foo"".
",i0rek,armon
290,2015-08-22 10:55:12,"@slackpad that sounds great! I was going to try and hack it by creating a namespace/directory for each tenant and then restricting accordingly. But the benefits of preventing leaking via service registration and DNS have convinced me I should hold off.

If there's some way to help with the development let me know. I'd like to try and do more than add another +1 :smile: 
",glenngillen,slackpad
290,2015-08-31 23:13:36,"@scalp42 I'm not sure I follow. The ACLs should be rich enough for you to provide read-only access to services if so desired. Do you have a specific use case in mind that we wouldn't hit?
",slackpad,scalp42
287,2015-02-08 00:04:15,"@armon is there any roadmap for this?
",niclashoyer,armon
284,2014-08-23 00:27:54,"Thanks @miekg and @armon. We don't have a test case per se but I can patch a dev server and see how it holds up. We finally encountered another panic recently but I haven't gotten the scrubbed packet capture from my ops guy yet. I'll email that once I have it so maybe we can construct a test case for the future.
",payoffstan,armon
266,2014-08-01 17:53:11,"Yeah as mentioned by @wuub, it is already handled automatically. We will add a flag to tune that ""reap"" interval, so you can change it from 72h as you see fit.
",armon,wuub
263,2014-07-31 17:53:09,"@mtchavez hey! I like that idea and placing. If we have that row there, we can probably move the IP down as well.
",pearkes,mtchavez
262,2015-02-21 04:03:30,"@armon is this partially solved by the new `consul lock -n` semaphore?
",ryanuber,armon
260,2015-01-09 15:44:47,"@armon Awesome, this is much appreciated!
",sandstrom,armon
259,2016-05-27 02:28:43,"I think @raboof  point is right. If the consul-externalservice node goes down all the external services go down too.
I understand the reasoning for not adding scripted health check for external services, but a TTL would solve most of this problems cleanly. I could register an external service with a TTL and then it is my responsibility to do the checking and update consul with the result.
If my service/application goes down, it will be marked as unhealthy after it misses its TTL.
",mterron,raboof
258,2014-07-23 18:40:41,"@armon this was brought to my attention last night by a co-worker of mine. I agree that service checks should be marked as _critical_ if the serfHealth check becomes critical. If it is not, then I believe it will become a common pattern in the application layer to check for both the status of the service check AND the status of the serfHealth check on a node.

@chrisDeFouRire as a side note: we're also using Consul in the online gaming space and it's been great to us, too!
",reset,armon
258,2014-07-23 19:05:26,"@armon If that is the case I think you're right and it's probably best leave this up to the application level to determine what a healthy check looks like. Perhaps a healthy check to some applications are not just the service but also the status of serf.
",reset,armon
257,2014-07-25 23:47:01,"Thanks for the pointers guys!

@armon What I was thinking for ""service deregister"" was if you had some service that had died/been killed without deregistering, while serfHealth stands strong. Perhaps another has been started on the same node with a new ID so you don't want to deregister the whole node. Is that an alright use case?

@pearkes I haven't found a good place to fit a row of buttons... but what about a standard Bootstrap dropdown placed somewhere in the top? Picture shows two possible places for that. Also featured is an attempt at anti-blockiness and squeezing in some more useful service details (namely service ID and port).

![screen shot 2014-07-25 at 4 44 58 pm](https://cloud.githubusercontent.com/assets/211613/3709438/ee89ca22-1455-11e4-8d69-28617563aa0f.png)
",spro,pearkes
257,2014-07-25 23:47:01,"Thanks for the pointers guys!

@armon What I was thinking for ""service deregister"" was if you had some service that had died/been killed without deregistering, while serfHealth stands strong. Perhaps another has been started on the same node with a new ID so you don't want to deregister the whole node. Is that an alright use case?

@pearkes I haven't found a good place to fit a row of buttons... but what about a standard Bootstrap dropdown placed somewhere in the top? Picture shows two possible places for that. Also featured is an attempt at anti-blockiness and squeezing in some more useful service details (namely service ID and port).

![screen shot 2014-07-25 at 4 44 58 pm](https://cloud.githubusercontent.com/assets/211613/3709438/ee89ca22-1455-11e4-8d69-28617563aa0f.png)
",spro,armon
254,2014-07-22 15:05:59,"With the new fix @armon, it looks like cluster bootstrapped normally with 3 nodes no problems)
Btw could you please tell if it's okay already preparing to use consul in production? Because now I get constant flapping of agent states  and it's seems a bit suspicious...?
https://gist.github.com/dennybaa/c09d56723bdf4d42e247
",dennybaa,armon
254,2014-07-22 15:24:51,"Oh, thanks a lot @armon. It's exactly docker! About `-bootstrap-expect` awesome I will mind this.
",dennybaa,armon
252,2016-01-13 22:33:47,"@a86c6f7964 prepared queries can help across datacenters for sure (using pre-configured fallbacks or network coordinates, or both). Within a datacenter, many HTTP endpoints now support the `?near=` argument that lets you find the closest service, but this issue still stands for a more general weighting feature.
",slackpad,a86c6f7964
252,2016-03-27 07:26:46,"While not exactly server priorities, many on this issue have referenced automatic DC failover as a reason for wanting server priorities.  As @slackpad mentioned earlier, with Prepared Queries this is possible, and has been made easier with Prepared Query Templates.  We held a webinar and covered this at around minute 31.

https://www.youtube.com/watch?v=FGbzS6ripXA&feature=youtu.be&t=1690
",sean-,slackpad
250,2014-07-18 07:42:03,"Thanks @armon ! That's exactly what I need to adjust to a lower limit...

Sorry I didn't find it by myself... I guess I was mislead by my `curl`attempt which did hit the agent instead of a server (so the API seemed to answer immediate values, while the GUI lagged by 5m)...
",chrisDeFouRire,armon
246,2014-07-15 17:05:31,"@ryanuber I don't see any potential caveats off the top of my head... I think its actually a bit simpler since Consul requires a data directory, we have a convenient location to put the key ring file.
",armon,ryanuber
246,2014-07-15 21:14:38,"Related is a request to allow symmetric encryption of RPC messages -- I'd love to have rotation for both. I chatted with @armon a bit about this today...I have some ideas for how it could work, and for what caveats you'd want to put in your documentation about security guarantees vs. TLS. If you are using symmetric encryption for RPC messages, rotation is really something that you need.
",jefferai,armon
233,2014-06-30 01:25:29,"@armon Thanks! I think these are the tests I wanted, so I'm now happy with this.

`wrapTLSclient` is mostly copied from http://golang.org/src/pkg/crypto/tls/handshake_client.go#L235 if that makes you feel any better about it.
",nelhage,armon
230,2014-06-29 01:52:17,"@abursavich Hmm that is a good point. I think you are right, the agent will deregister them when anti-entropy happens.
",armon,abursavich
228,2014-06-23 18:56:37,"@drnic AFAIK the behavior of linux resolver is to failover to next nameservers defined in /etc/resolv.conf only if the previous one is **timed out**. Once a nameserver responds to the query (either with failure or success), the resolver process is over.
In your case, if consul agent is available, secondary nameservers are always bypassed.
",salehe,drnic
224,2014-07-16 17:57:11,"@tiwilliam Sorry, didn't realize this was waiting for so long! I don't think we want to modify the structs directly, since I think it is weird from a user perspective to put ""Node Foo"" in and get ""node foo"" out. I think it's better to preserve the case, but do insensitive lookups. 

My thinking so far has been to add maybe a `CaseInsensitive` bool to `MDBIndex`, and basically push this into the index level. This way the structs are not modified, only the indexes on top. Thoughts?
",armon,tiwilliam
224,2014-07-23 08:38:48,"Alright, so this is what I've done now:
- Lowercased incoming DNS query
- Added `CaseInsensitive` to `MDBIndex`
- Set Node and ServiceName indices to be case-insensitive
- Made the service tag filter case-insensitive

So my previous two test cases work as expected but I'm not sure how we should treat datacenters. @armon any thoughts?
",tiwilliam,armon
224,2014-07-23 13:42:23,"@tiwilliam Awesome! This is looking great. I think we take the simplest approach with the DC and just lower-case it in the configuration. We may need to add some additional hacks to prevent Consul from being confused if it joins ""Datacenter"" when it is in ""datacenter""
",armon,tiwilliam
208,2014-07-11 09:34:30,"@armon this is very interesting. are there any active work/design going on, or is it only an idea?
",wuub,armon
208,2014-07-11 17:53:29,"@wuub No active work on this yet, but its in the design phase you could say. Definitely something I'm keen to support!
",armon,wuub
208,2014-10-27 17:17:55,"@mfischer-zd As a note, this ticket will only affect DNS and not the KV store
",armon,mfischer-zd
208,2014-10-27 17:19:34,"@armon understood - this would affect how the Consul HTTP server (which would be accessible remotely) would be resolved.
",mfischer-zd,armon
208,2014-10-27 17:22:24,"No, I don't think so. It would affect the answers you got back from the
consul server you send DNS queries to.

On Mon, Oct 27, 2014, 1:19 PM Michael S. Fischer notifications@github.com
wrote:

> @armon https://github.com/armon understood - this would affect how the
> Consul HTTP server (which would be accessible remotely) would be resolved.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/208#issuecomment-60631558.
",andrewwatson,armon
208,2014-10-27 17:25:34,"@andrewwatson in my scenario I have two separate Consul clusters, one configured in the usual way (cluster A), and another that provides a replicated K/V store (cluster B, running on a dedicated set of hosts which does not include the clients).  Cluster A would be used by clients to perform DNS queries to resolve members of Cluster B.  

So really we're saying the same thing.
",mfischer-zd,andrewwatson
208,2015-04-08 15:54:03,"@mfischer-zd then you have to implement and configure some other piece of software to do this, when Consul already knows where things live.
",jefferai,mfischer-zd
208,2015-07-23 13:56:05,"Thanks @armon - what's the release timescale on those?
",StephenTallamy,armon
206,2014-06-12 17:40:38,"@tarrant On thinking about this more, I think a few more pieces are clear:

1) There is increased Serf traffic because we now send the ""build"" tag with the version (e.g. 0.3rc). Since you are doing a rolling upgrade, all the clients are sending new ""alive"" messages to update the tags. This will cause some temporary congestion on a very large cluster like yours, since effective throughput is only about 40-80 updates/sec with Serf. This is not an issue, since Serf is designed to be eventually consistent.

2) The increased activity causes increased logging, and for some reason the syslog write is blocking.

3) Once the process locks up in the write, other nodes detect a failure (since the agent is not responding to ping messages).

So, I think the root issue here is the blocking syslog. The other pieces of this make sense.
",armon,tarrant
197,2014-06-08 20:18:20,"@andrewwatson UI is not tested via Travis no worries. I will let @pearkes review and merge this since he is owning the UI.
",armon,andrewwatson
197,2014-06-11 13:00:37,"@andrewwatson Does the above make sense? Let me know if not and I can implement separately.
",pearkes,andrewwatson
189,2014-06-12 16:59:18,"@tiwilliam Awesome. I'd love to talk more about this while you are working on it. I think that largely we can do this all in the state store by just doing a ToLower on all the indexes and corresponding read values. I think most of the changes can actually be localized to the MDBTable
",armon,tiwilliam
184,2014-06-02 21:31:25,"Thanks @armon. I would be good to highlight that in the docs.
",c4milo,armon
181,2014-06-02 02:11:06,"@andrewwatson I think we will be rethinking bootstrap for 0.4 entirely. Most likely, instead we will have something like ""-bootstrap-servers 3"" which instead can be set on all servers, waiting until 3 servers are available to do the initial bootstrap. This should make it much simpler since they can come up in any order without a single special node.
",armon,andrewwatson
181,2014-06-02 11:42:50,"@armon Forgive my ignorance, but why is it necessary to specify N at all? Couldn't an election be held in respond to _any_ membership event in the absence of a leader provided a majority?

To elaborateâ€”a single node doesn't accept writes. When another node joins, they elect a leader. If a third node joins, no election is necessary. If the leader is partitioned from the rest of the nodes, the leader steps down and doesn't accept writes (holding the invariant above). The other side of the partition notices the leader has failed/left and those nodes hold an election since they have a quorum (N/2 + 1) based on the previous N = 3. 

Again, I'm no expert but something like this seems to eliminate the need to specify N explicitly. I also haven't thought through all the implications when a (set of) node(s) is ""flapping"". I bring up the idea mainly to spark some interesting dialogue and learn something. 

Cheers...

Edits: change 1 to majority, change majority to quorum
",christianromney,armon
181,2014-06-02 14:26:20,"@christianromney it could be that the algorithm isn't reliable with < 3 nodes.  @armon are you thinking of the  Bully Algorithm http://en.wikipedia.org/wiki/Bully_algorithm?  Seems like you'd have to have tight clock sync to prevent two bullies from electing themselves.
",andrewwatson,armon
181,2014-06-02 14:26:20,"@christianromney it could be that the algorithm isn't reliable with < 3 nodes.  @armon are you thinking of the  Bully Algorithm http://en.wikipedia.org/wiki/Bully_algorithm?  Seems like you'd have to have tight clock sync to prevent two bullies from electing themselves.
",andrewwatson,christianromney
181,2014-06-02 14:40:25,"@andrewwatson I'm re-reading [this](http://www.consul.io/docs/internals/consensus.html) (and the Raft paper) to educate myself further. Paragraph 6 on the Consensus Protocol page gives a good example of this situation when we have only 2 peers. Of course, the 2-peer ""problem"" is just a special case of the general even-numbered peer problem. 

Edit:
I did want to add that what I'm trying to advocate is not a particular algorithm since I obviously lack the requisite expertise to do so, but rather a means of forming a cluster that involves as little ""special case"" intervention as possible. Omitting the specification of N may not be possible (and I would like to understand why) but even @armon's suggested mechanics above are a big improvement over the current bootstrapping dance. The two problems of setup and consensus are orthogonal as even in the current bootstrap process there is a point in time when a 3-peer cluster becomes a 2-peer cluster (when the bootstrapped peer leaves) prior to the former leader re-joining.
",christianromney,armon
181,2014-06-02 14:40:25,"@andrewwatson I'm re-reading [this](http://www.consul.io/docs/internals/consensus.html) (and the Raft paper) to educate myself further. Paragraph 6 on the Consensus Protocol page gives a good example of this situation when we have only 2 peers. Of course, the 2-peer ""problem"" is just a special case of the general even-numbered peer problem. 

Edit:
I did want to add that what I'm trying to advocate is not a particular algorithm since I obviously lack the requisite expertise to do so, but rather a means of forming a cluster that involves as little ""special case"" intervention as possible. Omitting the specification of N may not be possible (and I would like to understand why) but even @armon's suggested mechanics above are a big improvement over the current bootstrapping dance. The two problems of setup and consensus are orthogonal as even in the current bootstrap process there is a point in time when a 3-peer cluster becomes a 2-peer cluster (when the bootstrapped peer leaves) prior to the former leader re-joining.
",christianromney,andrewwatson
181,2014-06-02 21:41:04,"@armon thanks for the explanationâ€”that makes perfect sense. 
",christianromney,armon
180,2014-06-02 04:25:44,"In my opinion, no, there should not be an option for a normal user to list these entries. The idea is that they are hidden from enumeration and by using one that is random and long, you can store entries in consul that are undiscoverable by others.

@armon An administrator, though, should have a way to do that. Adding such an ability is tricky because there isn't currently an admin mode. Is a configured token that can be presented by an admin be enough?

This (as well as this evenings BBQ with @mitchellh) has made me realize perhaps we should put energy into a ACL/capabilities system instead, since dealing with all of the side effects of hidden entries may result in more changes that a proper ACL system.

@armon Love to chat about that on Tuesday!
",evanphx,armon
180,2014-06-02 21:36:24,"Just food for thought, I've said this privately before but I think its worth bringing up in public forum:

I think an ACL system begets hidden keys in a more correct way. As @tiwilliam said, and as I know everyone in this thread so far is aware, the hidden dot-prefixed files in Unix was never a point of security. Adding hidden keys would be easy if we had a flag or attributes bitmask internally on keys (UX issues aside). An ACL system would likely require some sort of attribute/flag system for marking permission bits, and it would be interesting there to perhaps discuss hidden keys. But it might turn out that the semantics of an ACL make it such that hidden keys are no longer necessary.

Either way, I think discussing ACLs is the proper discussion.
",mitchellh,tiwilliam
172,2014-12-13 06:18:43,"Closed by @amalaviy via #524 
",armon,amalaviy
169,2014-08-04 16:48:31,"@blalor It should have broken the DNS parser to have a DC like that. Were you using the DNS interface at all? 

We must have mistakenly failed to put it in the change log.
",armon,blalor
166,2014-05-22 20:25:22,"@armon The node isn't even listening on port 8500
",bscott,armon
166,2014-05-23 00:33:59,"@armon Yes, the agent is starting and joining the cluster.
",bscott,armon
166,2014-05-29 16:14:45,"@armon: The UI >does< work on Windows when I compiled the latest version from source (re: 
https://github.com/hashicorp/consul/issues/177#issuecomment-44442962).
",webcoyote,armon
166,2015-11-23 17:52:58,"@slackpad I mean this:



I also get a 200 and the same response on the body of the client if I do not specify `ui_dir`. However, as soon as I enable it I get a 301 on both the root and `/ui` endpoints. Why does root `/` redirect to `/ui`, is that intended or is that a side-effect on some misconfiguration on my part?
",calvn,slackpad
166,2015-11-23 21:22:33,"@slackpad @hridyeshpant Got it working by adding this to my `config.json`:



As explained in #599 the client binds the HTTP address to localhost by default so within the client you're able to curl the `/ui` endpoint, but you'll just get `connection refused` if you try to resolve it from the outside. 

I'd suggest to update the docs on the Web-UI page so that it explicitly states that the default config only enables the UI within `localhost`.
",calvn,slackpad
166,2016-07-19 17:29:35,"@slackpad Thanks. When I try to hit the URL http://xx.xxx.xxx.xx:8500/ui/ from the browser, it says ""Failed to Open Page"". I have opened the ports on the server but still the same problem.


",gvenka008c,slackpad
166,2016-07-19 17:47:39,"@slackpad I started consul with -client argument and that fixed the issues.


",gvenka008c,slackpad
165,2014-06-06 15:40:38,"@tarrant Agreed, I kind of got it in there as a stub for now, still working out tags for the 0.3 release

@andrewwatson Would be great to see a PR if you're able!
",pearkes,andrewwatson
165,2014-06-06 15:40:38,"@tarrant Agreed, I kind of got it in there as a stub for now, still working out tags for the 0.3 release

@andrewwatson Would be great to see a PR if you're able!
",pearkes,tarrant
164,2014-05-22 17:41:08,"@drnic For any of the hosts that are returning that tag value, can you run: `curl localhost:8500/v1/agent/services`?

I've grepped the code and don't see that string anywhere on our side
",armon,drnic
159,2014-05-22 17:46:49,"@jim80net There was a missing file that @ryanuber fixed. Could you try again? I think that the cgo support for SmartOS is limited, which may prevent Consul from compiling.
",armon,ryanuber
159,2015-11-29 12:22:27,"Thanks @slackpad! Managed to get it to build with your tips :+1:  
I'll break this out into an optional step in my Ansible role using a patch from the changes I made to get it to build.  

I'll likely be doing automated builds, and host a zipped archive for the amd64 binary for Solaris (more specifically, illumos/SmartOS) systems on my personal domain: http://cmacr.ae/consul/solaris_amd64.zip
Mostly for my own convenience, but, others can grab it too, if they so wish :)

EDIT: Chucked a quick page together for builds: http://cmacr.ae/consul/
",cmacrae,slackpad
159,2015-12-11 10:57:38,"@MerlinDMC Thanks for pointing this out - these patches were chucked together quickly one evening after work, and I haven't had time to review them properly. Given the fact that this now seems to be moving toward to an official pkgsrc port at Joyent, I trust that those involved will address any issues posed by my hasty patching ;)
",cmacrae,MerlinDMC
159,2015-12-11 16:37:04,"@MerlinDMC thanks for this, I'm able to get hashicorp/vault almost built as well.  Looking now at patching both vault and consul to use [bgentry/speakeasy](https://github.com/bgentry/speakeasy) for cross-platform getpasswd support.
",doublerebel,MerlinDMC
159,2016-01-06 10:14:32,"Awesome! Thanks @slackpad & @jen20 :+1: 
",cmacrae,slackpad
155,2014-05-16 07:30:01,"@armon : Imagine we have a same service running on multiple servers, but that we segregate different pool of users to a specific subset of those hosts for whatever reason (performance, multitenancy, etc ...)

We can use service tags to automate reverse proxy's upstream lists, but when we switch one server from one pool to an other, we have to deploy a new service.json file on each host and then SIGHUP consul

It would come in handy to allow this tag update thru HTTP and RPC, but we would then need to persist this change upon the next server restart/failure to make sure it gets back to the desired upstream pool and not to the one that it was first deployed with

EDIT: Of course it should work with node tags as well #154 
",XavM,armon
155,2015-02-18 06:36:36,"@armon: Thank you so much !!
",XavM,armon
155,2015-02-18 18:44:44,"Yes thanks @armon !
",darron,armon
154,2015-02-22 20:45:03,"I agree with @armon, having node-level tags seems reasonably useful. I think this would provide enough functionality to add ""facts"" about nodes by use of tags without needing to support specific fact generation systems like Ohai, facter, etc.
",ryanuber,armon
154,2017-01-05 07:29:34,"I didn't quite follow the /dev/null approach. Does this refer to registering the service with a dummy check and tag the service to our needs? In this case I am assuming the service names can be the same.

Particularly interested in the behavior, where lets say 

Service A was tagged with Tag1, Tag2 & Tag3 in Node1
Service A was tagged with Tag 2, Tag3, Tag4 in Node 2

Will querying for Service A and Tag 1 yield Node 1, Service A and Tag 2 return Node 1 & 2?

Looking to try this out today but @ybogdanov and @scalp42 if you are aware of the behavior please let me know.
",gamefundas,scalp42
148,2014-06-11 10:52:52,"@armon Thanks!
",davidfeldi,armon
136,2014-05-16 20:52:43,"@tiwilliam Awesome work. Thanks so much, it'll be great to have the tests be more reliable.
",armon,tiwilliam
136,2014-05-16 22:03:46,"@tiwilliam Actually, I'm going to merge this in now! We can port the tests in master!
",armon,tiwilliam
134,2014-05-22 17:35:36,"And to perhaps address the original issue, we've been bouncing ideas for long-running processes to avoid the fork/exec cost for thousands of services. Is this what you were thinking @armon?
",mitchellh,armon
131,2015-04-07 18:22:29,"@discordianfish Which numbers are you referring to? We switched to a solution where we wait for the leader until it is elected using polling and then have a timeout for failure. That replaced using estimated sleeps in tests.
",tiwilliam,discordianfish
126,2016-01-15 13:18:22,"@armon -- I know this is closed but I stumbled over this as well. And I think there could be a better solution: **Two** domains could be specified, one for node's one for service's. Default would just prefix a singular domain with `.node` and `.service` as before. 

This would vastly simplify non-greenfield integrations -- especially if a _new_ environment is connected to the _legacy_ (seen that a few times) world and naming for nodes _connected_ needs to follow some archaic internal DNS-guideline.
",LeDominik,armon
126,2016-06-02 19:43:21,"@armon @slackpad 
Before I try to dig into the code, would you like to accept pull requests? May be I have some time in two or three month.

EDIT: my proposal fixes #215. It's not really broken, but it gives @darron ability to work around his problem.
",Bessonov,armon
126,2016-06-02 19:43:21,"@armon @slackpad 
Before I try to dig into the code, would you like to accept pull requests? May be I have some time in two or three month.

EDIT: my proposal fixes #215. It's not really broken, but it gives @darron ability to work around his problem.
",Bessonov,slackpad
126,2016-08-14 20:42:46,"@slackpad I don't used it before, but I can give it a try. Hopefully this year. Thank you!
",Bessonov,slackpad
124,2014-05-05 01:09:07,"@tiwilliam The ""folder"" view is just imposed by the UI. There is no actual folder structure. So if the only key is ""1/2/3/4"" and that key is removed, then those ""folders"" also are removed. Does that make sense?
",armon,tiwilliam
124,2014-05-05 07:57:13,"@armon Thanks for explaining! This should now work as expected and redirect to nearest existing parent on delete or pop back to root if needed.
",tiwilliam,armon
121,2014-06-06 23:04:40,"I think this is an abstraction leakage the client should not worry about. If I'm correct, @blalor you've found a way to not need this. Closing.
",armon,blalor
121,2014-06-07 03:45:42,"Not really, I just ignored the problem for now. The leader election discussed in the now-missing Consul docs look good, however. I'm hoping that's in. 0.3! :-)

## 

Brian Lalor
blalor@bravo5.org

> On Jun 6, 2014, at 7:04 PM, Armon Dadgar notifications@github.com wrote:
> 
> I think this is an abstraction leakage the client should not worry about. If I'm correct, @blalor you've found a way to not need this. Closing.
> 
> â€”
> Reply to this email directly or view it on GitHub.
",blalor,blalor
121,2014-06-07 04:28:46,"@blalor If its in master ,it'll be in 0.3. :)
",mitchellh,blalor
112,2014-05-03 16:23:58,"We're planning on implementing an event system into Consul in the near, but not short, term. 

@josephholsten It will be turing complete: it will just be shell scripts that are executed that are under contract to finish within a timely manner. If they need to spend a longer time, they should detach off.
",mitchellh,josephholsten
111,2014-05-02 22:30:56,"@armon Thanks!, I was just reading the code in consul and figured that out. 
",bscott,armon
110,2014-05-04 20:30:14,"@blalor: Not sure i get your question right; What i meant : 

Upon start up, the consul agent queries the DNS (the one you have specified with the new suggested configuration key, or the one set in resolv.conf) for the SRV record ""consul.service.consul"", then, the DNS answers the list of available servers (including ips and associated ports) where you can join an existing consul cluster

The DNS you query could be an existing consul cluster, or your main DNS server (bind, dnsmasq, etc ...) that you have previously setup to forward queries to Consul as appropriate (when zone is ""consul"")

My point was : Consul is designed for service discovery; Why not use consul to discover existing and healthy consul cluster members

PS : of course, the SRV lookup should use the ""domain"" configuration key when specified, and only fall back to the ""consul"" default domain when missing
",XavM,blalor
110,2014-05-04 20:57:06,"@armon: Thank you for your answer

I think i must have missed your point (sorry about that)

Regarding the consul join command with a DNS host name, you have to know which host is up, is running consul (and on which port) and is member in the desired cluster, meaning you still have to maintain a hard-coded list of hosts:ports to join on startup

A rejoin using old cached member information could fail due to a stale cache (Depending on how long the node has been down, the topology could have change)

Any way, thank you for this promising solution; I am sure you will make the best choice

---

Edit :
@armon: After I have seen your previous response, I tried to join using ""consul join consul.service.consul"" and it works brilliantly !! (The doc does not mention it)
",XavM,armon
110,2014-05-04 21:37:39,"@blalor This actually does not solve the chicken and egg issue. This solution assumes that the DNS servers exist at a well known address to begin with (otherwise the SRV record would fail with no DNS server). At some point, there must be a well known address, that may be Consul or it may be DNS.

My suggestion is to because this is unescapable, simply run Consul on the DNS server. You need a well known address for at least one of them, this way it is 2 birds with one stone. Doing this allows you do use DNS to join the cluster without making any changes to Consul.

If you have 3 well known DNS addresses, then the DNS lookup for ""consul.service.consul"" will work unless all the DNS nodes are down, which is unlikely. Hope that helps.
",armon,blalor
110,2014-05-04 21:45:07,"@blalor Can you have a cron job on the consul servers that writes their IP to Route53 every few minutes? This way you can just join a well known address that is relatively up to date. It is only the initial join that is an issue, since moving forward we will be adding the re-join support.
",armon,blalor
110,2014-05-04 22:44:41,"@blalor Why do you need the leader node specifically? You only need to do a join with any node, so it doesn't need to be the leader. It is totally fine if `server-a` overwrites the record of `server-b`, since a join to any of them will succeed. 

Trying to ensure only a single write from the cluster leader only seems like an optimization that isn't necessary due to the nature of the gossip and the join. If you just have a cron on the servers, allowing an override, then even when you decommission, one of the remaining live nodes will update the record by overwriting it.
",armon,blalor
108,2014-05-02 22:26:31,"@armon Thanks, I'll give it a try now
",bscott,armon
104,2014-05-02 03:23:26,"@blalor This is valid as well, opening an issue.
",mitchellh,blalor
104,2014-05-12 13:25:54,"I think @mitchellh's note about daemonization is also valid about logging. It's up to the service manager to handle log output of a process on it's standard output.
",salehe,mitchellh
104,2016-05-11 07:54:37,"Hi, I was wondering if there is any easy way to know when consul has finished bootstrapping. I explain my case:

I have a systemd service that launches consul at boot. I have other services that dependes of consul, so they should start when consul has finished starting. The problem is that with systemd files, the service is considered active at the moment the command is executed. (this happends when de _Type_ is set to default, but I didn't find any other Type useful to this case). So the next services start when consul hasn't finished bootstraping, resulting on several problems. 

I thought that maybe it was a good idea to modify consul and set somethig like docker has to notify when it has finished bootstraping: [docker-systemd-notify](https://github.com/docker/docker/blob/master/cmd/dockerd/daemon_linux.go), but I guess that this contradicts what @mitchellh said of leaving daemonization to a higher level.

So I thought about wrapping the consul service with something that checks that consul has finished and make the nofity. In this case, my initial idea was to make request to `/v1/status/leader` every second and when the request's reponse was ok, then notify. But I don't know if there's a better way of doing this.

Thanks!
",jorgemarey,mitchellh
96,2014-04-30 19:36:05,"@gmr That was also an issue with 0.1. Fix is in master.
",armon,gmr
95,2014-04-30 19:03:24,"@gmr Thanks for the report. This is a 0.1, and is fixed in master. Fix will be in 0.2 going out tomorrow.
",armon,gmr
86,2014-04-29 05:22:25,"@tarrant Thanks for reporting. It is mostly cosmetic, but this is an issue with Serf. Nothing to worry about since the behavior will be correct, but shouldn't be happening nonetheless. I'll get back to you when I know more.
",armon,tarrant
86,2014-04-29 19:31:12,"@tarrant This should be fixed by https://github.com/hashicorp/memberlist/commit/2595b7e29e0fb25891b9f131151020aa5ac6ba5a. Turns out to be caused by a subtle issue around metadata changes when there is no graceful leave and before the failure detector notices the node has failed. Let me know if you are able to reproduce this issue with the fix.
",armon,tarrant
84,2014-05-05 01:44:25,"@twirrim dnsmasq can not cache a record if the original TTL is 0. As @armon mentioned, having the TTL 0 by default but making it configurable makes sense.

This feature is necessary for my applications which already have a local dnsmasq running to reduce read latency.
",ijin,armon
75,2014-04-24 15:40:21,"I agree with @mitchellh. I think having a Synapse plugin would be great. No need to re-invent the wheel! 
",armon,mitchellh
75,2015-01-10 00:09:40,"We're shopping for nicer solutions to this as well. @mitchellh I just watched your recent dockercon presentation and you mentioned it's on the roadmap for Consul, do you think that's a near-future feature? Cutting out that extra layer for our small team would be awesome!
",tj,mitchellh
74,2016-01-16 21:39:49,"@highlyunavailable  @StefanScherer Hi again Stefan, after finding this thread and spending ages trying to build on ARM docker.. the binary comes as welcome news. We really need some official ARM images for things like Consul.

Ref: https://github.com/hashicorp/consul/issues/125 (says no consul binary available on arm)

I'm trying to set up a multi-host docker 1.9.1 ARM cluster with swarm, so the documentation calls for Consul. Anyway this is what I've put together:



agent.config


",alexellis,highlyunavailable
73,2014-04-24 05:29:19,"@tarrant Nice! I think I know what the issue is now. Basically Raft has an ElectionTimeout and a HeartbeatTimeout value. If we don't hear from the leader in HeartbeatTimeout we start an election. We restart the election every ElectionTimeout until eventually somebody ones. In this case ElectionTimeout is 400ms and HeartbeatTimeout 1s.

Due to the safety properties of Raft, franken8 can never win since it is behind, hence the message about rejecting the vote. But because of these values, if franken8 reaches the HeartbeatTimeout first, it  will run the election first. It will loose, but it will restart the election every 400ms. This pre-empts the other two nodes (which could win) since they will only timeout every 1s.

I think the solution to this is actually to ensure ElectionTimeout >= HeartbeatTimeout. Let me push the appropriate changes now.
",armon,tarrant
73,2014-04-24 05:35:13,"@tarrant I just pushed https://github.com/hashicorp/raft/commit/09d87a3995bc4fdb3a182a3044fc7349e8ca9f40. I am fairly confident this was the root of the issue. This was easier to trigger before since the old node has a HeartbeatTimeout of 300ms, instead of 1s in the latest versions. I think the ElectionTimeout was the lurking issue in there, which should be resolved now. Let me know if you can reproduce it, otherwise we can close the ticket.

Thanks a lot for beating on this!
",armon,tarrant
71,2014-04-22 21:07:27,"I agree with @mitchellh on this one. I think usually its either a config file or config dir, and it's rather confusing to have one link to the other. 
",armon,mitchellh
61,2014-04-24 09:33:51,"@sammcj Not difficult, but might be a nuisance. Essentially what @mitchellh said. 
",lsc,mitchellh
61,2014-04-30 17:24:59,"@sammcj Yeah I agree with @mitchellh. It's just yet another thing for us to maintain.
",armon,mitchellh
57,2014-04-18 18:08:11,"@armon I think a GET parameter to `/catalog/service/foo` would be easiest, as was originally suggested, since its just a filter on the same operation.
",mitchellh,armon
57,2014-04-18 18:19:46,"In that case, I agree with @mitchellh. We can do this with a filter flag.
",armon,mitchellh
40,2014-04-24 04:55:52,"@drnic @mbrevoort Hmm. I'm on Mavericks and it works without any issues for me. This is really bizarre, since it looks like its an open issue with the Golang toolchain. How did you guys get go? Build from source?
",armon,drnic
40,2014-04-24 13:48:23,"I installed with the installer. I'll try to build from source today and see
if I'm able to.

Thanks!

On Wednesday, April 23, 2014, Armon Dadgar notifications@github.com wrote:

> @drnic https://github.com/drnic @mbrevoorthttps://github.com/mbrevoortHmm. I'm on Mavericks and it works without any issues for me. This is
> really bizarre, since it looks like its an open issue with the Golang
> toolchain. How did you guys get go? Build from source?
> 
> â€”
> Reply to this email directly or view it on GitHubhttps://github.com/hashicorp/consul/issues/40#issuecomment-41242614
> .
",mbrevoort,drnic
40,2014-04-24 14:05:06,"@armon @drnic 
I built Go from source and updated my path and problem solved! It must be something with the binary distribution.

Thanks!
",mbrevoort,armon
40,2014-04-24 14:05:06,"@armon @drnic 
I built Go from source and updated my path and problem solved! It must be something with the binary distribution.

Thanks!
",mbrevoort,drnic
40,2014-04-24 14:12:01,"I believe I also have Go from an installer

On Thu, Apr 24, 2014 at 8:05 AM, Mike Brevoort notifications@github.com
wrote:

> @armon @drnic 
> I built Go from source and updated my path and problem solved! It must be something with the binary distribution.
> 
> ## Thanks!
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/40#issuecomment-41283630
",drnic,armon
40,2014-04-24 14:12:01,"I believe I also have Go from an installer

On Thu, Apr 24, 2014 at 8:05 AM, Mike Brevoort notifications@github.com
wrote:

> @armon @drnic 
> I built Go from source and updated my path and problem solved! It must be something with the binary distribution.
> 
> ## Thanks!
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/40#issuecomment-41283630
",drnic,drnic
38,2014-04-30 17:24:29,"@jpfuentes2 I'm going to close this for now. Can you re-open when you are ready for review?
",armon,jpfuentes2
32,2014-04-09 17:21:41,"@andrewwatson I don't think you want to make use of multiple zones, it is much better to let Consul handle that routing internally. Otherwise you need to update bind configs if you change the server addresses. Otherwise I think this is super helpful!
",armon,andrewwatson
32,2014-04-09 18:14:21,"@andrewwatson Nice! Would you mind rebasing so I can merge this in? Thanks!
",armon,andrewwatson
24,2014-04-03 17:42:33,"@ryanuber Agreed. There is a lot of inconsistency between the command line flags. Lots of cleanup needed there. Probably some flags need to be added/removed as well.
",armon,ryanuber
23,2014-04-04 20:11:36,"@mitchellh I was more thinking, once a service had been discovered, a node could then register its use of that service. This could be a one-time operation using a Serf event or query, which could contain the node's name/address/whatever else in the event payload.

This would require the endpoint doing the discovery using Consul to take on responsibility of registering utilization once a suitable service had been found. There would also need to be a reliable way of deregistering if a node died/got reaped.

This could help with transparency on who is talking to who in the cluster, which sounds like part of what @andrewwatson needs in #22, and wouldn't rely on DNS query frequency as @armon pointed out. 

Since automatic service discovery moves the source of truth for network topology into runtime, I could see using this to build a topology graph if the data were exposed over say, the HTTP interface.

Anyways, it might not be the immediate goal of Consul to handle stuff like this, and #22 points back here so its cool if we close this out. Thanks for your comments!
",ryanuber,mitchellh
22,2014-04-03 17:41:15,"@andrewwatson I think this would be simple to add given the existing telemetry infrastructure. What I wonder is if you would get meaningful data however. E.g. in our case, most services do some initial DNS queries, but then have persistent connections to the backend services. So they are not constantly re-doing the DNS queries. I think this will be a pretty common performance optimization that limits the utility of metrics that we can provide
",armon,andrewwatson
13,2014-04-03 17:44:23,"@ryanuber This was kind of a ""thought"" ticket for me. Any integration with Consul would just use it's existing APIs (specifically the various /v1/health/ endpoints). I don't think PagerDuty would be ""blessed"" in any way. Just some generic set of wrappers around the existing HTTP API.
",armon,ryanuber
13,2014-04-21 23:07:57,"@armon there are a couple of ways to integrate with PagerDuty. lots of people integrate with us via PD Connect: https://www.pagerduty.com/docs/integration-api/pagerduty-connect/ if you need help with the integration, feel free to reach out to me at vivian@pagerduty.com
",vivianma,armon
13,2014-08-29 19:55:17,"@josephholsten Agreed that the integration itself doesn't belong on Consul proper. What's the watch mechanism though? Thus far I haven't found anything better than periodic polling.
",morgante,josephholsten
13,2014-08-29 20:16:23,"Look at blocking queries in the HTTP API. It's a long poll style thing that returns on timeout or state change.

-----Original Message-----
From: ""Morgante Pell"" notifications@github.com
Sent: â€Ž8/â€Ž29/â€Ž2014 12:55 PM
To: ""hashicorp/consul"" consul@noreply.github.com
Cc: ""highlyunavailable"" highlyunavailable@gmail.com
Subject: Re: [consul] PagerDuty integration (#13)

@josephholsten Agreed that the integration itself doesn't belong on Consul proper. What's the watch mechanism though? Thus far I haven't found anything better than periodic polling.
â€”
Reply to this email directly or view it on GitHub.
",highlyunavailable,josephholsten
13,2014-09-17 22:08:00,"@armon Now that the `consul watch` handler mechanism is present in 0.4.0 should this be closed out? 
",jrnt30,armon
11,2014-05-02 04:11:59,"@mitchellh No... the that was a KV client only. It actually doesn't support any of the things we need. We could add basic KV manipulation.
",armon,mitchellh
9,2014-02-23 01:48:08,"@mitchellh This is special. Apparently linux only applies `setuid` to the current thread... https://groups.google.com/forum/?fromgroups=#!topic/golang-nuts/BZWXqv3YSg4

Not sure of a sane way to do this, since the runtime has at least like 9 threads...
",armon,mitchellh
9,2014-03-31 04:20:43,"@andrewwatson Great point. bind can also be used as a recursor instead of consul
",armon,andrewwatson
2825,2017-03-23 22:25:52,Hi @charles-dyfis-net thanks for opening a PR. I don't think this code should be in use any more once @sean- merges his pending change to switch over to https://github.com/hashicorp/go-sockaddr.,slackpad,sean-
2803,2017-03-17 18:31:54,"We have a use case that we're trying to accommodate with prepared queries, but can't quite get to work. We're trying to setup puppet SRV records, https://docs.puppet.com/guides/scaling_multiple_masters.html#option-4-dns-srv-records. 

We can get a prepared query setup that almost does what we're looking for, but not quite. The catch is that we have multiple ""well connected"" datacenters in a region and want to return all of the puppetservers across those sites, not just the ones in the current DC. This would be analogous AZs within an AWS region.

The Failover functionality is almost what we want, but not quite. We want it to return things from a list of datacenters always, not just as a failover.

It seems slightly related to https://github.com/hashicorp/consul/issues/671, and https://github.com/hashicorp/consul/issues/252 would likely be useful as well, but isn't 100% required. 

Anyway, I'm happy to open an issue in the repo to discuss, but I wanted to reach out and check to make sure that I'm not overlooking something or failing to find a previous issue about this.

Moving to an issue from the [mailing list](https://groups.google.com/d/msg/consul-tool/UZqGRpqeBtQ/uHW5b8MMBgAJ).

/cc @slackpad ",ross,slackpad
2795,2017-03-10 21:58:17,Consul is trying to resolve that internal address and getting into a loop. We should guard against that in Consul and I'll /cc @sean- on here for thoughts on the right way forward from the Vault side.,slackpad,sean-
2791,2017-03-09 08:58:08,"This was discussed before in issue #410, and with @mfischer-zd here: https://groups.google.com/forum/#!topic/consul-tool/Axow65BtSuY

If we change the behaviour to be ""watch only keys with new UpdateIndex"", then it is possible by just filtering in the endpoint code.

Reading through the code, here

https://github.com/hashicorp/consul/blob/master/consul/kvs_endpoint.go#L151

and here

https://github.com/hashicorp/consul/blob/master/consul/kvs_endpoint.go#L191

we see that in both cases, the result is filtered by applying the ACL.  What if we simply add options and code here to filter out entries or keys that have an old ModifyIndex.  That way, we effectively get values that have been updated.

This should be a relatively simple code change.

A more efficient way would be to also pass this option into the state functions so that only the updated entries are returned, but that is just an optimisation.

My use case is to let a client hold an in-memory replica of a set of KVs, allowing a local scan/query through the values.  This would be possible by first listing all entries with a prefix, and then subsequently doing a blocking pathprefix get with a `?index=N&updates_only` option.



",krestenkrab,mfischer-zd
2790,2017-03-08 17:43:46,"ðŸš§ WIP. Don't merge until final approval from @pearkes

HashiCorp is adding a high-level element to provide navigation and visibility to OSS project sites. We like to call it Mega Nav :zap:. Mega Nav is pulled in from [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp) and is positioned above the local nav in the site. It looks like this: 

### Desktop Inactive
<img width=""1430"" alt=""screen shot 2017-03-08 at 9 29 53 am"" src=""https://cloud.githubusercontent.com/assets/416727/23715979/6b303488-03e3-11e7-81d2-d043b4f11667.png"">

### Desktop Active
<img width=""1423"" alt=""screen shot 2017-03-08 at 9 30 04 am"" src=""https://cloud.githubusercontent.com/assets/416727/23715989/72f0ecda-03e3-11e7-8894-5019ac436af9.png"">

### Mobile Inactive
<img width=""402"" alt=""screen shot 2017-03-08 at 9 30 40 am"" src=""https://cloud.githubusercontent.com/assets/416727/23716013/846abb8a-03e3-11e7-87ee-ee23cdbff89a.png"">

### Mobile Active
<img width=""400"" alt=""screen shot 2017-03-08 at 9 30 49 am"" src=""https://cloud.githubusercontent.com/assets/416727/23716033/92b6a9ba-03e3-11e7-801e-7b94598fbb8d.png"">

cc @hashicorp/design ",jasoncostello,pearkes
2783,2017-03-10 07:03:41,"@wuub @armon @slackpad 
Please help in resolving this issue.",p1nkrock,armon
2783,2017-03-10 07:03:41,"@wuub @armon @slackpad 
Please help in resolving this issue.",p1nkrock,wuub
2783,2017-03-10 07:03:41,"@wuub @armon @slackpad 
Please help in resolving this issue.",p1nkrock,slackpad
2783,2017-03-13 10:26:51,"It is recommended to have 3 or 5 servers for high availability but it is not mandatory. Hence the above quoted issue should not occur even in single server case. 

Here, we had to do multiple reloads because of watch registration from various applications. We write watch jsons to a consul config directory and trigger reload as there is no Consul Endpoint where watches can be registered thru HTTP calls. Its either thru config file or consul watch command.

We have a workaround now where we queue these watch registrations for a certain interval and then trigger reload. Cons for this workaround is the delay for processes to know the state of other processes.

@slackpad @armon",p1nkrock,armon
2783,2017-03-13 10:26:51,"It is recommended to have 3 or 5 servers for high availability but it is not mandatory. Hence the above quoted issue should not occur even in single server case. 

Here, we had to do multiple reloads because of watch registration from various applications. We write watch jsons to a consul config directory and trigger reload as there is no Consul Endpoint where watches can be registered thru HTTP calls. Its either thru config file or consul watch command.

We have a workaround now where we queue these watch registrations for a certain interval and then trigger reload. Cons for this workaround is the delay for processes to know the state of other processes.

@slackpad @armon",p1nkrock,slackpad
2766,2017-03-16 04:35:45,Hey @armon - Do know something about this?,vrenjith,armon
2764,2017-02-22 00:54:07,":wave:

This PR is part of a larger effort by HashiCorp to implement more consistent typography across the OSS sites. The changes are: 

- Headings are set in Klavika font (remove Museo)
- Paragraphs are set in Open Sans
- Updated logo
- Subtle tweaks to the docs typography for legibility

It looks like this: 

**On Desktop**

![screencapture-localhost-4567-1487721788315](https://cloud.githubusercontent.com/assets/416727/23191917/3da26ae8-f855-11e6-9d7d-f14e0a59f633.png)

**On Mobile**

![screencapture-localhost-4567-1487724110206](https://cloud.githubusercontent.com/assets/416727/23191933/5889e3f4-f855-11e6-8345-926d05935b34.png)

**Docs**

![screencapture-localhost-4567-docs-upgrading-html-1487724653941](https://cloud.githubusercontent.com/assets/416727/23192048/ff046ca4-f855-11e6-99b2-d145237966df.png)

cc/ @captainill @sethvargo 
",jasoncostello,captainill
2764,2017-02-22 00:54:07,":wave:

This PR is part of a larger effort by HashiCorp to implement more consistent typography across the OSS sites. The changes are: 

- Headings are set in Klavika font (remove Museo)
- Paragraphs are set in Open Sans
- Updated logo
- Subtle tweaks to the docs typography for legibility

It looks like this: 

**On Desktop**

![screencapture-localhost-4567-1487721788315](https://cloud.githubusercontent.com/assets/416727/23191917/3da26ae8-f855-11e6-9d7d-f14e0a59f633.png)

**On Mobile**

![screencapture-localhost-4567-1487724110206](https://cloud.githubusercontent.com/assets/416727/23191933/5889e3f4-f855-11e6-8345-926d05935b34.png)

**Docs**

![screencapture-localhost-4567-docs-upgrading-html-1487724653941](https://cloud.githubusercontent.com/assets/416727/23192048/ff046ca4-f855-11e6-99b2-d145237966df.png)

cc/ @captainill @sethvargo 
",jasoncostello,sethvargo
2710,2017-02-03 05:06:01,"@sean- 
   This is the PR with just the the unit test for what I am trying to do with the TXT RR in Consul. If we agree on a solution it would solve #2709.

",sodre,sean-
2709,2017-02-03 02:32:15,"@sean- 

As discussed, It would be useful for Consul to serve TXT records at multiple levels in the domain hierarchy. One use-case in mind is a Kerberized cluster configured purely through DNS. This requires that the DNS server respond to `TXT _kerberos.[.data center]<.domain>` with the configured realm name.

One thought is to store this information is in the key-value store, perhaps in a format such as...
key: `/service/dns/req=TXT/<FQDN>` value: `TXTDATA`.",sodre,sean-
2688,2017-01-27 21:04:01,"Adds Google Tag Manager to the website per Hashicorp's request in (~redacted~).

@captainill",ryon,captainill
2678,2017-01-26 05:16:13,"Individual commits contain more detail.

/cc @slackpad ",sethvargo,slackpad
2664,2017-01-19 09:37:06,"Hi all, 

thanks for the amazing job you're all doing with Consul!
However, I could not find any mention of which cipher suites are supported by Consul when implementing TLS. @macb [mentioned](https://github.com/hashicorp/consul/issues/1349) Consul relies on Golang (now updated to the latest 1.7 version) which supports TLS back to TLS 1.0 included.

1. Could you please tell me which cipher suites are supported?

I found AES-GCM 128, using PKCS7 padding and AES-GCM 128, no padding mentioned at [security.go](https://github.com/hashicorp/consul/blob/6f0a3b9bf5c7fd0673213d451bbc9e66f7a9cad9/vendor/github.com/hashicorp/memberlist/security.go). Could you kindly confirm please that those are the ciphers specified by Consul for the TLS configuration that Golang needs to be fed with?

2. Also, usually a cipher suite for TLS is comprised of key-exchange algorithm, bulk cipher algorithm and MAC (Hash) algorithm, e.g. TLS_RSA_WITH_3DES_EDE_CBC_SHA. Since in the mention of ""AES-GCM 128"" AES is for key exchange and GCM is the bulk cipher alg, which hash algorithm are you using?

3. Finally, it would be great to have the possibility to customise the cipher suites used and the minimum supported version of TLS.


Thanks a lot in advance.",iammyr,macb
2657,2017-03-17 08:30:15,"Hello @slackpad,

would you have any feedback regarding this PR?
We've been using this on top of 0.7.3 for a month without any issue",kamaradclimber,slackpad
2656,2017-01-17 13:04:35,"""raft_multiplier"" should be nested into ""performance"". 

Seems like it was accidentally changed in https://github.com/hashicorp/consul/pull/2320
cc @slackpad ",legal90,slackpad
2640,2017-01-09 03:53:11,"Not ready to merge, but continuing the discussion on #2300

I created an agent namespace. When you query agent.consul, the behavior is simply to retrieve the NodeName from config and query that name. This returns effectively the bind address, however I think if a user has overridden this with `advertise_addr` config it will return that. I'm not sure @slackpad if this is what you intended or if this interface needs to be more intelligent. @ryansch or @far-blue is this meeting your need or did I misunderstand the use case?",moofish32,far-blue
2640,2017-01-09 03:53:11,"Not ready to merge, but continuing the discussion on #2300

I created an agent namespace. When you query agent.consul, the behavior is simply to retrieve the NodeName from config and query that name. This returns effectively the bind address, however I think if a user has overridden this with `advertise_addr` config it will return that. I'm not sure @slackpad if this is what you intended or if this interface needs to be more intelligent. @ryansch or @far-blue is this meeting your need or did I misunderstand the use case?",moofish32,slackpad
2634,2017-01-06 10:18:58,"@magiconair you seeing this, i assume it is a issue with fabio, i tried to use several urlprefixes. ",raben2,magiconair
2630,2017-01-23 21:45:33,"@slackpad Since dev mode is not supposed to write to disk at all, should the `keyring -install` command even be supported in dev mode?",mckennajones,slackpad
2612,2016-12-22 11:13:19,"Following up on [a conversation](https://github.com/solarkennedy/puppet-consul/issues/282#issuecomment-268246692) I had with @armon, it may be worth setting the example here as well, not to send SIGINT to server-mode agents, because they might unintentionally change the Raft consensus pool.

From the commit message:

> Since Consul 0.7, client-mode agents are shutting down gracefully by
> default, so no need to send them a SIGINT specially. The default for
> server-mode agents is still not to leave gracefully on SIGTERM, but it
> was left this way for a reason. To override this, it is better to set
> the leave_on_terminate option, rather than changing the KillSignal.",amiryal,armon
2582,2016-12-09 10:47:55,"@mckennajones, looks like your pull request #2577 failed for the same reason.",ybubnov,mckennajones
2580,2016-12-07 22:02:15,/cc @slackpad ,sethvargo,slackpad
2579,2016-12-07 19:33:47,"This updates the main Consul page to use the KV CLI instead of curl as requested by @armon. I'm working on updates to the other pages that will show both `curl` and `consul kv` as options, but Armon thinks this looks better and easier on the home page.",sethvargo,armon
2572,2016-12-06 19:12:29,Thanks for the tips @sethvargo!,brianshumate,sethvargo
2567,2016-12-02 18:14:57,"If there's an issue with Circonus (in our case we hit a usage limit) we weren't able to start the Consul agent at all:



Since we are depending on an external service, we should probably be robust to outages there. A few different mitigations might be possible:

1. Print a warning and periodically retry, adding the sink when Circonus is available.
2. Print a warning and skip creating the sink.
3. Register a health check for metics that we can set to a failed state if we have issues with an external metrics provider.

This probably isn't limited to Circonus so we should apply whatever we do to all of them.

/cc @phinze @sean- ",slackpad,phinze
2567,2016-12-02 18:14:57,"If there's an issue with Circonus (in our case we hit a usage limit) we weren't able to start the Consul agent at all:



Since we are depending on an external service, we should probably be robust to outages there. A few different mitigations might be possible:

1. Print a warning and periodically retry, adding the sink when Circonus is available.
2. Print a warning and skip creating the sink.
3. Register a health check for metics that we can set to a failed state if we have issues with an external metrics provider.

This probably isn't limited to Circonus so we should apply whatever we do to all of them.

/cc @phinze @sean- ",slackpad,sean-
2557,2016-12-01 15:27:58,"The testutil server uses an atomic incrementer to generate unique port
numbers. This works great until tests are run in parallel, _across
packages_. Because each package starts at the same ""offset"" idx, they
collide.

One way to overcome this is to run each packages' test in isolation, but
that makes the test suite much longer as it does not maximize
parallelization. Alternatively, instead of having ""predictable"" ports,
we can let the OS choose a random open port automatically.

This still has a (albeit smaller) race condition in that the OS could
return an open port twice, before the server has a chance to actually
start and occupy said port. In practice, I have not been able to hit
this race condition, so it either doesn't happen or it happens far less
frequently that the existing implementation.

I'm not sure how I feel about the panic, but this is just test code, so
I'm including to say it's okay?

/cc @slackpad ",sethvargo,slackpad
2549,2016-12-21 16:39:26,"This feature has been discussed in https://github.com/prometheus/prometheus/pull/2028.
@slackpad, what do you thing about it ?",Thib17,slackpad
2549,2016-12-26 09:50:16,"We would be interested by this feature as well @slackpad.
Could you provide some inputs onto the likelihood of it to be merged ? 

",erebe,slackpad
2547,2016-11-30 02:17:38,"I forgot to actually update the types ðŸ˜¦ 

/cc @slackpad ",sethvargo,slackpad
2547,2016-11-30 04:08:21,"Aye! LGTM

> On Nov 29, 2016, at 6:17 PM, Seth Vargo <notifications@github.com> wrote:
> 
> I forgot to actually update the types ðŸ˜¦
> 
> /cc @slackpad
> 
> You can view, comment on, or merge this pull request online at:
> 
>   https://github.com/hashicorp/consul/pull/2547
> 
> Commit Summary
> 
> Return the correct type
> File Changes
> 
> M api/health.go (14)
> Patch Links:
> 
> https://github.com/hashicorp/consul/pull/2547.patch
> https://github.com/hashicorp/consul/pull/2547.diff
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",slackpad,slackpad
2529,2016-11-28 20:37:50,@babbottscott Thoughts on this @slackpad ? It wouldn't be hard to implement but I'm not sure if this is the intended behavior for this case. ,mckennajones,slackpad
2525,2016-11-22 00:55:28,@pearkes might be able to give a little guidance on how we update this,slackpad,pearkes
2516,2016-12-29 02:53:30,"@kyhavlov @slackpad I realize this is merged, but this seemed the best place to comment about an issue before possibly opening a new bug/item. 

The TestAgent_Reload in the tests for this feature break on a machine with 2 private IP's. It took me a while to figure out how to get the output from the MockUi, (this drove me NUTS btw) but once I did it led me to the understanding that while nexConfig is called to get a config, it's never actually used to create the instance of the server used in the test. It builds a DefaultConfig on a Run(), but in that default, the bind is 0.0.0.0. If that's the bind, the agent fails to start because of the multi-private-ip issue. 

Not sure how/if this needs to be fixed. I've worked around it by simply adding a -bind to the args list for the Command. It seems odd I haven't hit this for any other tests, so I'm not sure what this test is doing that's different from the rest. I haven't dug into it deeply yet.",rhyas,slackpad
2448,2016-10-29 19:01:46,"This has been working really well on Nomad and hashicorp.com, so I am ready to port it out to Consul as a beta. This moves the local development to a Docker container, which is the same container that we use to publish the website in production. The result is much faster and more consistent deploys.

/cc @slackpad 
",sethvargo,slackpad
2434,2016-10-25 18:16:13,"@slackpad 
",kyhavlov,slackpad
2418,2016-10-25 17:45:14,"hey @slackpad we rebased with master and travis is passing now, let us know if there is anything you'd like us to change!
",zankich,slackpad
2417,2016-10-25 23:37:49,"@slackpad -- seems like it's merge week, just bumping the PR
",moofish32,slackpad
2412,2016-10-13 22:06:42,"ðŸ”´  Early POC ðŸ”´ 

This is a fairly large, but localized refactor to attempt to centralize our CLI parsing options and output. It adds a `Meta` struct that is aware of common information and includes functions for generating an HTTP/RPC client and the associated CLI flags. It also has logic on how to pretty-print flags, wrap to a specified line length, and more.
### TODO
- [ ] RPC Client
- [ ] Don't print out help output on flag failure (the failure is way at the top and the help output often scrolls beyond)

/cc @slackpad for early review.
",sethvargo,slackpad
2412,2017-02-08 02:20:21,"@kyhavlov the todo ""Don't print out help output on flag failure (the failure is way at the top and the help output often scrolls beyond)"" is worth keeping track of - that's actually pretty bad rn because the error is always at the top of a bunch of stuff.",slackpad,kyhavlov
2395,2016-10-07 00:29:26,"### hashicorp/consul now has a Chat Room on Gitter

@slackpad has just created a chat room. You can visit it here: [https://gitter.im/hashicorp-consul/Lobby](https://gitter.im/hashicorp-consul/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&content=body_link).

This pull-request adds this badge to your README.md:

[![Gitter](https://badges.gitter.im/hashicorp-consul/Lobby.svg)](https://gitter.im/hashicorp-consul/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=body_badge)

If my aim is a little off, please [let me know](https://github.com/gitterHQ/readme-badger/issues).

Happy chatting.

PS: [Click here](https://gitter.im/settings/badger/opt-out) if you would prefer not to receive automatic pull-requests from Gitter in future.
",gitter-badger,slackpad
2384,2016-10-12 17:28:24,"Hey @slackpad we'll go ahead and submit a PR for this, and are open to discuss in this issue or on the forthcoming PR.
",Amit-PivotalLabs,slackpad
2380,2016-10-01 22:35:50,"- adding cli config and config file support for specifying the serf wan and lan bind addresses 
- updating documentation for serf wan and lan options 
  Fixes #2007

@slackpad - I am not sure about the non-loopback IP test. I couldn't think of a better way to do this. I need to verify I didn't break any tests, but it should behave the same as the current defaults.
",moofish32,slackpad
2380,2016-10-03 20:17:51,"@slackpad -- from what I see running this locally the failing tests are not differing from the list on master. They are not always the same errors as I think you know.
",moofish32,slackpad
2380,2016-10-25 23:38:11,"@slackpad  - one more bump during the merge party
",moofish32,slackpad
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,armon
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,pearkes
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,ryanuber
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,sean-
2360,2016-09-26 15:17:07,"This implements the `kv` subcommand CLI for reading, writing, and deleting keys. This pass does not support the transaction-based keys yet, but that could be implemented in a later pass. The framework is in place for adding new commands and formats pretty easily.



/cc @slackpad @ryanuber @armon 
",sethvargo,armon
2360,2016-09-26 15:17:07,"This implements the `kv` subcommand CLI for reading, writing, and deleting keys. This pass does not support the transaction-based keys yet, but that could be implemented in a later pass. The framework is in place for adding new commands and formats pretty easily.



/cc @slackpad @ryanuber @armon 
",sethvargo,slackpad
2360,2016-09-26 15:17:07,"This implements the `kv` subcommand CLI for reading, writing, and deleting keys. This pass does not support the transaction-based keys yet, but that could be implemented in a later pass. The framework is in place for adding new commands and formats pretty easily.



/cc @slackpad @ryanuber @armon 
",sethvargo,ryanuber
2353,2016-09-22 19:56:04,"@ryanuber that's an interesting idea, but we range over `serviceStatus`/`checkStatus` maps in order to do the failed lookup in the primary maps, so I think we need some piece of state to say that it needs to be deleted.
",slackpad,ryanuber
2352,2016-09-21 16:20:52,"/cc @slackpad 
",sethvargo,slackpad
2343,2016-09-16 23:15:27,"Hey @slackpad, thanks for meeting with some of us from the Pivotal Cloud Foundry team, here's some of the points we talked about.
- [ ] Make a server leave as a first class thing.
- [ ] Does leave give the right feedback? Seems like it returns before leave has happened.
- [ ] Server name change issue: https://github.com/hashicorp/consul/issues/2172.
- [x] Migrate all gossip key stuff off RPC client so we don't have to use the RPC client at all to orchestrate how we start the consul binary.
- [x] Have an HTTP API endpoint for `leave` command, instead of only RPC interface.
- [ ] Will stale Serf info add a failed server back in (do we check the health)?
- [ ] Gossip keys install should say who failed and why (at least the IP).
- [ ] ""Stats for Raft -> consul operator healthy server replication OK CLI + API"" -- so that we can simplify Consul orchestration, knowing that a server is synced rather than polling stats endpoint and comparing numbers.
- [ ] ""Bootstrap CLI + API -> are you in a cluster and are you synced"" -- so that we can programmatically put a server into bootstrap mode instead of rewriting config and having to restart server.
- [ ] If keys have been rotated new agents don't have the old key history - where are the keys stored?  What files would they need to keep on a restart?
- [ ] Client rapidly turning into a server gets ignored by other clients as a non-server.
- [ ] Do we need a special case operator command to help with leaves (like maybe take a list of server IPs to RPC to)?
- [ ] Manual mode would need TLS configs and stuff, i.e. being able to cURL a Consul server with keys and certs, or even the `consul` CLI supporting commands to remote servers and supporting flags for TLS things -- needs to support just giving it an IP and maybe ignoring domain name verification (chicken-egg problem).

Some of the items above are maybe a bit roughly worded, we can work on refining them.

Also, please let us know how we can help on these via PRs.

Thanks!
",Amit-PivotalLabs,slackpad
2343,2016-10-12 17:09:52,"Hey @slackpad any update on any of these issues, or ideas on how we can help?
",Amit-PivotalLabs,slackpad
2297,2016-08-23 21:59:51,"@slackpad who can assist us please? We keep this setup up and running and need some advice to extract more relevant data from it. 
Thanks
",rom-stratoscale,slackpad
2292,2016-09-12 16:04:12,"LAN and WAN gossip use the same protocol SWIM (https://www.cs.cornell.edu/~asdas/research/dsn02-swim.pdf), implemented in memberlist package with the Serf (with vector clocks blah-blah) on top of it. 

Read docs.

https://www.consul.io/docs/internals/gossip.html
http://sitano.github.io/2015/10/06/abt-consul-outage/

About connecting cross-dc with lan level serf - you can, but there are certain constraints in the protocol in the deterministic failure detector (timeout based thing) and that may result on the state convergence. 

@armon wrote somewhere about thats not recommended and everything. Search if you want. Or just do some tests.

p.s. Actually we do that in one of our clusters cross 3 dcs.
",sitano,armon
2291,2016-08-18 23:37:32,"Currently points to http://localhost:4567/docs/guides/outage.html - should be https://www.consul.io/docs/guides/outage.html

Introduced by https://github.com/hashicorp/consul/commit/ee5740847ce80f6493e670953de0bdb0a9ec67e0

cc @slackpad :)
",CpuID,slackpad
2285,2016-11-18 00:18:47,"@sean- can you plz. look at this one wrt. to go-sockaddr?
",slackpad,sean-
2262,2016-08-24 02:08:18,"@slackpad PTAL
",WIZARD-CXY,slackpad
2262,2016-09-09 02:07:22,"@slackpad PTAL thx
",WIZARD-CXY,slackpad
2248,2016-11-10 01:41:12,"@slackpad Is this still happening? If yes, can I fix this?
",lucasalcantara,slackpad
2229,2016-08-02 07:45:12,"Ping @slackpad @ryanuber @armon 
",sethvargo,armon
2229,2016-08-02 07:45:12,"Ping @slackpad @ryanuber @armon 
",sethvargo,slackpad
2229,2016-08-02 07:45:12,"Ping @slackpad @ryanuber @armon 
",sethvargo,ryanuber
2227,2016-10-26 16:37:41,"@slackpad @joshuaspence I can tackle this. What should the format be for adding the timezone? 

Currently a timestamp in the log looks like this:
2016/10/26 09:28:13 [INFO]

Should the timezone simply follow the time?
2016/10/26 09:28:13 PST [INFO] for example
",mckennajones,slackpad
2215,2016-08-18 22:07:47,"@slackpad any comments on this??
",abhinavdahiya,slackpad
2203,2016-07-25 15:04:12,"Hey @slackpad, I added a very reproducible test and very simple soak test for this here:
https://github.com/FrankHassanabad/consul-e2e-tests-crashes

I uploaded my logs for when it occurs.

Also, I cloned consul, and from the v0.6.4 tag, I did _only_ an upgrade of boltdb.  Then when I reran the soak test again (overnight), it looked like the resize locking error did not show up again.

You don't need to restart windows or any other funny business.  Just soak test for a while and the error shows up eventually.
",FrankHassanabad,slackpad
2175,2016-07-10 17:34:48,"cc: @slackpad @sean- 
",armon,slackpad
2175,2016-07-10 17:34:48,"cc: @slackpad @sean- 
",armon,sean-
2174,2016-07-10 12:31:25,"### All my nodes are servers
### `consul version`

Consul v0.6.4
Consul Protocol: 3 (Understands back to: 1)
### `consul info` for both Client and Server


### Operating system and Environment details

CentOS Linux release 7.0.1406 (Core)
### Description of the Issue (and unexpected/desired result)

Hi
I'm trying to change the tags of a service ""from outside"" (i.e. through the catalog) using the EnableTagOverride feature.
I've read the good explanation of @slackpad  about how EnableTagOverride works during service sync.
https://github.com/hashicorp/consul/issues/1572#issuecomment-170155251
However, it seems that if, after I change the tag on the catalog, a **check-sync** happens before a service-sync, then the check-sync copies the agent's tags into the catalog - like the behavior of a service **without** EnableTagOverride. 

Thanks in advance,
Motty
### Reproduction steps
1. Register a service using the agent (PUT v1/agent/service/register) with enableTagOverride=True and Tags=[""orig""], and with a health check (Here I use TTL, but I saw it also with a script check)
2. Change the tags using the catalog (PUT v1/catalog/register) with    {""Node"":..., ""Address"":..., ""Service"": {""Id"":..., ""Tags"": [""new""] }}
3. From time to time, read the service's tags both on the agent and the catalog (GET v1/agent/services, GET v1/catalog/service/<name>).  You will see ""new"" in the catalog but ""orig"" on the agent.
4. Change the health check status (v1/agent/check/warn) to induce syncing the check.

**Actual result**:  The tag ""orig"" on the agent remains, and is also copied to the catalog.
**Expected result**:  The tag ""new"" should remain in the catalog, and be copied to the agent.
**Note**: If you skip step 4 (or don't do it fast enough), a periodic service-sync occurs, and it yields the expected result.
### Log Fragments or Link to gist

I used `-log-level=TRACE` but then cut out the boring parts..
https://gist.github.com/motty-stratoscale/521c57bca424169ebf38b3917f9e37df
",motty-stratoscale,slackpad
2170,2016-07-06 23:00:08,"This requires a bit of discussion and shouldn't be merged as-is without a conversation first.  Should servers attempt to drain their connections first or only the clients?  This patch does both atm.

CC @slackpad 
",sean-,slackpad
2160,2016-07-02 23:06:21,"/cc @slackpad
",ryanuber,slackpad
2156,2016-07-01 21:31:27,"/cc @slackpad 
",ryanuber,slackpad
2150,2016-06-29 12:09:34,"This isn't a bug, but an extension of a conversation that happened on a vault issue https://github.com/hashicorp/vault/issues/1273.

@jefferai recommended I make my suggestion here.

I created a logical backup utility https://github.com/BSick7/envoy that will dump the consul k/v store into a filesystem and archive into a tar.gz file. This github repo includes automated releases to ""GitHub Releases"".
",BSick7,jefferai
2137,2016-06-21 22:57:58,"Allows the use of the `Near` parameter in a prepared query definition. This parameter works just like the `?near=foo` HTTP API parameter, only it is baked into the query, allowing it to be used from the DNS interface. 

This enables some interesting functionality and opens up additional useful prepared query features when using DNS as the query mechanism.

/cc @slackpad 
",ryanuber,slackpad
2132,2016-06-20 23:19:29,"cc @sean- @slackpad 

A simple change that may make using consul health checks for leader health slightly easier. 
",pshima,slackpad
2132,2016-06-20 23:19:29,"cc @sean- @slackpad 

A simple change that may make using consul health checks for leader health slightly easier. 
",pshima,sean-
2118,2016-06-15 18:45:02,"Likely of interest to @slackpad and @evan2645.

This PR builds on https://github.com/hashicorp/consul/pull/1698. That PR translates a returned IP address to a WAN address when Consul is configured appropriately, but only through the DNS interface.

This PR additionally translates a node's address to the WAN address in the HTTP API. The rationale is:
- the DNS and HTTP APIs should return consistent results
- returning an IP local to DC1 to an HTTP client in DC2 is likely not useful (the client can't do anything with it)

The particular use case that motivated this change is ""using the HTTP API in a NAT'd, multi-DC environment, I want to query for all nodes providing service X, and I want to be able to connect to those nodes using the returned `Address`"".

The changes that this PR makes are:
- adding `TaggedAddresses` to the `ServiceNode` struct (so that the `catalog_endpoint.go`, in particular, has access to them and co do the WAN translation before returning the result)
- setting `TaggedAddresses` in the `ServiceNode` struct in `state_store.go`
- moving `translateAddr` into `agent.go` and modifying the signature slightly so that it can be used from both HTTP and DNS handlers
- translating node addresses in the following HTTP APIs (tests added for all)
  - `/v1/catalog/nodes`
  - `/v1/catalog/node/<node>`
  - `/v1/catalog/service/<service>`
  - `/v1/health/service/<service>`
  - `/v1/query/<query or name>/execute`

Added tests are passing, but it seems some of the existing tests are somewhat flaky and will occasionally fail. AFAICT, the failures don't have anything to do with this PR's additions.

First time Go user, view the code with suspicion :-).
",DWvanGeest,slackpad
2118,2016-06-15 18:45:02,"Likely of interest to @slackpad and @evan2645.

This PR builds on https://github.com/hashicorp/consul/pull/1698. That PR translates a returned IP address to a WAN address when Consul is configured appropriately, but only through the DNS interface.

This PR additionally translates a node's address to the WAN address in the HTTP API. The rationale is:
- the DNS and HTTP APIs should return consistent results
- returning an IP local to DC1 to an HTTP client in DC2 is likely not useful (the client can't do anything with it)

The particular use case that motivated this change is ""using the HTTP API in a NAT'd, multi-DC environment, I want to query for all nodes providing service X, and I want to be able to connect to those nodes using the returned `Address`"".

The changes that this PR makes are:
- adding `TaggedAddresses` to the `ServiceNode` struct (so that the `catalog_endpoint.go`, in particular, has access to them and co do the WAN translation before returning the result)
- setting `TaggedAddresses` in the `ServiceNode` struct in `state_store.go`
- moving `translateAddr` into `agent.go` and modifying the signature slightly so that it can be used from both HTTP and DNS handlers
- translating node addresses in the following HTTP APIs (tests added for all)
  - `/v1/catalog/nodes`
  - `/v1/catalog/node/<node>`
  - `/v1/catalog/service/<service>`
  - `/v1/health/service/<service>`
  - `/v1/query/<query or name>/execute`

Added tests are passing, but it seems some of the existing tests are somewhat flaky and will occasionally fail. AFAICT, the failures don't have anything to do with this PR's additions.

First time Go user, view the code with suspicion :-).
",DWvanGeest,evan2645
2092,2016-06-04 06:51:13,"Seeing this in [Travis CI](https://travis-ci.org/hashicorp/consul/builds/135208382) with the latest SCADA changes:



I'll take a look a bit later this weekend. I thought we deleted the agent-level class so this needs double check of a few things.

[Changes came in here](https://github.com/hashicorp/consul/commit/ebf7ea1d759184c02a5bb5263a7c52d29838ffc3) with [original PR here](https://github.com/hashicorp/consul/pull/2084).

/cc @jefferai 
",slackpad,jefferai
2089,2016-06-03 18:26:27,"In [the Google group](https://groups.google.com/forum/#!msg/consul-tool/09OkySyoSnA/MOsK5plxFQAJ) we discussed a problem with TTL health checks in PaaS-like or ""serverless"" environments where there are only servers and no agents. In these environments, Consul isn't collocated with the application client so there's no good way to assign a client to a particular server. This means Consul is making topology assumptions that work well for â€œmachines,â€ but are in conflict with other uses. We don't have VMs, so we don't need Consul to be aware of the underlying infrastructure and impose assumptions about it, but still want to be able to use Consul for service discovery in the application.

@misterbisson and I suggested that health checks (for TTLs) could be defined at the catalog level rather than the agent level. 

@slackpad responded with the following:

> This definitely would not make sense for any other health check type but I could see TTL checks being useful when used this way. There are two architecture questions we'd need to think through:
> 1. Having Consul servers manage TTL expiration for these checks would be a significant new feature. This is currently managed completely on the agent side and they send edge-triggered updates to the Consul servers when a TTL expires and the state changes, so Consul servers have no concept of what kinds of checks are present, and they don't know anything about check TTLs. We have some precedent for servers handling TTL expirations via sessions, and I have a design sketched out to make managing TTL expirations much more efficient, so it seems like we could work something out here to add potentially lots more TTL-expiring things to be managed by servers.
> 2. Agents currently provide a buffer between the load from refreshing TTLs (which the Consul servers never see) and service state changes (which the Consul servers see but happen much less often). Having many, many processes posting TTL refreshes directly to the servers could put a lot of extra load on them in a way that may not scale well. I don't think all the TTL refreshes should need to go through Raft, but we'd need to do some careful planning to make sure that's true so we don't create a bottleneck.
> 
> We'd want to have a solid plan for #2 before jumping into code - that's probably best worked out via a new Consul Github issue. I'm happy to help figure this out!

I'm happy to help contribute to the design discussion as well as a PR for this work when it comes to it.
",tgross,slackpad
2089,2016-06-09 11:58:44,"@slackpad I've spent a lot of this week getting to understand SWIM/Serf and how Consul agents gossip updates to the servers, and I think I've come around to this being a bad idea to change in Consul. It's really clear that having agents gossip but not participate in the raft is key to Consul scalability (particularly compared to etcd where all TTLs get sent up to the servers). I'd hate to introduce an architectural change that breaks this core advantage of Consul.

The specific use case we were running into with https://github.com/joyent/containerpilot/issues/162 we're going to solve with https://github.com/joyent/containerpilot/issues/175 and running a Consul agent as a co-process in the container. I may at some point explore the idea of a Consul agent _library_ (probably in C or Rust so it's can be embedded in arbitrary applications), but that's certainly out of scope for my current project or for Consul itself.

I'd be happy to close this issue if you're in agreement with the above @slackpad 
",tgross,slackpad
2080,2016-06-01 05:03:24,"Hi:
       i am doing a test. i run consul in three server



then, i login to each server and call `consul leave`.
after this,  i want to start the cluster again, but the cluster can not elect a leader

login 172.16.13.161



login 172.16.13.162



login 172.16.13.160



error log like below:



server - 172.16.13.160

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n1"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.160"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

server - 172.16.13.161

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n2"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.161"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}
`

server - 172.16.13.162
`
{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n3"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.162"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

after join, i found `null` in the file ${data_dir}/raft/peers.json, 
is it a bug ??? @armon @slackpad 
",zackshen,armon
2080,2016-06-01 05:03:24,"Hi:
       i am doing a test. i run consul in three server



then, i login to each server and call `consul leave`.
after this,  i want to start the cluster again, but the cluster can not elect a leader

login 172.16.13.161



login 172.16.13.162



login 172.16.13.160



error log like below:



server - 172.16.13.160

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n1"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.160"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

server - 172.16.13.161

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n2"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.161"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}
`

server - 172.16.13.162
`
{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n3"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.162"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

after join, i found `null` in the file ${data_dir}/raft/peers.json, 
is it a bug ??? @armon @slackpad 
",zackshen,slackpad
2069,2016-05-25 06:19:42,"When I kill with `pkill -f consul` agent correctly leaves cluster:



And node status change to ""crit"":



With `pkill -f -9 consul`:



And node still have status ""passing"":



@armon Is that a bug, or what I'm doing wrong? Reproduced when agent is running on Centos 7. In Windows I don't see problems when killed agent with `taskkill /T /F /IM consul.exe`
",odiszapc,armon
2066,2016-06-12 07:08:37,"No idea about the snapshot files, but if my memory serves me right the data will still be there. This will sound obvious but if you care about your data, you'll need to test this yourself. My knowledge is based on an experiment I did over a year ago and it might behave differently now. If you do end up testing this, I'd love to know the results. 

@slackpad the page https://www.consul.io/docs/guides/outage.html doesn't address cluster failure recovery, and it's more or less absent from the other pages, too. I'm not sure if that's intentional but I think it would help others if the issue was addressed with more clarity. Nobody anticipates an entire cluster to fail but should that happen, can it be recovered after removing bad servers from each peers.json file? What would be the best approach to take? 
",shilov,slackpad
2018,2016-05-04 00:45:48,"@slackpad This fixes https://github.com/hashicorp/consul/issues/2017

I verified the issue/fix by getting virtual box setup with Windows 10 and Internet Explorer.
",captainill,slackpad
2015,2016-08-07 22:38:17,"@sorenh I'm not entirely sure why I've had this tab open, but I want to make sure you're not accidentally setting `only_passing=false` in a config file someplace.  If you're still seeing this behavior, could you provide additional detail?

As for the intended behavior, if you look at `dns.go` unhealthy nodes are filtered out:

https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L553-L554

which is implemented in `Filter()`:

https://github.com/hashicorp/consul/blob/master/consul/structs/structs.go#L435-L436

So if that behavior isn't working as expected, we'd definitely be interested in learning more about what's going on in your situation.

If you `pkill -9 consul`, Serf will begin to fail, and the host should no longer be in the results because it is marked as critical as soon as the leader receives the serf failed member event.

Let us know!
",sean-,sorenh
2002,2016-06-22 09:34:40,"@sean- @slackpad 
Any update on this PR?
We hit the similar issue about the DNS retry.
",bingosummer,slackpad
1987,2016-04-26 03:35:12,"Hey @sean- @slackpad, we are looking to use consul in production but constantly hear that it may not be production ready. Will it be possible for you to share some large organizations which are using it in prod for us to touch base with. Would love to hear your opinion on the same too.

For reference we are looking ~ 6k vm running right now and moving to multiple docker containers per host very soon across 3 data centres. 

I'm fairly certain this question has been asked a billion times so I apologize in advance if it's already answered somewhere.  
",yagnik,slackpad
1987,2016-04-26 03:35:12,"Hey @sean- @slackpad, we are looking to use consul in production but constantly hear that it may not be production ready. Will it be possible for you to share some large organizations which are using it in prod for us to touch base with. Would love to hear your opinion on the same too.

For reference we are looking ~ 6k vm running right now and moving to multiple docker containers per host very soon across 3 data centres. 

I'm fairly certain this question has been asked a billion times so I apologize in advance if it's already answered somewhere.  
",yagnik,sean-
1965,2016-06-11 02:35:37,"Hey @fusiondog 

Stumbled upon your work when I was reading the mailing list and this really fits into what I'm experiencing as well.

I'd love to get Consul to output to graphite and have this kind of handler.

Have you been updating any of this work lately?

Perhaps we can discuss this with @armon as well in regards to getting the ball rolling again here? :)
",cdrage,armon
1962,2016-11-22 18:06:39,"@sethvargo is working on normalizing how the CLI commands all parse this stuff, and the RPC interface should be gone by 0.8.",slackpad,sethvargo
1952,2016-04-14 21:40:07,"Massive HTTP responses can cause performance problems when we store them unbounded in the state store. This applies the same 4K buffer we use for script checks to HTTP replies to avoid such overload.

/cc @slackpad
",ryanuber,slackpad
1941,2016-04-13 06:00:44,"I'm actually ok with this as-is since it's much more difficult to look at the agent's tags vs. look in the catalog. Doing the sync down to the agent will be a lot of complexity. @sean- feel free to re-open if you disagree.
",slackpad,sean-
1930,2016-11-18 00:13:10,"Sorry for delay responding to this one, and thanks for the PR @abhinavdahiya. What use case do folks have in mind for configuring this? It's a simple change, but we'd like to avoid extra complexity unless there's a compelling reason to be able to tweak this.
",slackpad,abhinavdahiya
1930,2016-12-09 02:26:02,"Just FYI - I have made a few other enhancements that I think will help this. PR will be in coming shortly. 

TL;DR: Currently consul does not serve back full URL paths in its `Location:` headers when it's doing redirects for the UI, nor does the UI itself append on the correct HTTP origin that accessed it in the first place. These things are necessary to properly support reverse proxies not just on things like port or host but on path as well.

I'll reference back this issue on the PR when I'm ready.

@abhinavdahiya maybe if you could look at it if you'd like and see if we could combine work to have the best of both patches. @slackpad your feedback would be welcome as well.",vancluever,abhinavdahiya
1888,2016-04-12 18:57:18,"Hi @markbugejacba this is a bit of a subtle artifact of configuring Consul to allow stale DNS responses. Assuming that you've enabled https://www.consul.io/docs/agent/options.html#allow_stale, there will be a window after the outage occurs (outage being no Consul leader) where Consul servers will still provide DNS results based on their own in-memory store. Once the https://www.consul.io/docs/agent/options.html#max_stale window has been exceeded, it will attempt to retry the RPC requests internally, which will fail because there's no leader, so you will start getting `SERVFAIL` responses.

Does this explanation fit with how you've got things configured? This seems like the right behavior given that stale responses are allowed, and lets the cluster better ride out brief moments without a leader, such as during leader elections. We are also planning on making this more robust with some internal retries under https://github.com/hashicorp/consul/issues/1554.

/cc @sean- 
",slackpad,sean-
1846,2016-03-18 19:47:53,"I see now why you did this, I noticed that Go's testing package includes a `private()` function in the interface to expressly prevent implementing it. The code seems reasonable. @slackpad any thoughts?
",ryanuber,slackpad
1838,2016-10-31 02:03:26,"@slackpad What should the expected behavior be in this case? Should consul error out if the -data-dir points to a consul binary? 
",mckennajones,slackpad
1838,2016-12-15 16:56:16,"Despite what I said in https://github.com/hashicorp/consul/pull/2529#issuecomment-263389938, during some testing with this change merge I realized I think we were auto-creating the directory before, so this might be a regression. @kyhavlov will take a look; pulling into the 0.7.2 release milestone.",slackpad,kyhavlov
1825,2016-03-10 21:17:22,"Got an LGTM from @jefferai - merging.
",slackpad,jefferai
1813,2016-03-09 07:11:16,"Took https://github.com/hashicorp/consul/pull/1734 by @idubinskiy and made a few minor tweaks.
",slackpad,idubinskiy
1810,2016-03-08 23:00:43,"@slackpad this is the display fix.

I also refactored so all style changes are in one file for clarity when announcement bnr is displayed.
",captainill,slackpad
1803,2016-03-09 15:49:23,"@slackpad (or someone with access) please add the ""docs"" label to this pull-request.
",tylert,slackpad
1789,2016-03-03 20:26:55,"@pearkes @KFishner
",captainill,pearkes
1789,2016-03-03 20:26:55,"@pearkes @KFishner
",captainill,KFishner
1779,2016-03-24 15:33:09,"Any update about this @slackpad? What are you thinking about here?
",BrianHicks,slackpad
1776,2016-03-10 07:06:08,"Hi @saswatp we are looking into some structured logging libraries so we can take a look at this along with that effort.

/cc @sean- 
",slackpad,sean-
1764,2016-02-26 09:56:05,"This is ready for review.

/cc @ryanuber and @sean-
",slackpad,ryanuber
1764,2016-02-26 09:56:05,"This is ready for review.

/cc @ryanuber and @sean-
",slackpad,sean-
1762,2016-02-26 04:00:15,"@slackpad This addresses https://github.com/hashicorp/consul/issues/1508
",mshean,slackpad
1757,2016-02-24 23:41:51,"The change in #1667 was a good one, but there is a bigger refactor going on under https://github.com/hashicorp/consul/pull/1743. Since we are likely cutting a 0.6.4 release before this lands, we will roll this back for now in favor of the upcoming change post-0.6.4 release.

/cc @sean- 
",slackpad,sean-
1752,2016-02-24 20:34:40,"Thanks to @kikitux for pointing out that there is an existing raw interface for reading keys that I totally didn't know was there :-)

> If the ""?raw"" query parameter is used with a non-recursive GET, the response is just the raw value of the key, without any encoding.

(from [here](https://www.consul.io/docs/agent/http/kv.html))

So the example would just be:

echo $(curl -s http://demo.consul.io/v1/kv/global/time?raw)

Sorry about that!
",slackpad,kikitux
1734,2016-02-19 20:52:28,"Per discussion with @slackpad on IRC, added another commit to the compression branch which adds an `enable_compress` config option and only tries compression if that one is set.

https://github.com/idubinskiy/consul/commit/fa72770bbddb5ddd4b916ceaa7f2f1b4c246378f
",idubinskiy,slackpad
1715,2016-02-13 02:42:00,"@sean- this is a legit borkage. Let's see if we get that weird error from the CI build for this branch.
",slackpad,sean-
1712,2016-02-12 20:25:22,"Based on work done by @fusiondog in #1583, extend the concept to use an integer instead of a boolean.  This is required to work around RFC3484 Section 6 Rule 9.

Fixes: #1583 && #1481
",sean-,fusiondog
1698,2016-02-07 21:47:26,"All of the real work here was done by @evan2645 under https://github.com/hashicorp/consul/pull/1547. This takes that PR and does the following:
- Rebased to latest master.
- Added some documentation and extra tests.
- Generalized the WAN address configuration into a first-class `TaggedAddresses` config item. This is populated only with the WAN address for now, but it gives us a good base to expose this as a configurable thing later for additional address tags.
- Changed the name of the `Node` structure member from `Addresses` to `TaggedAddresses`. Having `Addresses` next to `Address` was too subtle (even though it was my original suggestion to name it that, sorry to change it again).
- Made anti-entropy sync take care of setting this in the catalog instead of the Serf layer. This will be better if we add more later, and it keeps the logic out of some places like `leader.go`, and it doesn't add any new Serf tags where space is limited.
",slackpad,evan2645
1698,2016-06-09 17:06:17,"@slackpad thanks for your awesome work on this! We've been trying to use this feature but unfortunately it seems that it's only available through the DNS interface. What I would really like to see is the appropriately translated address available in the `""Address""` field of the node object when querying through the HTTP API.

I've been chatting with @evan2645 about this, and he thinks that the above should be do-able. I'm ready to start on a patch but wanted to check with you to see if there was any reason this isn't feasible, or if there was any reason it's a Bad Idea. Thanks!
",DWvanGeest,evan2645
1680,2016-06-14 19:18:11,"@slackpad discussed this earlier today with you - no need to create a duplicate... :)

Need to determine what the [HealthCheck](https://github.com/hashicorp/consul/blob/master/consul/structs/structs.go#L368-L380) type needs to look like, to augment it to expose the actual checks.

There were thoughts regarding future use of HCL from @sethvargo - and structuring the Go type/s to future proof it.

An initial brainstorm of a response JSON body would be something like:



Not super well thought out and I'm almost certain it will need to be tweaked, but something to start iterating against.

Related types:
- [CheckTCP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L467)
- [CheckHTTP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L341)

Things to consider:
- Expanding the single string key TCP and HTTP in each of the above types respectively to be pieces of a URI, or Hostname and Port separately. For example HTTP would become Scheme, Hostname, Port, URI. TCP would become Hostname and Port.
",CpuID,slackpad
1680,2016-06-14 19:18:11,"@slackpad discussed this earlier today with you - no need to create a duplicate... :)

Need to determine what the [HealthCheck](https://github.com/hashicorp/consul/blob/master/consul/structs/structs.go#L368-L380) type needs to look like, to augment it to expose the actual checks.

There were thoughts regarding future use of HCL from @sethvargo - and structuring the Go type/s to future proof it.

An initial brainstorm of a response JSON body would be something like:



Not super well thought out and I'm almost certain it will need to be tweaked, but something to start iterating against.

Related types:
- [CheckTCP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L467)
- [CheckHTTP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L341)

Things to consider:
- Expanding the single string key TCP and HTTP in each of the above types respectively to be pieces of a URI, or Hostname and Port separately. For example HTTP would become Scheme, Hostname, Port, URI. TCP would become Hostname and Port.
",CpuID,sethvargo
1680,2016-11-16 19:51:13,"@slackpad _bump_ :)
",CpuID,slackpad
1679,2016-02-03 00:35:41,"There is this [old thread on googlegroups](https://groups.google.com/forum/#!msg/consul-tool/qewFEqgAoF8/b9hxhmy1v6gJ) asking about why consul warns to set GOMAXPROCS > 1 on startup.  Then there's [a commit](https://github.com/hashicorp/consul/commit/a61d89d0e66c6698d4b166aa457bf020d5c383cc) which removes these warnings due to changes in Golang 1.5.  But what about machines with 1 core?  In this case is it necessary to manually set GOMAXPROCS to something else?  And if so, does it matter what, is `2` ok?

/cc @fraenkel
",Amit-PivotalLabs,fraenkel
1661,2016-01-28 23:48:11,"I remember finding this a long time ago but I forgot to register it as a bug. Was talking with @slackpad last week and remembered.

I ran into it when a service that was writing config files failed and wrote a blank file into the folder - Consul then fails to start up - tries to parse and craps out.

Example output here:

https://gist.github.com/darron/7275837c7734041c5a4a

Not sure if it's something y'all can fix - guard against - but if it's possible that would likely be pretty awesome.

Thanks for the great software!
",darron,slackpad
1656,2016-06-15 20:42:45,"@slackpad after taking look at the https://www.consul.io/docs/guides/datacenters.html, particularly this fragment 

> The join command is used with the -wan flag to indicate we are attempting to join a server in the WAN gossip pool. As with LAN gossip, you only need to join a single existing member, and the gossip protocol will be used to exchange information about all known members. For the initial setup, however, each server will only know about itself and must be added to the cluster.

It appears to me that this is in fact a bug and this issue should be relabeled accordingly
",takeda,slackpad
1632,2016-01-20 05:58:40,"This fixes #1626.

The basic problem is that we were returning the underlying `NotifyGroup` object here:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L100-L112

This worked fine the first time through, but when a prefix was notified, this `NotifyGroup` would get deleted:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L140-L143

So in a blocking RPC, once you looped around because the watch was notified, you'd end up calling `Wait()` on a `NotifyGroup` that was no longer part of the watch manager:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/rpc.go#L342

The solution is to never expose the underlying `NotifyGroup` to the blocking RPC code. I created a wrapper object that re-registers the wait channel with whatever `NotifyGorup` is in the tree, or it creates one.

This bug was pretty subtle because you had to have these conditions:
1. Make a blocking query on some key ""A"".
2. Update some key ""B"" whose key is a prefix of ""A"".

This is probably not super common, but this would have been difficult to detect. The query timeout would eventually un-block the first query, but it would report stale results from the first time it looked at the state store.

/cc @armon or @ryanuber 
",slackpad,armon
1632,2016-01-20 05:58:40,"This fixes #1626.

The basic problem is that we were returning the underlying `NotifyGroup` object here:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L100-L112

This worked fine the first time through, but when a prefix was notified, this `NotifyGroup` would get deleted:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L140-L143

So in a blocking RPC, once you looped around because the watch was notified, you'd end up calling `Wait()` on a `NotifyGroup` that was no longer part of the watch manager:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/rpc.go#L342

The solution is to never expose the underlying `NotifyGroup` to the blocking RPC code. I created a wrapper object that re-registers the wait channel with whatever `NotifyGorup` is in the tree, or it creates one.

This bug was pretty subtle because you had to have these conditions:
1. Make a blocking query on some key ""A"".
2. Update some key ""B"" whose key is a prefix of ""A"".

This is probably not super common, but this would have been difficult to detect. The query timeout would eventually un-block the first query, but it would report stale results from the first time it looked at the state store.

/cc @armon or @ryanuber 
",slackpad,ryanuber
1630,2016-02-02 02:33:38,"Hi @Millnert,

Normally, Consul only verifies that a certificate is signed by a configured CA, it doesn't look at the hostnames. The config you cited is used by this feature - https://www.consul.io/docs/agent/options.html#verify_server_hostname. If `verify_server_hostname` is turned on, then Consul will also verify the hostname is `server.<datacenter>.<domain>`. This lets you create a special certificate just for servers to keep random clients with valid certificates from acting as a server.

I tagged this as docs because I think we can enhance the documentation about this. Does this make sense?

/cc @sean- 
",slackpad,sean-
1624,2016-02-02 01:38:36,"Hi @panda87 I took a look back through the code and these have been floats since the beginning. I'll tag @armon to see if he can lend any insight into why they were built this way, but I'll go ahead and close this out since it is the intended behavior and didn't change in 0.6.x.
",slackpad,armon
1622,2016-01-18 18:55:05,"Changing api.Client to interface will break all programs using consul/api since `*api.Client` will have to change to `api.Client`. We should probably add newly named interfaces and transition to them while still supporting old API. @armon ?
",avishai-ish-shalom,armon
1592,2016-01-13 05:11:45,"This is the Consul side of https://github.com/hashicorp/consul-template/pull/511. Unit tests look good as a regression - I will do some integrated testing in the morning, similar to what was done in the CT PR.

/cc @sethvargo 
",slackpad,sethvargo
1570,2016-08-09 22:37:43,"@slackpad What can I do to help push this forward? This would really help me with some overlay/underlay networking stuff. There seems to be a merge conflict now, but the patch looks pretty self contained, so I'd imagine it is easy to resolve. I'd be happy to resolve the conflicts and make a new PR. I suspect there is something more keeping this from getting merged.
",ChrisLundquist,slackpad
1566,2016-02-09 23:23:44,"@slackpad - if you have any ideas about a test that could be added to ensure this builds in the project's tests overall, let me know.  I had to update this as the provision script was failing due to an old consul version being removed, and wouldn't want it to break again in the future without warning.
",jzohrab,slackpad
1559,2016-01-02 14:59:16,"Wanted to give @railsguru credit for a fix that I missed previously and was added later by someone else but it ended up duplicating the token variable. This fixes it.
",slackpad,railsguru
1554,2016-02-02 03:14:25,"/cc @sean- 
",slackpad,sean-
1548,2016-01-12 08:21:23,"@ryanbreen Thanks very much!
",kikitux,ryanbreen
1547,2015-12-24 15:57:49,"Often times, it is necessary to discover and communicate with a service in a different datacenter which is behind a NAT. Currently, only Consul servers have the concept of a WAN address. Here, we re-use this knob to enable clients to set their WAN addresses as well, and introduce a new configuration option to instruct Consul to prefer the WAN address (if set) when making cross-DC requests.

@slackpad this feature is a blocker for us. Solves #1386. I have not written much go, so please let me know if anything here is non-idiomatic.
",evan2645,slackpad
1539,2015-12-22 05:53:05,"/cc @ryanuber or @sethvargo for review
",slackpad,ryanuber
1539,2015-12-22 05:53:05,"/cc @ryanuber or @sethvargo for review
",slackpad,sethvargo
1534,2015-12-21 09:24:22,"Following the discussion here: https://groups.google.com/d/topic/consul-tool/SJYfMMcE9xI/discussion

We are powering off all the nodes of a 5-node cluster, and powering them back up (this is an instant powerdown, not a graceful one, so the nodes rejoin the cluster after we restart them). 
After the cluster crash, ""consul members"" seems fine, but in about 1 of every 3 cases, we see that the following HTTP requests are hanging:
http://localhost:8500/v1/agent/services
http://localhost:8500/v1/agent/checks
In comparison, the /v1/agent/self request works fine.

This happens with 0.6.0, but also with older versions (0.5.0).

Per @slackpad 's recommendation, we collected debug info about the go routines. If I run the debug/pprof/goroutine command a few times, while the HTTP request is hanging, I see that over time the number of go routines is growing all the time.

Attached is the latest output. 

TIA.
[goroutines.txt](https://github.com/hashicorp/consul/files/68284/goroutines.txt)
",shimshon-stratoscale,slackpad
1534,2016-02-08 06:22:13,"Thanks @slackpad for the analysis. Indeed in this state we found out we cannot write to the KV store.
I had a correspondence on the outage issue with @armon in the past (see here: https://groups.google.com/forum/#!topic/consul-tool/k1ZnMHVwobA ), in which he said that if we restart each of the consul agents with the same flags they had in their previous run, we should be ok - has that changed?
BTW - we added a post-restart code that upon detecting that writes are stuck, it restarts the consul process. Sometimes it takes multiple restarts, but eventually it works. However, that's just a workaround. Appreciate your input on this.
",shimshon-stratoscale,armon
1503,2015-12-28 22:19:34,"@slackpad Yeah, looking at it again, I don't think I need it either. Removed. Also rebased on master.
",nicholascapo,slackpad
1500,2015-12-19 07:11:41,"Hi @ErikEvenson take a look at https://github.com/sethvargo/atlas-demo - that's got an end-to-end demo with Consul that should be helpful (though be careful it is set up to allow open access for demo-ing). There are some ssh examples for key handling in there.

/cc @sethvargo 
",slackpad,sethvargo
1500,2015-12-21 16:07:46,"@slackpad @erikdubbelboer here are some more examples:
- https://github.com/sethvargo/terraform-workshop-atlas
- https://github.com/hashicorp/best-practices
",sethvargo,erikdubbelboer
1493,2015-12-11 15:23:25,"/cc @armon
",sethvargo,armon
1493,2015-12-14 19:43:10,"Thanks @sethvargo (and @tgwizard I fixed that)!
",slackpad,tgwizard
1472,2015-12-07 16:09:40,"I have an apprentice who needs a real project to work on to level up his skills. I would like to work with him upgrading this codebase to latest version of Ember and to EmberCLI. 

Do you have any objections to this? Would you be open to merging such a PR?

/cc @pearkes @tiwilliam
",taras,pearkes
1472,2015-12-07 16:09:40,"I have an apprentice who needs a real project to work on to level up his skills. I would like to work with him upgrading this codebase to latest version of Ember and to EmberCLI. 

Do you have any objections to this? Would you be open to merging such a PR?

/cc @pearkes @tiwilliam
",taras,tiwilliam
1467,2015-12-04 04:53:11,"I was testing the final 0.6.0 build of the web UI and realized that the settings icon is broken:

It's missing on Chrome:

![image](https://cloud.githubusercontent.com/assets/673509/11582111/50e999ec-99ff-11e5-9a68-cca10123186e.png)

And it looks super weird on Safari:

![image](https://cloud.githubusercontent.com/assets/673509/11582120/630c3b98-99ff-11e5-95d3-73fd5d20aa48.png)

Here's how it used to look:

https://www.consul.io/assets/images/consul_web_ui-aeb578f2.png

This has been deployed to the demo cluster if you want to take a look here - http://demo.consul.io/ui/. I don't think this is a show stopper for release since it's easy to update the web UI, but it would be nice to fix soon.

/cc @pearkes @meirish 
",slackpad,pearkes
1467,2015-12-04 04:53:11,"I was testing the final 0.6.0 build of the web UI and realized that the settings icon is broken:

It's missing on Chrome:

![image](https://cloud.githubusercontent.com/assets/673509/11582111/50e999ec-99ff-11e5-9a68-cca10123186e.png)

And it looks super weird on Safari:

![image](https://cloud.githubusercontent.com/assets/673509/11582120/630c3b98-99ff-11e5-95d3-73fd5d20aa48.png)

Here's how it used to look:

https://www.consul.io/assets/images/consul_web_ui-aeb578f2.png

This has been deployed to the demo cluster if you want to take a look here - http://demo.consul.io/ui/. I don't think this is a show stopper for release since it's easy to update the web UI, but it would be nice to fix soon.

/cc @pearkes @meirish 
",slackpad,meirish
1463,2015-12-02 17:06:18,"While testing the example snippets in my blog post I realized you can register the same name multiple times.

/cc @ryanuber or @armon 
",slackpad,armon
1463,2015-12-02 17:06:18,"While testing the example snippets in my blog post I realized you can register the same name multiple times.

/cc @ryanuber or @armon 
",slackpad,ryanuber
1452,2015-11-28 01:22:16,"Shrink idle yamux streams in the connection pool to reduce memory overhead. Otherwise, each stream may allocate up to 512KB of buffers, and we may have up to 64 idle streams per remote peer.

/cc: @slackpad 

Depends on https://github.com/hashicorp/yamux/pull/21
",armon,slackpad
1450,2015-11-26 02:02:35,"These warnings no longer make sense for Go 1.5+ since it now defaults to the number of CPUs present. They will fire only on single core machines now and we don't want those people oversubscribing their single-core machines so this is strictly giving bad advice.

/cc @armon 
",slackpad,armon
1445,2015-11-23 18:48:39,"This came up in https://github.com/hashicorp/consul/commit/8738f9780bd30f628508d4e721df0d77ad0bd3b7#commitcomment-14566231. It looks like it's probably https://github.com/golang/go/issues/8998, but I couldn't find a newer version of `wget` for precise64, and I couldn't find a good newer Ubuntu box with VMWare support, so I switched to `curl` which checks the cert successfully.

/cc @catsby 
",slackpad,catsby
1432,2016-05-17 18:30:12,"@slackpad Is there anything that prevents merging this PR?
",t3hk0d3,slackpad
1428,2015-11-19 04:32:12,"I have a Consul cluster with 2.8 million garbage `/vault/core/leader` entries (resulting from a bug in some older versions of Vault - https://github.com/hashicorp/vault/issues/679) that hurts Consul KV and UI performance (operations apparently take too long and timeout because of the number of keys that have to be crawled - https://github.com/hashicorp/consul/issues/1407). 

I had no idea that I had accumulated this huge number of keys until things got slow and started timing out and then @slackpad recognized the symptoms and suggested running `strings state.bin | grep vault/core/leader | wc -l` to count the number of keys.

To prevent this in the future I'd like to set up monitoring (e.g.: Nagios, Zabbix, etc.) that can watch the number of keys. It would be best if the Consul HTTP API had a method that exposed the # of keys.

Looking at https://www.consul.io/docs/agent/http/status.html, I wonder if something like `/v1/status/keys` would make sense. It could look something like this:



or maybe it makes more sense to live under the `/kv` API and then maybe it could support returning the count of keys under a certain prefix?



Cc: @sudarkoff
",msabramo,slackpad
1419,2016-03-05 01:29:07,"@sean- and I were thinking more about this and we can probably eliminate all ACL caching in favor of this if it's full ACL replication. We'd create a new endpoint that supports blocking queries and provides a complete snapshot of ACLs (SHA256 hash of token and policy), or we could make a fancier API that can intelligently send updates after an initial full dump. Any server with the replicated ACLs can hash an incoming token and look up the policy, but won't have any other access to the actual tokens. If we do full replication, we can eliminate the ACL cache code completely, which would massively simplify that code path.

We can still support the old ACL endpoint to fetch a policy for a token, so for upgrades you just need to upgrade your ACL DC to Consul 0.7 before you upgrade any of your other servers.
",slackpad,sean-
1404,2015-11-11 16:34:14,"Along similar lines to https://github.com/hashicorp/vault/issues/765, should Consul also print its version when starting up, to aid in troubleshooting?

Currently it prints info that's very similar to what Vault prints:



I figure it might as well print the version, just like Vault now does, thanks to @jefferai's fine work on https://github.com/hashicorp/vault/issues/765
",msabramo,jefferai
1376,2015-10-30 21:59:38,"We should add a CLI to manipulate bootstrap mode vs. flags or configs. If it manipulates the state of consul's data directory, it should be a one-shot command that can not be in a config file or a command line argument that is accepted by the `consul agent` sub-command.  For example:
1. `consul set encrypt-key=foo`
2. `consul agent`

The encrypt key can't be specified on the agent line.  Same for bootstrap flags.

/cc @sean-
",slackpad,sean-
1375,2015-10-30 21:56:01,"Right now they hopelessly keep trying and spam the logs. They could wait for the event before they try again.

/cc @sean-
",slackpad,sean-
1374,2015-10-30 21:55:03,"While interactively debugging an issue with @sean- a number of improvements were noted:
1. It's hard to tell who a server is replicating TO, add IPs to the logs.
2. It's hard to tell who the current leader is without logging into each and looking at `consul info`, make `consul members` show who the current leader is.
3. Consider adding a `consul peers` type command that shows the Raft details in a clear, parseable format. The peer set version is hard to understand, expose the Raft index.
4. Add better metrics for Raft-related events such as leader elections. Right now we can only look at events which are output by all the nodes, so it's really hard to see the actual number of leadership transitions.
",slackpad,sean-
1374,2016-03-01 21:06:57,"Hi all - this hasn't yet been implemented. I'd hold off on working on this for right now - @sean- is looking at a cluster-level status endpoint that would support this type of info. We should have more details in a bit.
",slackpad,sean-
1374,2016-06-08 01:21:20,"@slackpad or @sean- do either of you have any updates on this issue?
",CpuID,sean-
1365,2015-10-29 20:12:48,"This avoids a redirect by adding a trailing slash... it's the little things in life.

/cc @slackpad 
",sethvargo,slackpad
1359,2015-10-29 02:16:21,"In general, coordinate updates are funneled to the leader who batches them in a local data structure and writes them to the Raft log after a timer fires. This helps cut down on the number of Raft transactions due to coordinates. If there's a leadership transition with unwritten batch items, the follower node will emit this:

`2015/10/29 01:51:27 [ERR] consul.coordinate: Batch update failed: node is not the leader`

As its implemented, the follower will throw these updates away, so it does the right thing and doesn't keep spamming. This is pretty ugly, though. We should flush the batch during leader transitions and only run the updater while we are the leader.

/cc @armon - can you think of any reason this is unsafe as-is?
",slackpad,armon
1354,2015-10-28 01:21:16,"Noticed that index.html expects these to be in a subfolder, and it's easier for development to put them in there, I think, vs. deleting the subfolder.

/cc @sethvargo 
",slackpad,sethvargo
1344,2015-10-26 21:30:56,"/cc @slackpad 
",sethvargo,slackpad
1337,2016-02-05 05:22:00,"@AlexisSellier thank you for the tip, we have been running into this issue as well, 0.6.3 helps a lot, we only received a few flapping a day, compared to before where we received a few flapping every 15 minutes. 
@slackpad I wonder if we can tune these values at the config file level ?
",changwuf31,slackpad
1331,2015-10-23 22:30:48,"This should complete network tomography on the Consul side. There was a pretty major rebase after the memdb changes, so the final commit (https://github.com/hashicorp/consul/commit/ecd3a1d1d21d635fd62555b710abbb9bc76d0eff) has the major changes associated with that. That change is worth a quick review, everything else has been reviewed previously.

Here are the biggest changes made during the rebase:
1. While in here I realized that the state store would accept coordinates for nodes that weren't in the catalog. Since deleting coordinates is tied to deleting nodes, and we don't really control if agents send coordinates before they have successfully been registered in the catalog, this seemed like a potential for inconsistency. I made the state store just skip coordinate updates for nodes not in the catalog, which required some changes to unit tests.
2. Got rid of the single coordinate get function since it was only used in unit tests.
3. Beefed up unit tests in some places.
4. Cleaned up the coordinate types in the structs package.

/cc @armon and/or @ryanuber 
",slackpad,armon
1331,2015-10-23 22:30:48,"This should complete network tomography on the Consul side. There was a pretty major rebase after the memdb changes, so the final commit (https://github.com/hashicorp/consul/commit/ecd3a1d1d21d635fd62555b710abbb9bc76d0eff) has the major changes associated with that. That change is worth a quick review, everything else has been reviewed previously.

Here are the biggest changes made during the rebase:
1. While in here I realized that the state store would accept coordinates for nodes that weren't in the catalog. Since deleting coordinates is tied to deleting nodes, and we don't really control if agents send coordinates before they have successfully been registered in the catalog, this seemed like a potential for inconsistency. I made the state store just skip coordinate updates for nodes not in the catalog, which required some changes to unit tests.
2. Got rid of the single coordinate get function since it was only used in unit tests.
3. Beefed up unit tests in some places.
4. Cleaned up the coordinate types in the structs package.

/cc @armon and/or @ryanuber 
",slackpad,ryanuber
1311,2016-02-05 22:46:57,"Hey @slackpad 

Thanks for following up.  Yes, we're still having this issue.  We [guarantee data persistence when scaling up from 3 to 5](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L80-L100) whereas we [only guarantee the cluster is functional after scaling up from 1 to 3](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L28-L46). @ryanmoran and @zankich spoke with @mitchellh and some HashiCorp folks when they visited our office, sounded like this is something we have to live with for now.
",Amit-PivotalLabs,mitchellh
1306,2016-06-07 18:46:54,"@slackpad are you able to provide any feedback on this one?
",CpuID,slackpad
1306,2016-06-08 22:26:04,"@sean- @slackpad - how would you feel about augmenting [RemoveFailedNode](https://github.com/hashicorp/consul/blob/master/consul/server.go#L643-L652) to support cleaning up the Raft entry in addition to cleaning up the Serf side, for `force-leave` operations?

I wonder if the correct way to do this is to use the Serf layer to broadcast a Raft removal which is actioned on each node locally?

Or potentially hook into the [lanNodeFailed/wanNodeFailed](https://github.com/hashicorp/consul/blob/master/consul/serf.go#L248-L293) hooks as a Plan B? Not 100% sure if these are called on `RemoveFailedNode` scenarios right now.
",CpuID,slackpad
1306,2016-06-08 22:26:04,"@sean- @slackpad - how would you feel about augmenting [RemoveFailedNode](https://github.com/hashicorp/consul/blob/master/consul/server.go#L643-L652) to support cleaning up the Raft entry in addition to cleaning up the Serf side, for `force-leave` operations?

I wonder if the correct way to do this is to use the Serf layer to broadcast a Raft removal which is actioned on each node locally?

Or potentially hook into the [lanNodeFailed/wanNodeFailed](https://github.com/hashicorp/consul/blob/master/consul/serf.go#L248-L293) hooks as a Plan B? Not 100% sure if these are called on `RemoveFailedNode` scenarios right now.
",CpuID,sean-
1301,2016-11-28 03:53:52,@slackpad may be we do a full dns support to consul?,westsouthnight,slackpad
1295,2015-10-13 00:44:58,"It would be great if the [Consul vs Other Software](https://www.consul.io/intro/vs/index.html) section of the website included a comparison of Consul vs [Eureka](https://github.com/Netflix/eureka/wiki).

@armon provided a quick summary in the [google group](https://groups.google.com/d/msg/consul-tool/fsLGavCv-j8/xGH2f6XACgAJ)...

> Could you please file a ticket? We can hopefully get this done in more detail, but in gist:
> 
> Eureka:
> - AP (weak consistency), state is replicated with â€œbest effortâ€
> - Services are registered with one server, which attempts to replicate to other servers
> - Service registrations have a TTL, and clients must heartbeat
> - Reads are routed to any server, can be stale or missing data
> - Scales well due to low coordination, especially when server failures relatively rare
> - Fails if all servers down
> 
> Consul
> - CP (strong consistency), state is replicated using Raft
> - Services registered with any server, but written via Raft to a quorum
> - Registrations have complex health checks, including gossip failure detection instead of heartbeating
> - Reads routed to any server, consistent by default but stale reads can be requested
> - Stale reads scale well, Consistent reads scale to tens of thousands per second
> - Consistency offers locking and cluster coordination
> - Lots more features (health checking, locking, KV, federation, ACLs)
> - Fails if a majority of servers down
> 
> Hope that helps!
> 
> Best Regards,
> Armon Dadgar
",philsttr,armon
1291,2015-10-12 17:05:37,"I'll be pushing up some other changes today but this is worth an initial look /cc @armon @ryanuber.
",slackpad,armon
1291,2015-10-12 17:05:37,"I'll be pushing up some other changes today but this is worth an initial look /cc @armon @ryanuber.
",slackpad,ryanuber
1291,2015-10-20 06:19:39,"@armon and @ryanuber all the outstanding comments have been addressed so please take another look.

I'm going to leave the TODO in `PrefixWatch.Notify()` for now since it's an existing bug and clean that up on another PR if I have time. I think it'll need a periodic sweep kind of cleanup, or else the notify groups will have to be able to tell the parent `PrefixWatch` once they have become empty.
",slackpad,ryanuber
1284,2015-11-03 18:48:51,"Any chance to look at this @slackpad following @nbrownus PR ? Would be greatly appreciated.
",scalp42,slackpad
1278,2016-12-21 03:37:05,"@saifabid I use 0.6.4 and try to delete a folder on KV which contains much more than 10M entries, using the HTTP API `curl -X DELETE http://localhost:8500/v1/kv/locks\?recurse\&token=xxxx`

As my understanding, this is a block operation and must be done on leader, and once I send my delete request, my consul cluster leader looks unresponsive and other peers in cluster start to election, and my entire cluster became unstable, finally it goes to `No cluster leader`. Very frustrating.

The delete operation will return `rpc error: EOF` eventually but the big entry still there and also makes my cluster unavailable.
Is there any other efficient way to delete such big entry?",kongchen,saifabid
1271,2015-10-26 17:16:44,"Gotcha. I apologize, I admit i didn't fully understand the problem on first read. Very interested to understand what is happening here as well.

I'm first thinking maybe all servers except the first have to call `-join <first server>`, but that would be hard to detect, and why wouldn't it just continue where it left off.

Any ideas @armon @slackpad ?
",djenriquez,armon
1271,2015-10-26 17:16:44,"Gotcha. I apologize, I admit i didn't fully understand the problem on first read. Very interested to understand what is happening here as well.

I'm first thinking maybe all servers except the first have to call `-join <first server>`, but that would be hard to detect, and why wouldn't it just continue where it left off.

Any ideas @armon @slackpad ?
",djenriquez,slackpad
1265,2015-09-30 19:18:58,"Per the conversation on the mailing list here: https://groups.google.com/forum/#!searchin/consul-tool/thousands$20of$20services/consul-tool/vPAhS1EhABM/_SPAIXuMFDQJ 

There is a slowdown due to how the gent loops over all services and the catalog returned from the server that completes in O(N^2). After talking with @slackpad at HashiConf we think that we can improve on this  fairly simply with an index on the server result. 
",spheromak,slackpad
1265,2015-10-12 08:42:32," @slackpad did you do anything with this since hashiconf ?
",spheromak,slackpad
1254,2015-10-05 18:58:24,"@slackpad I brought this issue up to you during Hashiconf. Would love to hear your recommendation on this.
",calvn,slackpad
1254,2015-10-05 19:07:03,"Interesting topic. We are currently backing up our dockerized Consul servers using [Convoy](https://github.com/rancher/convoy), but it appears that this will cause issues if we were to restore this data onto a new Consul server on a machine with a different IP address, as @highlyunavailable noted. We followed this as recommened by @armon in this [Google Group topic](https://groups.google.com/forum/#!msg/consul-tool/cbe_W_SClog/u3PhFlDlyaAJ).

We know that [Consulate](https://github.com/gmr/consulate) exists, but we are striving for a service-agnostic back up solution, which is why we settled with Convoy. 

Our main goal was to backup the K/V store. Is there a subdirectory we should be backing up instead of the `/data/` directory in its entirety?
",djenriquez,armon
1251,2015-09-20 18:04:16,"We migrated to this in Vagrant. The reason to do a subtree split is for preserving history. We don't actually care about history since this is just the static site and we force-push to heroku anyway.

This PR copies the website into a staging directory and creates a fresh git repository in there. This severely reduces the amount of time required for a deploy :smile:

/cc @ryanuber @slackpad 
",sethvargo,slackpad
1251,2015-09-20 18:04:16,"We migrated to this in Vagrant. The reason to do a subtree split is for preserving history. We don't actually care about history since this is just the static site and we force-push to heroku anyway.

This PR copies the website into a staging directory and creates a fresh git repository in there. This severely reduces the amount of time required for a deploy :smile:

/cc @ryanuber @slackpad 
",sethvargo,ryanuber
1240,2015-09-14 17:49:34,"When building from master, I was getting errors that `-X main.GitCommit ${GIT_COMMIT}${GIT_DIRTY}` was missing an equal sign and may break in a future version.

/cc @ryanuber @slackpad 
",sethvargo,slackpad
1240,2015-09-14 17:49:34,"When building from master, I was getting errors that `-X main.GitCommit ${GIT_COMMIT}${GIT_DIRTY}` was missing an equal sign and may break in a future version.

/cc @ryanuber @slackpad 
",sethvargo,ryanuber
1238,2015-09-15 18:35:48,"Oh I see, you mean you can exec inside the allowed key space that the clients can write to.

In 0.6 you will be able to deny firing events, but it's pretty easy to forget to configure that and open up this hole. It seems like maybe if you aren't allowed to write to ""_rexec"" then you shouldn't be able to exec on any other prefix (kind of an implied extension of the ACL), plus we'd look at your ACL for the prefix as well. This might be a little subtle to explain, but it would work without a new ACL type. Alternative could be a first class exec ACL.

I'll ping @armon and @ryanuber for their thoughts on the interface for this.
",slackpad,armon
1238,2015-09-15 18:35:48,"Oh I see, you mean you can exec inside the allowed key space that the clients can write to.

In 0.6 you will be able to deny firing events, but it's pretty easy to forget to configure that and open up this hole. It seems like maybe if you aren't allowed to write to ""_rexec"" then you shouldn't be able to exec on any other prefix (kind of an implied extension of the ACL), plus we'd look at your ACL for the prefix as well. This might be a little subtle to explain, but it would work without a new ACL type. Alternative could be a first class exec ACL.

I'll ping @armon and @ryanuber for their thoughts on the interface for this.
",slackpad,ryanuber
1235,2015-09-17 09:55:50,"@slackpad 

> Want to take a crack at preventing multiple reloads as well?

I'm pretty sure `handleReload()` is only called from `handleSignals()`, and AFAICT handleSignals is fully synchronous (https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L797) and as such doesn't need a mutex to prevent multiple reloads.  (/cc: @ryanuber ?) 

It seems that all the interference was caused by `handleReload` and `antiEntropy` fighting with each other NOT multiple configuration reloads running simultaneously.  It's just easier to trigger a Pause/Resume conflict with `antiEntropy` if you force consul into contant reload mode by spaming SIGHUP for a while. 
",wuub,ryanuber
1231,2015-09-21 14:50:23,"/cc @sethvargo thoughts?
",ekristen,sethvargo
1223,2015-09-08 19:21:22,"In the default-deny setup, it seems `consul maint` is not able to make progress even with the correct ACL tokens that have write permissions. Errors also occur on the server side for this.

/cc: @ryanuber @sean-
",armon,ryanuber
1223,2015-09-08 19:21:22,"In the default-deny setup, it seems `consul maint` is not able to make progress even with the correct ACL tokens that have write permissions. Errors also occur on the server side for this.

/cc: @ryanuber @sean-
",armon,sean-
1219,2015-09-12 20:00:58,"Cool, this LGTM.  Only question is whether @armon, @ryanuber, or @slackpad have philosophical objections to ""first public IPv6"" being a supported config when we've only ever offered first available private IP binding for IPv4.

I know there are systemic differences between IPv6 and IPv4 that make public IPs more appropriate in IPv6, but this is enough of a difference that I'm not comfortable merging without one of the project owners weighing in.
",ryanbreen,armon
1219,2015-09-12 20:00:58,"Cool, this LGTM.  Only question is whether @armon, @ryanuber, or @slackpad have philosophical objections to ""first public IPv6"" being a supported config when we've only ever offered first available private IP binding for IPv4.

I know there are systemic differences between IPv6 and IPv4 that make public IPs more appropriate in IPv6, but this is enough of a difference that I'm not comfortable merging without one of the project owners weighing in.
",ryanbreen,slackpad
1219,2015-09-12 20:00:58,"Cool, this LGTM.  Only question is whether @armon, @ryanuber, or @slackpad have philosophical objections to ""first public IPv6"" being a supported config when we've only ever offered first available private IP binding for IPv4.

I know there are systemic differences between IPv6 and IPv4 that make public IPs more appropriate in IPv6, but this is enough of a difference that I'm not comfortable merging without one of the project owners weighing in.
",ryanbreen,ryanuber
1219,2015-11-09 17:02:56,"ping @armon, @ryanuber, @slackpad 
Any comments ?
",42wim,armon
1219,2015-11-09 17:02:56,"ping @armon, @ryanuber, @slackpad 
Any comments ?
",42wim,slackpad
1219,2015-11-09 17:02:56,"ping @armon, @ryanuber, @slackpad 
Any comments ?
",42wim,ryanuber
1217,2015-09-02 14:17:44,"Subtle bug, we found in production. dig works, but some applications fail.

We only need to send the SOA record when the answer is empty, not NXDOMAIN (because the resource exists, it only doesn't have the required type), otherwise no other records will be asked.

@ryanbreen could you merge this ?
",42wim,ryanbreen
1196,2015-08-25 22:16:44,"Hi @armon 

Assuming we have a Redis service defined as `redis.json` in consul directory:



Now assuming there is a check `redis_check.json`:



This example does not make sense in itself, but it's just to clear up the doc.

What happen in that case in Consul ? Should checks be tied to services or vice versa (or doesn't really matter) ?

Thanks in advance!
",scalp42,armon
1188,2015-08-20 20:14:01,"I brought this to the attention of the mailing list [here](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/consul-tool/1wEHSx3Qp-Y). @slackpad asked me to go ahead and file a bug. Below summary of the issue from the discussion thread.

We have services that are being orphaned and we cannot deregister them. The orphans show up under one or more of the master nodes. In our configuration the master nodes are `dev-consul`, `dev-consul-s1`, and `dev-broker`.

The health check of the orphaned node looks something like the following:



I attempted to deregister via:



The node was removed but then reappears within 30-60s. As @slackpad's recommended, I tried deregistering with:



Both commands returned status `200 OK`. But that also failed. You can see the output in this [gist](https://gist.github.com/drsnyder/3016efb02efebc6afbe6) as well as the debug logs from consul.

From the debug logs in consul we see:



The annotation is from @slackpad. 

It's also noteworthy that the orphans are always associated with one of the master nodes (e.g. `dev-consul`) and not the node (`dev-mesos`) that's running the service that was registered. I should also mention (it could be a coincidence) that the service (`discussion`) is also flapping though from what I can tell from the debug logs for consul on `dev-mesos` everything is fine.

Our consul version:



Thanks!
",drsnyder,slackpad
1187,2015-09-10 21:32:37,"@slackpad @ryanuber - Thanks for the review, guys.

@slackpad - I have added a couple test cases in TestAgentAntiEntropy_EnableTagDrift.  But perhaps you can see in this conversation that the Travis failing with errors that don't appear to be related to my updates.  I'm not sure why they are failing - they seems to be complaining that an interface is being used. (in code that I did not modify)  Perhaps you guys have seen these errors before?  Known issue?

Travis errors:
command/maint_test.go:48: not enough arguments in call to a1.agent.EnableServiceMaintenance
command/maint_test.go:53: not enough arguments in call to a1.agent.EnableNodeMaintenance
",sfncook,ryanuber
1182,2015-08-17 18:14:55,"From #1181: We are linking to a 404 page in Atlas from our public Consul documentation.

/cc @pearkes @sethvargo
",ryanuber,pearkes
1182,2015-08-17 18:14:55,"From #1181: We are linking to a 404 page in Atlas from our public Consul documentation.

/cc @pearkes @sethvargo
",ryanuber,sethvargo
1165,2015-08-11 01:46:09,"Talked about this with @armon - we probably want to lock per-address rather than one big lock for the pool. Otherwise, a slow connect to a remote DC could hold up a connection to a local server.
",slackpad,armon
1154,2015-08-05 22:15:31,"@darron Hmm this is odd. I haven't seen that before. @slackpad is looking into this.
",armon,slackpad
1150,2015-08-11 17:47:36,"@evanccnyc Hmm, so this looks like about ~35 services queries, and sounds like a few hundred nodes were involved.

My guess is this is similar to the issue #1154 #1165 and the other is the repro case @darron provided us. We are tracking those separately, but this seems like a related issue. We are working to address some of the read pressure issues CT causes in Consul 0.6 to increase the stability of the cluster under that kind of load.

A big improvement to his is the approach of running CT on a single node (or a few under `consul lock`) and storing the result template in a KV entry. Then the 100+ nodes only need to watch a single key for updates instead of 35+ endpoints. This dramatically reduces the load on the servers and helps with overall performance and stability.
",armon,darron
1130,2015-07-23 20:41:32,"This is interesting. I think it's worth probably just reducing the scope to tcp only. A UDP health check doesn't really make much sense in any case. 

/cc: @ryanuber @slackpad 
",armon,slackpad
1130,2015-07-23 20:41:32,"This is interesting. I think it's worth probably just reducing the scope to tcp only. A UDP health check doesn't really make much sense in any case. 

/cc: @ryanuber @slackpad 
",armon,ryanuber
1130,2015-07-24 00:10:30,"@ryanbreen of course you're correct on UDP, I wasn't thinking.  We could send a packet with no payload though.  WRT IPv6/IPv4, there's no way to check explicitly for one or the other if you also want to check via hostname, without specifying the protocol..
",pdf,ryanbreen
1107,2015-09-28 19:49:45,"@slackpad This is the issue I was talking about. It's related to https://github.com/hashicorp/consul/issues/697.

There are also a couple of issues on it on registrator: https://github.com/gliderlabs/registrator/issues/52 / https://github.com/gliderlabs/registrator/pull/242
",amochtar,slackpad
1104,2015-07-17 17:13:32,"@omribahumi I think there may be a misunderstanding here. The cap is the maximum amount you may _extend_ the life of a session at a time, and not the total time a session may be valid for. It is the responsibility of the client to ""renew"" the session before this time period expires using the [renew api](https://consul.io/docs/agent/http/session.html#session_renew). More info on session internals can be found [here](https://consul.io/docs/internals/sessions.html).

I _think_ the 1h cap is in place to prevent dead client sessions from lingering around as a security practice. It seems reasonable to require clients to renew their session liveness each hour at least, but I'll let @armon comment here in case there are other reasons we cap it there.
",ryanuber,armon
1081,2015-07-13 16:37:29,"@bung87 thanks for the PR. Some before / after screenshots might be helpful to see the difference here. 

/cc @pearkes
",ryanuber,pearkes
1080,2015-07-16 22:40:00,"@armon or others, can I get a review on this, time permitting?
",babbottscott,armon
1072,2015-07-01 19:22:32,"Hi @ketzacoatl - you are right, we should beef up the documentation to make this more clear. I found this thread which gives some info about the format of the token from @armon:

https://groups.google.com/forum/#!topic/consul-tool/lN3jZRbS2-g

> If the `acl_master_token` is not supplied, then the servers do not create a master token. If they did,
> there would be no way to programmatically provide it safely. When you provide a value, it can be
> any string value. Using a UUID would ensure that it looks the same as the other tokens, but isnâ€™t
> strictly necessary.
",slackpad,armon
1057,2016-04-23 01:52:10,"Need to re-open this one. This seems to still be an issue:
1. TTL check gets registered after a service is created (output will default to empty).
2. External process starts hitting the TTL check with non-empty output at a 5 second interval.
3. Check output doesn't update unless the state changes (remains blank).

Doing some tracing it looks like the check always has a deferred timer active, even well after it should have expired.

Also, if the output _always_ changes there may be an issue where it _never_ syncs, need to double check this case as well.

/cc @sean- 
",slackpad,sean-
1049,2015-06-22 17:45:45,"Makes sense to me, marking as an enhancement! /cc @pearkes
",ryanuber,pearkes
1029,2015-06-13 00:04:53,"I don't think we use `the INTEG_TESTS` env var anywhere during the tests. This change will just use the `test` target for CI so that we can run the API tests there as well (we build the binary to a temp path in `scripts/test.sh`).

Also removed flowdock because I'm not sure what that is. If we need it I can add it back in.

/cc @armon
",ryanuber,armon
1019,2015-06-17 04:58:19,"@ryanbreen Thank you very much. I get it.
",feiyang21687,ryanbreen
1014,2015-06-08 14:16:25,"/cc @ryanuber 
",sethvargo,ryanuber
1003,2015-06-04 19:02:31,"The `consul lock` command is great (and can be used in tandem with `consul exec`), but it would be great if `consul exec` accepted a `-n` parameter and handled all the locking automatically:



This would be really great for rolling deploys or even Kernel upgrades:



/cc @armon @ryanuber @phinze 
",sethvargo,armon
1003,2015-06-04 19:02:31,"The `consul lock` command is great (and can be used in tandem with `consul exec`), but it would be great if `consul exec` accepted a `-n` parameter and handled all the locking automatically:



This would be really great for rolling deploys or even Kernel upgrades:



/cc @armon @ryanuber @phinze 
",sethvargo,phinze
1003,2015-06-04 19:02:31,"The `consul lock` command is great (and can be used in tandem with `consul exec`), but it would be great if `consul exec` accepted a `-n` parameter and handled all the locking automatically:



This would be really great for rolling deploys or even Kernel upgrades:



/cc @armon @ryanuber @phinze 
",sethvargo,ryanuber
1002,2015-06-05 05:13:50,"@phinze , the build seems to have failed, I hope it's nothing to do with this pull, please check
",sathiyas,phinze
993,2015-06-10 00:25:30,"@reversefold - After digging more I think you are seeing the same thing as is being discussed on #750 and #454.

I was able to reproduce your situation locally and verify that the consul.data/raft/peers.json file ends up with `null` inside on all three servers. That's why a `TERM` sig doesn't lead to this because it doesn't formally leave the set of peers (see [leave_on_terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate), which defaults to false).

I'll let @armon and/or @ryanuber weigh in on the best practice to follow to get into a working state. Maybe we should add a new ""Failure of all Servers in a Multi-Server Cluster"" section in the outage recovery docs since this seems to be confusing to people. I think it will end up being something similar to the manual bootstrapping procedure, picking one of the servers as the lead. In my local testing I was able to get them going again by manually editing the peers.json file, but I'm not sure if that's a safe thing to do.
",slackpad,armon
993,2015-06-10 00:25:30,"@reversefold - After digging more I think you are seeing the same thing as is being discussed on #750 and #454.

I was able to reproduce your situation locally and verify that the consul.data/raft/peers.json file ends up with `null` inside on all three servers. That's why a `TERM` sig doesn't lead to this because it doesn't formally leave the set of peers (see [leave_on_terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate), which defaults to false).

I'll let @armon and/or @ryanuber weigh in on the best practice to follow to get into a working state. Maybe we should add a new ""Failure of all Servers in a Multi-Server Cluster"" section in the outage recovery docs since this seems to be confusing to people. I think it will end up being something similar to the manual bootstrapping procedure, picking one of the servers as the lead. In my local testing I was able to get them going again by manually editing the peers.json file, but I'm not sure if that's a safe thing to do.
",slackpad,ryanuber
988,2015-06-01 20:39:15,"@rafikk we generally recommend against using any non-DNS compatible characters in service names. That said, as long as it's allowed in Consul, the UI should support it too. @pearkes any thoughts on this?
",ryanuber,pearkes
985,2015-06-25 03:30:28,"Okay, so this is very interesting and behaves super differently in a variety of scenarios:
1. I set up 3 servers, got them into a cluster.
2. I set up 1 agent, joined it to the cluster.
3. I then did `consul lock test ""sleep 60""`

Now, this is where it varies (TL;DR scroll to the end to watch the lock be violated):

Scenario 1: Cleanly exiting the leader with leave_on_terminate at its default value of `true`, which means it shuts itself down and sends a message to remove itself from Raft, which isn't the same as a partition, but can easily happen.

I got the following result:



I immediately tried running the same command and got the following error until the election finished:



I can see not being able to create a lock during an election, so I'm actually fine with this except the error is a bit unclear.

---

Scenario 2:

I ran `pkill -9 consul` on the leader box after starting a new round of ""sleep 60"".

Results:

Serf immediately detected the failure in the server, but there were 0 errors from the agent and the 60 seconds finished cleanly. However, because of what you'll see in scenario 3, the agent was clearly not connected with the leader, but some other server. The output was as follows:



---

Scenario 3 (The one you're interested in):

I started a new consul lock sleep test and started running `sudo iptables -I INPUT -s 192.168.33.10 -j DROP` on boxes until I figured out which one the agent was talking to.

This is some strange behavior that I think @armon or someone else that wrote this needs to comment on.

Here's what happened, with consul communicating with `serverB`:



There are 2 problems here:
1. Consul lock hangs, and there's a chance depending on which server died to actually not even show the ""Error running handler: signal: terminated"" message. It doesn't respond to SIGTERM at all until the **_child process exits**_, it needs to be killed with `kill -9`. I'm suspecting a deadlock waiting on a channel somewhere.


1. The agent does not try to reconnect with another server and re-establish the session renewal. This wouldn't be a big deal except that if it can't renew the session, the session is destroyed due to the TTL, _and also_ due to problem 1, the child process is _still running_. This seems problematic.

I also replicated it on a single server/single agent - same problem, but this time it seemed to detect the failure a bit better due to the complete lack of consul servers. It still left the child process running though!
",highlyunavailable,armon
971,2015-06-25 04:46:01,"@ryanuber awesome, it looks like you reviewed and posted literally right as we were discovering that issue. 
",epipho,ryanuber
964,2015-05-20 19:29:26,"@phinze Thoughts?
",armon,phinze
956,2015-05-19 22:28:56,"@sean- Can you tell if its hung or just migrating? Our own servers took like 90 seconds to finish the migration. Or did they just sit there forever?

/cc: @ryanuber any ideas why it would be hanging?
",armon,ryanuber
955,2015-05-19 00:44:38,"I'd like to add the gradle-consul-plugin to the community tools page. @armon requested that I'd do that using a pull request.
",amirkibbar,armon
938,2015-05-29 17:27:14,"Thanks for reporting this, marking as a bug! /cc @pearkes @markupboy 
",ryanuber,pearkes
938,2015-05-29 17:27:14,"Thanks for reporting this, marking as a bug! /cc @pearkes @markupboy 
",ryanuber,markupboy
938,2015-05-29 17:29:08,"@ryanbreen fwiw, this happens similarly as well for Lock Sessions:

![image](https://cloud.githubusercontent.com/assets/375744/7888426/7e2c43f6-05ed-11e5-94c0-2ddefe6c61d7.png)
",mattrobenolt,ryanbreen
938,2015-10-26 21:05:49,"Kicking over to @meirish who's been looking into some UI bugs.
",slackpad,meirish
936,2015-05-14 08:17:09,"Clarify that the user is assured that Consul will listen to a
specific address when specifying a `bind` address, rather than
providing some kind of insurance policy.

/cc @ryanbreen 
",ceh,ryanbreen
930,2015-05-29 17:36:44,"Makes sense to me, preserving the values might be the way to go since flags are not such a commonly used feature, so I'm not sure if we want to expose it in the UI. I'll defer to @pearkes on that. Thanks for reporting!
",ryanuber,pearkes
924,2015-06-03 23:43:12,"@mainframe thanks for reporting this. This is happening in the gossip layer. After reading the code, it appears this is intentional. The gossip layer uses logical time only in its state which makes it more resilient to clock differences between the agents. My best guess at why the timers aren't restored is to avoid writing the local system time into the agent state to make this behavior more predictable. @armon can probably clarify here for us.

As for the peers.json file, that is intentionally left populated. You can read more about these types of failure scenarios in [this guide](https://consul.io/docs/guides/outage.html). Of particular interest here is the section on failed servers, which explains how this scenario may be recovered from.

I think the TL;DR is that this is working as intended, but I'll leave this open for now in case I missed something.
",ryanuber,armon
916,2015-07-22 22:49:50,"Thanks @armon.

/cc @fraenkel @ematpl @luan see above comment from @armon re UDP routing issues.
",Amit-PivotalLabs,fraenkel
916,2015-09-04 23:16:43,"@aj-jester: Everything we (myself, @ematpl, @fraenkel, @luan) have done has been in a VPC.
",Amit-PivotalLabs,fraenkel
899,2015-05-04 21:28:08,"@rhelmer, yeah, I thought this might be a good fit for you because it seems our usage is pretty similar.  We have a bunch of configuration files we want to splat out onto the filesystem of remote hosts, so we use git2consul because we want to manage / version those in git and distribute them using Consul.  We then use http://github.com/cimpress-mcp/fsconsul to write them to disk on remote systems.  It makes a nice complement to git2consul.

If that seems like a good fit for you, it might make sense to close this ticket.  It's up to @armon and @ryanuber, of course, but IMHO it seems unnecessary to modify Consul itself if the constellation of tools around Consul can provide the desired functionality.
",ryanbreen,armon
899,2015-05-04 21:28:08,"@rhelmer, yeah, I thought this might be a good fit for you because it seems our usage is pretty similar.  We have a bunch of configuration files we want to splat out onto the filesystem of remote hosts, so we use git2consul because we want to manage / version those in git and distribute them using Consul.  We then use http://github.com/cimpress-mcp/fsconsul to write them to disk on remote systems.  It makes a nice complement to git2consul.

If that seems like a good fit for you, it might make sense to close this ticket.  It's up to @armon and @ryanuber, of course, but IMHO it seems unnecessary to modify Consul itself if the constellation of tools around Consul can provide the desired functionality.
",ryanbreen,ryanuber
893,2015-05-03 23:21:25,"Hi @ryanuber 
- [this is the link to the chocolatey package](https://chocolatey.org/packages/consul)
  - the comments (scroll down) are what I'm talking about.
- I _think_ the package source is https://github.com/sitano/chocolatey-packages, and I would guess community-provided.
  - this is the maintainer: https://chocolatey.org/profiles/mirthy

However, the chocolatey package lists @mitchellh and @armon as authors, so I assumed it was owned by Hashicorp.

I've used the package to bootstrap my use on Windows nodes - it saved me needing to figure out a service wrapper and so forth.
",petemounce,armon
893,2015-05-03 23:21:25,"Hi @ryanuber 
- [this is the link to the chocolatey package](https://chocolatey.org/packages/consul)
  - the comments (scroll down) are what I'm talking about.
- I _think_ the package source is https://github.com/sitano/chocolatey-packages, and I would guess community-provided.
  - this is the maintainer: https://chocolatey.org/profiles/mirthy

However, the chocolatey package lists @mitchellh and @armon as authors, so I assumed it was owned by Hashicorp.

I've used the package to bootstrap my use on Windows nodes - it saved me needing to figure out a service wrapper and so forth.
",petemounce,mitchellh
892,2015-04-28 22:12:22,"Since the ACL tokens are currently not passed as part of the URL's in the UI, a page refresh can cause the user to need to re-enter their ACL token. It also prevents sharing a URL with a team, which could be useful if you wanted to pass around a read-only token in a direct link.

Original report is here: https://groups.google.com/forum/#!topic/consul-tool/4XItKG8jO4M
/cc @pearkes
",ryanuber,pearkes
892,2015-05-07 18:56:44,"I think this is on purpose, to avoid leaking them. The token is saved in a cookie or local storage though. I'll let @pearkes comment.
",armon,pearkes
890,2015-05-18 22:47:38,"@mitchellh You did the `godep` integration on Vault, any thoughts?
",armon,mitchellh
884,2015-04-23 22:05:16,"Also, not sure how @ryanuber and @armon feel about this, but I'm not convinced this needs to be configurable.  A little bit of stagger by default seems like the right approach.
",ryanbreen,armon
884,2015-04-23 22:05:16,"Also, not sure how @ryanuber and @armon feel about this, but I'm not convinced this needs to be configurable.  A little bit of stagger by default seems like the right approach.
",ryanbreen,ryanuber
884,2015-04-23 22:10:16,"Hah, yeah, I actually pulled the logic from that function but for some reason though it was in a different package. Updated that.

@ryanuber and @armon, let me know what you think about it being configurable. I added it so that the behavior doesn't change for existing users unexpectedly but it may be a small change that would actually help everyone.
",artushin,armon
884,2015-04-23 22:10:16,"Hah, yeah, I actually pulled the logic from that function but for some reason though it was in a different package. Updated that.

@ryanuber and @armon, let me know what you think about it being configurable. I added it so that the behavior doesn't change for existing users unexpectedly but it may be a small change that would actually help everyone.
",artushin,ryanuber
883,2015-04-23 20:50:57,"I am trying to setup our DNS server hosted on windows in order to target our consuls instances when a client requests something within the 'consul' zone.
As far as I understand, we need to setup either a Forward Lookup zone or a Stub Zone on our master DNS.

**Setup**
Our master DNS: 192.168.1.130
Our consul instances: 192.168.1.190, 200, 210

All our clients have 192.168.1.130 as primary DNS.
They need to be able to resolve **.consul. In another hand, everything ending with '.consul' needs to be forwarded to consul.



Windows does not seem to recognize consul as an Authoritative zone.
Do you know if what i am trying to achieve is supported ?

PS: For some reason, it worked once for few minutes(despite error message saying that its not an Authoritative zone), and then went down. I never managed to make it work again.

**Error message on windows:**
https://www.dropbox.com/s/ql32tic5du8on9j/dns-1.jpg?dl=0
https://www.dropbox.com/s/yrxwvoxoewul5lk/dns-2.jpg?dl=0

Any feedback would be greatly appreciated

@mfischer-zd, @ryanuber and @armon you might have an idea
",florentvaldelievre,armon
883,2015-04-23 20:50:57,"I am trying to setup our DNS server hosted on windows in order to target our consuls instances when a client requests something within the 'consul' zone.
As far as I understand, we need to setup either a Forward Lookup zone or a Stub Zone on our master DNS.

**Setup**
Our master DNS: 192.168.1.130
Our consul instances: 192.168.1.190, 200, 210

All our clients have 192.168.1.130 as primary DNS.
They need to be able to resolve **.consul. In another hand, everything ending with '.consul' needs to be forwarded to consul.



Windows does not seem to recognize consul as an Authoritative zone.
Do you know if what i am trying to achieve is supported ?

PS: For some reason, it worked once for few minutes(despite error message saying that its not an Authoritative zone), and then went down. I never managed to make it work again.

**Error message on windows:**
https://www.dropbox.com/s/ql32tic5du8on9j/dns-1.jpg?dl=0
https://www.dropbox.com/s/yrxwvoxoewul5lk/dns-2.jpg?dl=0

Any feedback would be greatly appreciated

@mfischer-zd, @ryanuber and @armon you might have an idea
",florentvaldelievre,mfischer-zd
883,2015-04-23 20:50:57,"I am trying to setup our DNS server hosted on windows in order to target our consuls instances when a client requests something within the 'consul' zone.
As far as I understand, we need to setup either a Forward Lookup zone or a Stub Zone on our master DNS.

**Setup**
Our master DNS: 192.168.1.130
Our consul instances: 192.168.1.190, 200, 210

All our clients have 192.168.1.130 as primary DNS.
They need to be able to resolve **.consul. In another hand, everything ending with '.consul' needs to be forwarded to consul.



Windows does not seem to recognize consul as an Authoritative zone.
Do you know if what i am trying to achieve is supported ?

PS: For some reason, it worked once for few minutes(despite error message saying that its not an Authoritative zone), and then went down. I never managed to make it work again.

**Error message on windows:**
https://www.dropbox.com/s/ql32tic5du8on9j/dns-1.jpg?dl=0
https://www.dropbox.com/s/yrxwvoxoewul5lk/dns-2.jpg?dl=0

Any feedback would be greatly appreciated

@mfischer-zd, @ryanuber and @armon you might have an idea
",florentvaldelievre,ryanuber
882,2015-06-25 14:41:23,"Please include me (@armon), @ryanuber and @slackpad. 
",armon,slackpad
872,2015-04-20 23:31:07,"cc @armon 
",KFishner,armon
862,2015-04-14 02:42:08,"Fixes #321. This adds all of the CNAME's in the resolution chain to the result when a service's `Address` field contains a name which chains DNS CNAME's. An example is RDS. Simple change, hard test.

Thanks to @alouche and @cwstrommer for the repro and example fix.
",ryanuber,alouche
850,2015-04-08 19:38:19,"Fixes #839
/cc @armon
",ryanuber,armon
848,2015-04-08 19:54:46,"Thanks for reporting this. The `undefined` makes me think maybe this is a javascript problem in the UI. @pearkes any ideas here?
",ryanuber,pearkes
831,2015-03-31 17:59:55,"From https://groups.google.com/forum/#!topic/consul-tool/JOGcE2o1GK0:

> the docs don't specify that you need to (or even that you can) set the 'https' address in the config. 
> If you don't do that it silently fails to set up the https server. Bit of a head-scratcher for a while.

/cc @ryanbreen
",ryanuber,ryanbreen
816,2015-04-01 09:42:42,"@armon would you mind please checking this to let us know whether we are on the right track or not?
",pepov,armon
813,2015-03-24 17:28:36,"Reference: #811 
/cc @pearkes
",ryanuber,pearkes
803,2015-03-24 22:38:58,"@Amit-PivotalLabs sorry about the delay, I've been gone for a few days. The agent configuration should be automatically copied into the server config at start time, so there shouldn't be any disconnect there.

I think it's probably fine to remove the validation from the agent, since the server does the same exact check during the next RPC call, and returns the same error. Invalid requests shouldn't be repeated, so I think this is sane.

Really it seems like this should be checked in one place (the session create code path). I'm not entirely sure why it is re-checked in the state store, and what the implications of removing that would be if servers are configured with different values. @armon any ideas on this?
",ryanuber,armon
802,2015-03-19 16:37:00,"Since this has come up a few times in different projects, I'm going to raise an issue for discussion. When determining a node's, service's, or logical service's status, one must do something like:



TL;DR - iterate over each check and `&` them together to get the ""best"" status for the node/service/logical service. 

I would like to propose that Consul does this calculation itself and exposes that result via the API and struct fields. It would be great if Consul could aggregate those checks into a single status. This would reduce a lot of duplication in our tooling and I think it would provide a better experience.

Thoughts @armon @ryanuber?
",sethvargo,armon
802,2015-03-19 16:37:00,"Since this has come up a few times in different projects, I'm going to raise an issue for discussion. When determining a node's, service's, or logical service's status, one must do something like:



TL;DR - iterate over each check and `&` them together to get the ""best"" status for the node/service/logical service. 

I would like to propose that Consul does this calculation itself and exposes that result via the API and struct fields. It would be great if Consul could aggregate those checks into a single status. This would reduce a lot of duplication in our tooling and I think it would provide a better experience.

Thoughts @armon @ryanuber?
",sethvargo,ryanuber
802,2016-09-15 08:46:27,"Ping @slackpad
",sethvargo,slackpad
794,2015-03-18 14:41:08,"/cc @ryanuber 
",sethvargo,ryanuber
758,2016-06-16 22:14:56,"Hi

We were having a similar conversation in one of the InfluxData Telegraf Github issues (https://github.com/influxdata/telegraf/issues/860) and @StianOvrevage mentioned  https://godoc.org/bosun.org/cmd/scollector has a -winsvc flag which makes the binary register correctly as a Windows Service. 

https://github.com/bosun-monitor/bosun/blob/master/cmd/scollector/service_windows.go seems to do the magic. 

@slackpad @mitchellh Would you consider adding something similar to make running the Consul agent a bit easier in Windows machines? NSSM works great but it certainly seems a bit of a hack
",ricardclau,mitchellh
758,2016-06-16 22:14:56,"Hi

We were having a similar conversation in one of the InfluxData Telegraf Github issues (https://github.com/influxdata/telegraf/issues/860) and @StianOvrevage mentioned  https://godoc.org/bosun.org/cmd/scollector has a -winsvc flag which makes the binary register correctly as a Windows Service. 

https://github.com/bosun-monitor/bosun/blob/master/cmd/scollector/service_windows.go seems to do the magic. 

@slackpad @mitchellh Would you consider adding something similar to make running the Consul agent a bit easier in Windows machines? NSSM works great but it certainly seems a bit of a hack
",ricardclau,slackpad
751,2015-03-03 22:19:24,"This is a rough pass at documenting the anti-entropy internals to help users better understand the mechanics of it. @armon if you could take a quick look and make sure everything is accurate that would be good. This is sort of hard to document in an easy-to-understand way so all suggestions are welcome.

/cc @ryanbreen if you want to take a look and adjust some language, move things around, or anything else that would be great!
",ryanuber,armon
751,2015-03-03 22:19:24,"This is a rough pass at documenting the anti-entropy internals to help users better understand the mechanics of it. @armon if you could take a quick look and make sure everything is accurate that would be good. This is sort of hard to document in an easy-to-understand way so all suggestions are welcome.

/cc @ryanbreen if you want to take a look and adjust some language, move things around, or anything else that would be great!
",ryanuber,ryanbreen
744,2015-03-02 00:16:24,"This suggested language covers cases where manual removal of failed nodes from peers.json isn't the most expedient path to resolution.  Since this doc is so critical for operators working in tense situations, I would love to get some feedback from @armon and @ryanuber about whether these changes are accurate and appropriate.
",ryanbreen,armon
744,2015-03-02 00:16:24,"This suggested language covers cases where manual removal of failed nodes from peers.json isn't the most expedient path to resolution.  Since this doc is so critical for operators working in tense situations, I would love to get some feedback from @armon and @ryanuber about whether these changes are accurate and appropriate.
",ryanbreen,ryanuber
730,2015-02-23 19:07:16,"Seth, totally agreed about the need for more granularity, but @ryanuber already cracked the HTTP API monolith prior to 0.5: https://consul.io/docs/agent/http.html.  Does that cover the specific example you cited?
",ryanbreen,ryanuber
723,2015-02-21 03:59:05,"Fixes #231 by blocking the HTTP API responses until a sync has been _attempted_. This is still a ""best-effort"" mechanism in that the call to `syncChanges()` can fail. In this case, the service or check actually **is** registered with the agent, so it doesn't make sense for the caller to retry. Thus, if we fail a `syncChanges()`, we only log a warning, but still return the 200-range response to the client. Consul's built-in anti-entropy will take care of syncing the services and checks to the catalog once it is able. This seems like the best we can do.

@armon thoughts on this?
",ryanuber,armon
721,2015-02-20 19:11:04,"As @ryanuber and I were discussing in #consul, after upgrading from 0.4.1 to 0.5.0 my single-node cluster (operating necessarily in bootstrap mode) has no leader.  It does self-elect but then steps down.  Starting up a _new_ single node cluster with an empty data-dir does not exhibit this problem.

config:



log:


",blalor,ryanuber
713,2015-02-19 22:25:53,"This looks good, but we should talk about ""data center"" versus ""datacenter"". We are very inconsistent in what we use and we should just standardize on one /cc @KFishner @armon @mitchellh 
",sethvargo,armon
713,2015-02-19 22:25:53,"This looks good, but we should talk about ""data center"" versus ""datacenter"". We are very inconsistent in what we use and we should just standardize on one /cc @KFishner @armon @mitchellh 
",sethvargo,mitchellh
713,2015-02-19 22:25:53,"This looks good, but we should talk about ""data center"" versus ""datacenter"". We are very inconsistent in what we use and we should just standardize on one /cc @KFishner @armon @mitchellh 
",sethvargo,KFishner
711,2015-02-18 23:17:09,"This PR adds support for the [SCADA service](http://scada.hashicorp.com) which is used to integrate into [Atlas](https://atlas.hashicorp.com). It makes use of the `scads-client` library to do most of the work. The only capability that is enabled via SCADA is the HTTP API, which required some minor changes to allow a dedicated listener.

/cc: @ryanuber 
",armon,ryanuber
710,2015-02-18 23:10:00,"@ryanbreen Fixed in ee51530
",armon,ryanbreen
707,2015-02-17 20:01:49,"/cc @ryanuber 
",armon,ryanuber
695,2015-02-13 01:03:06,"@ryanbreen So the code for it is here:
https://github.com/hashicorp/consul/blob/master/command/agent/session_endpoint.go#L105

But @sethvargo recently showed me that Golang time.ParseDuration does not allow a value without a suffix, so this may be a non-issue.
",armon,sethvargo
679,2016-08-17 08:05:08,"Great work @slackpad, thanks.
",j0hnsmith,slackpad
622,2015-01-21 03:00:34,"As yet another follow-up on #587 and #612, this re-introduces the ability to set ownership and permission bits as you please on the UNIX domain sockets.
- Delete socket if it exists on agent startup, and recreate during bind.
- Set ownership of socket file including user name/id, group id, and permissions e.g. `0755` via the new `unix_sockets` config construct. This makes setting any of these optional and keeps the address fields clean and concise.

The function which handles file permissions now takes an interface, and the `unix_sockets` construct implements it. This will make it very easy to introduce separate, nested config structures in the future if we want to support setting per-interface domain socket permissions.

This functionality is new to Consul, however, it was originally implemented in #587 by @jefferai. This is merely an iteration on the design.

@jefferai @armon @sethvargo any questions/suggestions/concerns more than welcome.
",ryanuber,armon
622,2015-01-21 03:00:34,"As yet another follow-up on #587 and #612, this re-introduces the ability to set ownership and permission bits as you please on the UNIX domain sockets.
- Delete socket if it exists on agent startup, and recreate during bind.
- Set ownership of socket file including user name/id, group id, and permissions e.g. `0755` via the new `unix_sockets` config construct. This makes setting any of these optional and keeps the address fields clean and concise.

The function which handles file permissions now takes an interface, and the `unix_sockets` construct implements it. This will make it very easy to introduce separate, nested config structures in the future if we want to support setting per-interface domain socket permissions.

This functionality is new to Consul, however, it was originally implemented in #587 by @jefferai. This is merely an iteration on the design.

@jefferai @armon @sethvargo any questions/suggestions/concerns more than welcome.
",ryanuber,jefferai
622,2015-01-21 03:00:34,"As yet another follow-up on #587 and #612, this re-introduces the ability to set ownership and permission bits as you please on the UNIX domain sockets.
- Delete socket if it exists on agent startup, and recreate during bind.
- Set ownership of socket file including user name/id, group id, and permissions e.g. `0755` via the new `unix_sockets` config construct. This makes setting any of these optional and keeps the address fields clean and concise.

The function which handles file permissions now takes an interface, and the `unix_sockets` construct implements it. This will make it very easy to introduce separate, nested config structures in the future if we want to support setting per-interface domain socket permissions.

This functionality is new to Consul, however, it was originally implemented in #587 by @jefferai. This is merely an iteration on the design.

@jefferai @armon @sethvargo any questions/suggestions/concerns more than welcome.
",ryanuber,sethvargo
617,2015-01-18 00:55:31,"The HTTP API documentation page has gotten fairly large over time. This splits the page into one page per ""section"", meaning K/V is a page, Health Checks are a page, etc., and gives each page a sub-nav link on the left hand nav pane:

![httpdocs](https://cloud.githubusercontent.com/assets/1642288/5790988/6efbdaae-9e69-11e4-8a5b-996421dccead.gif)

/cc @pearkes because I'm rather terrible at SCSS and may have made some mistake(s).
/cc @sethvargo because I'm sure this will affect SEO in some way.
",ryanuber,pearkes
617,2015-01-18 00:55:31,"The HTTP API documentation page has gotten fairly large over time. This splits the page into one page per ""section"", meaning K/V is a page, Health Checks are a page, etc., and gives each page a sub-nav link on the left hand nav pane:

![httpdocs](https://cloud.githubusercontent.com/assets/1642288/5790988/6efbdaae-9e69-11e4-8a5b-996421dccead.gif)

/cc @pearkes because I'm rather terrible at SCSS and may have made some mistake(s).
/cc @sethvargo because I'm sure this will affect SEO in some way.
",ryanuber,sethvargo
617,2015-01-18 00:58:27,"@pearkes @sethvargo Feel free to pull/update the branch as well if you need to.
",ryanuber,pearkes
617,2015-01-18 00:58:27,"@pearkes @sethvargo Feel free to pull/update the branch as well if you need to.
",ryanuber,sethvargo
617,2015-01-21 06:56:08,"ping @pearkes @sethvargo, any input? just a :+1: if you think its ok as-is would be fine.
",ryanuber,pearkes
617,2015-01-21 06:56:08,"ping @pearkes @sethvargo, any input? just a :+1: if you think its ok as-is would be fine.
",ryanuber,sethvargo
616,2015-01-18 04:35:26,"@ryanbreen No, thanks for noticing. Rebased, fixup and forced push.
",ceh,ryanbreen
612,2015-01-20 15:04:10,"@ryanuber @armon  I wish you guys had included me in the discussions before unilaterally changing this around. Both of these are bad changes. I would appreciate if you reverted these and included me in the discussion.
",jefferai,armon
612,2015-01-20 16:54:50,"Hi @sethvargo @ryanuber @armon 

First off, I want to point out that this is an example of being a _terrible_ upstream. The syntax was proposed on the mailing list. Nobody, including Consul team members, objected. Ryan asked about it on the previous pull request, then after I explained my rationale, he thanked me for it and expressed no reservation.

You guys could have had a further discussion with me on the previous PR. You could have expressed concern and asked for community input on the mailing list. You could have poked me in email or on IRC. You could even have gotten me to make needed changes prior to you merging them so that my time wasn't wasted coding them in and writing tests for them only for you guys to waste your time reverting them less than 24 hours later.

That sucks.

So let's go over the problems with these changes.

1) nginx is not the only game in town. Many other services -- for instance, dovecot, clamav, _and_ your own later example of postgres -- allow you to specify the (usually) user and (definitely) group and mode you want to use, to make it easier and -- crucially -- more secure for other services to interoperate. That way you don't need to have the primary group you are running consul under be the group that everyone else uses to communicate with it. Removing that capability reduces both flexibility and security.

2) You can't simply get around this by making a directory and creating the socket in that directory and having it inherit permissions. I don't know what man page you're looking at, but `man 7 unix` on my Ubuntu 14.04 system says nothing of the sort. And I just verified that using netcat -- permissions of the parent directory have nothing to do with anything, so the workaround you guys suggest isn't actually a workaround. Proof:



3) Rather than removing the user/group/mode altogether, you could have simply expanded the configuration language, as Ryan and I discussed in the previous PR. As I said there, nobody expressed any issue with the configuration language since the original RFC, and if people didn't like the coalesced syntax the right thing to do would be to modify configuration to support sockets properly. You guys picked the nuclear (and time-wasting) option instead.

4) Leaving aside the point of what a user would do with a dead socket if Consul died in an unclean fashion, I don't know where you got your intel about removing sockets and postgres, but it's wrong. If postgres dies and you restart it, something in postgres wipes the socket and recreates it. I don't know what does it, but I _can_ tell you that it's not Ubuntu's init script. It's one of the pg tools, or it's the daemon itself. I just tested this -- on unclean shutdown the socket remains, and upon restarting the socket is removed and recreated, which I can tell because the inode changes:



Here's another example, using everyone's favorite netcat:



As a contrast, let's see the workflow with nginx:



I don't know where you guys got your intel, but it's wrong. You care about principle of least surprise...so do I. The least surprise solution is not to leave a dead socket lying around that the user can't do anything with anyways and then fail to start because of it. That will just leave users pissed off when a simple restart of consul fails to work. The least surprise solution is to do what everyone else is doing, and remove the socket and then re-create it.
",jefferai,armon
610,2015-01-17 00:39:15,"OK @ryanuber - ready for your second pass.
",dave-tucker,ryanuber
606,2015-01-16 23:58:57,"I'm going to merge this in. @armon if you want to change the endpoints or anything else feel free, or let me know!
",ryanuber,armon
606,2015-01-20 22:22:13,"Looks really good. Minor feedback, could we also add the API client updates for this too? One thing worth discussing is a potential CLI command to easily toggle the node/services. It seems like it would be useful.

@sethvargo @mitchellh thoughts?
",armon,mitchellh
587,2015-01-08 20:13:32,"We strive for as high of test coverage as possible, and I think there are lots of testable areas with this patch. All of the tests are currently passing for us, and I believe @ryanuber changed the tests that were failing for you so that they should be passing more reliably as well.
",armon,ryanuber
576,2015-01-05 20:33:32,"This helps by rejecting configurations with invalid keys. Mapstructure supports this already, but the way we parse services and checks doesn't use straight mapstructure decoding, so there are a few discarded fields in the config struct. AFAIK there wasn't a better way to allow this.

/cc @armon @mitchellh
",ryanuber,armon
576,2015-01-05 20:33:32,"This helps by rejecting configurations with invalid keys. Mapstructure supports this already, but the way we parse services and checks doesn't use straight mapstructure decoding, so there are a few discarded fields in the config struct. AFAIK there wasn't a better way to allow this.

/cc @armon @mitchellh
",ryanuber,mitchellh
573,2015-01-05 19:17:03,"Good catch! @ryanuber maybe we can canonicalize somehow? I think windows has some characters it doesn't like either. Simplest may be to just MD5(ServiceID) or something.
",armon,ryanuber
563,2014-12-30 18:18:52,"/cc @KFishner 
",sethvargo,KFishner
557,2014-12-27 20:51:42,"While experimenting with consul on ceph based VMs, which were hanging due to ceph i/o (deep scrub), the VM becomes very slow/hangs for some time (time > 60 seconds). When tihs happens, consul-0.4.1 crashed with the following traceback.

I hope this helps do diagnose the problem.

@sethvargo edit, moved to Gist: https://gist.github.com/sethvargo/5b9f38e1693f414241a3
",telmich,sethvargo
555,2015-01-02 16:35:41,"@blalor Thanks for tackling this! The Apiary docs do look really good. I bet we can get pretty close to that by improving the docs generation we have now, instead of needing to link in an external service.

@sethvargo Thoughts? Any extensions to middleman we can use to make it more like Apiary and make the API doc experience nicer?
",armon,sethvargo
551,2014-12-19 11:57:50,"Ah, just noticed that @ryanuber already were assigned to #387.

This might even be considered a breaking change and should not go into /v1?
",ceh,ryanuber
550,2015-01-05 13:20:30,"@armon @ryanuber do you have any thoughts about that?
",i0rek,armon
550,2015-01-05 13:20:30,"@armon @ryanuber do you have any thoughts about that?
",i0rek,ryanuber
544,2016-04-11 07:17:12,"While implementing #1935 which makes this configurable, and reviewing it with @sean- we realized that lowering this too much can be fairly dangerous for the case of Consul servers. If there's a partition that isolates a server and this is set low, the server could get kicked prematurely and would need to be re-joined or restarted in order to work again, whereas with the current default setting you'd have to have 72 hours elapse before that's a problem.

Are people mostly worried about clutter in `consul members`, or is there some other problem people are hoping will be fixed by making this configurable?
",slackpad,sean-
539,2014-12-14 18:36:48,"Hey @Scorpiion it looks like we have [special cases for building BSD packages](https://github.com/hashicorp/consul/blob/0953efd5a0044756857860ca76c45f6690c5a423/scripts/build.sh#L30-L32) in the build script, but it doesn't look like we are uploading them to [the Bintray repo](http://dl.bintray.com/mitchellh/consul). I'll let @armon chime in, because I suspect there is a history/reason why we don't.
",sethvargo,armon
509,2014-12-03 19:12:22,"@lyrixx thanks for the report. Just looking over the MDB source I'm not exactly sure how this happens.

[This comment](https://github.com/armon/gomdb/blob/master/mdb.c#L6465) suggests that this should not happen, so perhaps this could be an upstream bug. Again, not sure though.

@armon thoughts?
",ryanuber,armon
504,2014-11-30 18:44:27,"@ryanuber thoughts? This may also be an issue for the API persisted services
",armon,ryanuber
497,2014-11-24 19:07:38,"Writes local services and checks to JSON files in the data directory, and loads them on agent start. The files are removed as services and checks are deregistered. Files seemed like the way to go since clients don't use MDB.

When checks are loaded, their health status is marked critical to avoid placing potentially unhealthy services into the service pool.

Fixes #464.

/cc @armon, let me know if I am missing anything here.
",ryanuber,armon
472,2014-11-25 19:34:00,"/cc @pearkes
",ryanuber,pearkes
452,2014-11-04 19:46:38,"This is definitely an odd situation. If you really are sealed off from all outside network activity, then I'm not sure how this could be happening. You might want to check your agent's configuration files to make sure you don't have any ""left-over"" start-join's for nodes that you no longer own.

I would strongly recommend enabling gossip-layer encryption to avoid this kind of thing in the future. If all of the gossip messages were encrypted, the only way for an outsider to access the cluster would be to guess the encryption key, which is really not likely to happen.

@armon any other thoughts on this one?
",ryanuber,armon
436,2014-10-27 02:23:21,"There are currently a number of sites on the Internet that link to the old
downloads_web_ui.html page, including some popular blog posts. Since the WebUI
has been moved onto the Consul page itself, these links are now broken.

This commit adds a 301 (to preserve SEO) redirect from the old page to the new
one.

/cc @armon @ryanuber 

If this looks good, we should merge it ASAP so we don't loose the existing SEO.
",sethvargo,armon
436,2014-10-27 02:23:21,"There are currently a number of sites on the Internet that link to the old
downloads_web_ui.html page, including some popular blog posts. Since the WebUI
has been moved onto the Consul page itself, these links are now broken.

This commit adds a 301 (to preserve SEO) redirect from the old page to the new
one.

/cc @armon @ryanuber 

If this looks good, we should merge it ASAP so we don't loose the existing SEO.
",sethvargo,ryanuber
435,2014-10-27 02:16:20,"The word ""Jespen"" is one of our top keywords because it appears so many times
in the Jespen Testing page. This commit adds a comment to disable Google
indexing in that code block so we can better target keywords.

/cc @armon 
",sethvargo,armon
435,2014-10-27 02:32:14,"@ryanuber want to take a quick look at this one too please :smile:? If it's good, I can deploy now
",sethvargo,ryanuber
417,2014-10-21 21:25:27,"## HashiCorp:
- [Envconsul](https://github.com/hashicorp/envconsul)
- [Consul Template](https://github.com/hashicorp/consul-template)
- [Consul Replicate](https://github.com/hashicorp/consul-replicate)
- [Consul Web UI](https://github.com/hashicorp/consul/tree/master/ui)
## Community
- [Confd](https://github.com/kelseyhightower/confd)
- [Consulate](https://github.com/gmr/consulate)
- [Crypt](http://xordataexchange.github.io/crypt/)
- [git2consul](https://github.com/ryanbreen/git2consul)
- [docker-consul](https://github.com/progrium/docker-consul)
- [fsconsul](https://github.com/ryanbreen/fsconsul)
- [registrator](https://github.com/progrium/registrator)

/cc @armon @mitchellh 
",sethvargo,armon
417,2014-10-21 21:25:27,"## HashiCorp:
- [Envconsul](https://github.com/hashicorp/envconsul)
- [Consul Template](https://github.com/hashicorp/consul-template)
- [Consul Replicate](https://github.com/hashicorp/consul-replicate)
- [Consul Web UI](https://github.com/hashicorp/consul/tree/master/ui)
## Community
- [Confd](https://github.com/kelseyhightower/confd)
- [Consulate](https://github.com/gmr/consulate)
- [Crypt](http://xordataexchange.github.io/crypt/)
- [git2consul](https://github.com/ryanbreen/git2consul)
- [docker-consul](https://github.com/progrium/docker-consul)
- [fsconsul](https://github.com/ryanbreen/fsconsul)
- [registrator](https://github.com/progrium/registrator)

/cc @armon @mitchellh 
",sethvargo,mitchellh
406,2014-10-17 18:58:29,"@fidian I was just talking with @armon about this. The main issue is that just straight replacing the value of configuration variables doesn't necessarily mean they will immediately take effect. This is because at agent start, various goroutines, port binding, and other setup takes place, which we would have to replace on config reloads to effectively change the configuration. It might eliminate the point of the config reload in the first place, which is to reload configuration without disrupting the agent.

The things that can be safely reloaded on the fly include:
- Log level
- Services
- Checks
- Watch Plans

For now, we don't have any plans to try supporting a live reload of the entire consul agent, since the disruptiveness becomes close to the same as just restarting.
",ryanuber,armon
393,2014-10-11 19:05:25,"I think this might be possible if mDNS was added to Consul. The gossip layer below actually does support mDNS discovery, which could possibly be enabled on both LAN and WAN gossip pools, allowing them to join each other in a zero-touch way. This, combined with the `-bootstrap-expect` flag, could allow a cluster of servers to find eachother and auto-bootstrap once the expected number of servers had joined. Raft should be able to figure out who the leader is from that point.

@armon do you think something like this would work?
",ryanuber,armon
386,2014-10-06 23:20:32,"/cc @pearkes @mitchellh can you take a :eyes: please? This is the first step in unifying all the middleman projects in a single engine for consistency.
",sethvargo,pearkes
386,2014-10-06 23:20:32,"/cc @pearkes @mitchellh can you take a :eyes: please? This is the first step in unifying all the middleman projects in a single engine for consistency.
",sethvargo,mitchellh
384,2014-10-15 22:31:31,"@armon to my understanding we can't guarantee the service ID to be correct, as we initially included this but ended up removing it. Is that accurate?
",pearkes,armon
384,2016-05-03 08:48:59,"@armon any improvement on this issue?
",jsvisa,armon
336,2014-10-09 21:24:03,"Awesome! I'll give it another look over soon. I just discussed 1 with @mitchellh, and he had a good idea. Lets only use the `-encrypt` flag if there is no keyring to install the primary key. Once the key ring is in place, we should ignore the flag, and WARN the user that we are ignoring because of the keyring. This way a user can delete the keyring file if they want to reset it, but it removes this complex user interaction.

With 2, it just is the WAN timing is much slower. Gossip just takes longer, so I think that is fine.

With 3, that sounds great. Makes sense.
",armon,mitchellh
317,2014-09-02 17:54:41,"I feel bad making an Issue for the CI failures. But its just in case literally @armon doesn't know about it. Sorry if you do already.
",drnic,armon
276,2014-08-08 21:11:56,"#225 has an answer from @mitchellh on this. I think it probably came down to `.zip` being the most universal format in terms of out-of-the-box support in most operating systems.
",ryanuber,mitchellh
274,2014-08-06 21:21:08,"Aha... plain old ""bootstrap"" on a single node in 0.3.1 works as I'd expect. I guess I have @robxu9 to thank :-)
",kshep,robxu9
263,2014-07-30 15:17:14,"Regarding `consul info`, I agree. It would have to be thought out a bit as it applies to each consul node and has quite a bit to just shove into the UI. Mostly it would be nice to know the `consul:`, `raft:` and maybe `serf_lan/wan:` sections from that output.

@pearkes Any thoughts on where some of the member info can fit in? My initial thought was on the node detail when opened. There doesn't seem to be a whole lot of room to add detail to the node in the node list on the left if you want it there too. But here's a rough idea on what the open node view could be:

![screen shot 2014-07-30 at 7 54 23 am](https://cloud.githubusercontent.com/assets/44689/3750910/1cea1d0c-17fa-11e4-81b6-f8bfc6ab6746.png)
",mtchavez,pearkes
257,2014-07-22 19:29:31,"I've found myself wanting to deregister services from within the UI more than a few times, especially while debugging a new setup. @pearkes pointed out that an ""action bar"" would be a good way to fit these sorts of actions so I've mocked up the simplest possible version of what that could look like:
![2014-07-22-122231_517x391_scrot](https://cloud.githubusercontent.com/assets/211613/3663708/c0fb873a-11d5-11e4-8682-599aff34dc90.png)

Is this something you want? If so, what actions should be supported? Here's what I'm thinking so far:

Nodes:
- Deregister
- Register _?_

Services:
- Deregister
- Register _?_

Checks:
- Mark passing
- Mark warning
- Mark critical
- Register _?_
",spro,pearkes
248,2014-07-15 22:20:58,"I had a discussion with @armon today regarding the upcoming ACL support. It looks great, but I am in an enterprise setting and concerned about integration with existing SSO/auth mechanisms. Apparently you are thinking of LDAP; we use a combination of PubCookie/SAML...and the same thing everyone uses, SSH.

SSH is so ubiquitous that it's essentially in every enterprise large and small, every startup, and every nerd's set of home tools.

So, I thought I'd post my idea here for a bit broader input. My proposal is this: allow RPC authentication via SSH, by communicating with ssh-agent to verify ownership of private keys matching SSH public keys associated with tokens in Consul's database. Once authenticated, a Consul token could be provisioned to them for some period of time -- potentially storing the value in an environment variable, where it will disappear upon logout (unless the user specifically stores it somewhere).

The same mechanism could be used to get a token for the web UI; the generated token could be plugged into a web session to authenticate the user, without requiring SSH agent communication.

I'm sure the devil is in the details, but I like the idea of using an existing, widely deployed, and secure mechanism as the basis for (at least one method of) token management.
",jefferai,armon
246,2014-07-15 16:54:27,"I thought about doing this recently, actually. I helped with the Serf key rotation feature, but admittedly haven't done a whole lot of experimentation with Consul. If there is interest then I'd definitely be up for taking a stab at it. Perhaps @armon could shed some light on potential caveats (if any) of hooking into this from Consul.
",ryanuber,armon
233,2014-06-28 20:34:59,"cc @armon -- I'd probably like to write more tests before merging this, but can you ACK that this looks like the right track to you before I do so?

---

Namely, don't check the DNS names in TLS certificates when connecting to
other servers.

As of golang 1.3, crypto/tls no longer natively supports doing partial
verification (verifying the cert issuer but not the hostname), so we
have to disable verification entirely and then do the issuer
verification ourselves. Fortunately, crypto/x509 makes this relatively
straightforward.

If the ""server_name"" configuration option is passed, we preserve the
existing behavior of checking that server name everywhere.

No option is provided to retain the current behavior of checking the
remote certificate against the local node name, since that behavior
seems clearly buggy and unintentional, and I have difficulty imagining
it is actually being used anywhere. It would be relatively
straightforward to restore if desired, however.
",nelhage,armon
224,2014-07-16 10:27:35,"This should now cover the DNS interface, I'm not sure if we need to change any other interface. @armon any input?
",tiwilliam,armon
223,2014-06-18 23:20:23,"@armon and I talked about this privately, but we need to rename `-expect` to `-bootstrap-expect`. Although it isn't obvious even in the latter case what it exactly does, it is obvious and clear that it is related to bootstrapping and should therefore probably only apply to servers. We concluded that `-expect` is too vague for something we'll need to support forever.

This must happen prior to 0.4
",mitchellh,armon
214,2014-07-02 20:29:37,"Fixed by @nelhage in #233 
",armon,nelhage
208,2014-07-16 19:55:22,"@andrewwatson mentioned the possibility of named groups of data centers. e.g. ""EU"" -> [""UK"", ""GE"", ""FR""]
",armon,andrewwatson
202,2016-12-20 04:17:35,/cc @kyhavlov - this may get picked up if we do any HIL interpolation as part of node tag support,slackpad,kyhavlov
197,2014-06-08 20:18:20,"@andrewwatson UI is not tested via Travis no worries. I will let @pearkes review and merge this since he is owning the UI.
",armon,pearkes
180,2014-06-02 04:25:44,"In my opinion, no, there should not be an option for a normal user to list these entries. The idea is that they are hidden from enumeration and by using one that is random and long, you can store entries in consul that are undiscoverable by others.

@armon An administrator, though, should have a way to do that. Adding such an ability is tricky because there isn't currently an admin mode. Is a configured token that can be presented by an admin be enough?

This (as well as this evenings BBQ with @mitchellh) has made me realize perhaps we should put energy into a ACL/capabilities system instead, since dealing with all of the side effects of hidden entries may result in more changes that a proper ACL system.

@armon Love to chat about that on Tuesday!
",evanphx,mitchellh
177,2014-05-28 18:03:14,"Oh yikes! I will try to get a new binary uploaded today. I'll bug @mitchellh since he has a windows machine.
",armon,mitchellh
174,2014-05-26 21:05:27,"LGTM! Will let @armon have a second opinion before merge.

OT: Saw your talk live at DEFCON 2011, impressive work!
",tiwilliam,armon
165,2014-06-02 14:31:37,"It's my understanding that tags aren't necessarily consistent at the service level. That is, a service on 2 different nodes may have different tags, thus the Web UI would need to ""resolve"" this conflict, which isn't really ideal.

@armon may have thoughts on a solution for this.
",pearkes,armon
159,2014-05-18 20:54:46,"Well that is interesting. /cc @armon 

Reopening.
",mitchellh,armon
159,2016-01-05 19:20:10,"Hey all - it looks like @jen20 got a CLI change merged yesterday that fixes the syscall issue:

https://github.com/mitchellh/cli/pull/25

And the Docker client must have gotten fixed upstream:

https://twitter.com/jen20/status/684450871606939648

I'll take this and add solaris to the list of built flavors.
",slackpad,jen20
159,2016-01-06 10:14:32,"Awesome! Thanks @slackpad & @jen20 :+1: 
",cmacrae,jen20
126,2016-06-02 19:43:21,"@armon @slackpad 
Before I try to dig into the code, would you like to accept pull requests? May be I have some time in two or three month.

EDIT: my proposal fixes #215. It's not really broken, but it gives @darron ability to work around his problem.
",Bessonov,darron
112,2014-05-03 09:05:05,"<3! But is it reasonable to have a plugin system that's less than turing complete? I'm a acme/vi snob so I'd prefer these happen in a separate process, which requires an IPC (ideally STDIN/STDOUT). In-process is much more complicated, we (and [heka](https://github.com/mozilla-services/heka)) ended up using lua for an extension language.

Alternatively, @armon added consul support to [confd](https://github.com/kelseyhightower/confd) which supports a `reload_cmd` to trigger config updates. I have a feeling that this will handle 90% of the integration most folks need.
",josephholsten,armon
108,2014-05-02 17:35:36,"@mitchellh 

How do we change the bind address for the web ui, its only accepting connections from localhost.
",bscott,mitchellh
105,2014-05-02 03:21:30,"Originally reported by @blalor

We need to provide better options for logging that isn't geared towards humans. I think this should probably entail both syslog and a file option.
",mitchellh,blalor
98,2014-05-01 17:23:53,"Awesome work by @pearkes. This brings in the web UI.
",armon,pearkes
88,2014-04-29 16:26:09,"Yo Chavez. Actually, I was hoping we could persist this problem from the servers into the agents, so that any agents can see if any servers are running GOMAXPROCS == 1.

I'll let @armon decide.
",mitchellh,armon
75,2014-04-24 05:56:09,"I believe Synapse supports plugins. I think doing a Consul Synapse plugin would be ideal here, rather than building this into Consul itself. This gives you the freedom to modify the HAProxy configurations as you want. @armon?
",mitchellh,armon
71,2014-04-22 06:03:11,"The way Ubuntu standardizes on this sort of thing is having a ""defaults"" file such as `/etc/defaults/consul` that just exports raw flags to run. For example, a defaults file for Consul might look like:



Then in your service you can do



That is the approach I prefer to take with ops. Its also just as easy to template the service file to have the proper configuration directory.

I think having both a config-file and config-dir might be confusing for users since one would only be able to contain the directory. I think the above approach is better, but we'll defer to @armon.
",mitchellh,armon
58,2014-04-18 15:55:48,"I think keeping ""consul."" as the default makes sense, but I also think it would make sense to make this configurable. Thoughts, @armon?
",mitchellh,armon
54,2014-04-18 03:04:15,"/cc: @aphyr @jpfuentes2

We demand that all reads and writes are serialized through a leader. All writes naturally go through the Raft log, but we do reads directly from the leader state. The leader ""leases"" it's position for a configurable time, and checks that it is still leader each LeaderLeaseTimeout interval. However, if the leader is partitioned, a new leader could be elected and new writes processed. A read from the old leader could return a stale value in this situation.

This situation is hard to trigger, since by default a leader leases for 300msec, and a node only starts an election if it hasn't heard from the leader in 300msec - 600msec. This means generally the new election only happens after the old leader has already stepped down.
",armon,jpfuentes2
38,2014-04-16 05:21:57,"Adding a Docker Consul cluster inside of Vagrant. The `README` will also inform users they can bypass Vagrant if they have Docker running on their host.

This is a WIP so please don't merge or analyze too critically yet. This work will hopefully be used in upcoming Jepsen tests!

/cc @armon 
",jpfuentes2,armon
23,2014-04-04 20:11:36,"@mitchellh I was more thinking, once a service had been discovered, a node could then register its use of that service. This could be a one-time operation using a Serf event or query, which could contain the node's name/address/whatever else in the event payload.

This would require the endpoint doing the discovery using Consul to take on responsibility of registering utilization once a suitable service had been found. There would also need to be a reliable way of deregistering if a node died/got reaped.

This could help with transparency on who is talking to who in the cluster, which sounds like part of what @andrewwatson needs in #22, and wouldn't rely on DNS query frequency as @armon pointed out. 

Since automatic service discovery moves the source of truth for network topology into runtime, I could see using this to build a topology graph if the data were exposed over say, the HTTP interface.

Anyways, it might not be the immediate goal of Consul to handle stuff like this, and #22 points back here so its cool if we close this out. Thanks for your comments!
",ryanuber,armon
23,2014-04-04 20:11:36,"@mitchellh I was more thinking, once a service had been discovered, a node could then register its use of that service. This could be a one-time operation using a Serf event or query, which could contain the node's name/address/whatever else in the event payload.

This would require the endpoint doing the discovery using Consul to take on responsibility of registering utilization once a suitable service had been found. There would also need to be a reliable way of deregistering if a node died/got reaped.

This could help with transparency on who is talking to who in the cluster, which sounds like part of what @andrewwatson needs in #22, and wouldn't rely on DNS query frequency as @armon pointed out. 

Since automatic service discovery moves the source of truth for network topology into runtime, I could see using this to build a topology graph if the data were exposed over say, the HTTP interface.

Anyways, it might not be the immediate goal of Consul to handle stuff like this, and #22 points back here so its cool if we close this out. Thanks for your comments!
",ryanuber,andrewwatson
11,2014-05-02 03:31:46,"@armon I'm guessing this should be easier now since we had to write the Go API client for confd, no?
",mitchellh,armon
