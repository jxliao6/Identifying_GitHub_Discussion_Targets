issue_num,datetime,body,login,mention_login
2825,2017-03-23 22:25:52,Hi @charles-dyfis-net thanks for opening a PR. I don't think this code should be in use any more once @sean- merges his pending change to switch over to https://github.com/hashicorp/go-sockaddr.,slackpad,charles-dyfis-net
2822,2017-03-23 19:31:14,Hi @rileyje thanks for opening an issue. It seems like we should be able to use the bind address so we don't need to introduce any additional configuration.,slackpad,rileyje
2820,2017-03-23 17:09:51,"Hi @notuscloud that error is coming from these two lines, which should be deleted:



Consul doesn't know how to parse those, but setting `CONSUL_BIND_INTERFACE=eno33557248` should be sufficient (there's also `CONSUL_CLIENT_INTERFACE=eno33557248` you can set as well for the client socket). Hope that helps!",slackpad,notuscloud
2820,2017-03-23 17:29:22,"Hi @slackpad 

I tried with `CONSUL_CLIENT_INTERFACE=eno33557248` and I followed your advice, deleting the two lines `-client` and `-bind`.



I may be missing something...

Regards,
Thomas",notuscloud,slackpad
2820,2017-03-24 15:54:59,Thanks for the follow up @notuscloud! Consul 0.7.2 also added support for https://godoc.org/github.com/hashicorp/go-sockaddr/template syntax for these addresses so you can skip these environment variables altogether and have Consul look up the address for an interface as well.,slackpad,notuscloud
2818,2017-03-23 16:34:16,"Hi @r0p0s3c thanks for opening this issue. I think for this case since the service token was used for the registration it should also be used for the delete, so this sounds like a bug. Will take a deeper look here shortly.",slackpad,r0p0s3c
2818,2017-03-25 00:49:50,Hi @r0p0s3c if you can give master a try and see if that's working for you now we'd appreciate it!,slackpad,r0p0s3c
2817,2017-03-23 16:03:39,"Hi @ThatJames you are correct that the operator commands only work if you have a leader. If not, the peers.json recovery method is still available - it's documented here:

https://www.consul.io/docs/guides/outage.html#manual-recovery-using-peers-json",slackpad,ThatJames
2814,2017-03-22 18:11:58,"Hi @plorenz thanks for opening an issue. I tried to repro this locally and can't seem to get it to fail in this way. If you can try 0.7.5 I'd appreciate it as the fix there was related to the blocking mechanism, though it doesn't _seem_ related to what you are seeing. Also, does it get stuck every time, or sporadically?",slackpad,plorenz
2814,2017-03-22 19:07:44,"@slackpad I'll try it with 0.7.5. It doesn't happen every time. It seems to take several cycles of register/unregister before it fails on an unregister. It also seems to mostly happen on a specific service which takes a few minutes to come up and also registers two services (one for SSL, one for non-SSL). I tried it on a different service which comes up quickly, hoping for a faster repro cycle, but no luck. 

I think once it happens it seems to happen more consistently. I'll try to verify that and see if it happens on each unregister after the first failure. ",plorenz,slackpad
2814,2017-03-23 20:05:22,"@slackpad I was unable to reproduce the issue with 0.7.5, which is great. Because it was so hard to reproduce, we'll keep an eye for similar behavior in future. If does recur, we'll try to come up with more easily reproducible test case :)",plorenz,slackpad
2814,2017-03-23 20:08:55,"Hey @plorenz thank you for the follow up! That bug fix in 0.7.5 was pretty deep down, and could result in the wakeup accounting getting off, so it's definitely possible that was it. Thanks again!",slackpad,plorenz
2795,2017-03-10 15:52:33,Hi @rmb938 this looks like a recursor loop. Can you share some details about your Consul server configuration as well as what it shows for `/v1/catalog/service/vault?pretty`,slackpad,rmb938
2794,2017-03-09 19:10:27,"@dweomer sorry about that - this interface is deprecated and will be going away in Consul 0.8, but I added the page back with a deprecation notice for now.",slackpad,dweomer
2794,2017-03-10 23:58:26,@slackpad Thank you for the temporary fixed link. Would you have handy some links to understand the reasoning behind the deprecation? (I haven't been keeping up with Consul development).,dweomer,slackpad
2794,2017-03-11 00:01:48,"@dweomer this is an old interface that didn't use HTTP and only supported a subset of Consul's operations, and didn't have good support for things like ACLs. We expanded the normal HTTP interface to support everything that was in the RPC interface, and made things work in a standard way, so this is easier to support and keep in sync vs. supporting the old RPC interface as well. The operations equivalent to the RPC interface are in https://www.consul.io/docs/agent/http/agent.html and https://www.consul.io/docs/agent/http/operator.html#keyring.",slackpad,dweomer
2792,2017-03-09 15:58:23,"Thanks for the report @nathanwebsterdotme - the `acl_agent_token` for the Consul servers should have been the right thing here, so we will look into that bug. For 0.8 we are also going to set things up so the servers can always make catalog changes during a reconcile so you don't need the `acl_agent_token` set up at all for the servers, which will also fix this.",slackpad,nathanwebsterdotme
2792,2017-03-10 11:30:54,"@slackpad Just for curiosities sake, when might this be released as a binary?  We'll put in work arounds for our playbooks for now, but would like to revert these changes asap.  Thanks",nathanwebsterdotme,slackpad
2792,2017-03-10 16:13:37,@slackpad thanks for the update. I work with Nathan and can confirm that the change worked as expected. Will there be a 0.7.x version with these changes in them? or is it best to wait for the 0.8 release? Thanks again for the quick resolution on this issue.,wclarke1,slackpad
2792,2017-03-10 16:57:36,"Thats fine thanks @slackpad , we will wait for 0.8 release.",wclarke1,slackpad
2789,2017-03-08 15:55:19,Hi @hehailong5 you can let non-leader servers answer queries for better read scaling if you use the relaxed consistency modes - see https://www.consul.io/docs/agent/http.html#consistency-modes and https://www.consul.io/docs/agent/options.html#dns_config. Hope that helps!,slackpad,hehailong5
2783,2017-03-10 07:37:18,"@p1nkrock are those reloads by any chance running on consul server in bootstrap mode as your log suggests?

How many consul servers are you running in your deployment?

EDIT: as far as I can tell this doesn't look like a regression of #1173, most likely it's  caused by some kind of misconfiguration. ",wuub,p1nkrock
2783,2017-03-12 07:20:12,"Only one consul server running with bootstrap mode.

Sent from my iPhone

> On 10-Mar-2017, at 13:07, Wojciech Bederski <notifications@github.com> wrote:
> 
> @p1nkrock are those reloads by any chance running on consul server in bootstrap mode as your log suggests?
> 
> How many consul servers are you running in your deployment?
> 
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",p1nkrock,p1nkrock
2782,2017-03-01 21:47:33,"Hi @rhyas thanks for opening an issue. We can definitely improve the documentation around this - the `remove-peer` command only works if there's a leader, so a full outage does require a `peers.json` recovery.",slackpad,rhyas
2782,2017-03-23 08:34:07,@slackpad your documentation now produces usage errors when copied verbatim. Please explain the peers.json recovery as I am unable to bring up the server node now,ThatJames,slackpad
2780,2017-03-01 17:02:56,"Hi @cdharma thanks for opening an issue. That actually looks like it is working correctly, Consul is doing a redirect to `/ui` which is where the UI assets are. If you follow that redirect (add `-L` to `curl`) you'll see the HTML. You also don't need to use both `-ui` and `-ui-dir`. Consul now ships with the web assets built into the binary so all you need is `-ui`. Hope that helps!",slackpad,cdharma
2780,2017-03-01 18:28:27,"@slackpad thank you very much sir for a quick response. It is working now.

I also had to update the config.vm.network in my vagrantfile to access the consul ui from the host browser as my consul agents are running in vagrant machines.

Here is my vagrantfile for reference :- 


 ",cdharma,slackpad
2778,2017-03-01 15:46:48,Hi @gtmtech thanks for opening an issue - we definitely have plans to do this!,slackpad,gtmtech
2768,2017-03-07 10:20:18,"@vaLski, I'm not using consul-template, no other applications were using consul's api. how to get know who's sending this signal to consul and can we safely ignore it?",hehailong5,vaLski
2768,2017-03-07 10:39:58,"@hehailong5 By the time I was trying to debug this issue it looked to me that message is logged if something is querying consul catalog/kvstore and connection to this something unexpectedly closed. However I can not be 100% sure.

As for the message it does not indicate  any issues with the  consul itself but maybe an issue with the subsystem that is using/querying consul.

* Are you seeing this on consul ""server"" or on the consul ""agent"" nodes  or both?
* Are you absolutely sure that no component of your infrastructure is querying consul?
* Are you running consul under app hypervisor that is perhaps sending such signals?
* Unfortunately you can't easily track or log the sender pid of the signal but you can relate the timestamps of the logs and how often such signals are sent.  Then check the logs  of your other apps and see what they are doing at the same time?
* If you really want to detect the sender of this signal I assume sysdig (https://github.com/draios/sysdig/wiki/Sysdig-User-Guide) will do the trick    

",vaLski,hehailong5
2766,2017-03-16 05:10:33,"Hi @vrenjith we currently don't have any support for anything like this. Does this pass in some information with the client's DNS request, like a session ID?",slackpad,vrenjith
2763,2017-02-22 21:07:04,"@aprice To answer your question, prepared queries are DC-local. And yes, PRs are accepted very readily in my experience.",daveadams,aprice
2749,2017-03-01 07:47:16,Welcome @slackpad ,hadielmougy,slackpad
2744,2017-02-15 10:21:48,"Hi @jacob-koren 

Have you seen https://www.consul.io/docs/commands/operator.html ? ",jippi,jacob-koren
2743,2017-02-15 02:30:03,Hi @v6 thanks for the kind words and the PR!,slackpad,v6
2742,2017-02-14 15:12:59,"Hi @stefreak are you giving the node name to the `force-leave` command? A common mistake is to give an IP, and we need to fix that so it gives better feedback. Also, if your cluster is in an outage state then the `force-leave` won't be able to remove the servers, as server configuration changes to the Raft quorum require a leader to process. If you can't get the servers back you'd need to run the steps in https://www.consul.io/docs/guides/outage.html.",slackpad,stefreak
2742,2017-02-14 15:37:04,"@slackpad Yes I am giving the node name.
Also, the cluster is not in outage state while I am running force-leave.",stefreak,slackpad
2738,2017-02-13 04:18:29,Hi @huyjack178 having a quorum of followers commit each entry ensures that the cluster can carry on without losing data if a server fails (even the leader). You may want to look at https://raft.github.io/ to get a feel for how the Raft consensus protocol works. Hope that helps!,slackpad,huyjack178
2736,2017-02-12 18:18:43,Hi @Ashald I think we may be able to get this in for 0.8 or shortly after as we are doing some work in this area.,slackpad,Ashald
2728,2017-02-10 15:10:19,"Hi @mikezh15 the default for `leave_on_terminate` changed for servers in Consul 0.7 - please see the docs here - https://www.consul.io/docs/agent/options.html#leave_on_terminate:

> leave_on_terminate If enabled, when the agent receives a TERM signal, it will send a Leave message to the rest of the cluster and gracefully leave. The default behavior for this feature varies based on whether or not the agent is running as a client or a server (prior to Consul 0.7 the default value was unconditionally set to false). On agents in client-mode, this defaults to true and for agents in server-mode, this defaults to false.

",slackpad,mikezh15
2728,2017-02-10 18:37:39,"@slackpad We ran into the same issue while renaming our datacenter. We were able to bring back the cluster. But for some reason one of the old server is still showing in. We have completely removed this node but still the master consul info shows it in the Voter list. Thoughts?

",gvenka008c,slackpad
2728,2017-02-14 03:45:31,"@slackpad I terminated the client-mode agent instead of server-mode agent. According to consul document on ""leave_on_terminate"", the default behavior of consul client is graceful leave when TERM signal is received. But the client is in ""failed"" status instead of ""left"". I also try to enable leave_on_terminate on a client agent explicitly, it does not work as well.",mikezh15,slackpad
2727,2017-02-10 03:31:08,"Hi @sgrimm-sg this is working as designed. There's a random jitter applied to the max time here:

https://github.com/hashicorp/consul/blob/master/consul/rpc.go#L380-L381

This is designed so that if there's something like a partition event and a bunch of queries all come in at about the same time, with the same wait time (or just the default wait time), they won't all stay phase-aligned, which spreads the load out.

We should update https://www.consul.io/docs/agent/http.html to make this more clear, so this isn't surprising.",slackpad,sgrimm-sg
2724,2017-02-09 15:52:06,"Hi @cityofships thanks for the report - we will figure this out (it was new code for 0.7.3).

/cc @dadgar ",slackpad,cityofships
2724,2017-02-09 20:00:40,Thanks @mpuncel that helps show that this probably isn't related to `slow_notify()` which I initially suspected. Linking https://github.com/hashicorp/go-immutable-radix/issues/11 which may be related.,slackpad,mpuncel
2724,2017-02-09 23:01:33,@cityofships and @mpuncel are either of you able to reproduce this pretty readily? I've got some tests going now to try to trigger it but haven't had any luck.,slackpad,mpuncel
2724,2017-02-09 23:01:33,@cityofships and @mpuncel are either of you able to reproduce this pretty readily? I've got some tests going now to try to trigger it but haven't had any luck.,slackpad,cityofships
2724,2017-02-14 00:12:35,@cityofships thanks. Using your steps above (which I super appreciate) I was able to reproduce this and I've got a fix in the works. Should have something for you to try soon.,slackpad,cityofships
2724,2017-02-14 01:03:33,@cityofships the fix has been merged to master - if you have a chance to fuzz this again please let us know how it goes. Thank you!,slackpad,cityofships
2724,2017-02-15 22:24:31,"@jtchoi the cleanest recovery would be to shut down all the servers and upgrade the Consul binary of 0.7.5, which will be able to apply the update without a crash. You could also shut down the servers and remove the `raft.db` file from their data-dirs, though this will roll back to the last Raft snapshot, which will lose all the changes since that.",slackpad,jtchoi
2724,2017-02-15 23:00:07,@slackpad Thanks!  We were considering both approaches and will try the former,jtchoi,slackpad
2705,2017-02-27 12:42:19,"I agree with @janisz , tests take much more time now. Is it possible to minimize this?",kaskavalci,janisz
2705,2017-03-02 14:54:49,"This is still an issue in 0.7.5. My tests tooks from [20 seconds](https://travis-ci.org/allegro/marathon-consul/builds/207016255#L186) to [150 seconds](https://travis-ci.org/allegro/marathon-consul/builds/207016419#L195).

@slackpad How can I tune this to work better and be more predictable?

",janisz,slackpad
2705,2017-03-08 19:51:40,"@janisz I don't know what exactly is going under the hood when you set `raft_multiplier` to 1 but it speed up my tests. Ten invocations of starting Consul with `raft_multiplier` set to 1 took 17s and the same 10 invocations with `raft_multiplier` set to 5 took ~1m. I've prepared some test which shows difference, you can run it on your local machine:

https://github.com/pszymczyk/embedded-consul/commit/dd01686e59d314389ded726da4b49bd8a57c28da",pszymczyk,janisz
2701,2017-02-02 02:59:45,"@talonx you are correct, it does work. Some of my ansible playbooks didn't like it but its an easy workaround.",Deric4,talonx
2693,2017-02-15 18:28:24,"Hi @mradulmodi Consul is designed such that you run the Consul agent on each node in the cluster and the agent actually performs the health checks locally, and pushes updates to the Consul servers only when things change. This lets Consul scale to 10s of thousands of nodes in a cluster without having to have the servers need to scale to actually perform all those health checks. When you query Consul for the health status of a service, that query is routed to the Consul servers which give a consistent view based on the latest updates they have gotten from the agent. There's a video that talks about this in detail - https://www.youtube.com/watch?v=tzk2HaOZ5nY. Hope that helps!",slackpad,mradulmodi
2689,2017-02-08 05:37:50,"Hi @dhdanno - do you only see that error for other server nodes within the same datacenter? The local nodes will probe each other on the local network on the WAN side, too, using the public address. It might be that you are only binding to the private interface (seems like you must have a NAT for the WAN communications to be working). Something like https://www.consul.io/docs/agent/options.html#_serf_wan_bind might help here to bind to the public interface instead (though I'm not sure if that'll break with NAT).",slackpad,dhdanno
2672,2017-01-25 07:14:22,"Hi @huyjack178 in Consul's case your application makes HTTP requests to the local Consul agent, but that runs internally over a multiplexed TCP connection to one of the Consul servers. Similar to websockets (at least between the Consul agent and the server) there's a bunch of requests flowing over the same connection. The traffic between the application and the local Consul agent is usually over a loopback interface. There's a little more on this discussed on https://github.com/hashicorp/consul/issues/1815. I don't know enough details about websockets to give more info than that, but I hope this helps!",slackpad,huyjack178
2672,2017-01-25 07:38:14,"@slackpad thanks for the reply, I have seen that there is only one TCP connection between agent and server. But how about application to agent? Is there many HTTP Request for Blocking Query to watch key/value change?",huyjack178,slackpad
2672,2017-01-25 15:38:32,@huyjack178 yes on the application side it makes a new request each time it sets up a blocking query. That side isn't set up for something like websockets with a persistent connection (other than client libraries keeping HTTP connections open across a few requests kind of thing).,slackpad,huyjack178
2671,2017-01-25 18:33:40,"Amazing, good job @slackpad !",jippi,slackpad
2670,2017-01-24 15:42:05,"Hi @duijf thanks for opening an issue. Those long running loops use a method under the hood that actively chooses new servers, and stays up-to-date as servers come and go, so that doesn't seem like the issue here.

Do you have any logs from the server when you did the `consul leave`? If the leave didn't work correctly I could maybe see something like this happening.",slackpad,duijf
2670,2017-01-24 16:22:00,"Hey @slackpad, thanks for the response. 

I don't have access to the logs from that exact server, since we were re-imaging it. Here is the log from another consul server in the cluster:



At this point, we shut it down for re-imaging. Do the warnings indicate the leave didn't go as it should have?",duijf,slackpad
2670,2017-02-06 09:23:50,@slackpad Is there any further info I can provide here? Should I try to reproduce this? Or is that unproductive since you think it was an operator error?,duijf,slackpad
2664,2017-02-02 04:21:49,"Hi @iammyr thanks for the kind words!

Consul's Go TLS config is set up here - https://github.com/hashicorp/consul/blob/master/tlsutil/config.go. We don't make any tweaks to the `CipherSuites` configuration, so the implementation is up to the Go library (depending on the version of TLS in use). I'd point you at the Go library implementation for details about which are preferred and supported, since Consul lets the library decide what to use.

In #2699 we just added the ability to configure a minimum TLS version for Consul (that will ship shortly in Consul 0.7.4). We currently don't have plans to allow customization of specific cipher suites unless there's a lot of demand for it. Hope that helps!",slackpad,iammyr
2662,2017-01-18 15:51:20,"Hi @hehailong5 Consul doesn't have a way for servers to perform health checks for a node that's registered manually in the catalog. Consul's design puts all health checking with the agent, so this would be a fairly large change to Consul (and would have scalability concerns).

The https://github.com/hashicorp/consul/issues/259 issue has some thoughts on a solution for this via an external process. If such a process had built-in support for HA using Consul's leader election in the KV store then it could be made pretty reliable.",slackpad,hehailong5
2648,2017-01-12 16:58:06,Hi @linking12 sessions will expire if the TTL is exceeded or if any of the health checks they are tied to fail - it sounds like you are servicing the TTL in time - can you double check any health checks? By default it will be tied to the `serfHealth` check for the node that created the session.,slackpad,linking12
2648,2017-01-13 07:47:24,"@slackpad  I do not have any health check code in my program
I think use renew session is enough. is that true? as you say, it will be tied to the serfHealth check for the node that created the session.
I think selfHealth checked will be success, because my consul deployment is server agent and there is no network interrupt

By the way, i set LockDelay of session  is 0sï¼Œis it any problem?


",linking12,slackpad
2648,2017-01-16 02:19:29,"i have found the reason. 
the reason is when i request rest api to consul return error. and make next TTL scheduler is failed.
this is my fault. thanks @slackpad",linking12,slackpad
2644,2017-01-10 20:45:20,Hi @j-pnd thanks for opening an issue. Looks like we need to make sure we are the leader and that the initial barrier has been cleared before we serve any consistent results.,slackpad,j-pnd
2642,2017-01-15 12:01:53,"Hello @utdrmac,
 
It doesn't look like Consul specific issue.
This problem was discussed briefly [here](https://groups.google.com/forum/#!topic/consul-tool/lT4EA2HIq84)

Could you please check if your issue is exactly the same? If so, there is workaround.",jakon89,utdrmac
2642,2017-02-08 03:48:22,Thanks for triaging this @jakon89! Closing since we didn't hear back. Please ping this again if that wasn't the issue.,slackpad,jakon89
2640,2017-01-09 10:56:11,"Hi @moofish32 
If I understand you correctly then yes, I think this would cover my use case perfectly.

Basically, in a setup where you want to talk to the local consul agent you can simply use, in your config, ""agent.consul"" and the bind address is returned. Where you have the same service deployed on multiple hosts, with each host having a local consul agent or a pre-defined 'neighbourhood' agent, the config file for that service need not change to handle talking to the local agent.

I also think returning the advertise_addr might also be the correct behaviour if it has been overridden.

I also think this would help with people understanding that you should only ever register and modify a service with the local agent - you can't do it with just any random agent in the cluster.",far-blue,moofish32
2640,2017-02-08 03:34:11,Hey @moofish32 this looks like a good solution! I think we'd want to add a check to make sure there's nothing preceding `agent` and update the docs. It's probably fine to reuse `nodeLookup` though this technically doesn't need to go up to the Consul servers at all. That might be an optimization worth considering.,slackpad,moofish32
2640,2017-03-13 03:12:21,"@slackpad -- sorry for the delay on my end here, I missed your comment nearly a month ago. 

I updated the documentation and actually started trying to attempt the optimization. I ran in to a lot of edge cases that was making testing difficult. I started by trying to use agent config struct to pull `BindAddr` but discovered that might be `0.0.0.0`, then it might IPv6. At that point I started thinking of ways to use system calls to obtain the address and ran into the Docker deviations. 

For now, I have updated the documentation to reflect the fact a DNS lookup is going to the server for this call because I thought the edge cases would be hard to document and hard to test. Instead I was considering trying to use a caching optimization. Effectively, we know the IP can't change without restarting the agent and one dns lookup should be ok. What do you think?

I also see you cut 0.8.0, let me know if you want this in another version, branch etc.",moofish32,slackpad
2634,2017-01-06 06:35:21,"@gagan2u2002 

There is actually some good [documentation](https://www.consul.io/docs/agent/services.html) on this and [fabio-example](https://github.com/magiconair/fabio-example/blob/master/main.go#L68-L81) 

The document I linked is using the consul configuration to set the tags you would want something like:


In addition to the tags don't forget to define a health check.

A quick start video from [Fabio](https://www.youtube.com/watch?v=gvxxu0PLevs)

Recommend closing this issue.
",moofish32,gagan2u2002
2634,2017-01-06 09:44:17,"@moofish32 
Hi i have tried the same but not get any luck to resolve urlprefix issue  , 
 
 **project-stages.yml file** 

service:
    hpgdtv:
        service-name: ""GAGAN""
        service-tags: [""urlprefix-/hpgdtv""]
swarm:
    port:
        offset: 100
    consul:
        url: ""http://127.0.0.1:8500""
---
project:
    stage: production
service:
    hpgdtv:
        service-name: ""GAGAN""
        service-tag: ""/hpgdtv""
swarm:
    port:
        offset: 100
    consul:
        url: ""http://127.0.0.1:8500""

**Fabio Log and Consul log also attached , please go with once so that you can provide me better solution to fix this-**

[consullog.txt](https://github.com/hashicorp/consul/files/689496/consullog.txt)
[Fabio_log.txt](https://github.com/hashicorp/consul/files/689497/Fabio_log.txt)


",gagan2u2002,moofish32
2634,2017-01-06 12:08:24,"@moofish32: try `""tags"": [""urlprefix-/foo"", ""urlprefix-/bar""],`",magiconair,moofish32
2634,2017-01-06 13:19:29,"@gagan2u2002 It looks like you did not register a health check. If you look at the last line of the consullog.txt file you'll notice 



but I don't see anything like that for your `GAGAN` service. fabio will only consider services which have a passing health check. Please have a look at the fabio quickstart which you can find here: https://github.com/eBay/fabio#getting-started Step 3 talks about the health check.

Feel free to open an issue at https://github.com/eBay/fabio if this isn't working since this is most likely not a consul issue.",magiconair,gagan2u2002
2634,2017-01-07 02:47:28,"@magiconair  : if you looking Fabio_log.txt 
consul: Registered fabio with health check to ""http://[10.131.126.127]:9998/health""
consul: Health changed to #39
from that i understand service is passing health check.
As per the fabio log 
consul: Registered fabio with tags """"
from that statement i understand in consul tag is not set properly.

 even in console UI ,  i can able to see service GAGAN is GREEN , consul service  is GREEN and Fabio service also registered in consul and it is also GREEN but when i look routing table interface (http://localhost:9998/routes ) it will not have any records. 

can you share one example on git hub which have basic service who registered in consul and Fabio can pick this it would be a great help.

And yes i am going to open the same ticket on Fabio too.",gagan2u2002,magiconair
2634,2017-01-09 06:33:45,"@magiconair  Still i am not able to get any solution , when i am looking consul log it now say , health of service GAGAN is passing as true -
 **2017/01/09 11:43:10 [DEBUG] http: Request GET /v1/health/service/GAGAN?passing=true&wait=5s&index=117 (5.046s) from=127.0.0.1:65260**
 but still Fabio is not able to pick this -

Again i am share with you the screen shot of Consul UI , fabio_log.txt , consul_log.txt and Project-stages.yml in text format.  Please have a look and suggest me how can i resolve this issue or where i need to correct myself.
[consul_log

.txt](https://github.com/hashicorp/consul/files/692808/consul_log.txt)
![consul_ui](https://cloud.githubusercontent.com/assets/10513267/21758576/358c4608-d663-11e6-9925-c4b49d820aaf.png)
[fabio_log.txt](https://github.com/hashicorp/consul/files/692809/fabio_log.txt)
[Project-stages.yml.txt](https://github.com/hashicorp/consul/files/692810/Project-stages.yml.txt)






",gagan2u2002,magiconair
2634,2017-01-09 06:53:09,"@gagan2u2002 

I have no idea what project-stages.yml is for, but can you try using array syntax for tags.



Purely a guess on my part since I know the consul syntax is array.",moofish32,gagan2u2002
2634,2017-01-09 07:14:54,"@moofish32  Project-stages.yml is only a configuration file and if you are looking it i am able to assign helthcheck and urlprefix tags into this  and on the same time consul is able to pass healthcheck parameter as true if you are looking consul log which i shared earlier. 
So i need to understand where i am doing wrong or how can i resolve this issue as it become bottleneck for my project.

Or if you have any simple example of REST service  (like Hello world ) which is registered in consul with url prefix tags  and fabio can pick the same service then it would be helpful at my end.",gagan2u2002,moofish32
2634,2017-01-09 07:17:58,"@gagan2u2002 -- I am suggesting that your yml syntax is wrong. Did you try modifying as I suggested?


instead of 
",moofish32,gagan2u2002
2634,2017-01-09 07:28:58,@moofish32  i have tried it as you suggest but i am getting same result :(,gagan2u2002,moofish32
2634,2017-01-09 07:31:45,"@gagan2u2002 - I would suggest opening an issue with what ever framework is reading that yml file. Consul and Fabio I believe are behaving as expected.  The most likely issue is that yml file is not getting translated correctly into a consul configuration. Perhaps @magiconair has additional experience, but I don't know the framework you are using.",moofish32,magiconair
2634,2017-01-09 07:31:45,"@gagan2u2002 - I would suggest opening an issue with what ever framework is reading that yml file. Consul and Fabio I believe are behaving as expected.  The most likely issue is that yml file is not getting translated correctly into a consul configuration. Perhaps @magiconair has additional experience, but I don't know the framework you are using.",moofish32,gagan2u2002
2634,2017-01-09 07:48:45,"@moofish32 - for creating service i am using wild fly-swarm and then i will register this service in consul below is the Java code which i am using to get resource from  ""project-stages.yml"" , So i am not reading anyhow any yml file i am just get Resource from Yml and assign it to swarm container.

URL stageConfig = Main.class.getClassLoader().getResource(""project-stages.yml"");
Swarm swarm = new Swarm().withStageConfig(stageConfig);

Configuration overlays using stage properties
https://wildfly-swarm.gitbooks.io/wildfly-swarm-users-guide/content/v/2016.11.0/configuration/project_stages.html
",gagan2u2002,moofish32
2634,2017-01-09 09:46:48,"@gagan2u2002 if you look at the screenshot then you can see that there is no `urlprefix-` tag registered with the GAGAN service. You should be able to see that as well if you check the output of `curl -i http://localhost:8500/v1/health/service/GAGAN?pretty` assuming that your consul instance is on `localhost:8500`.

You need to figure out how to pass the service tags to the wildfly-swarm library since it is interfacing with consul. Unfortunately, their documentation regarding the wildfly-consul integration documentation is a bit basic (https://wildfly-swarm.gitbooks.io/wildfly-swarm-users-guide/content/topology/consul.html). See what you can find out.",magiconair,gagan2u2002
2634,2017-01-09 10:42:47,"@magiconair  yes now we are on same page , this is the challenge i am facing at my end urlprefix- tag is not registered.
  i have window 7 machine with me . i have consul , Fabio and wild fly service on my box . 
To validate this point whether wildfly service have issue with consul i need to validate 
whether a  simple service is working with consul and Fabio.  **Now one quick question are you have any service example ready at your end so that i can validate this with consul and Fabio on window box.**",gagan2u2002,magiconair
2634,2017-01-09 10:44:30,"@gagan2u2002 yes, you can go into the `demo/server` subdirectory of https://github.com/eBay/fabio and build that with `go build`. This is the test server that I'm using which does what you need.",magiconair,gagan2u2002
2634,2017-01-10 04:31:22,"@magiconair  No i am not looking for this , i am looking for one Rest Service which i can deployed on App server like JBoss / Wildfly and then check this service integration with Consul and Fabio . Have we tested Consul and Fabio Integration with Jboss / Wildfly ?",gagan2u2002,magiconair
2634,2017-01-12 11:46:49,"@raben2 why are you encoding a list in a list? That doesn't look right. I think this should be

",magiconair,raben2
2634,2017-01-17 14:41:27,@gagan2u2002 Wouldn't it make more sense to ask this the `wildfly-swarm` community? Once you have the tags in consul things will work as expected.,magiconair,gagan2u2002
2634,2017-01-17 18:25:09,"@magiconair  yes it make sense to me ,   i already put this in front of wildfly swarm community too.",gagan2u2002,magiconair
2626,2017-02-13 03:23:24,"Hi @slackpad  
I'm sorry, I think it is my personal use of the error. We cluster more than 10,000 nodes, and the cluster nodes will often change, resulting in often registered service, in the DeregisterCriticalServiceAfter function before we do not deregister the service. The program we run for about a year, and now the situation is to request the registration service, the request timeout, simply traced the reason is because the request time locked for too long, I moved to a new cluster There is no such a situation.
thanks.",celeskyking,slackpad
2625,2017-02-08 03:10:38,Hi @vrenjith that error is produced when consul is given a name that it is supposed to resolve (something in `.consul.`) but it doesn't parse correctly. Can you share an example name that's failing?,slackpad,vrenjith
2623,2017-02-08 03:08:49,"Hi @huyjack178 the canonical set of ACL tokens are stored on the Consul servers in the `acl_datacenter`, similar to how KV values are stored in their state store, with changes to ACLs going through Raft.

If you enable https://www.consul.io/docs/internals/acl.html#replication, then Consul servers outside the `acl_datacenter` keep a replicated set of ACL tokens in their state stores which can be used in the event of an outage or partition from the `acl_datacenter`. Hope that helps!",slackpad,huyjack178
2619,2017-02-08 02:47:38,Hi @stenio123 this is almost always a cached javascript issue. If you clear your cache or do a shift-reload it should fix it. Please ping back if that didn't fix it.,slackpad,stenio123
2617,2017-01-17 17:00:52,"Hi @arunkumar-m thanks for this PR as well.

This is protected for the the Go API client for /v1/kv but not /v1/txn. I think we should make those consistent so it errors early up there in the same way. Need to think through the implications of banning this on the server side for both of those as well, since it is technically valid right now. I think this would be a breaking change, so pinning this to 0.8.",slackpad,arunkumar-m
2616,2017-01-06 01:14:26,Hi @thomassun thanks for opening an issue. This is a dup of https://github.com/hashicorp/consul/issues/1244 so linking and closing this one.,slackpad,thomassun
2610,2017-01-16 14:40:45,"To fix #2566 completely requires edits to `import` and `export`. Additionally, `snapshot` is affected by the same pattern.

@arunkumar-m [f954393](https://github.com/asobrien/consul/commit/f954393d363b187dcd45d8694495c054672adc30) adds the required changes to the additional files, feel free to cherry-pick it to include in your PR if you want.",asobrien,arunkumar-m
2610,2017-02-07 20:31:51,"Hi @arunkumar-m thanks for opening a PR. We are going to close this in favor of https://github.com/hashicorp/consul/pull/2717, which will sweep through and update all the CLI commands, and put the client creation in a common spot so we can fix this for all commands.",slackpad,arunkumar-m
2608,2017-01-06 00:32:08,"Hi @aleung thanks for opening an issue. I definitely see what you are struggling with if you are trying to use sessions in this situation. Need to think through implications of a ""not ready"" state, but it might be a good way forward.",slackpad,aleung
2606,2017-01-06 00:22:26,Hi @MAS150MD200 thanks for opening an issue. Closing this as a dup of https://github.com/hashicorp/consul/issues/1769.,slackpad,MAS150MD200
2596,2016-12-20 04:12:58,Hi @hehailong5 I think we could possibly add a new argument to these APIs to do some filtering on the server. Will take a look.,slackpad,hehailong5
2589,2016-12-11 16:06:10,I understand your point of view. Thank you for your quick answer @jippi.,mytototo,jippi
2589,2016-12-11 16:08:06,"@mytototo keep in mind I'm not in any way associated with HashiCorp here, just voicing my own opinion on it :) ",jippi,mytototo
2589,2016-12-11 18:46:43,Agree with @jippi on this one :-) This isn't on the roadmap at this time.,slackpad,jippi
2586,2016-12-09 16:25:41,Hi @chiel1980 I don't know of any 3rd party security review that we have to share. We do ask if you can please give us a first look privately via security@hashicorp.com so we can review the findings and address any critical issues before they are publicly disclosed. Thanks!,slackpad,chiel1980
2576,2016-12-06 19:24:42,"awesome, thanks @slackpad ",chiefy,slackpad
2573,2016-12-05 21:38:10,"@brianshumate Can you include/verify samples for each?  For instance on some of the variables we require a scheme, like `unix://`, and others we don't.",sean-,brianshumate
2573,2016-12-06 17:56:48,"Hi @brianshumate 

This looks really great, and thank you so much for typing this up. I have a few concerns though:

1. This lives under the ""commands"" section, but it's not really a command. This will muck up the SEO, since the path will be ""docs/commands/environment.html"". If we ever added a `consul env` command (for some reason), this would add additional confusion.
1. There's a bit of a disconnect between this page and the CLI pages themselves. The envvars do apply to the CLI, but they technically apply to the agent. It's the agent that reads these values, not the CLI.

As such, I would provide two possible recommendations:

- Move this into an ""other"" section like [Vagrant does](https://www.vagrantup.com/docs/other/environmental-variables.html)
- Put this as its own page under the ""agent"" (https://www.consul.io/docs/agent/environment.html)

What do you think?",sethvargo,brianshumate
2570,2017-01-12 23:28:32,"Thanks for the PR, @vancluever! This is a nice piece of functionality to have alongside the EC2 join stuff.",kyhavlov,vancluever
2570,2017-01-13 00:29:55,No prob and thanks for the merge @kyhavlov!,vancluever,kyhavlov
2563,2016-12-22 18:31:45,"@rhyas Thank you for giving this a twirl, and yes, that's correct.  Internally we don't iterate over multiple addresses... yet.  That's next.  For now you do have to apply a `limit 1` and get to a single address, but the exact use case you describe is planned so that you can do exactly what you suggested above, which is to listen to `127.0.0.1` and the first IP address of an interface (e.g. `GetDefaultIP`).",sean-,rhyas
2563,2017-03-06 20:36:55,@RRAlex I spun up and merged https://github.com/hashicorp/consul/pull/2786 a few min ago in response to this.  Use `-bind={{GetPrivateIP}}` instead of `-client=0.0.0.0` and let me know if that works.  Thanks!,sean-,RRAlex
2563,2017-03-12 03:10:23,"@RRAlex Until I get around to fixing the tests that I broke in #2786, a few questions:

1. If you run the above template through the `sockaddr` command line utility, does it return the right value?

2. Why is the `-client` argument set to `0.0.0.0`?  Can you set that to `{{GetPrivateIP}}` and does that work for you?  The above patch removes the need to double-specify `-client` and `-bind`, but it's harmless in your case to do that as a temporary workaround until that PR gets revisited.",sean-,RRAlex
2563,2017-03-14 08:17:11,"@RRAlex Please be careful with your Vault data!  The UUID-based NodeID lookups were added in 0.7.4 (Feb 6th).  I don't personally use Consul in any Docker containers for anything that I do or work on so I'm not sure what the situation is there (we run Consul on the host itself and not in a container).  Because Consul can only advertise one address, I'm a little concerned about the notion that binding to `IN_ADDR_ANY` will reliably work in your environment.  Once you do have a chance to try `-client` with a non-`0.0.0.0` value, I'd be curious to know how things work.",sean-,RRAlex
2562,2016-12-01 22:54:29,"Hi @cliff-ops - you don't need to set that in the ACL datacenter, just all the remote datacenters. The ACL datacenter doesn't do replication and won't show anything special if it's enabled there.

The token you supply can be the master token, or another management token. Since any management token can see all other ACL tokens, it doesn't really make a difference which. That `ACL not found` error makes it seem like the `acl_replication_token` isn't valid, so maybe you need to create that with /v1/acl/create?",slackpad,cliff-ops
2562,2016-12-02 01:41:32,"HI @slackpad, thank you for clarifying the about the management token, that makes sense.
I created a fresh management token and I found the following:

""failed to sync ACL changes: ACL rule compilation failed: Failed to parse ACL rules: key 'key app03acl' expected start of object ('{') or assignment ('=')

That ACL something I created using the create endpoint a while back in 0.6.3. Not sure if this significant. 

 As soon as I deleted that key sync started working for me. 

Could you clarify whether after enabling ACL syncing we we are still bounded by the TTL's of the cached tokens in the event of a network partition? 

Previously since  we use a default deny we would bump the TTLs up to something reasonably high. Is this no longer needed with ACL sync? I

ts not clear from the docs how the interaction of these three related directives:

acl_replication_token: ""xxxxx-xxxxx-xxxxx-xxxxx""
""acl_down_policy"": ""extend-cache
""acl_ttl"": ""300s""

Thanks again for your help.",cliff-ops,slackpad
2558,2016-12-20 03:39:39,Hi @jacob-koren please take a look at this post with some details about this problem - https://groups.google.com/d/msg/consul-tool/64i0fZ5p3sA/QS2NvINFDQAJ. We should have some automation in Consul 0.8 that makes this easier to manage!,slackpad,jacob-koren
2554,2016-12-01 05:20:51,"Hi @shotdog please take a look at these mailing list posts which should help:

https://groups.google.com/forum/#!searchin/consul-tool/phillips$20failure$20domain%7Csort:relevance/consul-tool/0_fEPrbtT5g/r8c5Fk-tGgAJ

https://groups.google.com/forum/#!searchin/consul-tool/single$20point$20of$20failure%7Csort:relevance/consul-tool/_ZQVD4txyzM/oFRWpW7kCQAJ

The short answer is that as long as you have 3 or more Consul servers, Consul won't have a single point of failure. Having on Consul client on each node in your environment doesn't make things less resilient, as it's in the same failure domain as that host.",slackpad,shotdog
2550,2016-11-30 16:23:23,"Hi @shotdog can you point to where you saw that? I'm not sure exactly what the context is for your question. ""bootstrap mode"" generally refers to `-bootstrap-expect=N` where the servers will wait for N to come online before bootstrapping themselves.",slackpad,shotdog
2549,2017-01-11 03:59:13,"Hi @Thib17 thanks for opening a PR. We are currently working on making watches fine-grained for services which I think will fix the core issue here without adding any new interfaces. Right now if any service changes it wakes up watches for all of them. Once we have fine-grained watches (should be soon in 0.7.3) then only the affected services will wake up. I'd like to see if this fixes the issue rather than add a regex capability, which could add quite a bit of work for the Consul servers vs. the fine-grained watch approach. I'll update this once that support it in.",slackpad,Thib17
2549,2017-01-11 12:24:42,"Hi @slackpad , thanks for your answer.
I think it's an other problem. Here, the problem is that there is no filtering on the catalog services end point.
Indeed, we currently have to get all existing services, or list every services we want when we use the consul discovery (e.g. with prometheus). But the list of services may change over time, and hard-coding the list of services watched in other tools that use the consul discovery become painful. It seems a good idea to allow querying the catalog using a regexp to only get a subset of services (==services that match the regexp).
This feature has already been discussed in prometheus/prometheus#2028, and it seems that the filtering mechanism should not be client-specific but should be integrated in consul.",Thib17,slackpad
2549,2017-02-08 03:44:00,@Thib17 how about an option to just return the services that changed after a blocking query wakes up?,slackpad,Thib17
2549,2017-02-08 08:53:09,"@slackpad I'm not sure this fixes anything. Our initial issue is that when you have tons of services it's more efficient to do the filtering server side. Having a single TCP connection to watch multiple services would probably work too but be way less efficient (as we would be woken up by a lot things we don't really care about).

If you think that server side filtering for the catalog is not something that will happen, that's probably fine too, but please state it explicitly so we can make progress with prometheus/prometheus#2028 :).
",iksaif,slackpad
2549,2017-03-27 06:05:31,@slackpad : any way to make progress on this ?,iksaif,slackpad
2546,2016-12-01 05:15:52,@sean- mind rebasing this to resolve the conflict?,slackpad,sean-
2545,2016-12-02 07:28:20,"Hi @ezolenko2 I can't reproduce this, and Consul nor the UI code has anything related to Google Analytics. Is it possible you have a content filter / ad blocker / or some proxy in the middle?",slackpad,ezolenko2
2542,2016-11-29 18:44:38,"Hi @huyifanstar please open an issue with Kong or use the mailing list there. If you find a Consul-specific problem we can help you out, but we don't have enough context with Kong to help with this one.",slackpad,huyifanstar
2542,2016-11-29 18:57:05,@slackpad   https://getkong.org/,huyifanstar,slackpad
2539,2016-11-29 08:42:28,"Hi @thecodeassassin how many servers total are you running? In your config I see `""bootstrap_expect"": 2` which is unusual - Consul needs an odd number of servers to safely form a quorum (2 server configurations can't handle a server down so you might have lost quorum during the upgrade).",slackpad,thecodeassassin
2539,2016-11-29 09:40:38,@slackpad i am now trying a 3 node setup with 0.7.1. I'll let you know. But in any case that doesn't explain why it's trying to contact nodes on a non-existing IP i think.,thecodeassassin,slackpad
2539,2016-11-30 05:59:31,"@slackpad not possible, i create new machine images for every upgrade and replace the nodes with them. ",thecodeassassin,slackpad
2539,2017-01-16 14:53:17,"@slackpad This is still happening as of Consul 0.7.2. I create a fresh consul installation with packer and i don't start it. Then when i bootstrap the nodes the wrong ip addresses show up and consul cannot start the leader selection. I cannot explain where these 10.132.x.x ip's are coming from ðŸ˜• 



",thecodeassassin,slackpad
2539,2017-01-16 16:01:09,@thecodeassassin when its in that state (even if it can't elect a leader) do those addresses show up in `consul members` on the servers?,slackpad,thecodeassassin
2539,2017-03-13 13:17:48,"@lievendp running consul in docker swarm mode is hard:) 

I confirm that this happens. when -bootstrap-expect=1 and consul is running in docker with persistence enabled, when consul container gets a new IP (after restart, update of swarm service etc) It refuses to pick itself as a leader, in logs it looks like:


there is not much you can do with it:/ 

 
Remove peer does not work as there is no leader. 

",s4s0l,lievendp
2539,2017-03-13 18:54:29,"@s4s0l But I'm not running docker swarm. :-)
basically it's more like a no-redundancy scenario, right.",lievendp,s4s0l
2537,2016-11-29 05:39:42,"Hi @huyifanstar that looks like a problem with Kong so this is better pursued over in that project. From the `2016/11/29 05:02:15 Unexpected response code: 500 (CheckID does not have associated TTL)` message it looks like there might be an order problem where some process updating a TTL check is running before the check is registered, or the check is being registered as the wrong type. I don't have any knowledge of Kong internals, though, so I don't think I'll be able to offer much more. Sorry about that!",slackpad,huyifanstar
2536,2016-12-20 03:14:34,"Hi @tburt11 there are provisions to prevent adding a leading slash in the /v1/kv API, but the txn allows it through. It's interfering with how the UI asks for the keys by effectively creating another slash at the top - we should probably modify the /v1/txn endpoint to fail if you add the leading slash (or strip it) because you never want that as part of the key.",slackpad,tburt11
2535,2016-11-28 20:27:34,"Hi @jacob-koren Consul does store all of the KV data in memory. It uses disk for the Raft log and snapshots, but all of the current working set for the state store is in memory, so this is expected if you are adding more and more keys to the store. I'll tag this as a docs issue because I don't have a good place to point to that explains that, and we should make that clear in the docs.",slackpad,jacob-koren
2535,2016-11-30 18:57:02,"@slackpad If I add & remove some keys to consul KV over a long period (say P = 1 month) of time while at any time (say T) in period P I have nearly constant count of keys, do I have to expect memory footprint grow trend?

Thanks in advance",alexeyknyshev,slackpad
2535,2016-11-30 19:05:23,@alexeyknyshev it shouldn't grow over time - the RAM usage should roughly reflect the number of keys currently in there at any given time.,slackpad,alexeyknyshev
2534,2016-12-20 02:53:55,"Hi @Kane-Sendgrid that old KV API doesn't have a structure that allows us to add new fields. We added this information in the return response for https://www.consul.io/docs/agent/http/kv.html#txn, so you can use that.",slackpad,Kane-Sendgrid
2529,2016-11-28 20:37:50,@babbottscott Thoughts on this @slackpad ? It wouldn't be hard to implement but I'm not sure if this is the intended behavior for this case. ,mckennajones,babbottscott
2529,2016-11-28 20:49:38,"@mckennajones @babbottscott That's a good suggestion in general, but I'd keep the current behavior for Consul and not auto-create the directory. We use the presence of state in that directory to tell if a cluster is fresh and whether it's safe to bootstrap, for example, so I'd rather be conservative and have it error out. For non-servers it might be safe to create it on the fly, but that's probably too subtle/complex to have a behavior difference.",slackpad,mckennajones
2529,2016-11-28 20:49:38,"@mckennajones @babbottscott That's a good suggestion in general, but I'd keep the current behavior for Consul and not auto-create the directory. We use the presence of state in that directory to tell if a cluster is fresh and whether it's safe to bootstrap, for example, so I'd rather be conservative and have it error out. For non-servers it might be safe to create it on the fly, but that's probably too subtle/complex to have a behavior difference.",slackpad,babbottscott
2528,2016-11-22 19:52:47,"Hi @akamalov you don't want to specify the `""acl_token"": ""XXXXXXXX-4632-8ec7-e0c193bbae3c""` in your config file. That will be used by requests that don't supply their own token.",slackpad,akamalov
2528,2016-11-22 19:58:59,"Thanks @slackpad  Given that I remove that acl_token, it still won't solve a problem of bypassing ACL, right?

Thanks!",akamalov,slackpad
2528,2016-11-22 20:04:23,"@akamalov I think that's the problem. It's not that the ACL is getting bypassed, it's that if you configure `acl_token` that is used for requests that don't specify their own token via `?token`. If you remove that configs, then requests that don't supply `?token` will get the anonymous token, and should be denied access.",slackpad,akamalov
2528,2016-11-22 21:15:31,"Thanks @slackpad. If you have time, would you mind pulling  and trying to run your consul off this image, please ?? Meanwhile, I will look into my Dockerfile as well... Thanks!!",akamalov,slackpad
2528,2016-11-23 13:50:29,Resolved. You were right @slackpad. I had to provide args to my Marathon JSON to point to the config file. Once done it started working. Thanks again!,akamalov,slackpad
2526,2016-11-22 23:00:52,"@pheitman On my machine, when executing `consul kv put` with any negative values the command hangs. Does this happen do you too? I am running on Arch Linux.",mckennajones,pheitman
2526,2016-11-22 23:06:52,"Yes, I am pretty sure that consul is treating the negative value as if it
was a minus sign which tells consul to read the value from stdin.

On Tue, Nov 22, 2016, 6:01 PM McKenna Jones notifications@github.com
wrote:

> @pheitman https://github.com/pheitman On my machine, when executing consul
> kv put with any negative values the command hangs. Does this happen do
> you too? I am running on Arch Linux.
> 
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/hashicorp/consul/issues/2526#issuecomment-262391841,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AQYjg5MgHo0a5ebY_kmxTyrzv_r4H98Dks5rA3QtgaJpZM4K5oPz
> .
",pheitman,pheitman
2526,2016-11-22 23:10:32,"@pheitman aha, I just tried it out again and I think you're correct. Will look into fixing this.",mckennajones,pheitman
2524,2016-11-23 01:40:00,"Hi @joshuaspence the best way to do this is probably to query https://www.consul.io/docs/agent/http/health.html#health_node for the node name and make sure its `serfHealth` check is passing. This verifies that the agent is part of the cluster, the servers are aware of it and have logged it into the catalog, and that the rest of the cluster things that agent is alive.",slackpad,joshuaspence
2522,2016-11-20 01:10:56,"> num_peers = 0

Hi @jijojv it looks like your servers aren't properly connected together if the peer count is 0. That should show as 2 for a 3 server cluster. Is there anything in the logs related to Raft?
",slackpad,jijojv
2522,2016-11-20 02:49:08,"Hi @slackpad. I was not getting a leader election in the past and no checks were getting rpc errors, probably related to https://github.com/hashicorp/consul/issues/993 so i had added bootstrap_expect 1 on one of the nodes based on the comments.

Tried different combinations, finally had to  rm -rf /var/lib/consul everywhere  add readd bootstrap_expect 3 to get a consistent result and now i do see num_peers 2. 

Thanks a lot.
",jijojv,slackpad
2516,2016-12-29 02:53:30,"@kyhavlov @slackpad I realize this is merged, but this seemed the best place to comment about an issue before possibly opening a new bug/item. 

The TestAgent_Reload in the tests for this feature break on a machine with 2 private IP's. It took me a while to figure out how to get the output from the MockUi, (this drove me NUTS btw) but once I did it led me to the understanding that while nexConfig is called to get a config, it's never actually used to create the instance of the server used in the test. It builds a DefaultConfig on a Run(), but in that default, the bind is 0.0.0.0. If that's the bind, the agent fails to start because of the multi-private-ip issue. 

Not sure how/if this needs to be fixed. I've worked around it by simply adding a -bind to the args list for the Command. It seems odd I haven't hit this for any other tests, so I'm not sure what this test is doing that's different from the rest. I haven't dug into it deeply yet.",rhyas,kyhavlov
2516,2017-02-08 02:45:57,Hi @rhyas that sounds like it's worth tracking. Would you mind opening a new issue for that? Binding to the address in the config sounds like a reasonable fix for this.,slackpad,rhyas
2514,2016-12-19 23:56:51,"Hi @nidhishopback the hosted Consul Enterprise in Atlas is now deprecated and will be discontinued on March 7, 2017. You can check out https://atlas.hashicorp.com/help/consul/alternatives for more details.

Not sure if you are still experiencing this issue, but my guess is that's it's a different IP than you've set here. Also, only a subset of the data auto-refreshes in Atlas, so it may depend on what you are looking at. Feel free to shoot an email to support (at) hashicorp.com if you are still having trouble.
",slackpad,nidhishopback
2513,2016-12-20 03:09:34,Hi @ycheng-gh this is an odd one - I can't explain what was happening here. So rebooting 117 got things working again? It looks like 118 was able to connect to 117 - were there any logs on 118 related to 117 after those shown above (anything related to failed replication)?,slackpad,ycheng-gh
2488,2016-11-09 04:28:09,"Hi @joshuaspence we don't currently have an agent-level endpoint to pull the health of an agent. There's https://www.consul.io/docs/agent/http/health.html#health_node but that'll end up going up to the Consul servers, and the HTTP status code doesn't indicate the state of the health checks. This looks like a possible dup of https://github.com/hashicorp/consul/issues/1468.
",slackpad,joshuaspence
2483,2016-11-18 00:52:19,"Hi @keep94 thanks for opening a PR. We are in the process of changing logging libraries so we are holding off on any log-related changes right now. Thanks for making us aware of Dominator, though!
",slackpad,keep94
2482,2016-11-09 02:12:12,"Hi @amiryal thanks for opening an issue. I think this would require us to build platform-specific C code to work and we really don't want to give up Consul current status as pure Go, which makes it much easier to support multiple platforms. This kind of interface could be done as a separate project which shims these interfaces and uses the Consul API under the hood to talk to the local agent; that's probably a better approach here.
",slackpad,amiryal
2478,2016-11-07 22:24:36,"Hi @brianhays could you move this to match the parsing for the datacenter name param? https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L267-L275
",kyhavlov,brianhays
2478,2016-11-07 23:24:12,"Hi @kyhavlov thanks! I moved it to command.go as suggested and also added the validDatacenter check.
",brianhays,kyhavlov
2474,2016-11-08 02:38:10,"Hi @kamaradclimber this looks good! If you'd like to add the associated tests I think we can pull this in.
",slackpad,kamaradclimber
2474,2016-11-10 11:15:51,"@slackpad I've added tests. Would you have advices regarding failing tests? I'm unable to see if it is related to my patch or not.
",kamaradclimber,slackpad
2474,2016-11-28 11:11:15,"Hi @slackpad,

I finally managed to make test pass. Would you have any feedback regarding this PR?",kamaradclimber,slackpad
2474,2016-12-16 08:50:12,I've just rebased. @slackpad any feedback?,kamaradclimber,slackpad
2474,2017-01-13 17:35:32,"Hello @slackpad,

would you have some feedback on this PR?
If it suits you, could you consider it for merge?

Thanks",kamaradclimber,slackpad
2474,2017-02-03 09:07:12,"Hello @slackpad,

would you have some comments?
Thanks,",kamaradclimber,slackpad
2474,2017-03-17 08:28:55,@slackpad @simplechris any feedback on that PR. What can I do to make it progress?,kamaradclimber,slackpad
2465,2016-11-03 20:38:45,"Hi @stevehorsfield I've been bitten by this kind of thing, too. We could probably leverage go-getter to pull in a known revision that you point at, with maybe an optional way to say ""build my local Consul"".
",slackpad,stevehorsfield
2461,2016-11-02 23:43:26,"Hi @spanktar if the new servers coming up join with at least one existing agent from the cluster then word should get around via gossip without having to touch any of the existing agents. There's a change brewing under https://github.com/hashicorp/consul/pull/2459 that should make this easy to set up!
",slackpad,spanktar
2461,2016-12-14 23:13:29,"@slackpad I'll look at that.  In the meantime, that's pretty much what I'm getting at.  We understand that if we give it one good value, it will gossip (good), but the list given by -retry-join is never revisited, and this can cause problems as outlined above.

I'm very excited about the AWS auto discovery, but I think it might still have the same problem in the case I mentioned.",spanktar,slackpad
2458,2016-11-01 13:26:45,"Hi @NaseemMa thanks for opening an issue. The best way to see where the memory is going is to set the enable_debug option on one of your servers and then look at http://localhost:8500/debug/pprof/heap?debug=1 on that server to see the heap profile. Would you be able to post a few samples of that endpoint's output over time as a gist?
",slackpad,NaseemMa
2458,2016-11-09 03:58:08,"Hi @NaseemMa I took a look through the heap dumps and it looks like there's a lot of KV set operations as well as ListKeys operations. What kind of workload is this cluster doing? Is there some process that could be causing a lot of rapid KV churn with a corresponding blocking query for listing keys? Is it just Vault using Consul?
",slackpad,NaseemMa
2458,2016-11-09 09:03:41,"Hi @sabag a 7-8 second period for the session renew makes sense for Vault maintaining its leader lock (that has a 15 second TTL and the periodic fires at 1/2 that interval). Do you know the time interval between the two heap dumps you provided? I didn't see a dramatic difference in them. It might be useful to take them several hours apart. I'd also be curious if the memory usage didn't level off after some time - do you have any plots of memory usage over several hours?

I couldn't find any RHEL-related memory leak issues, but it might also be worth building Consul from master with Go 1.7.3 and see if that makes a difference. The next version of Consul will be built with that, and it's several versions newer than what we built Consul 0.6.4 with.
",slackpad,sabag
2458,2016-11-13 17:28:12,"Hi @sabag thank you for the update!
",slackpad,sabag
2455,2017-01-06 18:28:19,Hi @DamionWaltermeyer is that reproducible for you or do you just see that occasionally?,slackpad,DamionWaltermeyer
2455,2017-01-10 02:08:18,"@DamionWaltermeyer If you're running Consul inside a container, you probably don't want to enable syslog; it won't work unless you set up one inside the same container, which is more complicated than having docker itself send the container's logs to syslog: https://docs.docker.com/engine/admin/logging/overview/#/syslog-options.

For your second point about IPs, you probably want to look into the `--link` option or docker's network stuff, depending on your case.

",kyhavlov,DamionWaltermeyer
2452,2016-11-29 14:41:56,"I discovered the same thing today when testing node and service checks resulting in `warning`.

DNS queries seem to give a list of ""non-failing"" services (those in `warning` and `passing` state), which I now realize isn't the same as the ""passing"" param on `/v1/health/service/<service>` (returns only `passing`).

So, in order for a health query to give results similar to a DNS query, I'd need to stop using the ""passing"" param, then add extra filtering logic in my applications to filter-out services in `critical` state.

As @takeda said, it would be helpful if a param (or params) existed to include ""non-failing"" services... ie. both `passing` and `warning`.",bdclark,takeda
2445,2016-10-27 16:30:25,"Hi @raisomain thanks for opening an issue. We looked at this method when we added the feature but it added a bit more complexity internally (we'd have to track counts and time) so we opted for the time period since that covered a more general set of use cases. Also, it would add more complexity to the config. You should be able to set it to N times the interval to get roughly the same behavior.
",slackpad,raisomain
2441,2016-11-30 01:48:21,Hi @Evgen787 this looks like you don't have an ACL configured in your web ui that's correct for dc2 (the `?token` parameter is empty).,slackpad,Evgen787
2433,2016-11-19 22:46:02,"Hi @jaystramel what version of Consul is running on your servers?
",slackpad,jaystramel
2432,2016-10-27 05:42:26,"Hi @hehailong5 it is not recommended to run the client HA. Consul supports an HA server configuration by running 3 or more servers which provides HA for the cluster, but each node only needs one client agent. The client agent is in the same failure domain as the rest of the node (if the node shuts down, for example), so it doesn't add much to have multiple Consul clients on one machine. Running a process supervisor to restart the Consul client if it were to exit should be sufficient.
",slackpad,hehailong5
2432,2016-10-27 06:13:55,"@slackpad, I am not asking for running multiple consul client instances on one machine, this makes no sense obviously. actually I have a domain specific component coupled with a consul client and I want to deploy it onto a 3-nodes HA cluster. the problem is that the node name (specified by -node) for these 3 consul client instances can not be the same, otherwise 2 of them would fail to start because of the name conflict. if I name them with different names, we don't have HA anymore.  
",hehailong5,slackpad
2432,2016-10-27 16:23:34,"@hehailong5 sorry for the misunderstanding on my part. I think you would want to register a [Consul service](https://www.consul.io/docs/agent/services.html) with the same name on each of these nodes, then clients would look up <name>.service.consul and would be given the IP of one of the three instances as long as they are alive. Does that make sense or am I still misunderstanding the use case?
",slackpad,hehailong5
2432,2016-10-28 01:39:46,"Hi @slackpad, I am using the agent api ([Agent](https://www.consul.io/docs/agent/http/agent.html)) to perform the service create/update/delete as suggested in the official doc. Suppose in a 3-nodes HA cluster, client1 runs on node1, client2 runs on node2 and client3 runs on node3. in a typical HA scenario, suppose the first create request hits on node1, and the client1 creates the serviceA via the agent interface. suppose a subsequent update request on serviceA hits on node2, the client2 does NOT recognize serviceA because it was registered by client1, thus the update request would return with nothing done. If the client2 performs the update via the catalog interface ([Catalog](https://www.consul.io/docs/agent/http/catalog.html)) since all the services are there, the ANTI-ENTROPY would overwrite the update with the copy from client1 within one minute. the update performed by client2 still not work. 
Hopefully I made this clear.
",hehailong5,slackpad
2432,2016-10-28 02:58:51,"Hi @hehailong5 the agent API should only be used by processes on the node where that agent runs. For example, you'd run serviceA and it would always use 127.0.0.1:8500/v1/agent/ to create/update/delete the info for itself. The agent on that node will sync the catalog information for the services _on that node_, so there won't be any interference between the nodes. So the instance of your service on node1 will register with its local agent, which will sync the catalog on the Consul servers for the instance of the service on node1. You never want to have your service talk to the Agent API on another node, and everything should work fine (always talk to 127.0.0.1:8500/v1/agent/...).
",slackpad,hehailong5
2432,2016-10-28 03:37:04,"Hi @slackpad, yes, in my case, the process is running on the same node where the consul agent runs, and the process always talks to 127.0.0.1:8500. I just want all the process instances manage the same a single view for each service, that's exactly what HA requires. how about this, when the create request comes to node1, the registration process on the node1 asks the client1 on the node1 to register serviceA via 127.0.0.1:8500/v1/agent; after a while, a update request on serviceA come into the cluster, and the HA infrastructure chooses node2 to serve this request, the registration process on the node2 then asks the client2 on the node2 to update serviceA, how to do it? so that any query request via Catalog api from other client will get the updated  serviceA??
",hehailong5,slackpad
2432,2016-10-28 03:41:48,"@hehailong5 are you trying to do something like update service tags from some external request?
",slackpad,hehailong5
2432,2016-10-28 03:51:15,"@slackpad not limited to update, how to delete serviceA from client2 that created by client1, so that the serviceA will be completely removed from catalog?
",hehailong5,slackpad
2432,2016-10-28 06:40:19,"sorry @slackpad, I don't understand why this would achieve the HA. a create, update example would help :)
",hehailong5,slackpad
2432,2016-10-28 06:49:24,"I did the same as @slackpad suggestion.
",cmingxu,slackpad
2432,2016-10-31 08:51:26,"@cmingxu , @slackpad could you please explain more about this way? in my understanding, if I register serviceA via client1 with ""deregister_critical_service_after"", I still can not modify serviceA via client2. if the ttl expires, it does not exist in the catalog anymore. what all these are to do with the HA? 
",hehailong5,cmingxu
2432,2016-10-31 08:51:26,"@cmingxu , @slackpad could you please explain more about this way? in my understanding, if I register serviceA via client1 with ""deregister_critical_service_after"", I still can not modify serviceA via client2. if the ttl expires, it does not exist in the catalog anymore. what all these are to do with the HA? 
",hehailong5,slackpad
2432,2016-12-20 02:13:57,"Hi @hehailong5 I'm not sure I follow the concern. In the example above, ""serviceA"" will be deleted automatically after the service dies, so client2 doesn't need to be concerned with it.",slackpad,hehailong5
2432,2016-12-20 03:05:47,"Hi @slackpad, the services and consul clients are running on different nodes. the registrator running on the service node contacts with one consul client each time to send the add/update/delete request. the goal is to achieve the consul client side HA. is that possible?

![image](https://cloud.githubusercontent.com/assets/17330257/21336790/b5a22054-c6a2-11e6-8938-7e0c5803cc45.png)
",hehailong5,slackpad
2432,2016-12-20 03:19:52,"Hi @hehailong5 I see - Consul isn't designed for client side HA like this.

You'd want to run the Consul client on the same machine with serviceA and registrator in the example above. It's in the same failure domain as those pieces (such as if the machine itself fails) so you already have single points of failure for that instance of serviceA. If you have an HA setup for serviceA, you'd need another instance of that + registrator + the Consul client on a separate machine, and that Consul client would be independent (along with those other pieces). We didn't design for client side HA for Consul since there are always other single points of failure for a given instance of a service.",slackpad,hehailong5
2430,2016-11-22 17:38:21,"Hi @ross wanted to clarify did you see any health flaps _for_ nodes that were not part of this pair with duplicate IPs, or were you just seeing memberlist messages across the whole fleet related to those two nodes? The latter would be expected as the nodes fight it out, and we could see consul template being busy if quiescence wasn't set. We'd definitely not expect the former where some node outside of this pair actually has its own health affected by this.",slackpad,ross
2430,2016-11-22 19:24:46,"> Hi @ross wanted to clarify did you see any health flaps for nodes that were not part of this pair with duplicate IPs, or were you just seeing memberlist messages across the whole fleet related to those two nodes?

We were seeing consul-template restarts on nodes that matched up with the memberlist messages in the logs on that node. So somelb-ab12cd56 would log those messages and at the same point in time the restart command would fire. This happened frequently enough that things were restarting as quickly as we'd allow them. 

The conflicting nodes were just test/dev nodes that had no services on them, included in the lb's template or otherwise. I wasn't expecting the health/membership of those 2 nodes to cause consul-template to think it needs to re-generate a template and restart the services. Is that what you're saying is expected in this case? ",ross,ross
2429,2016-11-30 01:44:37,"Hi @gimlet2 this gets into thorny issues with clocks being out of sync, etc, so we've avoided timestamps in our APIs. The `ModifyIndex` values are monotonically increasing, so you could use set a key externally with a timestamp from the source of your choice and use that key's `ModifyIndex` to judge before/after for other keys. We probably won't add something like this, though, unless there's a super compelling use case.",slackpad,gimlet2
2428,2016-11-02 13:42:24,"I don't get the exact same error as @pascaldekloe, so I can create a new issue if you want.

I'm running the docker container with no extra configuration. The command that works is:



The command that fails is:



Only difference is -dev flag. Error trace is here:


",zbintliff,pascaldekloe
2428,2016-11-09 17:20:33,"Are you joking @slackpad? Please reopen this issue.

Something like the following causes the crash.


",pascaldekloe,slackpad
2428,2016-11-09 17:27:58,"@pascaldekloe thanks for the JSON, now I can reproduce your crash locally.
",slackpad,pascaldekloe
2428,2016-11-09 17:53:34,"Thanks for the poke @pascaldekloe - I hadn't carefully compared the stack traces and thought we were fixing the same issue. I've also updated our test environment to exercise this since it runs its script checks over in a Docker container and didn't hit this path, and our unit tests were properly setting up the mutex. Should be good now - please let me know if that's not the case!
",slackpad,pascaldekloe
2427,2016-10-21 22:00:58,"potencially we do, i'll turn them off and compare results. thanks a lot @jippi !!
",adrianlop,jippi
2427,2016-11-02 02:41:20,"how to config to let the outputs to log file? @jippi 
",xautjzd,jippi
2427,2016-11-02 16:50:23,"Hi @adrianlop there shouldn't have been anything new in 0.7 to cause this. If you look at [telemetry](https://www.consul.io/docs/agent/telemetry.html) and look at the counts for metrics with `fsm` in the name that may help narrow down what's churning.
",slackpad,adrianlop
2427,2016-11-03 08:30:23,"hi @slackpad thanks for the help.
Please find attached some additional info. do you see anything abnormal?

consul info output:



consul monitor output:



telemetry samples (gathered using `nc -u -l` during 5sec then `| grep fsm`, this is the result):


",adrianlop,slackpad
2427,2016-11-03 17:01:58,"Thanks @adrianlop that looks like the only churn over that 5 second period is writes to the KV store. Do you have something in your infrastructure that could be writing a large-ish value some set of keys over and over? We don't have a super great way to chase that down on the server side - if you have debug logging turned on your agents (or use `consul monitor` for a little while with debug enabled) you will be able to see the requests to /v1/kv on the agent side.
",slackpad,adrianlop
2427,2016-11-04 10:47:20,"@slackpad thanks a lot for the help! that's it.
we're using [consul-alerts](https://github.com/AcalephStorage/consul-alerts) for a basic alerting system on top of consul, and it's writing to the KV its own healthcheck info to compare previous data and generate alerts.
I'll try to tweak this tool to reduce intensive KV writing.
",adrianlop,slackpad
2424,2016-10-19 15:33:50,"Hi @sobertooth I think @jippi is right here. Haven't used consulate too much myself, but it looks like the datacenter gets configured for the client itself, not per-call - https://github.com/gmr/consulate/blob/master/consulate/__init__.py#L51.
",slackpad,sobertooth
2424,2016-10-19 15:33:50,"Hi @sobertooth I think @jippi is right here. Haven't used consulate too much myself, but it looks like the datacenter gets configured for the client itself, not per-call - https://github.com/gmr/consulate/blob/master/consulate/__init__.py#L51.
",slackpad,jippi
2423,2016-11-03 20:27:10,"Hi @buro1983 thanks for opening a PR. Closing this in favor of https://github.com/hashicorp/consul/pull/1984, which is similar but allows the TLS verification to be skipped on a per-check basis.
",slackpad,buro1983
2422,2016-10-18 21:44:10,"Hi @Ashald in this case the user needs the ID of a valid token in order to get information about it, so this doesn't expose any information to an anonymous user who doesn't have a given token already. The /v1/acl/list endpoint is protected so anonymous users can't list ACLs and discover new tokens. 

Thanks for taking the time to report this issue, but for security-related matters, we ask that you use our responsible disclosure policy https://hashicorp.com/security.html.
",slackpad,Ashald
2420,2016-11-30 01:31:34,Hi @Crapworks you can use https://www.consul.io/docs/agent/http/agent.html#agent_force_leave or https://www.consul.io/docs/commands/force-leave.html to kick the dead node from the cluster early. That will remove it from the members list and the catalog.,slackpad,Crapworks
2419,2016-11-30 01:29:42,Hi @paccer-cn Consul won't actually sync the services to the other nodes. Each agent has its own set of services and those sync back to the Consul servers. Please see https://www.consul.io/docs/internals/architecture.html and https://www.consul.io/docs/internals/anti-entropy.html for more details.,slackpad,paccer-cn
2417,2016-11-03 19:57:46,"Thanks @moofish32!
",slackpad,moofish32
2415,2016-11-30 01:22:52,"Hi @sobertooth that's correct right now - it will fire the script on the initial query. There's a tool called sifter that works around this - https://github.com/darron/sifter, and we have an open issue #571 that's tracking this.",slackpad,sobertooth
2414,2016-10-27 05:44:23,"Hi @juliangamble not currently, this would be an enhancement.
",slackpad,juliangamble
2410,2016-10-13 15:04:37,"Hi @sampointer sorry for the confusion on that one - added a note to the `consul kv` command about which versions it was added, that was an oversight. We've been working to label all new features with their versions.
",slackpad,sampointer
2409,2016-10-11 17:06:06,"@soumyasmruti that looks like you have a bad command line with something along the lines of `-advertise -join`. Please make sure you are not passing an empty advertise address in to Consul.
",slackpad,soumyasmruti
2409,2016-10-11 17:29:29,"Hi @soumyasmruti I don't think the address is bad, it looks like you have a bad command line for Consul. If you run Consul like this you get a similar error:


",slackpad,soumyasmruti
2407,2016-10-17 20:53:34,"@charliestrawn that's a good point. Consul 0.7.0 was built with Go 1.6.3, so there must be some other issue with Sierra.
",slackpad,charliestrawn
2407,2016-10-17 20:59:28,"@slackpad potentially, I've been running 0.7.0 with Sierra for a while now and not had problems. Just wanted to post for posterity. If I can help out any further let me know. It might help if @nugend posted the output of `go env`
",charliestrawn,nugend
2407,2016-10-17 20:59:28,"@slackpad potentially, I've been running 0.7.0 with Sierra for a while now and not had problems. Just wanted to post for posterity. If I can help out any further let me know. It might help if @nugend posted the output of `go env`
",charliestrawn,slackpad
2407,2016-10-18 21:07:47,"> I don't have go installed. I could get that, but would it be pertinent?

@nugend shouldn't matter - consul is shipped as a static binary and doesn't depend on the Go tools being installed.
",slackpad,nugend
2407,2016-11-08 14:41:34,"Thanks @magiconair and @lowzj. We got Go upgraded to 1.7.3 last night via https://github.com/hashicorp/consul/pull/2281 so that should fix this for the next release.
",slackpad,lowzj
2407,2016-11-08 14:41:34,"Thanks @magiconair and @lowzj. We got Go upgraded to 1.7.3 last night via https://github.com/hashicorp/consul/pull/2281 so that should fix this for the next release.
",slackpad,magiconair
2407,2016-11-08 15:06:44,"@slackpad any ETA for the next release?
",Sandmania,slackpad
2405,2016-11-18 00:46:04,"Hi @stevenLX can you describe your use case a little bit here? This seems like a pretty nuanced use case and may not be worth the complexity, but I'd like to understand more what you are trying to do.
",slackpad,stevenLX
2405,2016-11-18 03:36:52,"Hi @slackpad  
Beacuse of we need to send a lot of http requests for getting  or checking status for a group of service.
This can be a time-consuming operation for applications.
So we need a  batch interface.
",stevenLX,slackpad
2405,2016-11-18 03:38:45,"Hi @stevenLX is this for like a status dashboard? I'm wondering if more of an event feed would make sense for that kind of use case.
",slackpad,stevenLX
2405,2016-11-18 08:11:24,"Hi @slackpad
Not only for dashboard.For example,I write a application need access muti services,  so I need get the service's info (inculde regist info and health status)from consul.At this moment I should call the same http api muti-times, and wait for all responses back. It is a time-consuming.
So, Could I push the batch interface for this kind of case?
",stevenLX,slackpad
2403,2016-10-07 22:40:51,"@slackpad I could sniff the transaction and/or point the test code above to a dummy webserver.  What I have tested:
- Curl with a header _or_ a query parameter _works_ against a v0.7.0 server
- The v0.7.0 API does _not work_ with client config set to use a token against a v0.7.0 server
- The v0.7.0 API does _not work_ with QueryOptions passed with a token to a v0.7.0 server
- The v0.6.4 API using the exact same code above _works_ against a 0.7.0 server

I suspect the header is not being passed by the v0.7.0 API with either the client config or the QueryOptions set.  I will try and get confirmation though by using a dummy http server.
",leprechau,slackpad
2403,2016-10-07 23:47:49,"@leprechau thanks for the repro case. This is super weird as I see the token header going into the `Do()` call for the request in both examples. Will keep tracing this.
",slackpad,leprechau
2403,2016-10-11 00:01:23,"Hi @leprechau I think the root cause of this one is https://github.com/golang/go/issues/4800. With older versions of Go, the HTTP client will drop the headers when it is following redirects. It looks like a fix for this is teed up in master and will go out with the next release of Go, but in the meantime, if you get rid of the slash you won't get the redirect and the headers will display:



Your sample app happened to have the same behavior as Consul because it was querying with a double slash. I think we should make the API client smarter and drop any leading slash in the KV path, since it's not necessary.
",slackpad,leprechau
2403,2016-10-11 02:45:57,"@slackpad Interesting ... that makes sense.   I also agree about enhancing the API client to not hard-code the prefixing slash when making requests.  That was a rabbit hole.
",leprechau,slackpad
2398,2016-11-30 00:45:25,"Hi @ankurgla22 that sounds like a problem with your script. If you are still having this problem, please open an issue an include a link to logs from your agent with debug level set. Thanks!",slackpad,ankurgla22
2393,2016-10-06 15:32:51,"@blalor thanks for opening an issue and sorry for the confusion. We will get this cleaned up!
",slackpad,blalor
2390,2016-10-06 20:22:07,"Hi @JoeOrtiz it looks like that service has `""ServiceAddress"": ""10.20.0.124""` defined. If that's set then it won't do address translation, it will always report that. If you register the service and leave that blank I think it should work.

https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L765-L770
",slackpad,JoeOrtiz
2390,2016-10-09 04:12:36,"Hi @slackpad , this was indeed the problem. I can confirm it now works.

This was due to registrator, we had passing --ip, once this was removed, this works as intended.

Although this causes a problem now with the consul HTTP healthchecks, since consul does a GET on it, since there is no IP for $SERVICE_IP, those health checks will fail. Is there anyway to tell consul to use its own local lan IP, as the lan and wan IP show up properly, but not its service IP, so it can't run it's health check. 

I am a little afraid to enable in registrator the --internal option, but not too sure if this will mean it will register that now as the SERVICE_IP, and then I would lose my wan/lan capabilities.
",JoeOrtiz,slackpad
2388,2016-10-05 16:58:36,"Hi @imroc they are the same since there are no returns in the middle there. It would probably be better to use defer since there's a non-trivial amount of code in between and future maintenance could change the logic. Happy to take a PR for this.
",slackpad,imroc
2387,2016-11-30 00:34:38,Hi @banupriya20 this sounds like it would be better posted to the Consul mailing list.,slackpad,banupriya20
2382,2016-10-20 16:41:28,"Thanks @zaunerc that's a good addition.
",slackpad,zaunerc
2378,2016-10-05 23:14:49,"Hi @stephansnyt, Consul's statsd client currently uses UDP, so if you use `nc -k -u -l 9898` you'll see some telemetry. It looks baked in here, so we'd probably need to plumb another config variable to support TCP - https://github.com/armon/go-metrics/blob/master/statsd.go#L96-L101.
",slackpad,stephansnyt
2375,2016-11-18 00:42:26,"Hi @xychu thanks for the PR. Can you modify `AddService()` to call your new function with an empty string for the address and 0 for the port? This should cut down on the code duplication a tiny bit.
",slackpad,xychu
2375,2016-11-21 11:30:15,@slackpad done. And thanks for your advise.,xychu,slackpad
2374,2016-09-30 08:20:58,"@hehailong5, actually IPs do not change. As mentioned above, every start docker swarm service task, it is new containers, having unique name and hostname. See the logs:



It says `EventMemberLeave: 2f74fbbffdd2 10.100.0.2` and then `EventMemberJoin: 1ec48b592c2f 10.100.0.2` after task is restarted. As far as I understand members are identified by `-node` or if not provided `hostname`. So join shall not fail since new hostname assigned. But as you may see, since swarm landscape didn't change, new container gets same IP as previous one. May it be the source of problem? If it is, then it will hard to have consul as a service under docker swarm mode.
",muradm,hehailong5
2374,2016-10-20 16:32:52,"Hi @muradm `2016/09/30 03:49:53 [WARN] raft: Failed to get previous log: 6340 log not found (last: 6339)` is usually ok because the leader will send a snapshot to get the follower caught up. Does the cluster eventually stabilize or does it get stuck in an endless loop of those?
",slackpad,muradm
2374,2016-10-20 16:37:27,"Hi @slackpad, no it never comes back to normal, cluster needs to be bootstrapped from scratch. I waited an hour or two,  logs continue same as in Log Fragments.
",muradm,slackpad
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,muradm
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,slackpad
2374,2017-01-13 14:24:46,"@galindro no, I could not solve the problem. It could be done with too much effort overhead (creating many many scripts to handle such situations). So I gave up for some reasons:

* Initially consul is not designed to run dynamic environment, which is actually logical, since it is supposed to be reference point for everything else. Thus, trying to fight the design is quite hard. IMHO, just like one won't put database cluster in docker swarm, one should not try putting consul into swarm.
* On the other hand, docker swarm mode is a kind of competition for consul, since it provides service discovery and even load balancing via DNS and VIP addressing. Which is far more than what consul does.
* docker swarm mode service concept does not match (or interfere with concepts in consul), trying to fit docker services into consul service catalog causes other issues.
* If one decides to run consul outside the docker swarm mode cluster, there is a problem that consul cannot reach services within overlay network, which again makes consul more useless.
* etc. etc.

Giving up consul, we are losing basically three things:
* Health checks - docker actually started supporting [HEALTHCHECK in Dockerfile](https://docs.docker.com/engine/reference/builder/#healthcheck)
* KV store - here, one would look for another solution other than KV, at least I could not find reliable alternative that can be used within docker swarm mode. 
* Service catalog - em hm.. :) no alternative as well...

But since docker swarm mode provides so much out of the box, for me it was more reasonable to focus on alternatives for missing parts, rather than fighting design issues and trying to fit consul into docker swarm. And actually it was easier..

Probably it will be possible to run consul more or less reliably with --attachable flag coming in 1.13 of docker. This flag will allow connecting standalone docker containers (i.e. not docker service containers) to overlay networks. I tested it months back on first RCs of 1.13, and it was promising, but 1.13 was very unstable and still not released to repos. ",muradm,galindro
2374,2017-01-13 15:10:40,"@muradm I want to use consul for ceph: https://github.com/ceph/ceph-docker

I'm trying to build a ceph cluster in AWS with docker. As far ceph is running outside swarm (network=host), I'll put consul outside it too with network=host too. Or maybe I could try etcd...

Tks for quick reply

",galindro,muradm
2374,2017-01-13 16:49:37,Nice @slackpad! Whats the ETA for 0.8 launch?,galindro,slackpad
2374,2017-01-13 16:57:26,@galindro Currently shooting for early March.,slackpad,galindro
2374,2017-01-14 01:38:23,"Hi @slackpad, does it mean the recovery policy would change? the peers.json with ips will be abandoned? currently my script is dependent on the ip based peers.json for all the recovery scenarios. hopefully it would still work till then.",hehailong5,slackpad
2374,2017-01-14 11:57:46,@hehailong5 did your script could recover failed scenarios in Docker swarm mode? Could you share it?,galindro,hehailong5
2371,2016-09-29 13:37:48,"@ryanslade you might want to update your code URLs to point to specific commits and not master. Your links may break if anyone changes those files.

Not sure if you know this trick, but if you press your `y` key while viewing source code in GitHub it'll change your URL to the specific commit. `https://github.com/hashicorp/consul/blob/master/api/lock.go#L132` became `https://github.com/hashicorp/consul/blob/d5b7530ec593f1ec2a8f8a7c145bcadafa88b572/api/lock.go#L132`.
",theckman,ryanslade
2371,2016-09-29 13:40:24,"@theckman Thanks for the tip, done.
",ryanslade,theckman
2371,2016-10-06 01:03:28,"Hi @ryanslade thanks for opening an issue. We should definitely document this and I'm not totally sure if we should change the behavior. It seems like we should stop updating the session whenever the leader channel closes, but I'd need to think through if there are any other implications if we change that.
",slackpad,ryanslade
2368,2016-10-06 01:10:43,"Sorry @hehailong5 - I just committed a change that puts the right port numbers into peers.info.
",slackpad,hehailong5
2365,2017-02-11 01:41:40,"@kyhavlov fwiw, `consul lock -http-addr=127.0.0.1:8501` works for me also, with
",wyardley,kyhavlov
2363,2016-09-27 15:17:45,"Hi @gpaggi it's probably not a good idea to increase this by much more as this limit is designed to help keep Raft log entries to a reasonable size. It might be a better approach to have Terraform support compressing the state and/or breaking things up across multiple keys.
",slackpad,gpaggi
2363,2016-09-27 15:35:13,"Hi @slackpad, I was indeed thinking about the effect of big values would have on replication just after I submitted this. I'll open one at TF to check there what can be done.
Since Consul now supports transactions for updating multiple keys, perhaps splitting the state could be the way to go.
",gpaggi,slackpad
2360,2016-09-26 21:44:07,"@sethvargo that failing test is a known flaky one unrelated to this - sorry about that.
",slackpad,sethvargo
2357,2016-09-24 01:08:39,"Hi @strarsis `consul watch` is a separate command that talks to a locally-running Consul agent - it can't be passed in to the same command line as `consul agent`. I took your repro case (thanks for that) and got it working with this change - https://github.com/slackpad/consul-watch-issue/commit/07476dcf25bde78612a2ff88e9197a36a4fbc066.

I'm not well-versed in docker-compose so I just added `--net=host` since you had the API port for the Consul server exposed on the local host already. Hope that helps!
",slackpad,strarsis
2356,2016-09-23 17:30:01,"Hi @godefroi does the command succeed but you see this error in the log? It looks like there's an old check for this error to try to mask it, and we might need to make the string compare case insensitive - https://github.com/hashicorp/consul/commit/bae3c1606c54ee02be65a4d6484513be076a8e7b.
",slackpad,godefroi
2354,2016-09-22 15:39:00,"Hi @sitano thanks for the info in case someone wants to update an older fork to fix this. I'll close this out since this is fixed in 0.7.0.
",slackpad,sitano
2350,2016-09-24 01:13:22,"@mckennajones awesome! I think the `=` matches more of what's there and is clearer when reading documentation.
",slackpad,mckennajones
2348,2016-09-21 04:09:21,"Hi @pszymczyk thanks for opening an issue an PR but I have to agree this is kind of an anti-pattern. There are good tools for pre-vetting config, and depending on where the typo is you might end up in a dangerous state so it's much safer to have Consul bail out when given a bad config. As @daveadams hinted, you should be able to use https://www.consul.io/docs/commands/configtest.html even as part of Chef or Puppet to stop early.
",slackpad,pszymczyk
2348,2016-09-21 04:09:21,"Hi @pszymczyk thanks for opening an issue an PR but I have to agree this is kind of an anti-pattern. There are good tools for pre-vetting config, and depending on where the typo is you might end up in a dangerous state so it's much safer to have Consul bail out when given a bad config. As @daveadams hinted, you should be able to use https://www.consul.io/docs/commands/configtest.html even as part of Chef or Puppet to stop early.
",slackpad,daveadams
2348,2016-09-21 07:12:43,"@daveadams @slackpad thanks for feedback, I will try to implement `consul configtest` before restart Consul process. 
",pszymczyk,slackpad
2348,2016-09-21 07:12:43,"@daveadams @slackpad thanks for feedback, I will try to implement `consul configtest` before restart Consul process. 
",pszymczyk,daveadams
2347,2016-09-21 03:15:37,"Hi @zhaojigang this behavior comes from here:

https://github.com/hashicorp/consul/blob/master/consul/session_ttl.go#L76-L81

TTLs are internally doubled, so only the lower bound is guaranteed by Consul.
",slackpad,zhaojigang
2347,2016-09-27 07:05:43,"Thank you very much!!! @slackpad 
",zhaojigang,slackpad
2342,2016-09-16 01:00:07,"Hi @jvinod this is as designed. Here's a common way this can happen:
1. You do an initial query and are current through index 100.
2. A change is made and you wake up and get 101.
3. While your app is looping around to re-query, two more changes are made.
4. You app re-queries against 101 and immediately wakes up and gets index 103.

Consul doesn't have enough state internally to send you the key contents at index 102 any more, so it just gives you the latest. The only guarantee that Consul makes is that you will get woken up if there's a change, but not that you will get woken up for _each_ change. Hope that helps!
",slackpad,jvinod
2338,2016-09-14 14:13:23,"Hi @sokie which service would get deregistered in that case? It seems unexpected if all services get deregistered.
",slackpad,sokie
2338,2016-10-28 17:00:23,"Hi @sokie Consul will already stop giving any service on a node with a failing node-level check out over DNS. It seems a little strange to actually deregister them because you'd then need to have all of your services know how to re-register themselves after this condition clears. We targeted the `deregister_critical_service_after` at specific services under the assumption that it's registering itself or it's a one-shot kind of thing _and_ that the check is making sure the service is still there and alive. Having node-level checks cause services to be deregistered seems like it will lead to a lot of confusion for operators.
",slackpad,sokie
2335,2016-09-13 15:32:29,"Hi @pszymczyk thanks for the feedback on the RC build! There's a 512 byte limit for UDP responses so that can affect the number of results, especially if you have a long service name. Does that seem like it could be the case here?

If you query by TCP you'll get all of them, and the UDP results are shuffled, so if your app is trying the first entry it will get a different one there if it re-queries.
",slackpad,pszymczyk
2334,2016-09-12 21:15:35,"Hi @Ashald thanks for opening an issue (sorry about the late response on your PR, working through a lot of things in parallel here).

We ended up removing all the token logging here - https://github.com/hashicorp/consul/commit/e83172792386fd473dd3220c7e6ea38fe18936b0#diff-c7c6050c04c9988e6d2824b655764d9c, so I think this issue should be cleared up in Consul 0.7. What I'd like to do for tokens eventually is log a token accessor, which allows operators to query info about the token without getting access to the token itself.
",slackpad,Ashald
2332,2016-09-12 17:18:35,"Hi @sixtus thanks for the report - this isn't something we've seen before. Based on what you've provided so far I'd guess that perhaps you are having your session get expired due to the flaky network and possibly the application holding the lock isn't properly monitoring and realizing that the lock is lost. Are you using `consul lock` or integrating directly with Consul's API?
",slackpad,sixtus
2331,2016-09-08 08:28:10,"@junneyang -- not really sure this is a github issue. A couple of good resources: 
- [SE Radio Podcast](http://www.se-radio.net/2016/08/se-radio-episode-264-james-phillips-on-service-discovery/)
- [Consul Doc](https://www.consul.io/intro/vs/zookeeper.html)
- [second google hit](https://technologyconversations.com/2015/09/08/service-discovery-zookeeper-vs-etcd-vs-consul/)
",moofish32,junneyang
2331,2016-09-08 08:32:53,"@moofish32    thanks
",junneyang,moofish32
2330,2016-10-14 20:33:15,"@buro1983 -- a month later, but I assume you have figured out the issues. I suspect it was pretty difficult to talk to a server bound to LO, but perhaps you had some other magic on the box. Ready to close this?
",moofish32,buro1983
2330,2016-12-02 14:45:41,"@buro1983 you may want to give the latest code in `master` a twirl and let us know if that would have helped out your situation any.  There is now syntax for selecting the ""correct"" IP address, such as getting the first ""usable"" IP address on an interface, or any other manner of network craziness is likely possible now as a template evaluated address parameter can be passed to Consul addresses (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



Very few people should need to do anything as obscene as shown in the last example, but the functionality is there should you need it.

With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,buro1983
2328,2016-10-28 16:54:05,"Hi @akadoya this is the same thing that was happening in #1228 and should now be fixed by #2444.
",slackpad,akadoya
2327,2016-09-06 14:51:01,"Hi @MagicMicky sorry for the confusion. I added a note in https://github.com/hashicorp/consul/commit/0a34741d7266af34eed36048d1a8e8880a7b17a1 about the 0.7 version requirements.
",slackpad,MagicMicky
2325,2016-09-05 17:42:16,"Hi @janisz thanks for opening a PR. I've got one here https://github.com/hashicorp/consul/pull/2281 that had to deal with a few library changes related to TLS that came along with 1.7. Also, there's still a remaining issue with the unit tests that I haven't had a chance to track down yet, so we aren't quite ready to upgrade until that's done.
",slackpad,janisz
2324,2016-09-21 00:09:04,"Hi @lucaswxp this is kind of a weird one, but the quotes are getting removed by the invocation of `consul exec`. This works, but is awkward:

`consul exec ""bash -lc 'cd /tmp && ls'""`
",slackpad,lucaswxp
2323,2016-09-02 16:21:49,"Hi @sitano you can register the check with the initial state you'd like it to have at startup - https://github.com/hashicorp/consul/pull/859.
",slackpad,sitano
2317,2016-09-01 07:03:59,"Hi @illeatyourheart thanks for opening a PR. Unfortunately, I don't think this will work correctly if the user does a stale read because only the leader has the correct information. There's not a great way to solve that issue unless all the session updates go through Raft, but that would be a big performance hit just for this.

Usually the thing that creates the session renews it based on the time since it was created at some conservative TTL (like 1/2 the given TTL). What kind of use case do you have where you need the time?
",slackpad,illeatyourheart
2317,2016-09-01 15:25:52,"Greetings, @slackpad.
I had thoughts that this system might result in problems with multi-node configuration on non-leader nodes.
As of now I'm working on a coreos/flannel change that would allow to use consul as one of the variants alongside etcd. From what I understand, flannel depends on TTL behaving like in etcd, as in reflecting the real time of the key's life.
The key's TTL in flannel is set at 24 hours, and with that it's presumed that even when flannel is turned off it'll be possible to restore the configuration if that time didn't run out.
",illeatyourheart,slackpad
2314,2016-09-20 23:45:48,"Hi @janisz and @kshep, some health checks can be expensive, and multiple services might get registered all in one go, such as with a `consul restart`, so we always stagger them to try to randomize their phase. You can set the initial health state, so you can default healthy or unhealthy until the first check. Having it not show up until it has run the first check is an interesting idea. It's practically the same as starting it unhealthy, but I could see how you might care about that if you have monitoring set up.
",slackpad,janisz
2314,2016-09-20 23:45:48,"Hi @janisz and @kshep, some health checks can be expensive, and multiple services might get registered all in one go, such as with a `consul restart`, so we always stagger them to try to randomize their phase. You can set the initial health state, so you can default healthy or unhealthy until the first check. Having it not show up until it has run the first check is an interesting idea. It's practically the same as starting it unhealthy, but I could see how you might care about that if you have monitoring set up.
",slackpad,kshep
2309,2016-09-01 06:57:00,"Hi @Amit-PivotalLabs something like this seems pretty reasonable. Consul 0.7 should ship shortly and I'm trying to avoid new stuff at this point, but this should be able to make it into a point release following that one.
",slackpad,Amit-PivotalLabs
2309,2016-09-01 20:25:04,"Thanks! We'll probably submit a PR soon.

On Wed, Aug 31, 2016 at 11:57 PM, James Phillips notifications@github.com
wrote:

> Hi @Amit-PivotalLabs https://github.com/Amit-PivotalLabs something like
> this seems pretty reasonable. Consul 0.7 should ship shortly and I'm trying
> to avoid new stuff at this point, but this should be able to make it into a
> point release following that one.
> 
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/hashicorp/consul/issues/2309#issuecomment-243992593,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/AC9t3pVLQFWbSyWiEwH4_bcOrA6kzVYbks5qlndPgaJpZM4JunLu
> .
",Amit-PivotalLabs,Amit-PivotalLabs
2299,2016-08-23 16:29:25,"Hi @far-blue - what uses were you thinking of? We probably should just have Consul tag itself automatically for most things (leader, follower seems like a good one for servers), any other use cases you had in mind?
",slackpad,far-blue
2297,2016-08-23 22:05:36,"Hi @rom-stratoscale do you have any clients that are connecting to the http API and could possibly be leaking connections? This issue looks related and has some diagnostic steps to try - https://github.com/hashicorp/consul/issues/688#issuecomment-164824007.
",slackpad,rom-stratoscale
2297,2016-08-24 09:33:03,"@slackpad it seems most connection don't show a remote port in the lsof. They just read:
consul  8566 root 1020u     sock       0,6      0t0 255716323 protocol: TCPv6
",arie-stratoscale,slackpad
2295,2016-09-16 23:01:15,"Hi @favoorr thanks for the PR. We fixed this by setting the default to 127.0.0.1 in https://github.com/hashicorp/consul/issues/1878, so people no longer need to give the bind address for dev mode.
",slackpad,favoorr
2292,2016-09-12 17:13:03,"Here's the thread I think @sitano was referencing:

https://groups.google.com/forum/#!searchin/consul-tool/armon$20latency%7Csort:relevance/consul-tool/y1bFnMntF7M/cpM6Pw9BEAAJ

That has the upper limit of what's considered a LAN. We don't have native multi-DC load balancing, though you can get multi-DC failover via prepared queries - https://www.consul.io/docs/agent/http/query.html. Some folks use something like consul-template to configure a load balancer that feeds traffic across multiple DCs.

This has the best concise summary of LAN vs. WAN gossip - https://www.consul.io/docs/internals/architecture.html.
",slackpad,sitano
2273,2016-08-16 15:33:19,"Also @pradeepnss you may want to take a look at #2275 that may provide what you are looking for without needing to access the tagged addresses directly. 
",slackpad,pradeepnss
2263,2016-09-02 05:16:33,"@sweeneyb thanks for the PR!
",slackpad,sweeneyb
2254,2016-08-09 15:13:39,"Hi @dmitrybelyakov the instructions were out of date and have now been updated under - https://github.com/hashicorp/consul/pull/2104.
",slackpad,dmitrybelyakov
2248,2016-11-10 01:47:18,"Hi @lucasalcantara this is still an issue. We won't merge the change until the next major release since it's potentially breaking, but we definitely would like to fix this.
",slackpad,lucasalcantara
2248,2016-11-10 01:52:39,"@slackpad I would like to take a Look. Can you assign the issue to me? 
",lucasalcantara,slackpad
2245,2016-08-05 06:30:22,"@Kenovo you mean like https://github.com/containous/traefik - just minus the consul-template? :) 
",jippi,Kenovo
2245,2016-09-09 23:32:42,"Hi @Kenovo this is probably a better question for the mailing list. Lots of people configure HA load balancing setups with Consul + consul-template + some load balancer. If you have agents you can use things like https://github.com/eBay/fabio as well.
",slackpad,Kenovo
2242,2016-08-12 23:45:17,"Hi @Akagi201 thanks for the PR! This got cleaned up in https://github.com/hashicorp/consul/commit/561f9bb268bb56e3f05d3c4783fbd5e6a67e8035 which made a similar change.
",slackpad,Akagi201
2239,2016-08-18 01:13:48,"Hi @scarby this one is odd. Does that node show up in `consul members` output? If so you can probably do a `consul force-leave` to kick it, which should clean up these registrations as well.
",slackpad,scarby
2236,2016-08-18 01:14:34,"Hi @kunitake thanks for the PR. I'll review this right after we cut the final 0.7 release.
",slackpad,kunitake
2232,2016-08-18 00:55:37,"Hi @sandwwraith thanks for the PR - I'll review this once we cut the final 0.7 release.
",slackpad,sandwwraith
2231,2016-08-18 00:49:56,"Hi @luckyraul you are correct I don't think this is supported without a client cert. I'm not sure the best way to fix this, will need to think it through a bit. The only workaround I can think of at the moment would be to put a proxy webserver in front that will present a cert to Consul.
",slackpad,luckyraul
2230,2016-08-11 01:48:37,"Hi @akssagar basic auth isn't supported. Please see https://groups.google.com/forum/#!topic/consul-tool/_P7kI3-bFqs for some different options. Hope that helps!
",slackpad,akssagar
2227,2016-10-26 16:37:41,"@slackpad @joshuaspence I can tackle this. What should the format be for adding the timezone? 

Currently a timestamp in the log looks like this:
2016/10/26 09:28:13 [INFO]

Should the timezone simply follow the time?
2016/10/26 09:28:13 PST [INFO] for example
",mckennajones,joshuaspence
2227,2016-10-30 20:47:48,"@rom-stratoscale I agree, standards all always nice. However, the Log package doesn't support that standard for some reason. There is an option to use UTC time instead but that's about it. 
",mckennajones,rom-stratoscale
2224,2016-07-29 17:53:26,"Hi @brianshumate this is a great idea and is definitely an FAQ :-) There are some other ports we use, so it would be good to clarify this FAQ as ""between Consul agents"" and link to [docs/agent/options.html#ports](https://www.consul.io/docs/agent/options.html#ports) or replicate the full list here.
",slackpad,brianshumate
2224,2016-07-29 18:34:28,"Thanks for the feedback @slackpad!

I think the FAQ should probably just point the reader to the ports as already described at [Ports Used](https://www.consul.io/docs/agent/options.html#ports) instead. It was a bit tough to discover and maybe being linked from the FAQ page will help with visibility.
",brianshumate,slackpad
2223,2016-08-18 00:35:56,"Hi @WoZ the automatic ID creation is an intentional part of the API, though that name behavior is confusing. We should make this a little more flexible.

You can use https://www.consul.io/docs/agent/http/agent.html#agent_check_register in the meantime to add checks to services with custom IDs and names.
",slackpad,WoZ
2223,2017-02-13 10:18:30,"Hi @slackpad 

The behavior is the same using the agent API and definitely doesn't match the documentation. Adding a service via v1/agent/service/register:


Ends up being registered as:

![consul](https://cloud.githubusercontent.com/assets/13365164/22879315/c19960c8-f1dd-11e6-9e41-8a5438be78ec.png)

Version tested: 0.7.3
",user31459,slackpad
2219,2016-08-13 00:20:41,"Hi @maxvt thanks for the PR! I've done a rebase under #2271 and make a couple tweaks to the unit test.
",slackpad,maxvt
2217,2016-12-02 14:55:29,"@mfischer-zd , while this doesn't address the binding to multiple IP addresses portion of your issue, there is code in `master` now that will let you bind to an IP on a named interface:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,mfischer-zd
2217,2016-12-02 20:42:45,"That's great news, @sean- .  Let me know how I can help finish the work.",mfischer-zd,sean-
2216,2016-07-29 12:41:25,"@highlyunavailable yes, it's the same issue.
",WoZ,highlyunavailable
2213,2016-08-11 01:35:37,"Hi @nschoe that's correct - the quorum requirements change as servers are added and removed.
",slackpad,nschoe
2210,2016-08-11 11:24:54,"@jhmartin should this issue not be https://github.com/hashicorp/docker-consul ?
",swade1987,jhmartin
2210,2016-08-11 14:40:10,"@swade1987 The docker image does not document nor transform CONSUL_RPC_ADDR -- docker generically passes through the environment to Consul.  I believe that makes it a Consul doc issue rather than something related to the Docker image. 

I referenced the Docker image to describe in what environment Consul was running.  
",jhmartin,swade1987
2203,2016-07-25 23:31:25,"Hi @FrankHassanabad thanks for the detailed report and the soak test! Do you mind running again with master just as a quick cross-check? Thanks.
",slackpad,FrankHassanabad
2203,2016-07-26 20:17:30,"@slackpad Thank you for the quick response! Quick question regarding release:

This issue represents a significant bug in our deployed software today. Do you guys have any intention of releasing a patch (0.6.5) or an ETA on the next minor release (0.7.0)? If not, we will need to produce and deploy an in-house build with the bolt db upgrade. Thanks!
",autoric,slackpad
2203,2016-07-26 20:23:46,"Hi @autoric we are working on getting a 0.7.0 release candidate out over the next few weeks so this likely won't go out in a patch. If you can build locally that's probably the best option in the very near term.
",slackpad,autoric
2203,2016-07-27 15:09:57,"Hey @slackpad, I code reviewed what you checked in and then did a build of `master` on `windows 2000 R2` using `TDM-GCC` tool chain, and ran gatling against it with the boltdb upgrade.  `raft.db` was able to expand beyond `65 MB` to `256 MB` without any issues.

Test run was from @Tzinov15 here:
[SlamKeyValue](https://github.com/Tzinov15/GatlingConsul/wiki/Running-Gatling)

Here are the metrics from SlamKeyValue if you're curious (everything is ms and OK means REST response 200, KO means non REST 200 was returned, and a `-` means no KO):



The other 2 stress tests look to be passing as well.

Only artifact from upgrading boltdb I noticed was that `raft.db.lock` is a new file which shows up when boltdb opens the memory map.  Once it releases the memory map, the `raft.db.lock` file goes away.
",FrankHassanabad,slackpad
2203,2016-07-27 15:25:01,"@FrankHassanabad thank you for the follow up and I super appreciate the extra stress testing!
",slackpad,FrankHassanabad
2202,2016-07-23 22:02:56,"Hi @sunmoonone can you elaborate on your use case for the second item? I'm not sure I fully understand that one.
",slackpad,sunmoonone
2200,2016-07-21 15:57:08,"@slackpad so we did some thorough network related testing and were able to confirm that all nodes are able to communicate over UDP on port 8301 (we are using default ports). We made sure to investigate those avenues before opening up an issue. 

The one thing that did show up was that the consul servers did not seem to be probing each other (via UDP on 8301). This behavior differed from our other clusters in that, while not that often, that traffic was being sent. While that is not definitive (those packets might be tried at some point either before or after we were monitoring), no UDP send or receives showed up between the consul servers themselves (monitoring done via tcpdump). 
",carkmorwin,slackpad
2200,2016-07-26 15:13:23,"@slackpad thanks for the info, will look into this further. 
",carkmorwin,slackpad
2200,2016-10-31 22:37:57,"@SunSparc Do not have a solution yet. The hope was that Consul 0.7.x would fix things but I have not gotten around to that rollout yet. I did recently notice a configuration error on our end where all nodes are initially connecting to and querying a single consul server for dns, but I don't have any traffic numbers around that. All instances seem to be under very little load, so yeah still confused. Again, I'm hopeful consul 0.7.x fixes/exposes the issue, or that our eventual configuration update to use all nodes in our cluster will cause these errors to go away. 
",carkmorwin,SunSparc
2198,2016-07-20 20:30:21,"Hi @vikasmb that's no longer the case after Consul 0.6.0. We build the UI contents into the Consul binary so `-ui` is all you need. We support the old method with `-ui-dir` for backward compatibility and because some people tweak the UI locally for various things. Hope that helps!
",slackpad,vikasmb
2194,2016-07-23 22:11:16,"Hi @yeyincai can you provide any more details about what's going on? Is your service down and Consul's health checking causing many TCP sockets to accumulate in TIME_WAIT, or is your service working properly and there's something causing Consul to stop functioning? Thanks!
",slackpad,yeyincai
2189,2016-07-21 12:07:56,"@hehailong5 you mean, whether it can serve TXT (which would be custom) and AAAA resource records for a node? Only AAAA is supported at the moment, and it does not support custom resource-records. As per [dns.go#L386-L390](https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L386-L390). Also related: https://github.com/hashicorp/consul/issues/1470
",kwilczynski,hehailong5
2189,2016-10-26 21:49:38,"Closing based on @kwilczynski's response.
",slackpad,kwilczynski
2188,2016-07-18 18:21:46,"Hi @maier noted a few small things in comments but otherwise looks good. We'd need to update the vendored go-metrics (I can do that after pull if you'd like) as well as the documentation (it's in the same repo here under website).
",slackpad,maier
2188,2016-07-18 20:28:24,"@slackpad  I haven't used godep before and it isn't cooperating with me. I don't want to break anything so, I'll leave that one to you (if you don't mind). I did update the documentation, I believe I added the configuration setting information in the right location.
",maier,slackpad
2186,2016-07-18 14:37:05,"Hi @Kenovo the `translate_wan_addrs` setting needs to be set in the _remote_ datacenter for this feature to work - that's where the decision is made.
",slackpad,Kenovo
2185,2016-07-18 14:10:17,"Hi @richard-hulm thanks for the PR! One small comment and then I think we are good to merge this.
",slackpad,richard-hulm
2185,2016-07-19 09:05:38,"@slackpad Updated with that change, cheers.
",richard-hulm,slackpad
2185,2016-07-19 22:15:55,"Thanks, @richard-hulm!
",msabramo,richard-hulm
2184,2016-07-17 05:24:55,"Hi @kbhute-ibm we don't recommend building with that old version of Go (there have been several vulnerabilities fixed since then) nor this version of Consul as it's very much out of date. Here's a Dockerfile with a recipe for building this old version of Consul with the latest version of Go:



If you save this as `Dockerfile` in a directory and run `docker build .` you should see:



You can use Docker volumes to get the artifact out of the container, or just adapt this recipe to build locally. The key is restoring the dependencies using godep - the current HEAD of many of these is incompatible with the older Consul version. Hope that helps!
",slackpad,kbhute-ibm
2181,2016-07-12 22:28:35,"Hi @Kenovo generally you run the local agent on each machine and have your applications talk to their local agent (localhost:8500). Consul will take care of forwarding requests up to the servers for you behind the scenes. This way, the rest api is coupled to the same failure domain as the node running the agent, and with multiple Consul servers you won't have a SPOF. If you do happen to need to make requests against a server you can choose any server. It will forward to the leader automatically if needed. Hope that helps!
",slackpad,Kenovo
2180,2016-07-12 20:27:18,"Hi @quulah indeed - this is a duplicate. I think we can add a column to `consul members` for this. Thanks for opening an issue. @
",slackpad,quulah
2179,2016-11-18 00:08:33,"@sean- any thoughts on this one? I don't fully understand what the difference is here.
",slackpad,sean-
2177,2016-07-14 06:53:43,"Hi @hehailong5 can you provide some more detail about your request? There's a known issue where some of the agent endpoints don't properly report JSON errors (200 is returned but no update takes place) so that's the most likely issue. That's similar to https://github.com/hashicorp/consul/issues/1188.
",slackpad,hehailong5
2176,2016-07-14 06:54:51,"Hi @akbarahmed you are correct - that's an error. Appreciate the offer for a PR!
",slackpad,akbarahmed
2176,2016-07-14 20:38:44,"@slackpad I'll work on submitting the PR before Sunday. Knee deep in some complicated code...so I'll get this done when I need a breather.

BTW, thanks for releasing Consul. We're loving it.
",akbarahmed,slackpad
2175,2016-07-10 20:26:20,"@armon this looks great! One tiny comment and it would be good to add a unit test for this :-)
",slackpad,armon
2174,2016-07-23 22:07:26,"Hi @motty-stratoscale thanks for the bug report! We reworked this logic after the 0.6.4 release - any chance you can give things a try with a build from master?
",slackpad,motty-stratoscale
2173,2016-07-12 22:25:26,"Hi @ofbizbrazil, @Kenovo is right that Consul is designed around running an agent on every node and registering the services on a given node with the local agent. There's a layer of health check that the Consul agent's do through the gossip protocol, so if the agent fails it will take its services out of service discovery (such as via DNS). Also, the agent use the cluster's gossip mechanism in order to locate the Consul servers, manage connections to them, and deal with server failures for you. If you don't run local agents then you'd have to deal with all that in your application which isn't ideal. It's technically possible to use the Catalog API to do everything manually without an agent, but that's not taking advantage of a lot that Consul offers. Hope that helps!
",slackpad,Kenovo
2173,2016-07-12 22:25:26,"Hi @ofbizbrazil, @Kenovo is right that Consul is designed around running an agent on every node and registering the services on a given node with the local agent. There's a layer of health check that the Consul agent's do through the gossip protocol, so if the agent fails it will take its services out of service discovery (such as via DNS). Also, the agent use the cluster's gossip mechanism in order to locate the Consul servers, manage connections to them, and deal with server failures for you. If you don't run local agents then you'd have to deal with all that in your application which isn't ideal. It's technically possible to use the Catalog API to do everything manually without an agent, but that's not taking advantage of a lot that Consul offers. Hope that helps!
",slackpad,ofbizbrazil
2173,2017-01-05 12:29:36,hi @slackpad can you share me how to use Catalog API to register a service without running an agent,bhargavchukka234,slackpad
2173,2017-02-08 03:24:10,Hi @bhargavchukka234 you'd point your application at the Consul servers and interact with https://www.consul.io/docs/agent/http/catalog.html directly.,slackpad,bhargavchukka234
2172,2016-07-07 18:33:52,"Hi @zankich did the IP addresses of the servers change as well, or just the node name?
",slackpad,zankich
2172,2016-07-07 18:42:02,"@slackpad only the node names, the ip addresses stayed the same.
",zankich,slackpad
2172,2016-07-07 23:04:03,"@slackpad we would like to change our orchestration to detect whether the cluster is scaling down vs. being rolled, and either leave or pull the plug accordingly.  Right now, we can't change that, and it will always leave.

We want to consider the following option:
1. Tear down the existing cluster (each node doing a ""leave"") -- we will lose all data with this, which is okay.
2. Bring up a brand new cluster with new names, but at the same old IPs.
3. Somehow make sure all clients can start talking to the new cluster without having to roll all clients.

We don't have control over the teardown logic, but we do have control over the startup logic.  We're concerned that when all the nodes leave, the clients will forget about them, and then when the nodes come back up, the servers (having lost all data) won't know about clients, and the clients have no reason to remember the servers because they've received the leave announcements.  Is there a way on startup for the new servers to reannounce themselves to the clients, assuming we could tell them a list of client IPs?  If so, would we need to know all client IPs or just some, and then rely on Serf to propogate the presence of the new servers to the rest of the clients?
",Amit-PivotalLabs,slackpad
2172,2016-07-08 18:07:43,"Thanks @slackpad, good to know we have that option.  One more question, let me know if you'd rather I start a different issue or ask on the mailing list instead, but if I have access to a node's raft.db, is there any way to determine what its name was before being shutdown?  The scenario I'm imagining:
- 3 node running cluster, under one naming convention
- one node leaves, stops, disk is detached, new VM is created, old disk re-attached, and something on the new VM deduces what the node's name was based on what's in raft.db
- the consul server is started on the recreated node, being fed its old node name.

Would there be a way to find out what the node name was for the VM I'm on?  Would probably need to be able to do this without the Consul server running, since by then the server needs to have a node name given.  And I believe this rules out obvious things like running `consul members` or something like that.
",Amit-PivotalLabs,slackpad
2172,2016-07-11 22:35:34,"Hi @Amit-PivotalLabs this one is a little tricky because it's not really in the Raft log or any single place in a super easy form. The only thing I could come up with would be to parse <data-dir>/serf/local.snapshot and see what node name is associated with that machine's IP address. This is basically some state the Serf layer holds so it can come up more quickly, so it will be available even if Consul isn't running. Here's how that file looks:



It's a bunch of single lines, so should be pretty easy to grep | awk to pull out the info. If I can come up with something cleaner I'll report back.
",slackpad,Amit-PivotalLabs
2172,2016-07-12 01:37:52,"Thanks @slackpad!

We'll have a think about using that, but we have a workaround if there are any issues with it.  As usual, thanks for all the help.
",Amit-PivotalLabs,slackpad
2172,2016-08-08 08:09:56,"@slackpad do you have any insight on what's happening here? Can we rename a server while keeping the same ip address?
",iverberk,slackpad
2171,2016-08-22 15:20:13,"Hi @pradeepnss this won't be in the 0.7 release but should make it into one of the following releases.
",slackpad,pradeepnss
2169,2016-08-11 01:24:56,"Hi @sakshigeminisys we don't recommend a single node cluster, as even replacing the server will cause an outage. You are recovering correctly, though, by putting the new server into the peers.json. There are references in the Raft log to the configuration with the old IP, and that's what's causing the trouble here. We've got a fix for this coming in 0.7.0 which will make it respect the peers.json's configuration as final. That said, we hope you run at least 3 servers for any production situation :-)
",slackpad,sakshigeminisys
2167,2016-07-06 17:15:38,"Hi @misham it looks like you are using the ACL language as part of the service definition in your agent config which isn't possible. ACLs are managed using the [ACL endpoint](https://www.consul.io/docs/agent/http/acl.html), and the policies in the guide you referenced go into the `Rules` field when creating or updating tokens.
",slackpad,misham
2166,2016-07-05 19:08:13,"Hi @EugenMayer this code path looks identical to the others. Is it possible that `fpm55` is a node-level check, not associated with any service?
",slackpad,EugenMayer
2166,2016-07-05 19:15:46,"@slackpad how would i check this for sure - not wanting to confuse you. What i do to register this service is



And then i restart consul to pick up the service. The node does not have any checks. You should even see this issue in the node-list:

https://goo.gl/vj7Fyf

As you see, i can see the services when selecting the node. As you see, since the UI has yet no token, you see all nodes have 0 services ( on the left side ) listing the services looks like this https://goo.gl/ixSxej

It should be pretty easy to reproduce and you see this issue gets visible from different angles.
",EugenMayer,slackpad
2164,2016-07-05 15:43:52,"Hi @ajays20078 there are some background processes like network coordinates doing writes that will cause these to increment slowly over time (increasing by a few per minute since the updates are batched). If the index is increasing very rapidly that can often be caused by a health check where the output changes every time (like requesting a page with a time stamp) - those should be avoided if possible. How rapidly are the indexes counting up for you?
",slackpad,ajays20078
2154,2016-06-30 15:14:42,"Hi @JensRantil have you looked at the [`consul lock`](https://www.consul.io/docs/commands/lock.html) command? If I understand your use case correctly I think it does exactly what you are looking for :-)

`consul lock -n=<concurrency> /some/lock/prefix yourscript.sh`

This will run up to `n` at any given time and will simply execute the command and then exit.
",slackpad,JensRantil
2154,2016-06-30 15:54:09,"@slackpad Slackpad. Rereading the documentation I now see that the `consul lock` command doesn't restart a command! ðŸ‘  Closing this!
",JensRantil,slackpad
2153,2016-07-14 06:56:56,"Hi @dnblankedelman things should work fine with a newer box such as Ubuntu. Would you like to PR this? Thanks!
",slackpad,dnblankedelman
2153,2016-11-21 19:00:20,"Hi @dnblankedelman,

I made some improvements to the demo's `Vagrantfile` in #2523 and you can now specify any Vagrant box you'd prefer to use so that you can specify a box that supports your preferred provider.

With my improvement, you can do the following:



and the demo will use Ubuntu 16.04 (Xenial) instead of Debian. This is all documented as part of the [README](https://github.com/hashicorp/consul/blob/master/demo/vagrant-cluster/README.md) now, too.

That said, the official Ubuntu Vagrant boxes are built only with VirtualBox support as well. So, provided you have a box in mind that you know is built for the VMware provider, you should be able to use the same syntax as above to specify that box name, and use the demo with VMware instead.

Hope this helps!
",brianshumate,dnblankedelman
2153,2017-02-23 18:06:08,"(just seeing this now). @brianshumate Nice! Thanks for doing this work, it will be very helpful.",dnblankedelman,brianshumate
2153,2017-02-23 21:39:26,"@dnblankedelman No problem! I think the [Bento boxes](https://github.com/chef/bento) have both VirtualBox and Vagrant provider support and their Ubuntu boxes are generally more compatible with Vagrant than are the ones under the *ubuntu* namespace, just as an aside.",brianshumate,dnblankedelman
2152,2016-06-29 18:39:24,"Hi @Oloremo you are correct that the protocol version thing is a little confusing but if you are using 0.6.4 everywhere then it's definitely using the TCP fallback ping, there's no debug logging around those, unfortunately. 

The most likely cause for outages like this is when low end cloud instances (t2.micro and similar) get overloaded and experience periods lasting tens of seconds with heavy packet loss. We've got some [changes teed up in master](https://github.com/hashicorp/consul/pull/2101) designed to combat this by preventing one bad node from being able to mark a bunch of others as failed. This should be shipping soon in 0.7. We've also got some work in progress on a retry under the hood when servicing DNS requests - https://github.com/hashicorp/consul/pull/2002. Hopefully these changes can help make things more robust for you.
",slackpad,Oloremo
2152,2016-06-29 22:07:23,"@slackpad Thanks you for a quick reply.
I really glad to hear what some work is done towards this issues, but about logging, there is TCP ping log here: https://github.com/hashicorp/consul/blob/v0.6.4/vendor/github.com/hashicorp/memberlist/state.go#L292 and I wonder why I can see it in my logs
",Oloremo,slackpad
2152,2016-06-29 22:36:46,"@Oloremo I just meant that there's no debug logging for that when it sends the ping :-) If it sends the ping but ends up hearing back over UDP from the indirect pings it won't print that final message, and the log message you linked should only happen if there's a socket error. If you can run a local build you could probably supplement with some extra logging or telemetry to confirm this.
",slackpad,Oloremo
2152,2016-07-01 12:32:47,"@slackpad I think this is the same as https://github.com/hashicorp/consul/issues/916 right?

Did you see my last comment on this topic? 
",rgardam,slackpad
2151,2016-06-29 18:41:34,"Hi @tpotega thanks for the PR. I think this is a good feature to add, though by default it seems a little dangerous since if you are selecting for a particular tag you don't want to just pick up any tag if the match didn't work out. I think if we add a boolean `RemoveEmptyTags` to the template definition that defaults to `false` then this would be good to go.
",slackpad,tpotega
2151,2016-06-29 20:22:11,"@slackpad - you're right, it all depends on the use case. Gave the `RemoveEmptyTags` a try - with just the basic test in place.
",tpotega,slackpad
2150,2016-09-29 19:06:16,"Hi @astrostl we are working on a new shapshot/restore API right now and should have some more details soon; it will make DR much easier. There are improvements to make still, but we also updated https://www.consul.io/docs/guides/outage.html with information on how to recover from multiple server outages as part of the 0.7 release. Once we have the new API we will update this with more detailed DR info with a totally new cluster + a snapshot.

UPDATE: Snapshots landed here - https://github.com/hashicorp/consul/pull/2396.",slackpad,astrostl
2148,2016-07-06 14:58:54,"Hi @rboyer sorry for the delay - working through a review backlog but this should make it into the next release for sure - looks like a good change.
",slackpad,rboyer
2147,2016-06-28 03:17:35,"Hi @wenhx8 you should use the [Agent API](https://www.consul.io/docs/agent/http/agent.html#agent_service_register), not the Catalog API to register services. [This thread](https://github.com/hashicorp/consul/issues/1188#issuecomment-185977469) has a little more background info on why it's getting deregistered. Hope that helps!
",slackpad,wenhx8
2146,2016-06-28 02:56:09,"Hi @cohenaj194 please don't double post here and to the list - it creates noise because folks often monitor both.

You shouldn't need the event as part of this. The way watches work is that they will get invoked when something changes and pass JSON into your handler script, so you'd need to parse that to make sure it affected your container and you'd have to implement logic like looking for 5 failures down at that level. The registration would be something like this:



Whenever _any_ check goes critical it will call your watch handler and pass in a body that looks like this - https://www.consul.io/docs/agent/http/health.html#health_state. Your script would parse that and decide what to do (look for the check id, persist some state about how many times it has failed, restart the container, etc.). Hope that helps!
",slackpad,cohenaj194
2145,2016-06-27 16:00:51,"HI @EvertMDC we are close to what's needed to support this via https://github.com/hashicorp/consul/pull/2028, but I think we'd need to add support for something like `copy-tree` and `move-tree` operations via K/V transactions, then the UI would be simple and reliable. We've had a couple requests for these operations from other folks as well.
",slackpad,EvertMDC
2145,2016-06-28 06:56:19,"Hello @slackpad . That's great. I actually didn't find it because I searched on 'ui'.
I went through the code quickly and it seemed like a lot of work already, thank you.

Support for something like copy-tree and move-tree would indeed be interesting for a lot of people in my opinion. It would allow to easily switch between two configurations or test some settings while making a sort of local backup of the current state.
",EvertMDC,slackpad
2143,2016-06-23 15:20:16,"Hi @micahhausler this looks like it might be a typo - the failing case uses ""sukid"" and the passing case uses ""skuid"" :-)
",slackpad,micahhausler
2142,2016-06-23 17:45:58,"Hi @clintonm9 this error is very unusual:

`Jun 22 23:14:21 srv-dev-01-eastus-consul-03 consul: 2016/06/22 23:14:21 [WARN] raft: Remote peer 127.0.0.1:8300 does not have local node 10.0.5.6:8300 as a peer`

It looks like one of the servers is publishing a non-routable address which is causing problems. Is it possible that Consul-01 is coming up with a different set of interfaces? It would be interesting to see Consul's first few logs after the restart which should show which addresses it is advertising to other nodes.
",slackpad,clintonm9
2142,2016-06-23 18:28:20,"@slackpad thanks for the feedback.

Here is the log:



what I noticed is after consul boots, eto0 comes up:



Thoughts on how to make consul wait to start?
",clintonm9,slackpad
2141,2016-08-11 01:10:18,"Hi @rboyer thanks for the PR! This is a common use case so I think we want something like this. Once we get 0.7.0 out I'll give this some cycles.
",slackpad,rboyer
2139,2016-08-11 01:09:05,"Hi @byrnedo can you please double-check the final configuration under /v1/agent/self to make sure the `OnlyPassing` configuration is as you expect? Haven't seen this reported before.
",slackpad,byrnedo
2139,2016-08-11 07:36:05,"Hi @slackpad, you can close this, I was being stupid and not querying the services correctly. Sorry for the trouble.
",byrnedo,slackpad
2138,2016-06-23 02:08:48,"As of Vault 0.6.0, it also registers active.vault.service.consul name that you can use to advertise and always point to the active instance and standby.vault.service.consul that points to the standby instances in addition to the vault.service.consul that has all of them together  @dbresson 
",mterron,dbresson
2138,2016-06-23 05:33:07,"@dbresson Thanks for the report.  This is actually an issue that belongs with Vault, not Consul, but I'm happy to resolve the issue here.  Could you let us know what version of Vault you're using?
",sean-,dbresson
2137,2016-06-22 02:57:15,"@ryanuber took a look through and added some comments - this is looking good! I think the `.Source` thing is the biggest change since that's already there, otherwise some minor stuff.
",slackpad,ryanuber
2137,2016-07-01 00:20:04,"@ryanuber looks good! I still think we need to revert the `parseSource()` changes and the only other thing is to mention this in the docs. Otherwise, :shipit:.
",slackpad,ryanuber
2134,2016-08-11 01:05:31,"Hi @mcandre Consul doesn't have any knowledge of the data being stored in the KV entries, so it makes JSON APIs difficult if there are values that can break encoding. You can use the ?raw query parameter to get a single key from /v1/kv without any of the encoding.
",slackpad,mcandre
2133,2016-06-22 04:25:30,"Hi @mcandre this would be tricky if any of the values break the JSON output (or we'd need special encoding / size header to be able to separate the raw values if this response isn't JSON) - not sure how this one would work.
",slackpad,mcandre
2126,2016-06-21 06:36:35,"Hello @wenhx8 , the Consul Agent is the source of truth for checks.  If the Agent has failed, its checks will also be in a failed state until the Agent comes back.  If you have something more specific that you would like to see discussed, please let us know with more detail.  Cheers.
",sean-,wenhx8
2124,2016-08-11 01:02:11,"Hi @jsvisa it's hard to tell what's going on from just the members output. Do you see anything in the Consul logs related to those hosts that are leaving? The members list is driven by the gossip layer, so they can be different on different hosts, but the results should converge.
",slackpad,jsvisa
2120,2016-08-11 00:54:39,"Hi @akabdog it looks like there might be a mismatch between your configured advertise addresses and what Consul is binding to., which is this one:

`Cluster Addr: 172.17.0.3 (LAN: 8301, WAN: 8302)`

Setting https://www.consul.io/docs/agent/options.html#_bind should help here.
",slackpad,akabdog
2120,2016-10-21 14:10:14,"@slackpad I am seeing the same error on all my 3 nodes



Here is the config for bootstrap node



Here is the config for 2 other nodes



Here is the consul version



Thoughts?
",gvenka008c,slackpad
2120,2017-03-06 20:43:18,"@gvenka008c can you try a build from `master` and remove the `-client` argument and try again?  https://github.com/hashicorp/consul/pull/2786 probably fixes your issue.  Let us know if it does.  You can also remove the `advertise_addr` argument, too.  Lastly, try setting, `-bind={{GetPrivateIP}}` and see if that works.  If it does, can you let us know?",sean-,gvenka008c
2119,2016-08-11 00:51:54,"Hi @meskarune that's a great library :-) This feels like something that should probably be a separate project as suggested by @HalosGhost that consumes the API, but I'll keep this open for a bit to think about any possible uses in the existing Consul CLI.
",slackpad,meskarune
2119,2016-08-11 00:51:54,"Hi @meskarune that's a great library :-) This feels like something that should probably be a separate project as suggested by @HalosGhost that consumes the API, but I'll keep this open for a bit to think about any possible uses in the existing Consul CLI.
",slackpad,HalosGhost
2118,2016-08-15 23:16:27,"Hey @DWvanGeest thanks for the PR and sorry for the delay. I did a little follow on work for this under #2275 and will be merging here in a sec. Code looked great!
",slackpad,DWvanGeest
2117,2016-08-11 00:47:56,"Hi @vrenjith thanks for the PR! I think this might be confusing because this should be an IP address, not a FQDN. This is getting reworked under https://github.com/hashicorp/consul/issues/2076, so I'll close this one so we remember to clean up the documentation as part of that change.
",slackpad,vrenjith
2115,2016-08-11 00:43:18,"Hi @ggershoni thanks for the PR, but this shouldn't be required. It'll default the `id` to the `name` (just tested it locally). It is possible you pasted the JSON incorrectly?
",slackpad,ggershoni
2113,2016-08-11 00:58:19,"Closing as we haven't heard back (thanks for the help @tiwilliam)! Please let me know if you are still running into issues.
",slackpad,tiwilliam
2110,2016-08-11 07:00:24,"Hi @shahuwang , this should be fixed in 0180f20352ab1696a77fdbb37adcfbc6d3f8dd5c. Instead of splitting on the path separator, `scripts/build.sh` now uses `which` to determine the path of `gox`.  If a user has multiple directories in their `GOPATH` they can ensure the correct `$GOPATH/bin` is in their `PATH`.  Let us know if that doesn't work for you.  Cheers!
",sean-,shahuwang
2103,2016-06-08 04:26:57,"Hi @joshuaspence there's a setting on the _agent_ to do this called [`translate_wan_addrs`](https://www.consul.io/docs/agent/options.html#translate_wan_addrs).
",slackpad,joshuaspence
2102,2016-11-22 17:49:31,"Hi @iforapsy looking at this further it's all related to how the Windows shell handles quotes for command line arguments. All this processing happens before Consul is executed, so I don't think there's anything we could do in Consul itself to fix this. The caret appears to be a reasonable solution to escape the spaces.",slackpad,iforapsy
2095,2016-06-06 14:44:09,"Hi @WUMUXIAN thanks for the bug report! I'm going to close this as a duplicate of https://github.com/hashicorp/consul/issues/1778 - they have the same root cause.
",slackpad,WUMUXIAN
2094,2016-08-11 00:20:35,"Hi @meskarune did you figure this one out? I'm not sure how to configure lighthttpd, bit it looks like it's trying fetch ""/"" from Consul instead of ""/ui/"". That redirect comes from here - https://github.com/hashicorp/consul/blob/master/command/agent/http.go#L419-L436. If you can get lighthttpd to pass on the full URL that should fix it. Hope that helps!
",slackpad,meskarune
2089,2016-08-11 00:28:58,"Thank you for the update, @tgross!
",slackpad,tgross
2086,2016-06-02 15:57:32,"Hi @igal-stratoscale servers sync the disk when committing new write log entries through Raft, so a heavy write load to Consul can cause a lot of disk i/o. That write rate seems fairly high. If you pull [telemetry](https://www.consul.io/docs/agent/telemetry.html) there might be some insight there. Look for telemetry with names including ""consul.fsm"" and the counts there will give you how many of each log type are being committed in that interval, which may point to something that's churning rapidly in the cluster. Consul stores all its data in RAM as well, so you'll also want to make sure you have enough RAM and aren't swapping.

The high disk i/o doesn't seem like it should be related to file descriptors. Running something like `sudo lsof -n -P` should shed light on what's happening there. That's usually caused by a client rapidly making HTTP connections and not closing them, as could happen with earlier versions of the Go API client, for example.
",slackpad,igal-stratoscale
2086,2016-06-02 18:27:58,"@igal-stratoscale there's also https://github.com/hashicorp/consul/issues/907, which could be related.
",slackpad,igal-stratoscale
2086,2016-06-02 20:04:19,"@slackpad what is the expected i/o rate for consul from your experience?
The base is 4 nodes cluster, with 3 servers.
",rom-stratoscale,slackpad
2083,2016-08-10 23:39:28,"Hi @tshak thanks for the PR! I'm working on the 0.7.0 release right now, but I'll try to give this some cycles shortly after that's done so we can get this into the release that follows.
",slackpad,tshak
2082,2016-06-01 13:50:00,"@shakisha, did you verify your networking configuration? it seems the node `mariadb-de-02` couldn't be reached through UDP but TCP. 
",c4milo,shakisha
2082,2016-06-01 14:11:27,"@c4milo yes, everything is fine in the network.

What about suspect message?
",shakisha,c4milo
2082,2016-06-01 15:43:58,"Hi @shakisha, @c4milo is correct - this looks a lot like there was a temporary network disruption on that node that caused the server to close the TCP connection to this agent and caused other nodes to think the agent was failed. This can be caused by problems with the network itself, or it's also common on cloud platforms like AWS with small instance types where periods of high activity can steal resources from network packet processing and cause high packet loss. From the log I don't think Consul actually crashed, it seems like it's starting to recover near the end there (seeing some suspect messages from other nodes thinking it's down), though there are still i/o timeouts so it looks like it's not fully back yet. I suspect that if you ran a network test when this was happening you'd see heavy packet loss independent of Consul.
",slackpad,c4milo
2082,2016-06-01 15:43:58,"Hi @shakisha, @c4milo is correct - this looks a lot like there was a temporary network disruption on that node that caused the server to close the TCP connection to this agent and caused other nodes to think the agent was failed. This can be caused by problems with the network itself, or it's also common on cloud platforms like AWS with small instance types where periods of high activity can steal resources from network packet processing and cause high packet loss. From the log I don't think Consul actually crashed, it seems like it's starting to recover near the end there (seeing some suspect messages from other nodes thinking it's down), though there are still i/o timeouts so it looks like it's not fully back yet. I suspect that if you ran a network test when this was happening you'd see heavy packet loss independent of Consul.
",slackpad,shakisha
2081,2016-06-07 13:05:19,"@ssenaria  were you ever able to resolve this ? 
",johntdyer,ssenaria
2081,2016-06-07 13:15:12,"@johntdyer I ended up using the correct hostname that the cert was intended for. I was using the hostname, but the cert wasn't valid for it. I changed it to one of the names we used in Apache's virtualhost and all is well.

The client I was running this on is also a web server for other things.
",ssenaria,johntdyer
2080,2016-06-01 05:32:57,"Hi @zackshen running the leave on all the servers is putting the cluster into an outage state, so it is expected that it cannot recover without intervention. The first leave should leave things still operating (2 servers left). Once you run the next leave, the quorum of servers can process the leave, but the cluster with 1 remaining server has lost quorum and can no longer process any changes (such as to add new servers). You'd need to manually restore the contents of your peers.json (see https://www.consul.io/docs/guides/outage.html), or re-bootstrap the cluster by temporarily running a single server in `-bootstrap` mode and then joining the other two servers afterwards to form a new cluster.
",slackpad,zackshen
2080,2016-06-01 07:34:00,"Hi @slackpad running consul in three server, when reboot one server would not affect the cluster, until leave all the consul then need us to recover manually.   do i understand right ??? 
",zackshen,slackpad
2080,2016-06-02 02:05:30,"@slackpad  thank you very much!
",zackshen,slackpad
2077,2016-08-10 23:33:23,"Hi @joshuaspence writing a watch handler is probably the best way to do this, since you can basically run any script and have that script notified when things change. I don't think we'd do a deeper integration with any specific API since there are so many options.
",slackpad,joshuaspence
2076,2016-08-10 23:31:28,"Hi @joshuaspence thanks for opening an issue. Right now, clients have to realize that the address is empty and look up the node's address in the other part of the structure (that's what Consul does internally for DNS, for example). We should consider filling this in to make this API easier to consume.

Implementation note - we will need to be a little careful how this is done (probably in the agent) because the servers will have a pointer into the state store, so we can't just loop and tweak them. 
",slackpad,joshuaspence
2068,2016-08-18 02:03:54,"Hi @varshashastri thanks for the PR. This could be useful, but I don't think it'll perform well with huge lists of keys, and offering a search function I think will make people think it's doing more than it is. We aren't really set up to index for arbitrary searches, so I think we should hold off on this.
",slackpad,varshashastri
2066,2016-05-24 01:04:30,"@shilov, does this workaround just make the cluster running again or the old data can be restored as well? I see some snapshot files also having IPs embedded. not sure what's in the raft.db.
",hehailong5,shilov
2065,2016-05-23 00:11:14,"Hi @joshuaspence can you please be more specific about which endpoints need clarified? The health endpoint's ""?passing"" documentation is here, for example:

https://www.consul.io/docs/agent/http/health.html#health_service
",slackpad,joshuaspence
2064,2016-05-22 20:53:07,"Hi @winpat thanks for the detailed bug report. This is also captured in #1738 and should be fixed by https://github.com/hashicorp/consul/pull/2058. I'll add some unit tests and then merge that one. Linking this issue to those and closing as a duplicate.
",slackpad,winpat
2063,2016-05-31 14:36:01,"@ross sorry for the delay - I'll pull this down locally and take a look soon. Definitely interested in seeing this land!
",slackpad,ross
2063,2016-05-31 14:49:20,"> @ross sorry for the delay - I'll pull this down locally and take a look soon. Definitely interested in seeing this land!

No worries. Just wanted to make sure before I put a bit more time in to clean it up, both visually and code-wise. I should get to that in an evening later this week or early this weekend.
",ross,ross
2063,2016-08-10 23:57:18,"Hi @ross sorry about the delay on this one. I ended up making a tiny JS change over in https://github.com/hashicorp/consul/pull/2251 that I think we will need to rebase and port over here. There was a JS error if coordinates were not available. I can help you rebase, or if you'd like to we can get this in - please let me know!
",slackpad,ross
2063,2016-08-11 01:00:34,"Hi @slackpad. May be best for you to rebase & fix as it'll take me a bit before it'd get back to the top of my todo list.
",ross,slackpad
2062,2016-05-24 21:57:58,"@sspreitzer there's a ""services"" key that works similar to ""checks"" - please see [_Multiple Service Definitions_](https://www.consul.io/docs/agent/services.html).
",slackpad,sspreitzer
2062,2016-05-28 09:10:38,"@slackpad Thanks James!
",sspreitzer,slackpad
2061,2016-08-10 23:13:05,"Hi @arun-gupta - take a look at any startup logs from Consul - there's likely a configuration difference between the two images that's causing the problem (the official image isn't set up the same way as `progrium/consul`. Also, the official image doesn't run Consul as root, so there may be some differences there to sort out. Hope that helps!
",slackpad,arun-gupta
2056,2016-08-11 16:10:40,"@slackpad Nope. Just checked again and did not see anything in stderr log when starting. I also tried restarting rsyslog before starting consul with syslog enabled, but that did not seem to work or showed anything in stderr log. 
",carkmorwin,slackpad
2054,2016-07-05 20:54:08,"@maxenglander left minor comments but looks good! Sorry for the delay on our side.
",ryanuber,maxenglander
2054,2016-08-03 05:13:50,"Thanks for the review and comments @ryanuber. I followed all of them (I think).

After following your suggestion to check the result from `cmd.Wait()`, I discovered that `cmd.Run()` calls `cmd.Wait()` under the hood. This meant that, previously, my explicit call to `cmd.Wait()` was redundant, and was producing a [""wait already called""](https://github.com/golang/go/blob/master/src/os/exec/exec.go#L430) error. So, I removed that line of code. 

So far, the only error I've gotten from  logging the error from `cmd.Process.Kill()` is, on occasion, [""os: process already finished""](https://github.com/golang/go/blob/master/src/os/exec_unix.go#L53). I'm able  to produce this by terminating the watch process is terminated with `Ctrl-C`. I'm not sure how to get around this error. It seems pretty harmless; not worth doing a `goto ERR` for, I think.
",maxenglander,ryanuber
2046,2016-05-17 16:56:50,"@ross Looks super great!
",armon,ross
2046,2016-05-17 17:00:02,"@ross My only ask is to use the median distance instead of average, since you have it sorted and its less likely to get affected by outliers
",armon,ross
2046,2016-05-17 17:46:05,"> @ross My only ask is to use the median distance instead of average, since you have it sorted and its less likely to get affected by outliers

Updated version with median in place of average. 

Do you want the hover behavior, https://github.com/ross/consul/commit/a8370a0de9d0a78fb568f58b6867021f319fcb85, as-is? It's really nice functionality, but the implementation is lacking due to me knowing nothing about Ember.js
",ross,ross
2046,2016-05-17 18:39:59,"@ross I haven't played with it, but I worry it might be unwieldy for large clusters where there are too many nodes.
",armon,ross
2046,2016-05-17 19:31:04,"> @ross I haven't played with it, but I worry it might be unwieldy for large clusters where there are too many nodes.

Not sure if you're referring to the hover behavior or this PR in general. I've tested with with a couple thousand lines/nodes (by faking more data) and that works fine. Past that the svg rendering starts to bog down. 

My thought was to sample data (every Nth node) past some reasonable value, probably a few hundred, so that the chart would never be too bad and still be representative of the whole. 
",ross,ross
2046,2016-05-18 05:06:36,"Hi @ross thanks for this! Left a few comments - let's go ahead and add the mouseover as well. I like the down sampling - that seems like it should be effective for large clusters.
",slackpad,ross
2046,2016-05-19 02:07:03,"@ross thanks again!
",slackpad,ross
2039,2016-08-10 23:46:14,"Hi @jlambert121 thanks for the PR! I'm working on getting the 0.7.0 release right now but I'll try to give this some cycles soon.
",slackpad,jlambert121
2038,2016-05-11 20:06:47,"Hi @dmyerscough Consul's currently designed such that DELETEs for KV entries always succeeds whether they key exists or not so those requests are idempotent. Is there a particular use case this was causing you trouble with?
",slackpad,dmyerscough
2038,2016-05-12 02:17:59,"Hi @slackpad this isn't causing any problems, it was just a little off to me.. I can add additional logic around this.
",dmyerscough,slackpad
2037,2016-08-10 21:17:31,"Hi @chilumbugeorge when you take down the current leader (or restart it if you are upgrading in place) Consul will perform a leader election and one of the new servers will be elected (or possibly the old leader if you are restarting in place). There's unfortunately no way to avoid the leader election time. It's good to make your apps retry during periods with no leader, and we are working to make the Consul agent do that as well (lock monitors now retry, and we have some upcoming changes to make other places retry as well). Hope that helps!
",slackpad,chilumbugeorge
2036,2016-08-10 21:08:21,"Hi @AjeetK since you are using ACLs with default-deny, you need to supply a token `curl -v http://P.P.P.P:8500/v1/kv/?recurse\&token=token` to the request in order to read back the KV entries. The web UI is doing this for you if you set the ACL there. Hope that helps!
",slackpad,AjeetK
2035,2016-08-10 21:02:38,"Hi @hehailong5 can you describe your network setup a bit?
",slackpad,hehailong5
2027,2016-08-10 20:55:24,"@daveadams thanks for the suggestion - I agree this would be super useful. I think Vault has a similar concept via ""token accessors"".
",slackpad,daveadams
2026,2016-08-10 20:49:24,"Hi @goverdhanr55 it is probably just the time between running the two commands that's causing the difference there where it looks like it isn't caught up. The last contact time looks healthy in the output above.

I think this is probably the problem:

> registered the services with one of the follower servers in the cluster.

You are registering services for that particular server, so when it goes away they get deregistered. Instances of services belong to the agent where they are registered. Does that make sense?
",slackpad,goverdhanr55
2025,2016-05-05 17:42:33,"Hi @fxdgear could this be a problem with the permissions on ""/services/vault/consul/data"" that's being bound to that volume? The [Dockerfile](https://github.com/hashicorp/docker-consul/blob/master/0.6/Dockerfile#L39-L44) creates the data dir and assigns the `consul` user rights to it.
",slackpad,fxdgear
2025,2016-05-05 17:47:10,"@slackpad thanks for the response. I'm curious what the perms should be. 
",fxdgear,slackpad
2025,2016-05-05 18:13:43,"@slackpad so for a bit more info I'm using


",fxdgear,slackpad
2025,2016-05-05 18:30:08,"@slackpad ahh sorry I realized this is an issue with docker-machine and not with consul. :( 
",fxdgear,slackpad
2025,2016-05-05 19:05:00,"@fxdgear appreciate the update. Please link any context here if you can in case others run into this. Thanks!
",slackpad,fxdgear
2025,2016-05-30 16:01:09,"@deviantony Could http://www.projectatomic.io/blog/2015/06/using-volumes-with-docker-can-cause-problems-with-selinux/ be related to your issue?
",jhmartin,deviantony
2025,2016-06-09 09:14:45,"@jhmartin I'm having this issue on a fresh Ubuntu 14.04 server box (no SELinux).
",deviantony,jhmartin
2025,2016-06-09 14:38:41,"@slackpad 
do you mind letting us know which issue in [https://github.com/hashicorp/docker-consul ](url) tracks this one here ?

@jhmartin 
the z or Z options do not work for me

Ubuntu 16.04 , no SELinux,  
$ docker version
Client:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

Server:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

# docker logs:

$ docker logs consul
WARNING: ca_cert.pem does not contain exactly one certificate or CRL: skipping
WARNING: ca-certificates.crt does not contain exactly one certificate or CRL: skipping
WARNING: ca-cert-consulca.pem does not contain exactly one certificate or CRL: skipping
==> WARNING: Expect Mode enabled, expecting 3 servers
==> Starting Consul agent...
==> **Error starting agent: Failed to configure keyring: mkdir /data/serf: permission denied**
",barbarello,jhmartin
2025,2016-06-09 14:38:41,"@slackpad 
do you mind letting us know which issue in [https://github.com/hashicorp/docker-consul ](url) tracks this one here ?

@jhmartin 
the z or Z options do not work for me

Ubuntu 16.04 , no SELinux,  
$ docker version
Client:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

Server:
 Version:      1.11.2
 API version:  1.23
 Go version:   go1.5.4
 Git commit:   b9f10c9
 Built:        Wed Jun  1 22:00:43 2016
 OS/Arch:      linux/amd64

# docker logs:

$ docker logs consul
WARNING: ca_cert.pem does not contain exactly one certificate or CRL: skipping
WARNING: ca-certificates.crt does not contain exactly one certificate or CRL: skipping
WARNING: ca-cert-consulca.pem does not contain exactly one certificate or CRL: skipping
==> WARNING: Expect Mode enabled, expecting 3 servers
==> Starting Consul agent...
==> **Error starting agent: Failed to configure keyring: mkdir /data/serf: permission denied**
",barbarello,slackpad
2025,2016-06-09 14:43:38,"Hi @barbarello there's currently no issue tracking this - rather than re-open here it probably makes sense to make one over there and link it so it'll get better visibility.
",slackpad,barbarello
2022,2016-06-03 22:40:32,"@evan2645 sorry about that - I'd definitely take a PR to update the docs and push that out while we work on the fix.
",slackpad,evan2645
2022,2016-06-04 00:31:41,"@slackpad no apology needed :) opened https://github.com/hashicorp/consul/issues/2090
",evan2645,slackpad
2017,2016-05-04 00:48:19,"@clstokes definitely an issue! Submitted a pull request to fix.
",captainill,clstokes
2015,2016-07-05 20:35:57,"Hey @sorenmat, the behavior you are seeing is actually by design. When any node check goes into a critical state, Consul views the entire node as critical (and all services that are associated with it). This isn't to say that it will go and mark them all as critical, however. They instead are omitted from catalog results or DNS queries if the user is requesting healthy services. If you ensure you are requesting services from the `/v1/health` API, or if you are using the DNS interface, you should only get results from services who have all health checks passing, including node-level health checks.

Let me know if that clears this up. Thanks for the contribution!
",ryanuber,sorenmat
2015,2016-08-18 02:07:03,"Closing this out as this isn't the behavior we'd like, since Consul handles the AND-ing of the dependency on the serfHealth check under the hood. Please let us know if there's any follow up from @sean-'s comments that we can help with.
",slackpad,sean-
2013,2016-08-10 20:38:34,"Hi @clintonm9 I think you may have created this in the wrong project. Was this intended for Terraform?
",slackpad,clintonm9
2011,2016-08-10 20:37:14,"Hi @devth if you rebuild the UI locally you can tweak this setting to set a different path - https://github.com/hashicorp/consul/blob/master/ui/index.html#L12-L17. That should fix the static front end and get it pointed at the right place. Hope that helps!
",slackpad,devth
2011,2016-08-10 20:38:34,"@slackpad thanks, I'll give that a try!
",devth,slackpad
2007,2016-08-10 20:27:17,"Hi @jorgemarey not currently, sorry about that.
",slackpad,jorgemarey
2007,2016-10-03 18:37:12,"@jorgemarey -- I don't have a test environment up and the failing tests do not appear related to my change. Is there anyway you can help test by building locally?
",moofish32,jorgemarey
2006,2016-04-29 08:41:59,"Hi @fusiondog .  Thanks for the suggestion.  Can you add a small bit to this that includes a reference to the `recursors` option?  Without at least one specified, users with this configuration will have a hard time resolving non-Consul addresses.  In general we recommend a caching DNS service vs relying exclusively on Consul because Consul does not cache, it forwards.  Thanks!

https://www.consul.io/docs/agent/options.html#recursors
",sean-,fusiondog
2006,2016-06-02 22:35:51,"Hey @akurniawan.  In the latest update to the branch I have this line that explains about using the recursors option to resolve other domains.  Let me know what changes might clarify that better.


",fusiondog,akurniawan
2006,2016-06-02 23:08:40,"Hey @fusiondog, ah yes I forgot to mention that. I use recursors option actually, when I haven't applied the iptables rule everything was fine, I can resolve other TDL such google.com with this command `dig @localhost -p 8600 google.com`, but after I applied those rules I mentioned above, suddenly I couldn't resolve any host other than consul. Do you know why it's happen?
",akurniawan,fusiondog
2006,2016-06-02 23:31:07,"@akurniawan Do you have the recursors on a separate system or the same system?
You could check and post that the rules are in place properly: iptables -L -t nat
Or run a tcpdump to see if the connections are going where they are expected to go: tcpdump -ni any udp port 53
",fusiondog,akurniawan
2006,2016-06-02 23:43:52,"@fusiondog the recursors is on the same system.
Here is the output from `iptables -L -t nat`



Here is the output from `tcpdump -ni any udp port 53`


",akurniawan,fusiondog
2002,2016-06-22 09:34:40,"@sean- @slackpad 
Any update on this PR?
We hit the similar issue about the DNS retry.
",bingosummer,sean-
2002,2016-06-23 07:42:49,"Hi @bingosummer.  This PR became deprioritized for a while working on some other items, but will be seeing some attention from myself in the next week or so and has come up a few times recently.  Stay tuned, we haven't forgotten about it.
",sean-,bingosummer
2002,2016-11-17 23:57:49,"@sean- any thoughts on this one? We added the RPC hold timeout which paves over leader elections and we've made allow_stale opt-out with aggressive max_stale, so we may be able to call this good enough for now?
",slackpad,sean-
2000,2016-07-09 05:33:37,"Hi @onlyjob sorry we are in the middle of finishing up a major release and can't run a minor release cycle at this time. The major release will take a few more weeks to complete.
",slackpad,onlyjob
1999,2016-08-10 20:24:51,"Hi @gamefundas can you unset `HTTP_PROXY` for Consul completely, or do some checks need it and others don't? Right now we are using Golang's HTTP transport which does pick the settings out of the environment.
",slackpad,gamefundas
1998,2016-04-28 00:55:02,"Hi @BSick7 we noticed an error in the docs and fixed it earlier today (!) - here's the change:

https://github.com/hashicorp/consul/commit/c6bde826a45dc0002f12d094645109916a856f85

If you leave `only_passing` in its default state or set it to `false` it should have this exact behavior:

> I have a need to have non-critical nodes report dns records. When turned on, the following node statuses would be considered ""healthy"": unknown, passing, warning.

Sorry for any confusion :-)
",slackpad,BSick7
1997,2016-04-27 23:19:24,"Hi @centromere thanks for opening an issue - this one is being tracked over at https://github.com/hashicorp/consul/issues/1655.
",slackpad,centromere
1992,2016-08-10 20:20:05,"Hi @jtconnor this gets tricky because Consul doesn't always have enough time to gracefully leave when a machine terminates. For client agents this is rarely an issue because they will get expired after 72 hours. Servers will, too, but having an unclean leave will have undesired effects on the quorum. We are working on a process to have the remaining servers automatically clean up failed servers more quickly - that won't make it into Consul 0.7.0, but should be available shortly after that release.
",slackpad,jtconnor
1991,2016-08-10 20:17:08,"Hi @fatlazycat we are currently expanding the coverage of ACLs, but the [Agent API](https://www.consul.io/docs/agent/http/agent.html) are currently not covered, mostly due to ACLs being enforced on the Consul servers. We've got a design in mind to cover agent functions as well, and are actively working towards it, but right now changes can be made at the agent level from someone with access to that agent's client interface. In the meantime, the best thing is to make sure that the client interface is not exposed outside the machine (bind to loopback or better yet a UNIX socket protected by appropriate file permissions).
",slackpad,fatlazycat
1988,2016-04-27 06:55:05,"Hi @jippi it's definitely true that not everybody will want to use the official image, but it's pretty simple to configure something outside of Consul to do the reaping in your own container, so we will document that. The [reap lock](https://github.com/hashicorp/go-reap/blob/master/reap_unix.go#L23-L29) is just plain ugly and it's super easy to forget to do it in the code and introduce subtle errors, so that doesn't seem worth the liability. Adding reaping inside the container was basically just a matter of including `dumb-init` and adding a [single line](https://github.com/hashicorp/docker-consul/blob/master/0.6/docker-entrypoint.sh#L1) to the entrypoint, which is a lot cleaner.
",slackpad,jippi
1988,2016-04-27 07:57:53,"@slackpad alright, kill it with fire then :)
",jippi,slackpad
1986,2016-05-06 17:34:10,"@merri-j glad to know its not just me doing something stupid :p
",shortdudey123,merri-j
1986,2016-08-10 23:16:43,"Thanks @jgoldschrafe that sounds right. Can others here confirm if this works?
",slackpad,jgoldschrafe
1986,2017-01-13 03:28:22,"@kyhavlov i am not familiar with how to get Chrome to pass a cert request to the UI.
I can understand needing it for api requests, but not the web ui",shortdudey123,kyhavlov
1986,2017-01-13 05:40:37,@shortdudey123 [this](https://blog.codeship.com/how-to-set-up-mutual-tls-authentication/) talks about using pkcs12 and may help you. I have not tried this with the consul configuration described here yet.,moofish32,shortdudey123
1984,2016-07-05 20:19:26,"Hey @kylemcc, this looks great! Just a few minor comments but otherwise LGTM. Sorry for the delay!
",ryanuber,kylemcc
1984,2016-07-07 16:38:07,"@ryanuber I've made a few changes based on your feedback. The test failure here seems unrelated to my changes - it may be due to my rebasing on top of master. They do pass for me locally though.

Let me know if you have any other feedback.
",kylemcc,ryanuber
1984,2016-07-07 16:47:54,"@kylemcc great, will review again shortly!
",ryanuber,kylemcc
1984,2016-07-19 15:20:28,"@kylemcc I added a [PR](https://github.com/kylemcc/consul/pull/1) to your branch to include TLSSkipVerify in the api. Please review before this gets merged!
",cavemandaveman,kylemcc
1983,2016-04-24 23:40:31,"Hi @mpalmer that `go get` command is obsolete (just removed that from the README) now that we vendor all the non-tool dependencies. I just tried building on Go 0.6.2 and couldn't reproduce this issue (though I'm not on Linux). Could you try `CGO_ENABLED=0 make` and see if that helps?
",slackpad,mpalmer
1983,2016-04-25 00:03:50,"Hey @slackpad, thanks for the suggestion, but apparently no dice:



(I also tried `CGO_ENABLED=1`, just in case of typo, but that's no good either).

After some more digging, turns out this is a false alarm: I upgraded Go to 1.6 over my previous installation (because I missed the bit about removing the old Go install first) and now all appears to be well.  Sigh... that's Monday morning for you...
",mpalmer,slackpad
1982,2016-10-28 16:09:33,"I have similar issues as @vchekan, same version.
",arcz,vchekan
1980,2016-07-05 20:04:46,"Hey @jsipprell, sorry for the delay here. I'll review in depth here soon, but at first glance this sounds great!
",ryanuber,jsipprell
1980,2017-03-14 03:02:14,@jsipprell - Would it be possible to fix the merge conflicts here ? ,rangan337,jsipprell
1969,2016-07-17 11:56:45,"@slackpad this is great! Do you have any idea when we might get a first drop of this, ideally as a release, but if not then as a master commit we can at least test/build off? Thanks :)
",nickithewatt,slackpad
1969,2016-07-17 14:06:48,"Hi @nickithewatt this should land in the next few weeks in master and shortly after that as a release candidate build.
",slackpad,nickithewatt
1969,2016-09-28 14:17:11,"Hi @slackpad - did this change make it into the 0.7 release? I've seen the new performance config in 0.7, but even with the defaults we're still seeing timeouts when a consul server is destroyed and replaced with a new node in AWS. Server nodes are `t2.medium`s, but even then, we get timeouts which trigger leader election.
",madAndroid,slackpad
1969,2016-09-28 15:42:22,"@madAndroid this change made it in to 0.7 - the multiplier directly scales the leader lease timeout. So you are replacing a non-leader node and getting an election?
",slackpad,madAndroid
1969,2016-09-28 16:07:31,"Yes, but the heartbeats were timing out with the default... I've since
adjusted the `raft_multiplier` to `7`, and this appears to have improved
things somewhat... still testing atm, will report back on progress. Thanks
for taking the time to respond

On 28 Sep 2016 5:42 pm, ""James Phillips"" notifications@github.com wrote:

> @madAndroid https://github.com/madAndroid this change made it in to 0.7
> - the multiplier directly scales the leader lease timeout. So you are
>   replacing a non-leader node and getting an election?
> 
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/hashicorp/consul/issues/1969#issuecomment-250206631,
> or mute the thread
> https://github.com/notifications/unsubscribe-auth/ABQp3QMigdW4ykoeowBV0YzTDFMFjg0Vks5quorxgaJpZM4ILnA8
> .
",madAndroid,madAndroid
1969,2016-09-30 06:20:03,"@slackpad - We're still seeing the same behaviour, I'm afraid :(

We have 3 server nodes, one per AZ .. and we've now bumped these up to `m3.medium`'s, and have set `raft_multiplier` to 8 .... when we randomly killl one of the servers, ASG event kicks in, and replaces that box ... and when it comes back up, it attempts to join the rest of the cluster (at this point we still have a leader, since the quorum of 2 ensure that) ... it joins at first ... then we see heartbeat timeouts, and a leader election triggered on the node that attempts to join. The remaining two nodes reject the election request, and this continues



Config:



When the leader election is flapping we see this when running `consul operator raft -list-peers`


",madAndroid,slackpad
1969,2016-10-06 01:16:55,"@madAndroid the logs make it look like .87 joined the cluster - does it eventually become stable or does it repeat that with an election timeout shortly after?
",slackpad,madAndroid
1969,2016-10-06 06:32:06,"@slackpad - I'll need to do some more testing, but most recently I've seen that the node that joins will enter this flapping state for some time; during this time, the instance will appear to connect, logs indicate that it joins.. then the heartbeat fails, and it reenters candidate mode; the other two nodes don't enter that same state: they reject leader election requests from the node that enters candidate state with messages saying ""Rejecting vote request from 10.206.54.87:8300 since we have a leader"". The cluster does eventually stabilise, after an extended period of time - not sure exactly how long this continues for, but during this time anything that's using Consul for discovery and/or DNS endpoints, is in an unknown/unstable state.

I'll do some more testing and post more findings here
",madAndroid,slackpad
1969,2016-10-06 15:30:32,"@madAndroid ok thanks. Also 8 is really slow for the Raft multiplier, so those timings are likely why things take so long to stabilize. We tuned 5 with a t2.micro out of CPU credits, so if you are running on a m3.medium that should be fine. Lower numbers are for better performance.
",slackpad,madAndroid
1968,2016-07-23 22:20:01,"Hi @NileshTembhre - unfortunately I'm not aware of any details about this Consul configuration. Can you please contact the folks that provided this instead?

If you have access to the Consul logs and enable debug mode it may shed light on where the 500 error is coming from. If it looks like a core Consul issue and you can get repro steps/logs please feel free to open up another issue.
",slackpad,NileshTembhre
1967,2016-07-23 22:16:29,"Hi @fdhex the best way to monitor service status is to register checks with your service using the [Agent API](https://www.consul.io/docs/agent/http/agent.html). If you query Consul via DNS the node's health is always factored in, so services for an unhealthy node will not be returned. Similarly, when pulling service health from the HTTP APIs, the node-level health checks are also included in the response so you can filter appropriately. You are correct that the health status for the service might show healthy, but it's always possible to factor in the node's health, too. That way you can see the state of everything at the time the node died. Hope that helps!
",slackpad,fdhex
1966,2016-05-19 03:15:03,"Hi @hehailong5 these issues are almost always caused by network configuration issues. You need port 8301 open for TCP and UDP between all nodes in a cluster (Consul requires them to be a fully connected mesh).
",slackpad,hehailong5
1965,2016-06-11 02:35:37,"Hey @fusiondog 

Stumbled upon your work when I was reading the mailing list and this really fits into what I'm experiencing as well.

I'd love to get Consul to output to graphite and have this kind of handler.

Have you been updating any of this work lately?

Perhaps we can discuss this with @armon as well in regards to getting the ball rolling again here? :)
",cdrage,fusiondog
1965,2016-06-11 03:26:20,"Hey @cdrage 
I haven't done anything since this on the subject.  I wanted to get some feedback from people before going too far down a wrong path.  Assuming that option 3 makes sense to most people, then I just need to merge in the latest upstream and then begin consideration on how to source handlers. 
",fusiondog,cdrage
1965,2016-08-11 00:32:44,"@fusiondog thanks for the PR! I'll try to give this some cycles once we ship 0.7.0.
",slackpad,fusiondog
1964,2016-05-19 03:12:08,"Hi @feniix if a node is terminated but doesn't leave the cluster (it will get reaped after to 72 hours) then all of its service health checks will go stale, but it's serfHealth check will fail because the cluster will realize the node is gone. The raw ""passing"" query will still show the stale checks, but the serfHealth check is AND-ed with those others, so the failed node won't be returned in a DNS query to Consul, and https://www.consul.io/docs/agent/http/health.html#health_service with the ""?passing"" parameter will omit that dead node. Hope that helps!
",slackpad,feniix
1963,2016-04-20 00:38:56,"Hi @zankich currently not - the exploit seemed pretty limited in its ability to affect Consul users so we were planning on moving to 1.6.1 when we release Consul 0.7 (I don't have a firm release date for that right now).
",slackpad,zankich
1960,2016-05-19 02:50:36,"Hi @sanjoyb thanks for reporting an issue - this is an odd one. Can you provide some logs from when this happens? It would be interesting to see if something is happening to the quorum.
",slackpad,sanjoyb
1959,2016-05-19 02:47:21,"Hi @grobinson-blockchain closing this as a duplicate of https://github.com/hashicorp/consul/issues/1110, but linking these. For the case of docker, we [baked this into the official image](https://github.com/hashicorp/docker-consul/blob/master/0.6/docker-entrypoint.sh#L9-L18) via the entrypoint script, but we are still looking into adding this support in Consul itself.
",slackpad,grobinson-blockchain
1958,2016-04-18 14:54:51,"@panda87 I assume your private IP addresses are changing on restart unless you have configured ENIs to control private IP space. If managing IPs is your issue you can use a null resource like [here](https://github.com/hashicorp/best-practices/blob/6a6fa8d3730309dc4e526668d19edd2e2427d3c8/terraform/modules/aws/data/consul/consul.tf#L73-L98) to get the desired behavior you are after. You will obviously have to tweak that example a bit to fit your needs. I would remove the start_join and configure the null resource to join on change of private IPs. 

The other option is try out Atlas.
",moofish32,panda87
1958,2016-04-18 15:03:08,"Thanks @moofish32, but you may didn't understand my question, so thanks, I will clear it up.
I already setup my env, including the consul cluster.
My scheduling process runs only after Terraform finished to setup the env.
btw, the private IP addresses are remain the same when I stop the instances.
",panda87,moofish32
1958,2016-04-19 01:00:52,"@panda87 - do you have sample code for what you are trying to do? I am confused on where the code snippets above line up to your process.
",moofish32,panda87
1958,2016-04-19 14:26:08,"@panda87 - I'll cautiously warn you that I think the path you are on is probably not in line with best practices (but you would have to get somebody from Hashicorp to verify). 

If you log into the instances (consul servers) and manually join the nodes does it work?

Also if the env is automated with Terraform, why not just Terraform destroy and Terraform apply to automate the tear down and setup each day?
",moofish32,panda87
1958,2016-04-19 17:54:34,"@moofish32 - I know that this scenario is not expected and not by design, but still, I want to make sure whether this scenario I can work with or not.
Second, my env is pretty big with many components, part of them are still not fully automated, so I prefer to keep the env and not rebuild it every morning.
",panda87,moofish32
1958,2016-04-20 05:51:41,"@panda87 - I'm happy to keep attempting to help. @hehailong5 has an interesting suggestion. 

However this might be a better convo to move the google groups forum versus an issue here?
",moofish32,hehailong5
1958,2016-04-20 05:51:41,"@panda87 - I'm happy to keep attempting to help. @hehailong5 has an interesting suggestion. 

However this might be a better convo to move the google groups forum versus an issue here?
",moofish32,panda87
1957,2016-05-19 02:42:43,"Hi @siddharthist thanks for the PR and sorry for the delay in looking at this. I'm thinking we should incorporate the listing of allowed methods into [here](https://github.com/hashicorp/consul/blob/master/command/agent/http.go#L196). We could make a new registration function that turns this:

`s.mux.HandleFunc(""/v1/kv"", s.wrap(s.AgentSelf))`

Into something like this:

`registerEndpoint(""/v1/agent/self"", ""GET,PUT,DELETE"", s.wrap(s.KVSEndpoint))`

This way we can build the data structure one time alongside the registration of the endpoints. What do you think?
",slackpad,siddharthist
1957,2016-05-19 19:45:13,"@slackpad That makes a lot of sense. Most of the work on this PR was just finding out what endpoints respond to which methods, so I'm happy to redo the code :)
",siddharthist,slackpad
1957,2016-05-19 21:18:05,"@slackpad What are the supported methods on the `/v1/txn` endpoint?
",siddharthist,slackpad
1956,2016-04-19 02:11:08,"Hi @johntdyer similar to K/V, prepared queries belong to the cluster and not any individual agent, so they cannot be configured as part of an agent's config file. If you wanted to pre-seed them you'd need to script that outside of Consul with something like `curl` or using one of the Consul API clients. We have future plans for a better backup system on https://github.com/hashicorp/consul/issues/1254, which would include prepared queries. Most existing backup solutions only persist K/V, so at present the best way to back up your query definitions would be to save off a GET to [`/v1/query`](https://www.consul.io/docs/agent/http/query.html#general) using a management token which will enumerate all defined queries in one request.
",slackpad,johntdyer
1953,2016-04-25 06:47:46,"Hi @wxjs33 that should be possible with this endpoint - https://www.consul.io/docs/agent/http/catalog.html#catalog_service.

http://localhost:8500/v1/catalog/service/web?tag=apache
http://localhost:8500/v1/catalog/service/web?tag=nginx
",slackpad,wxjs33
1951,2016-04-25 06:31:05,"Hi @throrin19 this is probably a better question for the mailing list because you'll get a wider group of folks who may have experience with these stacks. Unfortunately, I don't have direct experience with Rancher to give good advice here. You might also want to check out [Nomad](https://www.nomadproject.io/) which also has Consul integration for containers and service discovery. Hope that helps!
",slackpad,throrin19
1949,2016-04-13 07:05:05,"Hi @wxjs33 can you provide some more detail about what you are trying to do? Services don't have TTLs in Consul. Sessions have as TTL, as do TTL health checks - are either of those what you are looking for?
",slackpad,wxjs33
1949,2016-04-13 07:48:02,"Hi, @slackpad In my config i set a service named ""web"", its service_ttl is 10s, like this
 `""dns_config"": {         
         ""service_ttl"": {
               ""web"": ""10s""
         }
}`
The TTL of ""web"" is 10s when queryed with dns lookup,  
If i register a new service(example: ""web2"") with http api, how can i set service_ttl of ""web2""  to 5s?
I want to set it with http api not to write in configï¼Œthx
",wxjs33,slackpad
1943,2016-04-12 09:27:43,"Hi @atomantic there's currently not an endpoint that will emit the services in one big data structure like that. It currently takes an initial query to get the list of services followed by a separate query per service. What kind of use case are you thinking the full query would be useful for?
",slackpad,atomantic
1939,2016-04-25 06:20:08,"Hi @Lax77 Consul tries really hard to keep the cluster together for nodes with the same datacenter. A super common way that merges happen like this is when IP addresses are reused. If you want to separate the clusters within the same network you should definitely assign them different datacenters, and good measure is to set them up with different encryption keys. Hope that helps!
",slackpad,Lax77
1938,2016-04-25 06:16:01,"Hi @Kooshaba this should be addressed once we fix https://github.com/hashicorp/consul/issues/1655.
",slackpad,Kooshaba
1937,2016-04-11 16:01:03,"Hi @rbink last night (!) we discovered an issue where there could be a side effect that cleared the output inadvertently. Is it possible for you to try out this change and see if it fixes the issue you are seeing?

https://github.com/hashicorp/consul/pull/1934
",slackpad,rbink
1936,2016-04-25 06:58:22,"@matteoturra is the /ui directory available inside the container? That looks like it may be the issue there. Also, if this is running Consul after 0.6.1 you should just be able to use `-ui` and it will use the built-in web assets, so no `-ui-dir` should be required.

@casertap the same should work for you since you are running Consul 0.6.4. If you remove `-ui_dir` and just leave `-ui` it should fix the 404.

Hope that helps! I'll close for now but please let me know if this doesn't fix the issue.
",slackpad,casertap
1936,2016-04-25 06:58:22,"@matteoturra is the /ui directory available inside the container? That looks like it may be the issue there. Also, if this is running Consul after 0.6.1 you should just be able to use `-ui` and it will use the built-in web assets, so no `-ui-dir` should be required.

@casertap the same should work for you since you are running Consul 0.6.4. If you remove `-ui_dir` and just leave `-ui` it should fix the 404.

Hope that helps! I'll close for now but please let me know if this doesn't fix the issue.
",slackpad,matteoturra
1936,2016-12-06 19:08:07,@slackpad is there any docs around `-ui-dir` and `-ui` combo? I just ran into this with the latest version of consul and couldn't figure out the issue for the life of me. ,chiefy,slackpad
1936,2016-12-06 19:19:54,Hi @chiefy we should make Consul error out (and update the docs) so it's super clear - https://github.com/hashicorp/consul/issues/2576.,slackpad,chiefy
1935,2016-09-05 17:40:30,"Hi @lucaswxp this one requires a restart.
",slackpad,lucaswxp
1933,2016-04-12 09:41:32,"Hi @chnrxn I tried to reproduce this but couldn't. Here's the main I used:



And I get this output:



Doing a `grep` looks like only unit tests pull in the package:



I bet there's some other package in your app that's importing `testing`. If that's not the case, can you please re-open this and attach a test case the compiles and shows the issue? Thanks!
",slackpad,chnrxn
1931,2016-04-10 16:31:20,"Hi @bkendall can you confirm which version of Consul you are using? There were some recent changes in 0.6.4 in this area but I don't think they would have caused this. You are correct we should probably trim the additional section in parallel to prevent a situation like this.
",slackpad,bkendall
1931,2016-07-23 21:33:59,"Hi @xytis this will be fixed for sure by the next release of Consul. Current workaround would be to use DNS over TCP or an older version of the agent. Sorry about that!
",slackpad,xytis
1930,2016-11-18 12:27:51,"@slackpad When using location rewrites with nginx proxy, it should be possible to customize the URI on which consul ui responds. If my nginx proxy is setup to forward `/server-1/consul-ui` to an upstream where consul ui is running, consul ui needs to be set to use `/server-1/consul-ui` context path. This setting is akin to `application.context` from Play framework, `-web.external-url` from Prometheus or Jetty `setContextPath`.

Does this help?
",radekg,slackpad
1930,2016-12-09 02:26:02,"Just FYI - I have made a few other enhancements that I think will help this. PR will be in coming shortly. 

TL;DR: Currently consul does not serve back full URL paths in its `Location:` headers when it's doing redirects for the UI, nor does the UI itself append on the correct HTTP origin that accessed it in the first place. These things are necessary to properly support reverse proxies not just on things like port or host but on path as well.

I'll reference back this issue on the PR when I'm ready.

@abhinavdahiya maybe if you could look at it if you'd like and see if we could combine work to have the best of both patches. @slackpad your feedback would be welcome as well.",vancluever,slackpad
1929,2016-04-09 07:52:09,"Hi @gdean123 and @kkelani - I'm wondering if somehow you've got a rogue server with `-bootstrap` that's started itself as a leader and is sending bogus AppendEntries calls to cluster members that were part of an earlier quorum with an index way ahead, and where log compaction for 327 happened long ago.

Can you give some more details about your setup, what kind of steps you are performing when this happens, and maybe link some gists with more complete logs from the new server and one of the existing ones?
",slackpad,gdean123
1929,2016-04-11 19:31:08,"Hi @slackpad. Thanks for the response. We have limited logs and info because this is occurring from one of the users of our application however here is the info that we know:
- The setup is a 3-node cluster and started with `-bootstrap-expect`
- The user was performing an application upgrade which triggered a rolling deploy
- The following logs are from a client that was connected to the cluster which contains event logs
- After a certain amount of time, if the client is unable to verify sync (by comparing the commit_index and the last_log_index) with the cluster, the client will kill the consul agent and then retry.

Gist: https://gist.github.com/kkelani/97147077b5f1d26cc477c0cbdaca6873

Thanks
@christianang & @kkelani
",kkallday,slackpad
1929,2016-04-25 06:17:17,"Hi @kkallday thanks for the info. I get a 404 with that gist - can you please take a look at the URL? Thanks!
",slackpad,kkallday
1929,2016-05-11 00:44:57,"Hey @slackpad did the gist help uncover any useful information? We are still experiencing this bug. 
",zankich,slackpad
1925,2016-05-19 03:03:29,"Hi @hehailong5 I'm going to close this out since it looks like there's an article here that can help you out. This might be a good type of question for the mailing list as well. If you can't run Atlas for joining, most folks run a handful of seed Consul agents and register those with their local DNS setup to use to join other nodes with the cluster. Please let me know if you have any more questions.
",slackpad,hehailong5
1922,2016-04-25 05:46:15,"Hi @deadok22 `Session.RenewPeriodic` is almost always run as goroutine, so the destroy is a best effort and Consul will clean up after the TTL otherwise. Is there a specific use case you are trying to address?
",slackpad,deadok22
1922,2016-04-30 03:32:58,"Hi @slackpad!

I'm doing leader election with Consul and I wanted to use a return from `Session.RenewPeriodic` as a signal that the leadership is lost in case it was held. 

I can still achieve the desired behavior if I wrap around the close signal and abdicate before sending the actual close signal to `Session.RenewPeriodic`.
",deadok22,slackpad
1922,2016-08-10 20:32:51,"Hi @deadok22 we actually do that with a separate routine that's waiting on the key itself:

https://github.com/hashicorp/consul/blob/master/api/lock.go#L353-L380

That's kind of a more direct check (like if the operator deleted the key but the session was still around, etc.). When the lock is lost, then we stop updating the session, but don't care about its return:

https://github.com/hashicorp/consul/blob/master/api/lock.go#L153-L159

Hope that helps!
",slackpad,deadok22
1921,2016-04-25 05:26:35,"Hi @maxnasonov - this looks pretty reasonable and I found some examples in the wild. It seems from the spec that it's harmless to add.
",slackpad,maxnasonov
1916,2016-04-05 05:17:32,"Hi @hehailong5 please see below:

> Regarding service registration, as the consul client is the only contact point, I understand more than one node should be configured to run as consul client to avoid the single point of failure situation.
> in this case (having multiple consul clients), how do I configure my consul registration tool? usually it requires to specify only one endpoint. what if this endpoint is down? will it automatically forward the registration request to an alive consul client in the cluster?

Normally you'll run a separate set of Consul _servers_ (usually 3 or 5) and then run the Consul client agent on every other machine in your infrastructure. Applications always talk to the local Consul client agent, which will automatically forward requests to and keep track of the Consul servers. The Consul servers provide stable storage for the catalog, key/value store, and provide coordination for things like locks and semaphores. The Consul client agents on each other machine manage registering local services on that machine, and provide interfaces to Consul for applications on that machine (HTTP or DNS). There's usually no need to have redundancy at the Consul agent level on each machine, as that's part of the same failure domain as the machine itself.

> If I register a HTTP health check in the consul, is it the consul server or the consul client that will do the actual checking?

The Consul client agent will run the health check locally and update the Consul servers with the results.

> is there a watchdog implemented in consul cluster? say initially I have 3 consul servers running in the cluster, if one of them goes down and then goes online, will it be automatically re-joined in the cluster?

Consul has a built in node health check called `serfHealth` that acts as a watchdog to make sure a node is alive and responding to network probes. This will automatically mark the node failed if it goes down, and will help the server rejoin the cluster if it comes back online.

Hope that helps! I'll close this out but feel free to re-open if you need any more clarifications.
",slackpad,hehailong5
1914,2016-04-12 08:30:01,"Hi @shakisha I'll leave this open as a reminder to improve the docs in this section. Here's some info that should help:

> what is the port number for wan and should be this one listening on public wan interface?

The port you'd want to use for the join is the ""Serf WAN"" port which defaults to 8302. You'd need the Consul servers participating in the WAN to expose this port bound to an interface that's reachable from the other Consul servers (they need to form a fully connected mesh). You'll need TCP and UDP access to this port from any firewalls.

> how to place this consul join -wan into configuration file without having to launch manually the command into cli?

The best way to do this is via the `retry_join_wan` config option - https://www.consul.io/docs/agent/options.html#retry_join_wan.

> this part ""Of course, all server nodes must be able to talk to each other. Otherwise, the gossip protocol as well as RPC forwarding will not work."" is referring about which datacenter?

The gossip part is the ""Serf WAN"" port discussed above. You'll also need to expose the ""Server RPC"" port 8300/tcp in order for RPC forwarding to work. All servers participating in the WAN should be able to reach each other on 8300/tcp.
",slackpad,shakisha
1914,2016-04-12 16:01:33,"Hi James @slackpad , thank you really much for your answer;
i still have got troubles for making this wan consul work properly, this is my configuration:



This remote consul server has got in the configuration the bind address configured as lan.

When i start consul on wan client i receive an error that the wan is available only in server mode.
After i switch to server, this is was i receive:



Where i'm lost? in the documentation i cannot find nothing about this issue ;(
",shakisha,slackpad
1914,2016-04-15 00:00:37,"Hello @slackpad , still not have got success on this :-(

Have you got any kinda of update for me? Thank you a lot!
",shakisha,slackpad
1914,2016-04-15 05:34:30,"Hi @shakisha I think it might be `""bind_addr"": ""MY LAN INTERFACE""` - is that interface reachable by the other server (that's the TCP connection failing to `SERVERIP:8302`)? If there are multiple interfaces then you can remove that config to bind them all and then set [`advertise_addrs`](https://www.consul.io/docs/agent/options.html#advertise_addrs) for `serf_lan` and `serf_wan` for the IP addresses for that server to advertise others should contact it on.
",slackpad,shakisha
1914,2016-04-15 07:21:33,"@slackpad : this is exactly the part of the docs which I didn't get.
on the bind address I have only lan interface because I have got 10 clients in the local lan (datacenter0)

in datacenter ""lon1"" I have the configuration listed above and connection refuse error, but from tcpdump in pretty sure that lon1 server is contacting the server at ""datacenter0"".

should I totally remove bind address and use https://www.consul.io/docs/agent/options.html#advertise_addrs  or put only advertise wan address? 

will be secure keeping only that port with encryption enabled? 

UPDATE:i have tried putting these values in the configuration of datacenter0 and lon1:



but didn't worked, still the same ""getsockopt: connection refused"" (firewalls are disabled on both side).

Also i've tried to remove bind_address, but even with serf_lan,wan and rpc parameters, consul refused to start because of multiple private ip address on the machine.
I'm desesperated
",shakisha,slackpad
1914,2016-04-15 19:56:24,"Hi @shakisha and sorry for the trouble on this one. It looks like there's a bug where it's doing the private IP check, even though you've specified the `advertise_addrs` structure. The individual form of these configs looks like they should properly skip that check:



You are right that this type of configuration will result in Consul binding to all interfaces on a machine so you'd want to enable encryption for the serf ports and TLS w/verification for the RPC port. Many folks bind everything to the LAN interface and use a NAT / VPN / tunneled connection to avoid exposing anything externally.
",slackpad,shakisha
1914,2016-04-15 20:05:32,"Hi @slackpad, 



this is very a GREAT idea, but how to do that if vpn is on tun0 interface and i have to listen on both eth1 (lan) and tun0 (vpn)? 
",shakisha,slackpad
1914,2016-04-15 21:02:02,"@shakisha I was thinking for the case where some other box provides the gateway - if the server itself has the tunnel then there's currently no way to support this other than bind 0.0.0.0 per https://github.com/hashicorp/consul/issues/1914#issuecomment-210617451 and possibly some firewall rules to pare down the configuration. Once we get #473 and the option to bind (potentially multiple addresses) for each function (wan, lan, rpc) then this should get easier to configure.
",slackpad,shakisha
1914,2016-12-02 14:52:51,"@shakisha please give the latest code in `master` a twirl and let us know.  The syntax for selecting IP addresses, such as getting the first ""usable"" IP address on an interface, or any other manner of network craziness is likely possible now as a template evaluated address parameter can be passed to Consul addresses (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



Very few people should need to do anything as obscene as shown in the last example, but the functionality is there should you need it.  I gave this issue a quick read and it seems like you could use this configuration enhancement to select the `tun0` address for the `bind_addr` and then use a different parameter value for the `advertise_addr`.  This doesn't solve your exact problem of listening on multiple interfaces or IPs, but it's on its way in the near future.

With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).

If this doesn't solve your issue, let us know.",sean-,shakisha
1914,2016-12-17 18:19:03,"Hello @sean- and @slackpad ;

thanks for your answers. I explain better my situation so we can make a big step next to enhance this consul version;
@sean- of course, i've seen your reply just yesterday; can you confirm that i can test directly with the 0.7.2 rc?

Actually i have got two datacenters:

DC1 datacenter with only a single consul, wan connected machine.
DC2 datacenter with a 6 consul, lan connected machines and every one with a public ip address.

basically, from DC1 datacenter, i want query the DC2 datacenter to have got a list of pubblic ip addresses of all the DC2 machines (to use it with consul-template, another project from you which i love).

So when running this command on the single consul machine of DC1:

`
or

`
i get in BOTH CASES
>rpc error: failed to get conn: dial tcp IP_ADDRESS_OF_THE_NODE_ON_DC2
>:8300: getsockopt: connection refused

these are the configurations that i used:
(@sean- i'm sorry if i didn't test your way like 
`
but i don't know the exact syntax to put it inside configuration file; i don't like to use the command line :-) )

*CONFIGURATION OF NODE ON DC1*
`

*CONFIGURATION OF NODE ON DC2*
`",shakisha,slackpad
1914,2016-12-17 18:19:03,"Hello @sean- and @slackpad ;

thanks for your answers. I explain better my situation so we can make a big step next to enhance this consul version;
@sean- of course, i've seen your reply just yesterday; can you confirm that i can test directly with the 0.7.2 rc?

Actually i have got two datacenters:

DC1 datacenter with only a single consul, wan connected machine.
DC2 datacenter with a 6 consul, lan connected machines and every one with a public ip address.

basically, from DC1 datacenter, i want query the DC2 datacenter to have got a list of pubblic ip addresses of all the DC2 machines (to use it with consul-template, another project from you which i love).

So when running this command on the single consul machine of DC1:

`
or

`
i get in BOTH CASES
>rpc error: failed to get conn: dial tcp IP_ADDRESS_OF_THE_NODE_ON_DC2
>:8300: getsockopt: connection refused

these are the configurations that i used:
(@sean- i'm sorry if i didn't test your way like 
`
but i don't know the exact syntax to put it inside configuration file; i don't like to use the command line :-) )

*CONFIGURATION OF NODE ON DC1*
`

*CONFIGURATION OF NODE ON DC2*
`",shakisha,sean-
1914,2016-12-22 18:44:55,"@shakisha Try with the following config snippets:

CONFIGURATION OF NODE ON DC1



You will have to plug in the IP/DNS addresses for `retry_join_wan`.  It would be more concise if you didn't want to pick out an IP address from a particular interface name because then you could use something like `GetPublicIP` or `GetPublicInterfaces`, or `GetPrivateIP` or `GetPrivateInterfaces`.  The same type or style of configuration could be used for the second configuration block.

If you want to test and experiment via the CLI, you can via:



Just be sure to re-escape the double quotes before injecting the working template back into your Consul config.  Keep us posted!",sean-,shakisha
1914,2016-12-22 18:56:39,@sean- doing now ðŸ‘ ,shakisha,sean-
1914,2016-12-22 19:19:04,"@sean-  and if i push in this way i have got:

`

>Error decoding '/etc/consul/conf/config.json': invalid character 'e' after object key:value pair",shakisha,sean-
1914,2016-12-26 14:20:14,"@sean-  should i put these inside the configuration file? 

>>> $ sockaddr eval 'GetInterfaceIP ""eth0""'
$ sockaddr eval 'GetAllInterfaces | include ""name"" ""eth0"" | sort ""type,size"" | include ""RFC"" ""6890"" | include ""flags"" ""up|forwardable"" | attr ""address""' 
>>>


Like 

`

?",shakisha,sean-
1914,2017-02-09 12:29:40,"Thanks @sean- 
ok, two issues now;

1. The ""{{ GetInterfaceIP \""eth0\"" }}'"" takes a strange ip address (10.9.2.0) which is not my eth0 ip.
 
2. from the consul wan machine, ran 
>curl http://localhost:8500/v1/catalog/nodes?dc=de01

and i have got
`

on iptables i have got these rules:

`",shakisha,sean-
1914,2017-02-09 12:55:03,"Basically it seems that consul doesn't listen on port 8300 for the requests from wan machine. 
I cannot find a solution.

@slackpad  have you got an idea?",shakisha,slackpad
1914,2017-02-09 17:40:08,"ok, i have identified the issue and got a workaround;

if i set 
""bind"" to PRIVATE INTERFACE (LAN)
""serf_wan_bind"": ""PUBLIC INTERFACE"",
""serf_lan_bind"": ""PRIVATE INTERFACE"",
**NOTHING WORKS**

but if i set
""bind"" to PUBLIC INTERFACE (WAN)
""serf_wan_bind"": ""PUBLIC INTERFACE"",
""serf_lan_bind"": ""PRIVATE INTERFACE"",

everything works perfectly ( i have at the moment a lot of Refuting a suspect message) but seems everything works.

basically the RPC forwarding is not working as expected.

-serf-wan-bind doesn't allow queries from other consul wan on port 8300 

Why this issue? @slackpad  is this a bug?",shakisha,slackpad
1913,2016-04-05 17:19:41,"Hi @sunfaces please take a look at these spots, which have all the details:

https://github.com/hashicorp/consul/blob/master/GNUmakefile#L53-L58

https://github.com/hashicorp/consul/blob/master/command/agent/bindata_assetfs.go

https://github.com/hashicorp/consul/blob/ea62d297565a1fec78bfa66e43beeecb504d13d5/command/agent/http.go#L283

It's all based on https://github.com/elazarl/go-bindata-assetfs.

Hope that helps!
",slackpad,sunfaces
1912,2016-04-12 09:03:15,"Hi @tpham-here if you run `consul members -wan` on that server does it show any other servers on the WAN? I'm wondering if that server isn't properly joined to any others in the WAN, or it has some bogus entries for failed servers. If it doesn't look right you should be able to `consul join -wan <another server>` to get it introduced to the other WAN members.
",slackpad,tpham-here
1905,2016-04-05 07:25:53,"Hi @rom-stratoscale - this would require some Consul API support to do properly. Consul currently doesn't care about or index the values, so it's not likely we'd search those, and we currently don't have an index that can do general searches over keys, so we'd need to think about the best way to support something like this.
",slackpad,rom-stratoscale
1905,2016-07-18 15:59:33,"agree with @slackpad. i needed the same functionality and i was able to setup something to help me by combining `consul template`, `elastic search` and `elasticui` (an `angularjs` based UI over ES). It's a `quick & dirty` solution - done with minimal coding - within couple of hours. 

https://github.com/awmanoj/consul-search
",awmanoj,slackpad
1904,2016-04-27 18:53:25,"@slackpad This has all the downsides of push based metrics. You never really know when something happened. And beside that, if you have a pull based monitoring system like Prometheus not having any way to pull in metics and having to resort to some kind of bridge make it worse.

I think consul should provide the metrics on some point for pull. See this discussion: https://github.com/hashicorp/consul/issues/817
",discordianfish,slackpad
1904,2016-08-10 20:22:32,"Hi @discordianfish thanks for your thoughts on this. I haven't had any recent cycles to devote to this, but I'll give it another look.
",slackpad,discordianfish
1904,2016-08-10 20:37:30,"@slackpad That would be great! Also see my suggestions in #817 
",discordianfish,slackpad
1903,2016-11-22 17:19:00,Hi @calvn haven't seen any similar reports to this one. Have you seen this again with any of the newer versions of Consul built with newer Go versions?,slackpad,calvn
1903,2016-12-15 05:18:19,"Hey @slackpad sorry for the delayed response, the issue was no longer being reported on our end so it's good to close.",calvn,slackpad
1897,2016-04-13 05:10:28,"Hi @hairyhenderson thanks for the PR! Instead of an environment variable that applies to all checks it seems like this would be better as a new Boolean field in https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L43 so it could be configured per-check. If the sense of the field is ""skip"" then it will default to `false` for existing checks and do the right thing.
",slackpad,hairyhenderson
1897,2016-04-13 13:31:48,"Thanks for the feedback, @slackpad - that's a good idea. I'll incorporate that :)
",hairyhenderson,slackpad
1897,2016-07-05 20:21:22,"Thanks @hairyhenderson, appreciate the contribution! I'm going to close this in favor of #1984. I agree with @slackpad that this fits better as a parameter of the check definition.
",ryanuber,hairyhenderson
1897,2016-07-05 20:21:22,"Thanks @hairyhenderson, appreciate the contribution! I'm going to close this in favor of #1984. I agree with @slackpad that this fits better as a parameter of the check definition.
",ryanuber,slackpad
1896,2016-04-13 04:55:18,"Hi @samber thanks for opening an issue, I'm going to close this as a duplicate of #1184.
",slackpad,samber
1893,2016-04-13 04:52:53,"Hi @DDuTCH take a look at the `WriteOptions` parameter to `Register()` - you can use that to pass a token:

https://github.com/hashicorp/consul/blob/master/api/api.go#L63-L65
",slackpad,DDuTCH
1892,2016-04-12 09:14:23,"Hi @abhimanyuvarma there's no built-in support for this in Consul. The best way to implement something like this is to put the logic into a script check and summarize the overall passing/warning/critical state to Consul via its return code. Hope that helps!
",slackpad,abhimanyuvarma
1889,2016-04-12 07:58:57,"Hi @mytwilight do you know how you have https://www.consul.io/docs/agent/options.html#leave_on_terminate configured? With Consul agents (other than servers) it's generally desirable to have them leave when they shutdown and re-join when they start back up again, which should cleanly handle the transition to the new IPs.
",slackpad,mytwilight
1888,2016-04-12 18:57:18,"Hi @markbugejacba this is a bit of a subtle artifact of configuring Consul to allow stale DNS responses. Assuming that you've enabled https://www.consul.io/docs/agent/options.html#allow_stale, there will be a window after the outage occurs (outage being no Consul leader) where Consul servers will still provide DNS results based on their own in-memory store. Once the https://www.consul.io/docs/agent/options.html#max_stale window has been exceeded, it will attempt to retry the RPC requests internally, which will fail because there's no leader, so you will start getting `SERVFAIL` responses.

Does this explanation fit with how you've got things configured? This seems like the right behavior given that stale responses are allowed, and lets the cluster better ride out brief moments without a leader, such as during leader elections. We are also planning on making this more robust with some internal retries under https://github.com/hashicorp/consul/issues/1554.

/cc @sean- 
",slackpad,markbugejacba
1888,2016-04-12 20:06:41,"Hi @Oloremo the `allow_stale` configuration is set on each client agent but is partly implemented on the Consul servers. Clients connect to any of the Consul servers, and if staleness is not allowed then read requests are internally forwarded to the leader. If staleness is allowed, then any server can fulfill the request, and the client decides if the result is fresh enough to use (otherwise it will re-request and turn off `allow_stale` just for that request). There's currently no caching in the client agents themselves.
",slackpad,Oloremo
1888,2016-04-12 20:18:29,"@slackpad Let me rephrase this:
Currently all hosts in my network do resolv lookup via my consul _masters_. If I'll add allow_stale = true to _master_ consul nodes, will this allow them to answer to dns loopup request for the ""max_stale"" period during the ""no leader"" situation? 

By dns loopup request I mean basic glibc one, like ""host nodename.node.consul"".
",Oloremo,slackpad
1888,2016-04-12 20:23:36,"@Oloremo ah ok - yes you'd need to set `allow_stale` on your Consul masters if they are handling DNS for your network. That should allow them to service requests in the absence of a leader, up to the maximum staleness you configure.
",slackpad,Oloremo
1888,2016-04-12 20:32:00,"@slackpad Thank you! 
",Oloremo,slackpad
1888,2016-04-13 05:38:13,"@slackpad We do indeed have `allow_stale` enabled on all of our servers, so that would explain the `NOERROR` responses.

Right now, I it appears that the DNS service remains active and will happily return data retrieved from other data centers (where the prefix of the other data center was explicitly specified,) whilst returning `SERVFAIL` only for calls that would otherwise have been serviced within the failed data center.

We're still keen to understand if it would be feasible to devise a method for DNS resolvers to reliably detect when the cluster in a given data center has failed, so as to avoid referring/forwarding DNS traffic to failed servers. Ideally, we'd like the option for the DNS interface to completely disable itself on any server that is no longer authoritative (ie. minority split brain or complete cluster failure.) for its local data.
",markbugejacba,slackpad
1888,2016-04-13 17:16:40,"@markbugejacba if you are seeing a difference between remote and local behavior it sounds like there might be a difference in how `allow_stale` is configured on the agents. The `allow_stale` configuration of the agent _servicing the DNS request_ is what determines the behavior. If an agent (even if it's a server) in dc1 is handling a DNS request for a server in dc2, then it's the agent in dc1's `allow_stale` setting that gets passed along in the RPC request.
",slackpad,markbugejacba
1887,2016-03-29 06:09:47,"Hi @ChrisAubuchon , that's an interesting idea that we will consider.  Thanks for suggesting this.
",sean-,ChrisAubuchon
1886,2016-04-12 09:00:03,"Hi @sstarcher - this is an odd one - Raft uses the `go-metrics` global so it _should_ pick up Consul's settings. Will have to dig a little to see what's going on here.
",slackpad,sstarcher
1885,2016-03-28 18:11:00,"Hello @akamalov .  This is by design, actually, however this can be fixed by giving the anonymous token read privileges to the KV store.  Try giving the anonymous key read privs:



Let us know if that doesn't work.

https://www.consul.io/docs/internals/acl.html
",sean-,akamalov
1885,2016-03-28 18:56:19,"Sorry @sean- , last question: will this be a correct syntax ?



...and submit it to Consul:


",akamalov,sean-
1885,2016-03-30 18:42:25,"@sean- Sean any feedback or pointers ?
",akamalov,sean-
1885,2016-04-13 05:16:22,"Hi @akamalov you might also want to remove the [`acl_token`](https://www.consul.io/docs/agent/options.html#acl_token) configuration from your `server.json` (and possibly any clients where you've configured it). This is sent in lieu of the anonymous token if none is given, and it looks like that token doesn't have the read permissions.
",slackpad,akamalov
1885,2016-04-13 16:56:33,"@slackpad Will do James. However, it shouldn't be the reason for 403, right ?
",akamalov,slackpad
1885,2016-04-14 14:33:37,"@slackpad 

Thanks James again. It did work. I went ahead and assigned proper rights to **acl_token** and web UI came up right after. Thanks yet again!
",akamalov,slackpad
1884,2016-04-13 05:06:47,"Hi @mtchavez thanks for the PR! Those retries look pretty reasonable and I've seen those fail from time-to-time as well.
",slackpad,mtchavez
1881,2016-04-25 05:49:28,"Hi @BRMatt thanks for the PR - been a little backed up with reviews so I'll take a look at this as soon as I can.
",slackpad,BRMatt
1881,2016-06-01 18:56:34,"@slackpad any thoughts on this?
",BRMatt,slackpad
1881,2016-08-10 23:40:59,"@BRMatt sorry for the delay. I'm working on the 0.7.0 release right now, but I'll try to give this some cycles shortly after that's done so we can get this into the release that follows.
",slackpad,BRMatt
1872,2016-04-05 05:57:37,"Hi @trong please take a look at https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/consul-tool/03WSqxvspno. Hope that helps, and feel free to re-open or continue on that thread if you have any questions.
",slackpad,trong
1871,2016-03-24 00:57:24,"Hi @Amit-PivotalLabs, your statement _all the servers end up being part of a common WAN gossip pool where most things can't talk to most things_ is spot on with respect to what will happen.  Unfortunately, the current WAN semantics require the servers to be a fully connected mesh. This will kind of work with a few servers, but the ones that can't talk to each other will start declaring other servers failed and they will start dropping in and out of the WAN pool of servers.

We hope to have a better solution for this type of application but it's a ways away. Is there any way you can allow TCP/UDP on 8302 among just your Consul servers? If you do that, you should be able to look up things like `service.dc2.consul` from `dc1`.
",slackpad,Amit-PivotalLabs
1871,2016-03-25 03:05:22,"@slackpad thanks for your incredibly fast response!  It will depend on the user whether they are willing to poke these holes in their ACLs, I suspect some will not.  Anyways, the clarification was very helpful.

Cheers,
Amit
",Amit-PivotalLabs,slackpad
1871,2016-04-01 03:04:44,"@slackpad what would you have in mind for WAN semantics to support this use case?  This is something we would be happy to submit a PR for.  Is it a ways away due to complexity, priority, both?

/cc @dieucao @onsi
",Amit-PivotalLabs,slackpad
1871,2016-04-05 21:51:15,"@b if I understand correctly, WAN in Consul just pertains to joining nodes in a particular gossip pool; Serf is the gossip protocol implementation.  I believe the Raft consensus does not apply to WAN.
",Amit-PivotalLabs,b
1870,2016-03-23 19:28:10,"Hi @slawekgh the gossip encryption feature is used to protect from other nodes joining the cluster (it's basically providing security for the traffic on ports 9301 and 9302 in your example), but it doesn't provide any security for the HTTP APIs. Docker swarm is talking to Consul over HTTP. That can be secured by enabling TLS and turning on the verify options - https://www.consul.io/docs/agent/options.html#ca_file.

Swarm isn't [joining the cluster](https://www.consul.io/docs/internals/gossip.html), it's registering things with Consul's APIs. Usually you'd only expose Consul's HTTP interface on the loopback interface, and you run a Consul agent on each node in your cluster. Then swarm would be connected to `consul://127.0.0.1:9500` and that machine would be required to have the proper encryption key in order to join the rest of the cluster.
",slackpad,slawekgh
1869,2016-03-23 16:34:34,"Hi @throrin19 I'm not an expert with Kong but from a quick look it doesn't look like it has a Consul integration. It looks like it manages registration of APIs internally via a REST API and is super focused on HTTP API proxying/scaling whereas Consul is much more general.

I'd encourage you to take a look at [Fabio](https://github.com/eBay/fabio), which is an open source project similar to what Kong is doing for HTTP APIs but built specifically to integrate with Consul. You run Fabio alongside Consul on your nodes, and you add tags like `urlprefix-/foo` to you Consul service definitions and Fabio will pick them up and start routing traffic based on the URL prefix. There's a good demo here - https://www.youtube.com/watch?v=gvxxu0PLevs.

Hope that helps!
",slackpad,throrin19
1868,2016-03-23 16:02:03,"Hi @trong, usually you'll run something like [dnsmasq](https://www.consul.io/docs/guides/forwarding.html) to expose Consul's DNS on port 53 without having to run Consul itself as root (dnsmasq will listen on port 53 and forward requests to Consul on port 8600). Then you'd edit your `/etc/resolv.conf` and put `127.0.0.1` in there so that Consul's DNS server is used for lookups on the host. Unfortunately, Docker won't let containers look up things on the `127.0.0.1` address by default because it runs its own server bound to that address, so you'll need to have dnsmasq bind to some other address on the host that's reachable by the Docker containers (the machine's external IP, or bridge IP) and use that address in `/etc/resolv.conf`. Hope that helps!
",slackpad,trong
1866,2016-04-05 05:29:46,"Hi @DaveBlooman thanks for the report - we will take a look!
",slackpad,DaveBlooman
1866,2016-04-06 14:46:29,"@slackpad -- I have some time this weekend to verify and resolve if you are not working this already. I most likely introduced the issue.
",moofish32,slackpad
1866,2016-04-06 23:42:06,"@DaveBlooman -- can you provide some additional details? 

Terraform version (mine is - 0.6.14)
The variable settings that differ from the defaults?

I have run terraform with a stock AWS Account in us-east-1 and us-west-2 (after subscribing to ubuntu AMIs). The only variables I have set are key name and key path.


",moofish32,DaveBlooman
1866,2016-10-01 23:19:38,"@viroos 

Direct from master I can build in a stock account. What is the error that terraform provides?





Terraform v0.7.4

We should probably update this to 0.7 but I think I saw a PR coming for that already.
",moofish32,viroos
1864,2016-04-05 05:28:40,"Hi @lud4ik if you query and don't get a key back the index is set to the last index that modified the KV store, since there's no key present that you are querying (you could use this to do a blocking query to wait for that key to get created, for example). If the key doesn't exist you can use `?cas=0` which means ""create the key only if it isn't already there"". Hope that helps!

> ?cas=<index> : This flag is used to turn the PUT into a Check-And-Set operation. This is very useful as a building block for more complex synchronization primitives. If the index is 0, Consul will only put the key if it does not already exist. If the index is non-zero, the key is only set if the index matches the ModifyIndex of that key.
",slackpad,lud4ik
1862,2016-03-22 05:06:42,"Hi @JoeOrtiz it's in the service lookup path as well - https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L688. Do you have https://www.consul.io/docs/agent/options.html#translate_wan_addrs set to `true` on the agent that's servicing that DNS request?
",slackpad,JoeOrtiz
1858,2017-02-09 14:07:37,@slackpad @here I got into the same issue. Renamed the datacenter name and restarted the service. But lost access to the cluster. What would be the best steps we can follow to rename the datacenter name without affecting the running cluster? ,gvenka008c,slackpad
1856,2016-04-01 19:13:05,"Hi @nejtr0n this currently isn't possible. Each datacenter maintains its own pool of servers that have their own Raft-based quorum. Once the different datacenters are WAN-joined the servers can forward queries so any datacenter can access the information in another, but there's a different leader in each datacenter. This guide has more details - https://www.consul.io/docs/internals/architecture.html. Hope that helps!
",slackpad,nejtr0n
1853,2016-03-22 00:37:06,"Hi @shakisha that log line is normal - that's what the agent prints when it is syncing the status of the check up to the Consul servers. Your check definition looks ok - what does the status of the check show with [this API](https://www.consul.io/docs/agent/http/health.html#health_service)?

For your case it would be something like http://127.0.0.1/v1/health/service/asterisk
",slackpad,shakisha
1850,2016-03-21 23:30:10,"Hi @ketzacoatl you are correct this currently isn't built-in. You'd have to look at all the edges and filter in your watch script, or we'd have to add some extra controls to the watch.
",slackpad,ketzacoatl
1850,2016-03-22 02:19:40,"AH, very cool, thank you for the reference @slackpad!
",ketzacoatl,slackpad
1846,2016-03-18 20:47:39,"Agree the change looks good, my only concern with this one was what @TeaBough had in terms of further plans. Was this for some Ginkgo-based testing of a project that uses Consul? I'd rather not introduce a testing framework into Consul core without thinking it through a little more first and seeing how it would fit with other HashiCorp products.
",slackpad,TeaBough
1846,2016-03-19 10:02:53,"@slackpad the idea is not to introduce another testing framework into Consul but simply to allow users that use  your testutils to integrate it into their own testing framework (in my case Ginkgo).
",TeaBough,slackpad
1846,2016-03-19 15:56:42,"@TeaBough ok makes sense - thanks!
",slackpad,TeaBough
1845,2016-07-05 19:47:42,"Hey @mssola, sorry for the delay here! I think this could also be avoided by simply enclosing the command to execute in quotes, like:



By automatically inserting double-quotes I think we are opening up the possibility for further unexpected behavior in cases where there may also be double-quotes in the command. Does that make sense?
",ryanuber,mssola
1843,2016-03-17 17:47:55,"Hi @bfloyd89 are you using the `consul lock` command, the Consul Go API client, or some custom code to do the locking?
",slackpad,bfloyd89
1843,2016-03-17 17:51:35,"Hi @slackpad, i'm using the consul lock command with no flags
",bfloyd89,slackpad
1842,2016-03-17 15:14:59,"Hi @sachinkarale you can change `.consul` by configuring this option - https://www.consul.io/docs/agent/options.html#_domain. The `.service` is part of Consul's interface and can't be changed, but you can change the part after that.
",slackpad,sachinkarale
1841,2016-03-16 15:06:33,"Hi @gt-tech this is currently not possible via those endpoints (see https://github.com/hashicorp/consul/issues/1781 and https://github.com/hashicorp/consul/issues/294). The only way to do this currently is using [prepared queries](https://www.consul.io/docs/agent/http/query.html) but those require a little state to be set up beforehand (create the query for multiple tags and then execute it). Closing this as a dup - please watch #1781 for updates on the other endpoints!
",slackpad,gt-tech
1840,2016-03-21 23:24:01,"Hi @brucewinger there's a discussion on this issue here - https://groups.google.com/forum/#!searchin/consul-tool/v2$20api/consul-tool/_2wQuRmyFHM/iOWKv8ViJQAJ. There's some design background there, as well as a possible workaround. Hope that helps! Please re-open / let me know if you have any more questions.
",slackpad,brucewinger
1840,2016-12-14 11:11:30,"Hi @slackpad, I am looking for a way out for the same, I am using the blocking query instead. unfortunately, I am not able to access google servers in my country, could you please elaborate the workaround here? thanks a lot!",hehailong5,slackpad
1836,2016-07-05 19:32:31,"@shaneog sorry about the delay here - this LGTM. Looks like we have a merge conflict but otherwise this seems like a good addition. :+1:
",ryanuber,shaneog
1836,2016-07-05 20:14:18,"I've rebased on master now @ryanuber 
",shaneog,ryanuber
1836,2016-07-05 20:55:07,"Awesome, thank you @shaneog !
",ryanuber,shaneog
1835,2016-03-21 23:03:15,"Hi @kamilchm I don't think Consul itself depends on Prometheus (it is referenced by go-metrics but not used by Consul). Can you provide a little more detail about which error you are seeing?
",slackpad,kamilchm
1833,2016-03-15 08:05:32,"Hi @Amit-PivotalLabs it sounds like they've been WAN joined at some point - https://www.consul.io/docs/guides/datacenters.html.

Does `consul members -wan` show a mix of servers from the different DCs if you run it from some of the servers? If you haven't joined them all, and if your WAN links are a little flaky, they can sometimes be unable to reach other, or possibly due to network rules they might not all be able to communicate in all directions. You'd need 8302/tcp, 8302/udp, and 8300/tcp between all the WAN servers for them to all communicate with each other, and you'd have to `consul join -wan` them at least one time to form a cluster.
",slackpad,Amit-PivotalLabs
1833,2016-03-15 08:43:56,"Hi @slackpad 

Thanks for the fast response.  They may have been WAN joined at some point, I can double-check that.  Do you think this behaviour should only be seen if they have been WAN joined at some point, otherwise this would be unexpected, yes?

Yes, `consul members -wan` shows a fairly eclectic mix.

#### DC1

##### Consul Server 1



##### Consul Server 2



##### Consul Server 3



#### DC2

##### Consul Server 1



##### Consul Server 2



##### Consul Server 3



#### DC3

##### Consul Server 1



##### Consul Server 2



##### Consul Server 3



All the VMs are within the same VPC, all part of the same security group that allows all TCP and UDP traffic within the security group.  Looks like they also had some Network ACLs set up possibly preventing traffic between clusters.  I've deleted the ACLs and restarted the consul processes on all the consul servers.  The `consul members -wan` still shows a mix.

I'm now also trying the following `nslookup`s on all 15 VMs:
- `foobar.service.cf.internal` (resolves on all machines, to the two IPs of the foobar nodes within the respective DC)
- `foobar.service.dc1.cf.internal` (resolves perfectly on all DC1 nodes, I get NXDOMAIN roughly 50-50 on all other nodes, seemingly independent of whether it's a DC2 node or DC3, independent of whether it's a foobar node or a consul server node, and retrying a couple times continues to give random results, different than the first try)
- similarly for the other to dc's. (dc2 works for DC2, but has random success for nodes in DC1 or DC3).

This is just a standard AWS VPC.  What would need to be done to make this less flaky?
",Amit-PivotalLabs,slackpad
1833,2016-03-15 14:50:26,"Hi @Amit-PivotalLabs correct - they have to be WAN joined otherwise the different datacenters wouldn't know about each other. If you'd like this to not be flaky the best thing would be to go to one of your Consul servers and `consul join -wan` each of the other servers. This will put them all into a single cluster and will give you the best chance of routing between the datacenters. You'll also want to arrange for newly-added servers to `-retry-join-wan` a list of servers to try at startup. If you can use the Atlas features of Consul it can handle the local and WAN join bits for you.
",slackpad,Amit-PivotalLabs
1833,2016-03-15 16:48:49,"Thanks @slackpad 

Atlas won't work for us as this needs to work in airtight on-prem networks.

Could you clarify your advice about reducing flakiness?  Does it suffice to have one server in one DC `join -wan` to one server in each of the other two DCs?  Would it somehow make things more robust if every server `join -wan`'d every other server in every DC?

If some consul servers are configured to `-retry-join-wan` some IPs intended for a consul cluster in another DC, and that other DC doesn't exist yet, will the first DC come up and work fine?  I.e. it will keep trying to `join -wan` the other DC, but until the other DC is up it will do it's own thing fine, correct?
",Amit-PivotalLabs,slackpad
1829,2016-03-21 22:56:50,"Hi @prashantabkari the [`-client`](https://www.consul.io/docs/agent/options.html#_client) option is what you set in order to get the HTTP (and DNS and RPC) sockets to bind to another interface. Currently, they default to loopback which I think is what you are seeing here. Note its generally a bad idea to bind these to an external interface from a security perspective. If you used `--net=host` for your Consul container I believe that would probably work better and allow you to keep these on loopback.

I noticed this in your log:



It would be interesting to trace that down and see what service registration is leading to that. It shouldn't be possible to get that message because the service should fail the validation much earlier than that point.
",slackpad,prashantabkari
1829,2017-02-16 11:32:11,"Hi @slackpad ,

Im also seeing this message in my log:
consul.fsm: EnsureRegistration failed: failed inserting check: Missing service registration

What do you mean by tracing that down? how do I find which service is responsible for this message?

Thanks",cshabi,slackpad
1828,2016-03-21 22:46:45,"Hi @suchkultur I think this is related to having an old Homebrew installation. These steps got things working for me:

https://github.com/caskroom/homebrew-cask/issues/15930#issuecomment-165849003
",slackpad,suchkultur
1826,2016-03-11 17:03:44,"Hi @Ashald this thread might be helpful for you - https://github.com/hashicorp/consul/issues/1186. It's not something we've vetted or officially supported, so we would need to do some work and testing for a procedure for this.
",slackpad,Ashald
1821,2016-03-21 22:33:37,"Hi @jimmypk it's hard to tell what's going on - are there any interesting logs from Consul that correlate to these timeouts? It could also be related to heavy packet loss if you have a heavily loaded instance. Any additional details you can provide would be helpful.
",slackpad,jimmypk
1819,2016-03-24 18:14:24,"@slackpad - Any idea tcp health isn't working for me, I'm running mongo container as per the reference in http://gliderlabs.com/registrator/latest/user/backends/#backend-reference ( consul tcp check ) , but in consul UI i didn't see the health point. Version : 0.6.4. please advise me.
",macbash,slackpad
1819,2016-03-25 06:58:33,"Hi @macbash can you provide a little more detail about ""i didn't see the health point""? Is the check not getting registered or is it registered but not working?
",slackpad,macbash
1819,2016-04-12 07:54:47,"@macbash the TCP check is relatively new to Consul. Is it possible you have an older version of registrator? You might want to ask the registrator folks about this problem as it sounds like it's not registering the check with Consul for some reason. Sorry about that.
",slackpad,macbash
1818,2016-03-10 01:32:13,"Thanks @slackpad.
",jzohrab,slackpad
1815,2016-03-11 04:20:11,"Hi @anthonybishopric we actually multiplex all the traffic from a given Consul agent back to a Consul server over a single TCP connection (using the yamux library), so the number of ports used on your servers should scale with the number of nodes in your cluster, but not with the number of watches. Do you run the Consul agent on each of your nodes?
",slackpad,anthonybishopric
1815,2016-03-11 17:16:12,"@slackpad thanks for the reply! To answer your questions and follow up:

No, we do not use Consul agents - just the servers. Unfortunately the gossip protocol really conflicts with our network ACL policy and we couldn't figure out a way to make them work, especially given that we wanted a single logical Consul cluster for our various datacenters. We implemented our own agent that does our deployment work without the gossip protocol and uses the HTTP API for updates and watches.

Is the multiplexing nature of Consul agents owed to the fact that they use the `net/rpc` package to communicate with servers? Is that API intended to be used by clients ever? If not, it seems like it might be very simple to add a GRPC wrapper for those same endpoints, with some established API contract and protos. If this is acceptable to you guys, we may have a PR coming your way.
",anthonybishopric,slackpad
1815,2016-03-11 18:53:38,"@anthonybishopric those underlying multiplexed interfaces are really intended to be internal to Consul so I don't think we'd expose or wrap them. I think the best way forward with this issue would be to look at improving the KV watch/blocking query capability which would benefit everyone. I'll do a little digging along that line.
",slackpad,anthonybishopric
1815,2017-02-16 05:15:33,"Hi @mpuncel I'll pull this forward so we can get it into an upcoming release. I think there's a pretty simple way to address this for KV to optionally send the deltas. We will need a little extra stuff to show that a key was deleted, but if we can figure out a good way to do that, the rest is a pretty simple filter.",slackpad,mpuncel
1815,2017-03-13 16:13:52,@slackpad What if there was an equivalent to the ?keys query that gave additional metadata about each key like modify index? That would make it a lot easier to build a client that watches keys and modify index and then re-fetches the value for keys whose index changed? That sounds like it would be easier to implement,mpuncel,slackpad
1814,2016-03-11 04:02:55,"Hi @tylert thanks for the PR. Can you do a quick rebase? These got reworked at the same time, but your change is still applicable.
",slackpad,tylert
1814,2016-03-11 14:00:24,"@slackpad Most certainly!  Rebase done.
",tylert,slackpad
1812,2017-01-10 15:52:15,"@slackpad which list?
",egidijus,slackpad
1808,2016-03-08 18:34:31,"Hi @bhuisgen sorry about that, a change merged yesterday introduced a Go 1.6 dependency. I updated our documentation to reflect that.
",slackpad,bhuisgen
1805,2016-03-11 04:14:07,"Hi @hehailong5 this is currently being requested under - https://github.com/hashicorp/consul/issues/1107. Not registrator-specific, but the ability to add service metadata.
",slackpad,hehailong5
1805,2016-04-25 05:02:45,"Hi @hehailong5, sorry for the delay on this one:

> 1. Regarding service registration, as the consul client is the only
>    contact point, I understand more than one node should be configured to run
>    as consul client to avoid the single point of failure situation. in this
>    case (having multiple consul clients), how do I configure my consul
>    registration tool? usually it requires to specify only one endpoint. what
>    if this endpoint is down? will it automatically forward the registration
>    request to an alive consul client in the cluster?

Usually you just run one Consul client per node, and have all applications on that node talk to their local client. That client will manage connecting to the Consul servers for you. Since the Consul client is in the same failure domain as the rest of the software on that node (the computer itself could fail), there's no need to have more redundancy at that level. Running the Consul client under a process manager that will restart it on failure should be sufficient.

> 1. If I register a HTTP health check in the consul, is it the consul
>    server or the consul client that will do the actual checking?

The client does the actual checking, and forwards the status to the servers.

> 1. is there a watchdog implemented in consul cluster? say initially I have
>    3 consul servers running in the cluster, if one of them goes down and then
>    goes online, will it be automatically re-joined in the cluster?

Yes it should re-join. There are some configuration options that could affect its ability to rejoin, such as https://www.consul.io/docs/agent/options.html#_rejoin, https://www.consul.io/docs/agent/options.html#leave_on_terminate, and https://www.consul.io/docs/agent/options.html#skip_leave_on_interrupt, but in general a restarted agent should reconnect with the cluster.
",slackpad,hehailong5
1800,2016-03-21 22:31:39,"Hi @thetuxkeeper this currently isn't configurable, if there's a recursor defined then Consul will try to use it if the reverse lookup fails.
",slackpad,thetuxkeeper
1799,2016-03-07 04:58:47,"Hi @Ashald thanks for opening an issue. I'm going to close this as a ""dup"" of #895 - we eventually plan to support https://github.com/hashicorp/hcl which has the benefits you cite, but is more inline with our other tools.
",slackpad,Ashald
1799,2016-03-07 05:15:42,"@slackpad Do you have it in roadmap already with some ETA or it's still not decided? Thanks!
",Ashald,slackpad
1799,2016-03-07 05:36:35,"Hi @Ashald no ETA yet, unfortunately.
",slackpad,Ashald
1798,2016-03-23 18:02:58,"@Ashald sorry for the delay reviewing this one - I'll try to knock it out this week.
",slackpad,Ashald
1798,2016-09-13 15:27:09,"Hey @Ashald sorry I never had a chance to get back to this one. Did you find you didn't need it? I'm getting ready to cut 0.7 tomorrow so am about to make a sweep through all these long standing PRs and issues so feel free to ping me if you'd like to try to get this in.
",slackpad,Ashald
1796,2016-03-06 03:47:40,"@ryanbreen you're right.  I'll add docs to match.
",doublerebel,ryanbreen
1795,2016-11-22 18:43:43,Hi @toddnni do you still see this with the newer versions of Consul?,slackpad,toddnni
1791,2016-03-11 02:33:20,"Hi @kamaradclimber if you run `consul members` on A does it show any of the other nodes?
",slackpad,kamaradclimber
1791,2016-03-11 07:58:31,"Thanks @slackpad for your answer. Sadly I've fixed the issue a few days ago by restarting the process.
",kamaradclimber,slackpad
1790,2016-03-11 02:30:01,"Hi @maroda if a node drops off, the `serfHealth` check will fail but the other checks from that node will be stale and can remain in a ""passing"" state. The `serfHealth` check is included by default as part of each service, so that host should not show up in DNS queries for that service nor in the /v1/health HTTP queries for that service if ""passing"" is requested. Once Serf gives up on that node and reaps it (normally 72 hours) then it should be removed from the catalog as well. Does that makes sense, or do you think it's not working like this?
",slackpad,maroda
1788,2016-03-11 02:23:47,"Hi @sitano thanks for the detailed report. We fixed a number of deadlock-type issues with yamux in Consul 0.6.0 - is it possible for you to try a newer version of Consul and/or do you have a reproducible setup where you can experiment?
",slackpad,sitano
1787,2016-03-10 07:27:27,"Hi @gtmtech - exactly, we'd call that out in the release notes and in https://www.consul.io/docs/upgrade-specific.html. For the case of 0.5.2 to 0.6.x we did change the protocol version but we designed Consul to ""auto upshift"" and start using new features automatically, so you don't need to manually pin protocol versions during that upgrade.
",slackpad,gtmtech
1783,2016-03-10 07:23:51,"Hi @TMaster a lot of things that happen in Consul can be pulled via blocking HTTP queries, so it should be possible to write tools to watch for changes and feed these into other systems pretty easily and efficiently. Were you looking specifically for operation actions like `consul reload`, though? I think that kind of information is mostly in our text logs at the moment.
",slackpad,TMaster
1783,2016-03-10 07:27:58,"@TMaster if you use a Windows Service Runner (e.g. NSSM (See https://github.com/hashicorp/consul/issues/758)) then you can easily redirect stdout to a text file and use normal text file streamers to collect the data. I've run a pretty extensive Windows Consul infrastructure and that's how I did it.

This was my setup code for Consul:


",highlyunavailable,TMaster
1783,2016-03-10 20:58:09,"@TMaster the monitor command is using an internal RPC interface that's subject to change, and is mostly intended for operators to do interactive debugging with an elevated log level. It's not intended as a general streaming log API.
",slackpad,TMaster
1782,2016-03-03 14:48:44,"@arie-stratoscale any ideas on how increment of the term on continuous self reelection related to - i/o timeouts?
",sitano,arie-stratoscale
1782,2016-03-03 15:04:15,"@arie-stratoscale yes, but it inc only local Term trying selfElect, so it should not affect whole cluster convergence. why it does not see other servers leadership or anything is the question... looks like some race cond. something prevents it to become a Follower of someone or Good Candidate.
",sitano,arie-stratoscale
1781,2016-03-10 07:39:55,"Hi @doertedev sorry I think the idea of multiple tags for ad-hoc queries over HTTP endpoints like catalog are still worth considering, and got lost in #294.
",slackpad,doertedev
1781,2016-03-11 04:23:31,"@doertedev I don't think I'd want to put JSON in there, the `?tag=&tag=...` kind of syntax seems like the most natural.
",slackpad,doertedev
1781,2016-11-26 03:04:23,"@doertedev please see this comment - https://github.com/hashicorp/consul/issues/294#issuecomment-98857436 and this stackoverflow answer - http://stackoverflow.com/a/24728298/205585

This is the most common way and for negation we could do ""!"" like it is done in prepared queries or nt-tag query as @slackpad suggested.",senthilkumar-kj,slackpad
1781,2016-11-26 03:04:23,"@doertedev please see this comment - https://github.com/hashicorp/consul/issues/294#issuecomment-98857436 and this stackoverflow answer - http://stackoverflow.com/a/24728298/205585

This is the most common way and for negation we could do ""!"" like it is done in prepared queries or nt-tag query as @slackpad suggested.",senthilkumar-kj,doertedev
1780,2016-03-10 07:11:27,"Hi @dropje86 not all requests are safe for the agent to retry but we can take a look and see if we can improve this. We've special-cased some common retry scenarios that we know are safe, though we've usually done that in the client library, not the agent. Will take a look.
",slackpad,dropje86
1780,2016-03-31 12:20:51,"@slackpad Any updates on this in the meantime? :)
",favoretti,slackpad
1776,2016-03-10 07:06:08,"Hi @saswatp we are looking into some structured logging libraries so we can take a look at this along with that effort.

/cc @sean- 
",slackpad,saswatp
1776,2016-03-12 03:36:36,"That would be great @slackpad  - Thanks !
",saswatp,slackpad
1775,2016-03-10 07:04:36,"Hi @shilov it looks like the ""unknown"" state is an old thing that was deprecated back in the 0.4.x series. We should probably just remove all references to it - it looks like it's only used in a dns_test.go unit test, and there's a reference in api/health.go. I'd be happy to take a PR if you are interested!
",slackpad,shilov
1773,2016-02-29 21:17:49,"@consultantRR thanks for reporting an issue. It's interesting the panic is coming from down here:

https://github.com/hashicorp/consul/blob/v0.6.3/command/agent/local.go#L575

Which looks like the checks list has gotten out of sync and it's pulling an empty ID.

Is there a particular job configuration in Nomad that seems to trigger this, or does it seem random? If you can predict when a node is likely to fail it would be interesting to pull https://www.consul.io/docs/agent/http/agent.html#agent_checks before it does a sync (this might be tricky because registering a new service/check will schedule a sync right away).
",slackpad,consultantRR
1771,2016-03-10 06:59:19,"Hi @JordyMoos since watches can only be created via config files or through running command line processes, we don't have plans to expose them via an API. Services are exposed because in addition to being created through config files, they can be created on the fly through the REST API, so it makes sense to always be able to list them.
",slackpad,JordyMoos
1770,2016-03-10 06:56:02,"Hi @devotox are you using Consul Registrator? Consul only has checks of type ""http"" but these can hit https endpoints. I'm not super familiar with Registrator, but you might want to try `SERVICE_3000_CHECK_HTTP=https://api/status`. If that doesn't work, I'd take this up with the Registrator folks.
",slackpad,devotox
1765,2016-02-26 19:30:27,"Hi @romansky can you post whatever you do see in the logs in a gist so we can see maybe where it's getting to when it crashes?
",slackpad,romansky
1765,2016-02-26 20:33:06,"@slackpad sorry to report that after investigation one side of the VPN was not configured to accept traffic from the subnet inside of it, it would pass traffic into it though. It was confusing because the it was working from the other side.. my bad!
",romansky,slackpad
1763,2016-03-10 06:39:35,"Hi @kaskavalci it should show the service health as not passing overall. Here's an example:

![image](https://cloud.githubusercontent.com/assets/673509/13661434/864f1654-e647-11e5-9194-92fc23d3edfd.png)

The fix was to change the status color of the top entry for that host, ""consul-client-nyc3-2"" in the example. @highlyunavailable is correct that some of the specific checks are showing green/stale since the node is dead, but since the `serfHealth` check is applied to the overall service health, the service is marked unhealthy overall for that node.
",slackpad,kaskavalci
1763,2016-03-10 06:39:35,"Hi @kaskavalci it should show the service health as not passing overall. Here's an example:

![image](https://cloud.githubusercontent.com/assets/673509/13661434/864f1654-e647-11e5-9194-92fc23d3edfd.png)

The fix was to change the status color of the top entry for that host, ""consul-client-nyc3-2"" in the example. @highlyunavailable is correct that some of the specific checks are showing green/stale since the node is dead, but since the `serfHealth` check is applied to the overall service health, the service is marked unhealthy overall for that node.
",slackpad,highlyunavailable
1763,2016-03-10 06:50:37,"Hi @slackpad thanks for the explanation, I didn't catch that part. However when we click on a particular service and list instances of that service in the cluster, then it will shown healthy, isn't it? Even though overall health is shown Critical, any watch that checks a particular service health will fail. Am I wrong?
",kaskavalci,slackpad
1763,2016-03-10 16:01:27,"@kaskavalci for that use case you probably want to do a service watch instead of one on the checks - it will do that for you (see the ""Type: service"" section here - https://www.consul.io/docs/agent/watches.html). That watches the health endpoint which takes into account all the node-level checks (like `serfHealth`) in addition to the service-level checks to provide a list of healthy instances.
",slackpad,kaskavalci
1761,2016-03-11 02:11:19,"Hi @JordyMoos and @hot13399 - we've thought about this as well but it adds a lot of complexity to Consul and creates issues around managing an ever-growing history of changes. I'd suggest using something like https://github.com/Cimpress-MCP/git2consul and not having folks change Consul's KV directly. This will get you the benefits you are looking for, and all the tooling that's available for Git to manage users, workflow, etc.
",slackpad,hot13399
1761,2016-03-11 02:11:19,"Hi @JordyMoos and @hot13399 - we've thought about this as well but it adds a lot of complexity to Consul and creates issues around managing an ever-growing history of changes. I'd suggest using something like https://github.com/Cimpress-MCP/git2consul and not having folks change Consul's KV directly. This will get you the benefits you are looking for, and all the tooling that's available for Git to manage users, workflow, etc.
",slackpad,JordyMoos
1755,2016-03-10 05:36:38,"Hi @Ashald thanks for opening an issue. I need to do a little research on this one to make sure I understand all the implications. Will follow up.
",slackpad,Ashald
1755,2016-03-11 16:40:00,"@slackpad here is a PR that implement this feature: https://github.com/hashicorp/consul/pull/1798

Nothing big - just an optional extra option. Please let me know what you think about the PR.
",Ashald,slackpad
1753,2016-03-10 05:33:59,"Hi @rbrutas you are correct that a wide-open write access to services will allow any application to disrupt any other. The documentation on this is here https://www.consul.io/docs/internals/acl.html (see ""Blacklist mode and Service Discovery"") and a little bit on here - https://www.consul.io/docs/upgrade-specific.html.

The best strategy is to give each agent a token that lets it write only to services that run on that agent and will be registered, and to give it read access to anything it needs to use (write access will imply read access). If you wanted a default read environment you could also let something like the anonymous token access to read all services and then give agent-specific tokens to control write access. Hope that helps! I'll close this out but feel free to re-open or post a question on the list if you need more help.
",slackpad,rbrutas
1752,2016-02-24 16:55:16,"Hi @mattwilliamson, @highlyunavailable is spot on in his comments. There are lots of folks using Consul KV from scripts as he described. Here's a working example:

`echo $(curl -s http://demo.consul.io/v1/kv/global/time | jq -r '.[0] .Value' | base64 -D)`

Consul does this so there's no way to break the JSON formatting for the arbitrary values. Tools like [consul-template](https://github.com/hashicorp/consul-template) and [consul-cli](https://github.com/CiscoCloud/consul-cli) also are pretty common in extracting keys and pave over this for you. His comment about lots of first class support for common KV use cases is also very apt. Instead of needing to make KV queries to look for services, for example, many applications can just use Consul's DNS interface and be configured simply with `foo.service.consul` to get a healthy instance.

We will take a look at a raw value (non-JSON) interface for the V2 API as an additional convenience.

Hope that helps!
",slackpad,mattwilliamson
1752,2016-02-24 16:55:16,"Hi @mattwilliamson, @highlyunavailable is spot on in his comments. There are lots of folks using Consul KV from scripts as he described. Here's a working example:

`echo $(curl -s http://demo.consul.io/v1/kv/global/time | jq -r '.[0] .Value' | base64 -D)`

Consul does this so there's no way to break the JSON formatting for the arbitrary values. Tools like [consul-template](https://github.com/hashicorp/consul-template) and [consul-cli](https://github.com/CiscoCloud/consul-cli) also are pretty common in extracting keys and pave over this for you. His comment about lots of first class support for common KV use cases is also very apt. Instead of needing to make KV queries to look for services, for example, many applications can just use Consul's DNS interface and be configured simply with `foo.service.consul` to get a healthy instance.

We will take a look at a raw value (non-JSON) interface for the V2 API as an additional convenience.

Hope that helps!
",slackpad,highlyunavailable
1750,2016-08-11 00:23:41,"Hi @alistanis sorry for the delay on this. Can you please rebase and run `go fmt` on your changes? Thanks!
",slackpad,alistanis
1750,2016-08-11 14:08:55,"@slackpad No problem! I'll take care of this tonight when I get home. I always run go fmt (or goimports) so I'm not totally sure what happened. 

Also thanks @multani, looks like I missed your comment the first time around.
",alistanis,multani
1750,2016-08-11 14:08:55,"@slackpad No problem! I'll take care of this tonight when I get home. I always run go fmt (or goimports) so I'm not totally sure what happened. 

Also thanks @multani, looks like I missed your comment the first time around.
",alistanis,slackpad
1749,2016-03-10 05:23:23,"Hi @csawyerYumaed thanks for the PR! I took your change and made it link to the existing table in the configuration page, and added the Atlas info.
",slackpad,csawyerYumaed
1748,2016-02-23 21:20:26,"@slackpad left minor comments. My biggest question here is what happens with the DNS interface if the tokens are eventually going to go away? It seems very restrictive to only allow the client's global ACL token access the PQ's. I suppose you could handle it by enforcing convention, where e.g. `private-*.query.consul` is hidden from DNS, but you also lose the ability to revoke access by ACL token. Also a bit strange that a user who creates a PQ and can query it from the API might have to jump through hoops to get someone with a management token to enable DNS access for the new query. The DNS interface is probably the most powerful way to use the PQ's so just want to make sure we have thought this through completely.
",ryanuber,slackpad
1748,2016-02-25 00:22:41,"@slackpad  the docs are looking great and nothing stuck out to me - merge when you are ready!
",ryanuber,slackpad
1747,2016-02-22 18:05:30,"Hi @Ashald this is a function of the longest prefix match behavior of ACLs (see https://groups.google.com/d/msgid/consul-tool/e1e286f7-f091-420f-93ee-3939268a23e9%40googlegroups.com?utm_medium=email&utm_source=footer). I think we'd need a special-case ""list"" permission to change this behavior. Consul KV doesn't really have knowledge of folders, though, so we'd need to see how this would look.
",slackpad,Ashald
1747,2016-02-23 16:17:56,"@slackpad can you please take a look at #1738 ? I believe it also might be an issue related to ACL resolution.
",Ashald,slackpad
1747,2017-03-20 22:03:09,"I agree that support for wildcards would be of great benefit to us. We have configuration data stored under different namespaces each ACL'ed off to the team that owns that namespace. Right now that involves explicitly denying every other namespace in every ACL. 40 teams = 1600 ACL rules and adding a rule to all 40 ACLs any time a new team is created :( . Being able to reduce that down to what @intelradoux suggested would be awesome.

@slackpack is there any update on possibly getting this support added?",hasPeterr,intelradoux
1746,2016-02-21 20:47:29,"Hi @devotox I think that can be controlled through registrator (which I assume is what you are using here). Please take a look at http://gliderlabs.com/registrator/latest/user/services/.
",slackpad,devotox
1745,2016-02-20 01:51:50,"Hi @Vanuan this is a bit of an unusual use case for Consul but it seems like it should be possible. Why not run a Consul agent on the machine where the test service is running? That will make sure things get cleaned up if the machine goes away, etc.
",slackpad,Vanuan
1745,2016-03-10 00:54:39,"Hi @Vanuan the Consul agent is part of the same failure domain as the machine it's running on so it doesn't make sense to fallback to another agent. If I understand your use case it seems like running an agent in CI alongside the service being tested is the way to go, and it makes sure things get cleaned up when all that gets torn down. I'll close this out for now but feel free to re-open or email the list if you have more questions.
",slackpad,Vanuan
1744,2016-03-11 02:26:25,"@jjones-smug sorry haven't had a chance to chase this down yet.
",slackpad,jjones-smug
1742,2016-03-10 05:13:25,"Hi @spellgen thanks for the fix! I added a couple more types to the list since it's best for the checks UI if we can get plain text, but `*/*` is also in there as a catch-all which should hopefully still work for your use case.
",slackpad,spellgen
1738,2016-02-24 23:12:39,"@Ashald this is an interesting bug, and applies mostly to external services because other services are usually managed by the agent which does use ACL Tokens proerly. Tracing this through the code, the the catalog register HTTP endpoint doesn't respect the `?token=` parameter passed in, nor does it take the agent's configured [ACL Token](https://www.consul.io/docs/agent/options.html#acl_token), so there's no way to get this to work at the moment, unless you do this:



This will ""fix"" it because the anonymous token, which looks like the only one that can go through the register path, will now be able to register the service.
",slackpad,Ashald
1738,2016-02-25 17:34:16,"@slackpad thanks for confirming the bug. Well I understand the proposed workaround but hope there will be a fix in upcoming release.
",Ashald,slackpad
1738,2016-02-25 17:37:34,"Hi @Ashald - totally agree! The workaround is not a good one - the right fix is to respect the token that's passed in.
",slackpad,Ashald
1738,2016-02-26 04:32:19,"@slackpad can you point me to the place where the issue exists? Maybe I will be able to contribute a PR with the fix.

Btw, are there any plans/schedule for next version release? Just to know whether I need to hurry with PRs etc. :)
",Ashald,slackpad
1738,2016-02-26 04:47:57,"@slackpad ok, I understand - code review, code freeze etc. Although I'll try to do the PR.

Last question: what's the best way to get in touch with Consul developers? I tried IRC channel but it doesn't seem to be very active. I'm working on integrating Consul with our infrastructure and thinking about contributing few PRs with additional features that will make Consul more flexible. So I might need to discuss few things while doing that. Sorry for off-topic and thanks for the answers.
",Ashald,slackpad
1737,2016-02-18 18:48:36,"Hi @sayden you are correct that Consul doesn't provide a single, centralized feed of cluster events. 

Watches under the hood are just doing blocking queries (https://www.consul.io/docs/agent/http.html) against some of the HTTP endpoints, so it is possible to write your websocket server completely outside the Consul core. Queries to the catalog and health endpoints can be done as a long poll, getting notified only when there are potential changes. Your server can consolidate these updates in any way it chooses and then pass the information along to clients. Our Atlas product has a similar implementation under the hood - it makes blocking queries against the catalog of nodes and the health of services and then exposes that to our application to power the dashboard, alerts, and things like chat notifications.
",slackpad,sayden
1736,2016-02-18 17:28:35,"@jefferai good call - we call build outside of the container but I'll add it there as well to perma-ban any cgo by anything that's built in there.
",slackpad,jefferai
1734,2016-02-26 10:10:52,"Hi @idubinskiy (just saw your IRC note) I didn't forget about this! Hopefully I'll get a little time tomorrow - I  want to look over the RFC and check a couple things before we merge.
",slackpad,idubinskiy
1734,2016-02-26 17:54:58,"@slackpad Thanks!
",idubinskiy,slackpad
1734,2016-03-09 07:14:12,"Hi @idubinskiy I took your PR and make a few small tweaks on the one linked above. Once CI passes I'll merge. Sorry for the delay in reviewing this one and thanks for the fix! I'd like to avoid compression as that puts an additional burden on clients to implement that correctly. Your fix should get at the root of the issue (compression was probably just making things work in some cases), and it doesn't seem necessary to compress on top of this change. We randomly shuffle the results, so even if the user is getting even 1 response back, things should work properly in most cases.
",slackpad,idubinskiy
1730,2016-03-02 00:05:58,"Hi @Veluu I think this possibly a dup of https://github.com/hashicorp/consul/issues/1057 - will take a look.
",slackpad,Veluu
1728,2016-03-01 21:02:57,"Thanks @mrcrilly - I took your PR and made a couple minor edits, merged under https://github.com/hashicorp/consul/pull/1777!
",slackpad,mrcrilly
1727,2016-02-17 02:23:35,"I will confirm this shortly and do a PR for the documentation.

Thanks @chuckyz 
",mrcrilly,chuckyz
1725,2016-03-01 20:23:05,"Hi @Kaign that's correct. Watches are really using blocking queries under the hood and that's where this behavior comes from. It's possible for a single query wakeup to summarize several changes that occurred together (or to wake up when there was no change).
",slackpad,Kaign
1724,2016-03-01 20:19:16,"Hi @kaskavalci thanks for opening an issue. I bet we are getting hit in here - https://github.com/hashicorp/consul/blob/v0.6.3/consul/state/state_store.go#L1306. This pulls all the checks for the node in the inner loop around services. We can profile to confirm but this seems like a reasonable thing to optimize.

Just to double check, are you hitting the health endpoint during your testing above?
",slackpad,kaskavalci
1724,2016-03-02 13:14:00,"Hi @slackpad thanks for your response. In fact we are hitting here https://github.com/hashicorp/consul/blob/v0.6.3/consul/state/state_store.go#L1271 . We used Consul to retrieve a particular service with a given tag. We would like to use ID here but there is no such API for that. Thus, we embedded a custom ID into tags. But this is not practical after few ten-thousand services.

It seems here there is a lookup by ID https://github.com/hashicorp/consul/blob/master/consul/state/state_store.go#L728 but I'm haven't tested its performance. Just to confirm, does `memdb` not let us to perform lookup by ID? 
",kaskavalci,slackpad
1723,2016-09-13 21:01:35,"@Vaccano m3.medium roughly equals 4 GB of RAM, Dual Core Processor. Our Consul cluster uses under 20 GB of hard drive space and it rarely spikes above 10 Mbps.
",polds,Vaccano
1723,2016-09-13 22:30:45,"@polds @slackpad Thanks!
",Vaccano,slackpad
1723,2016-09-13 22:30:45,"@polds @slackpad Thanks!
",Vaccano,polds
1722,2016-02-17 05:17:48,"Hi @lipanski this currently isn't supported and probably isn't something we'd add. Events in Consul are a pretty low-level mechanism, and are usually tied into some automation and not created manually (with the exception of `consul exec`, probably). Also, since they are managed at the gossip layer, displaying them would be pretty dependent on which agent you were talking to, unlike the other contents of the UI which comes from the state store managed centrally by the Consul servers, so it might change from agent to agent.
",slackpad,lipanski
1720,2016-02-17 05:30:32,"Hi @Niks-JJ we don't plan on adding any auth built-in - proxying it with another web server as @polds and @highlyunavailable have suggested is definitely the way to go.
",slackpad,Niks-JJ
1720,2016-02-17 05:30:32,"Hi @Niks-JJ we don't plan on adding any auth built-in - proxying it with another web server as @polds and @highlyunavailable have suggested is definitely the way to go.
",slackpad,polds
1720,2016-02-17 05:30:32,"Hi @Niks-JJ we don't plan on adding any auth built-in - proxying it with another web server as @polds and @highlyunavailable have suggested is definitely the way to go.
",slackpad,highlyunavailable
1720,2016-08-24 22:16:38,"@slackpad I think serving both UI and API over the same port kinda complicates this, though. 

+1 for even basic auth, it's silly to need to set up a whole proxy just to provide basic access control for what's supposed to be a full-featured cluster orchestration service
",jacohend,slackpad
1719,2016-02-17 05:00:38,"Hi @Niks-JJ the `curl` command you gave is using the same REST API you are attempting to use in your application code (showing things are good on the Consul side). It looks like you are not selecting the PUT verb somehow (I bet you are doing a POST, which is a common mistake). If you set that it should work like the `curl` call.
",slackpad,Niks-JJ
1718,2016-02-17 05:02:39,"Hi @dominikschulz if these are agents running as servers then this could depend on the amount of data you are storing, such as in the KV store. If they are client agents, then this would be an unusual amount of memory. Please let me know and then we can debug from there.
",slackpad,dominikschulz
1718,2016-02-22 22:29:29,"Hi @kendrickm it depends on whether the `-server` command line option or `server` JSON config option is specified. Can you please double check that in your configuration?
",slackpad,kendrickm
1718,2016-02-26 17:56:31,"@slackpad https://gist.github.com/kendrickm/2cbe991ed44c30ca7783 

Since the agent had to get restarted to pick up the config option, I can pull the stats again next week after the memory has had time to increase back up.
",kendrickm,slackpad
1718,2016-02-29 17:53:09,"@slackpad I don't know how but in one of my env which have only 50~ agents, consul service takes 1GB of memory, and we currently use it mostly for DNS.
The installed version is 0.6
",panda87,slackpad
1718,2016-03-09 11:15:56,"@slackpad do you have any updates on this issue?
",panda87,slackpad
1718,2016-03-10 22:02:20,"@slackpad pls look me attached graphs for the last 2 weeks goroutines metrics of my consul servers.
<img width=""1260"" alt=""screen shot 2016-03-11 at 12 01 28 am"" src=""https://cloud.githubusercontent.com/assets/3185476/13686046/6aa2c36c-e71c-11e5-93c6-241784f64a3a.png"">
Do you think that the PR above solve this problem?
Do you want to see another metrics?
",panda87,slackpad
1718,2016-03-10 22:41:08,"@panda87 if you had UDP closed you would have hit this bug. Fixing the firewall won't cause the goroutines to go down, but if you restart the agent it should stop leaking them. The PR will fix this issue, and I'm also about to release a test version of Consul with this fix (it'll be announced on the mailing list in a few minutes).
",slackpad,panda87
1708,2016-02-10 01:42:28,"Hi @Ashald thanks for opening an issue. This is indeed a ""feature"" in the current versions of Consul and we've got an open issue to add an ACL to protect this - https://github.com/hashicorp/consul/issues/1383.
",slackpad,Ashald
1706,2016-02-09 20:50:11,"Hi @gdiazlo thanks for opening an issue. I noticed this too during some local testing so I've got a test environment that does it and will see if the newer library version fixes the issue.
",slackpad,gdiazlo
1704,2016-02-09 21:21:11,"Hi @navinSing thanks for opening an issue. I opened an issue against our upcoming official Consul image repo - we can expand the documentation over there.
",slackpad,navinSing
1701,2016-02-08 21:50:37,"Thanks @highlyunavailable - agree the error message is super confusing here.
",slackpad,highlyunavailable
1701,2016-02-08 22:53:24,"@highlyunavailable , @slackpad : thank you issue resolved
",mg03,slackpad
1701,2016-02-08 22:53:24,"@highlyunavailable , @slackpad : thank you issue resolved
",mg03,highlyunavailable
1698,2016-06-09 17:06:17,"@slackpad thanks for your awesome work on this! We've been trying to use this feature but unfortunately it seems that it's only available through the DNS interface. What I would really like to see is the appropriately translated address available in the `""Address""` field of the node object when querying through the HTTP API.

I've been chatting with @evan2645 about this, and he thinks that the above should be do-able. I'm ready to start on a patch but wanted to check with you to see if there was any reason this isn't feasible, or if there was any reason it's a Bad Idea. Thanks!
",DWvanGeest,slackpad
1696,2016-02-07 05:45:49,"HI @CruzanCaramele can you include some logs from your Consul server as it starts up? It might also be good to add `-log-level=debug` so we can see what's going on.
",slackpad,CruzanCaramele
1696,2016-02-07 08:36:41,"hi @slackpad , the consul server does not start up at all, am unsure why that is. I configure consul at Packer build time, am thinking maybe am failing to start up the consul service/server, I am using puppet to configure other packages and services at packer build time as well, do I need to configure consul with puppet as well to make it start ?
",CruzanCaramele,slackpad
1696,2016-02-07 16:23:38,"Hi @CruzanCaramele usually you configure something like upstart to run Consul and keep it running. Here's a repository with sample scripts for configuring Consul using Packer on Ubuntu, including a sample upstart configuration: https://github.com/hashicorp/best-practices. Hope that helps!
",slackpad,CruzanCaramele
1694,2016-02-06 17:32:07,"Hi @jonDowdle thanks for the PR! Go's style is a single dash. Did you run into a situation where `-detailed` didn't work correctly?
",slackpad,jonDowdle
1694,2016-02-06 17:52:10,"@slackpad Doh. I didn't try the version with a `-`. `--` works and I was too quick with my PR! `-` does indeed work for me (OSX 10.11.3).

Apologies sir.
",jonDowdle,slackpad
1689,2016-02-05 23:54:27,"Hi @dfduarte - the SCADA/Atlas connection isn't HTTP, it's a TLS-secured TCP session with the https://github.com/hashicorp/yamux stream multiplexer running over that. There's an `atlas-endpoint` configuration directive or `SCADA_ENDPOINT` environment variable you can use to set the endpoint for address. I'm not a Squid expert but can you set it up with some additional configuration to proxy the TLS connection and set the endpoint to contact Squid?
",slackpad,dfduarte
1688,2016-02-05 23:27:13,"Hi @lattwood if I understand what happened, our next release on Go 1.6 should fix this by causing Consul to exit immediately. Does that seem correct? Thanks!
",slackpad,lattwood
1688,2016-03-04 02:19:19,"@justinclayton SIGPIPE is one of the 4 signals that systemd considers as OK when `Restart=on-failure` is set. You could use restart=always here.

https://www.freedesktop.org/software/systemd/man/systemd.exec.html
",joemiller,justinclayton
1687,2016-04-01 01:10:29,"@wuub Agreed, and thank you for that suggestion (I stubbed my toe on this earlier today, in fact).  The default behavior was changed in #1909 .  Where appropriate, we are very receptive to input regarding smoothing out operator and administrator user experience.  Cheers!
",sean-,wuub
1686,2016-02-05 11:54:26,"@blalor Thanks!! This is it!
",imtheghoul,blalor
1684,2016-02-04 17:03:26,"Hi @vrecan thanks for submitting a PR. I'm going to close this out per https://github.com/hashicorp/consul/issues/1682#issuecomment-179556874.
",slackpad,vrecan
1683,2016-02-04 00:38:32,"Hi @lym737 .  Right now you have to post one Service per API call.  In the future there might be a bulk register API, but the semantics around error handling become difficult (e.g. what do you do in a list of N services and service N-1 fails?).  Right now the semantics are clear and easy to understand, but it's something that has been considered in the past but never been fleshed out.
",sean-,lym737
1682,2016-02-04 00:55:31,"Hi @vrecan this is not something we really should support; Consul isn't designed to store large data blobs at all.

Having huge Raft log entries will trip a warning - https://github.com/hashicorp/consul/blob/eb27a02956e7e052c0bec6f96a0c0f7f6675f6a6/consul/rpc.go#L45-L47 because we've tried to keep the size capped for performance and throughput at the Raft layer.  Your best bet is to stick the data into another system and store a pointer to that in Consul. Another option is to chunk, similar to how `consul exec` does for command output.
",slackpad,vrecan
1681,2016-02-03 19:10:42,"Hi @Kaign you need to quote your URL for it to work properly (look in curl's output and you'll see the wait parameter isn't making it in). This will work:

`curl -v ""http://127.0.0.1:8500/v1/catalog/service/consul?index=4&wait=10s""`
",slackpad,Kaign
1680,2016-11-16 19:57:08,"@slackpad great thx ;)
",CpuID,slackpad
1680,2017-02-08 01:45:19,"@slackpad *bump*, I noticed it missed 0.7.3/0.7.4 :)",CpuID,slackpad
1679,2016-02-03 01:38:45,"Perfect, thanks @highlyunavailable and @slackpad!
",Amit-PivotalLabs,slackpad
1679,2016-02-03 01:38:45,"Perfect, thanks @highlyunavailable and @slackpad!
",Amit-PivotalLabs,highlyunavailable
1679,2016-02-03 14:23:58,"@Amit-PivotalLabs This is true for v0.6.0 or greater.
",fraenkel,Amit-PivotalLabs
1679,2016-02-03 20:23:45,"Thanks, noted.

On Wed, Feb 3, 2016 at 6:24 AM, Michael Fraenkel notifications@github.com
wrote:

> @Amit-PivotalLabs https://github.com/Amit-PivotalLabs This is true for
> v0.6.0 or greater.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1679#issuecomment-179263917.
",Amit-PivotalLabs,Amit-PivotalLabs
1674,2016-02-13 01:41:28,"Hi @glenwong - this should definitely not cause a leader election. This log line is very strange from your leader when the other node joins:



Is it possible that node is being started in bootstrap mode and maybe leading to a split brain situation?
",slackpad,glenwong
1674,2016-02-13 17:42:51,"Hi @slackpad. My consul info gives back this for two of the machines:



And this for the third:



And the config.json I'm using for the servers is:



I've tried taking out the  ""bootstrap_expect"" option as well as the ""skip_leave_on_interrupt"" but still continue to repro the issue.
",glenwong,slackpad
1674,2016-02-17 02:23:42,"@glenwong agreed - we should be able to fix this and avoid this situation. In practice this doesn't seem to come up very often - even an intermittent machine would have to hit kind of a sweet spot in the backoff timing.

You can set things like https://www.consul.io/docs/agent/options.html#allow_stale to allow other servers to service read requests (this is for DNS and there are similar controls for the HTTP endpoints) when a leader isn't available. This is helpful for riding out leader elections in general, and allow for reads to scale better across all your servers.
",slackpad,glenwong
1674,2016-02-26 17:18:00,"@slackpad You mention that there are similar configuration controls for enabling/permitting stale responses via HTTP endpoints. Sorry for the stupid question, but which settings are those ? I see the DNS-related state configuration settings, but nothing explicitly about HTTP responses. Thanks
",mrwilby,slackpad
1674,2016-03-10 06:44:19,"Hi @mrwilby those are controlled per-request and not configured on the agent. Please take a look at https://www.consul.io/docs/agent/http.html, specifically the ""Consistency Modes"" section. This is the most relaxed:

> stale - This mode allows any server to service the read regardless of whether it is the leader. This means reads can be arbitrarily stale; however, results are generally consistent to within 50 milliseconds of the leader. The trade-off is very fast and scalable reads with a higher likelihood of stale values. Since this mode allows reads without a leader, a cluster that is unavailable will still be able to respond to queries.
",slackpad,mrwilby
1671,2016-02-06 00:01:03,"Hi @anhcuong if you terminate the machines without giving the node a chance to gracefully leave, the cluster will detect it as failed and reap it after 72 hours. You can use the force-leave command to boot out a failed node sooner - https://www.consul.io/docs/commands/force-leave.html.
",slackpad,anhcuong
1670,2016-02-02 06:09:29,"Hi @danielbenzvi that error message is a little confusing - it's showing the raw Go time value which is in nanoseconds. The problem looks to be that https://www.consul.io/docs/agent/options.html#session_ttl_min is set to 3 minutes but by default `consul exec` tries to get a session with a duration of 15 seconds so the check fails. There's currently no command line option to change this TTL in `consul exec` so I think you'd need to lower https://www.consul.io/docs/agent/options.html#session_ttl_min in order to get things working.
",slackpad,danielbenzvi
1669,2016-02-02 02:47:01,"@JrCs Consul isn't really designed to do reverse lookups. It's generally only setup to resolve domains names with `.consul` in them.

This might work:
1. Install dnsmasq - set it to query Consul - but only for `.consul` domain names.
2. Use dnsmasq facility for reverse DNS records as detailed here:

http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq-man.html

Search for `--ptr-record` - also detailed here:

https://onemoretech.wordpress.com/2011/01/27/dnsmasq-reverse-lookups/

You could use Consul Template to write the specific configuration needed and drop it into a configuration folder.

I haven't done this with PTR records - but we use Consul with dnsmasq and it works well.
",darron,JrCs
1669,2016-02-02 16:07:26,"Ah - thanks @sean- I didn't know it did that. Learn something new everyday.
",darron,sean-
1669,2016-02-02 20:04:01,"The issue is that you end up with hundred of server directives unless I'm mistaken @sean- 
",scalp42,sean-
1669,2016-02-16 20:05:05,"Hi @JrCs - Consul only implements reverse lookups by nodes, using the node catalog under the hood. For the lookup you described it sounds like you could simply query for <name>.service.consul, which will contain a list of IPs running that service.
",slackpad,JrCs
1668,2016-02-02 05:56:19,"Hi @il9ue thanks for opening a PR!

The intent of this TODO was to lower the network utilization of coordinate updates, so pulling the list of coordinates down from the server would probably cost more than we save in this case. If we were to do this, we'd probably need to keep some state about the last coordinate we sent and then see how far we've moved from that and only send a new one when it's greater than something like 50 us. Looking back at this code, though, we regulate the rate of coordinates going up to the servers based on the size on the cluster - https://github.com/hashicorp/consul/blob/master/command/agent/agent.go#L603, so we should probably just remove this TODO. It's kind of an optimization on top of something that's already working well, so probably not worth the extra complexity.
",slackpad,il9ue
1664,2016-02-12 23:45:47,"Hi @ezjacob-maheim Consul uses the most specific rule by looking for the policy with the longest prefix match, so a setup like that should work. Unfortunately, we don't support wildcards so you'd need to make policies for each team/app/environment. Hope that helps!
",slackpad,ezjacob-maheim
1663,2016-02-02 05:27:49,"Hi @timmytofu I definitely see the appeal of enforcing this inside Consul itself, though I would hesitate to add this kind of functionality to the core - it's super difficult to hit everybody's use cases and we don't want to put any kind of complicated scripting capability in the KV set path. One option that might be a good alternative would be to use something like https://github.com/Cimpress-MCP/git2consul and enforce your policies on the input side with pre-merge checks / etc. just like you'd manage source code.

Will keep this open to think about it some more, but I think in general we'd lean towards doing this kind of enforcement outside of consul.
",slackpad,timmytofu
1661,2016-02-17 04:15:04,"Fixed in https://github.com/hashicorp/consul/pull/1703.

@MrMMorris I think #1221 is a different issue where we are truncating on the write side.
",slackpad,MrMMorris
1661,2016-02-17 07:33:11,"Thanks for fixing this @slackpad and @alistanis - appreciate that!
",darron,slackpad
1661,2016-02-19 21:29:29,"No problem @darron! Thanks for merging it @slackpad! 
",alistanis,slackpad
1661,2016-02-19 21:29:29,"No problem @darron! Thanks for merging it @slackpad! 
",alistanis,darron
1659,2016-01-28 07:34:19,"Hi @AI-PaaS can you explain a little more about what you are trying to do - do you have multiple instances of the service on the same host with different ports, or multiple instances of the service across different hosts?
",slackpad,AI-PaaS
1658,2016-01-28 07:40:18,"Hi @Amit-PivotalLabs were there other servers in the cluster previously? This line looks like there might be entries related to other servers in the Raft log since there's a different IP:

`2016/01/26 15:42:45 [INFO] raft: Added peer 168.72.182.27:8300, starting replication`

If you are trying to forcefully go down to a single node you can probably delete `peers.json` before you start this node in `bootstrap` mode.
",slackpad,Amit-PivotalLabs
1658,2016-01-28 20:18:29,"Hey @slackpad thanks for the response.

There were 3 servers.  It was then scaled down to 1 server, without changing the consul version or enabling TLS, and this was successful as far as I know.  It was then rolled with a new consul version and TLS enabled, remaining at 1 node, and this is what failed.  The plan after that was to scale back up to 3.

This process was done to migrate a 3-node cluster from non-TLS to TLS. We had to do an intermediate scale-down because we can't roll a cluster where one node is expecting encrypted communication and the other two are not.
",Amit-PivotalLabs,slackpad
1658,2016-02-05 02:37:24,"Thanks @slackpad 

On scale down, the nodes leaving the cluster should be doing a graceful leave, removing them from peers.json on all nodes.  What may be happening is if two nodes try to leave at the same time, the other node goes into outage mode, and perhaps the peers.json file on it doesn't get updated properly.
",Amit-PivotalLabs,slackpad
1656,2016-07-07 17:12:10,"@csghuser that is the correct way to configure Consul for servers connected to a
WAN.  It's not necessary to have this be configured in a full-mesh, however
there is no harm in having symmetry between all Consul servers participating in
the WAN pool.  The important part is that all members of the WAN eventually
converge to create a consistent pool.
",sean-,csghuser
1656,2016-07-07 18:39:02,"@sean- I consider this a bug, because when you connect two DCs together using command you expect it to mean for the entire cluster, this is why @wwalker  had connectivity problems.

Take look at for example Riak's MDC setup (http://docs.basho.com/riak/kv/2.1.4/configuring/v3-multi-datacenter/quick-start/) you just issue a single connection between the clusters it even obtains IPs of other nodes to connect to. It doesn't even matter what happens to the node you issued connections from, the cluster is connected.

Consul has all the tools necessary to accomplish the same thing.

I suppose one can use the configuration file, and that should work, it's essentially offloading work to something else. If it's done by hand is prone to mistakes, if is done automatically you'll need service discovery for the consul itself, plus dealing with special case like not listing own IP there.

Anyway as it is right now the join command line is totally useless. If you have 5 datacenters with 5 nodes won't you need to issue 80 joins to ensure that all nodes are connected with all nodes (5 \* 4 \* 4) so you won't encounter @wwalker's issues and then be on top of that each time a node is replaced (20 joins for a new node)

Edit: referenced wrong person
",takeda,wwalker
1656,2016-07-07 18:39:02,"@sean- I consider this a bug, because when you connect two DCs together using command you expect it to mean for the entire cluster, this is why @wwalker  had connectivity problems.

Take look at for example Riak's MDC setup (http://docs.basho.com/riak/kv/2.1.4/configuring/v3-multi-datacenter/quick-start/) you just issue a single connection between the clusters it even obtains IPs of other nodes to connect to. It doesn't even matter what happens to the node you issued connections from, the cluster is connected.

Consul has all the tools necessary to accomplish the same thing.

I suppose one can use the configuration file, and that should work, it's essentially offloading work to something else. If it's done by hand is prone to mistakes, if is done automatically you'll need service discovery for the consul itself, plus dealing with special case like not listing own IP there.

Anyway as it is right now the join command line is totally useless. If you have 5 datacenters with 5 nodes won't you need to issue 80 joins to ensure that all nodes are connected with all nodes (5 \* 4 \* 4) so you won't encounter @wwalker's issues and then be on top of that each time a node is replaced (20 joins for a new node)

Edit: referenced wrong person
",takeda,sean-
1655,2016-02-06 01:19:21,"Hi @muayyad-alsadi is it possible you are accessing the UI from multiple addresses and the token is stored with some other hostname? You can use your browser's dev tools to blow away the local storage as well - that's where the token is stored:

![image](https://cloud.githubusercontent.com/assets/673509/12863568/930b7db8-cc2c-11e5-8388-d3fb0016cbd8.png)
",slackpad,muayyad-alsadi
1653,2016-02-12 23:55:10,"Hi @muayyad-alsadi there's an explicit check to prevent this and I wasn't able to reproduce this behavior - https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L489-L491. Is it possible you've got some other configuration file with an empty item in that list?
",slackpad,muayyad-alsadi
1652,2016-02-02 03:02:33,"Hi @Veluu are all these subnets routable from any host in the cluster? Consul requires a fully connected mesh so is is possible that some set of servers can't see each other for routing or even firewall reasons?
",slackpad,Veluu
1652,2016-02-13 01:35:09,"Hi @Veluu one other thing to check, is it possible that you need to update the advertise address https://www.consul.io/docs/agent/options.html#_advertise? This will default to the bind address, but maybe the other address is the routable one? Issues of this type are almost always to do asymmetry in the ability of nodes to contact each other in the cluster.
",slackpad,Veluu
1646,2016-03-10 07:13:40,"Hi @doertedev we have a feature coming out very soon that will let you use a node's configured WAN address (even for non-server nodes) when talking to that node from outside its datacenter - https://www.consul.io/docs/agent/options.html#translate_wan_addrs.
",slackpad,doertedev
1646,2016-03-10 07:47:05,"Perfect! Awesome thanks @slackpad!
",doertedev,slackpad
1644,2016-02-06 01:23:20,"Hi @strarsis if you wan to disable update checks, this is the option to set - https://www.consul.io/docs/agent/options.html#disable_update_check.
",slackpad,strarsis
1643,2016-02-13 00:19:56,"Hi @strarsis the problem here is that you need to use the port number for the LAN cluster (8301) not the Consul client port (8500). It's trying to connect and getting an unexpected message back. If you use 8301 for a LAN join, or 8302 for a WAN join this should work.
",slackpad,strarsis
1642,2016-02-02 04:05:01,"@highlyunavailable is right - you have to join each sever to at least one other member of the WAN pool at startup. It's very similar to how the LAN pool works, and it's based on another instance of Serf under the hood, basically. If you can use the Atlas join feature it will join to the WAN pool for your servers - https://www.consul.io/docs/agent/options.html#_atlas_join.
",slackpad,highlyunavailable
1642,2016-07-07 03:39:40,"Thank you @slackpad @highlyunavailable
",tiagoalves83,slackpad
1642,2016-07-07 03:39:40,"Thank you @slackpad @highlyunavailable
",tiagoalves83,highlyunavailable
1640,2016-01-23 09:33:54,"@highlyunavailable Ah, excellent! We still haven't upgraded to 0.6, so we always got warnings on startup if it wasn't set. But then I won't update the PR :)
",carlpett,highlyunavailable
1640,2016-08-18 02:01:08,"Hi @carlpett thanks for the PR (and sorry for the delayed response). Given that we only distribute binaries outside of any packaging, this is probably better done as a separate project. We'd be happy to link to it from the community page.
",slackpad,carlpett
1638,2016-02-02 03:56:13,"Hi @cvvs if you just use `/var/lib/consul/rpc.sock` it should work. It keys off the leading slash to pick unix mode. Sorry for the late reply and please re-open if you are still having any issues!
",slackpad,cvvs
1637,2016-02-02 03:52:42,"Hi @discordianfish this is an interesting idea. One nuance is that the agents are actually the source of truth for service registration, so if the servers modified the central catalog of services then we'd have to add some special-case logic to keep the agent from canceling the configuration. We do have support via `EnableTagOverride` for doing this, just for service tags. One feature I could see that might be simpler is to be able to say ""tag service X for the lock holder with tag Y"". This would let you register the service in the usual way, but add a tag like ""master"" to whoever has the lock.
",slackpad,discordianfish
1637,2016-02-02 11:46:31,"@slackpad I'm not sure I understand the issue with canceling configuration.
I would keep things simple: Add service to local agent if lock is acquired and remove it if lock is lost. No assumptions about how many other services might get registered on other servers.
It's also not just for figuring out the leader within a number of services but also for 'singletons': I want to run only one instance of a service within my cluster and make sure if this goes down, another takes over. From a logical perspective this single instance of my service 'moves' to another host, so it doesn't make sense to have the have a tag on the active one given that all others simply don't exist (until they acquire a lock).
Another thing to consider are the health checks in this case: They will only work once the service is started which requires the lock. If I already register the service and health check even though I don't have a lock, I have a service marked failed in consul..
",discordianfish,slackpad
1637,2016-02-03 02:55:03,"@discordianfish ok this makes a lot more sense and would be simpler than I thought. You'd probably want to point the lock command at some JSON to register when it gets the lock and to deregister when it starts up / attempts to get the lock.
",slackpad,discordianfish
1637,2016-02-03 10:03:31,"@slackpad Yes exactly. I'm using this script as wrapper for now, but it's fragile and something build into consul would be awesome: https://github.com/Jodel/infra-scripts#consul-register
",discordianfish,slackpad
1630,2016-02-02 02:33:38,"Hi @Millnert,

Normally, Consul only verifies that a certificate is signed by a configured CA, it doesn't look at the hostnames. The config you cited is used by this feature - https://www.consul.io/docs/agent/options.html#verify_server_hostname. If `verify_server_hostname` is turned on, then Consul will also verify the hostname is `server.<datacenter>.<domain>`. This lets you create a special certificate just for servers to keep random clients with valid certificates from acting as a server.

I tagged this as docs because I think we can enhance the documentation about this. Does this make sense?

/cc @sean- 
",slackpad,Millnert
1629,2016-02-02 02:04:45,"Hi @moofish32 thanks for updating these! If you've gotten to test them then we can merge them in case they are useful to others. Only thing I saw from a quick look is that `GOMAXPROCS` doesn't need to be set any more with Go 1.5+.
",slackpad,moofish32
1629,2016-02-02 15:34:15,"@slackpad - I need to go back through and plum the `rhel7` variable and a few others. I will also kill the `GOMAXPROCS`

Thinking about this again though I'll probably call it `centos7`. It will take a couple of days to get the free time, in a bit of the busy season over here (as if there is a non-busy season).
",moofish32,slackpad
1629,2016-02-06 16:41:50,"@slackpad - so this change drifted a little. When I started I was going after just one and then I found a few others. In an effort to slim down I consolidated scripts. If you don't like this, let's just roll it back and I'll add only the rhel7/centos7 piece. I was a little annoyed I had to `subscribe` to use the centos AMI.

I'm looking into build issue with sudo. I may need to back track a bit.
",moofish32,slackpad
1629,2016-02-13 02:04:06,"Hi @moofish32 it looks like you need another rebase. If you were able to test the older scripts then we can update them all, but if not I'd prefer if we just updated the version 7 ones.
",slackpad,moofish32
1629,2016-02-13 14:36:22,"@slackpad rebased to master. A couple quick items:
- Tested - I ran the terraform script for each distro and verified the cluster was up with the right number of members. If there is a better way to test let me know.
- I updated all the Consul versions to 0.6.3, the PR you merged modified many to 0.5.x, was that intentional?
- The ""big change"" here is I refactored the bash installers into one script. IMHO I think it's easier to maintain.
",moofish32,slackpad
1629,2016-02-13 15:21:38,"@slackpad -- I am getting intermittent builds locally and on Travis. Is that new?
",moofish32,slackpad
1629,2016-02-13 16:43:00,"Hi @moofish32 moving up to latest Consul is definitely the right thing - sorry I regressed that with the older PR. We have a few tests that are timing dependent that are a little flaky and we are working on those. Your changes definitely don't interact with the unit tests :-)

I was looking through old issues and found this one that we might want to roll into this PR since you're in here - https://github.com/hashicorp/consul/issues/1304. You definitely want all three (8300 for RPC, 8301 for LAN, 8302 for WAN) to be exposed for servers and (8301 for LAN) for clients, though if things are working perhaps these are getting exposed anyway? The comment about a reboot seems apt, too. Would it be possible for you to take a look at that?
",slackpad,moofish32
1629,2016-02-16 04:32:57,"@slackpad  -- I was officially dominated by the linux distros today. I'll have a fix up in the next couple of days for all the issues you mentioned, but there is just enough difference between upstart in Ubuntu, Centos, and RHEL that I may have to move those back to separate files :( 

I thought about rendering a template inside a remote exec to append to file, but need to kick the tires one more time. 
",moofish32,slackpad
1629,2016-02-20 17:27:14,"@slackpad  -- All four OS variants are now tested and can be restarted. Obviously there is still an anchor dependency on the consul-0 host because that is the default join address. Please review and let me know if you find anything else.
",moofish32,slackpad
1629,2016-02-26 17:40:37,"@slackpad  -- rebased to latest master
",moofish32,slackpad
1629,2016-03-10 06:47:27,"@moofish32 thanks for all the work on this one! Looks good except we should knock this file out :-)

https://github.com/moofish32/consul/blob/update_terraform_rhel7/terraform/aws/terraform.tfvars
",slackpad,moofish32
1629,2016-03-10 14:25:41,"@slackpad  -- great catch, bad miss on my part but it was at least only the names; removed file and rebased.
",moofish32,slackpad
1629,2016-03-10 16:04:05,"@moofish32 thanks for all your work on this one!
",slackpad,moofish32
1628,2016-02-02 02:00:11,"Hi @st-isidore-de-seville I'll tag this as docs since we should add a note about it.

For a Consul client agent there should be a fairly small number of open file descriptors. The gossip layers will perform transient connections with a few other nodes, each connection to the client agent (such as for a blocking query) will open a connection, and there will be connections to usually one of the Consul servers. There are small extra things like your watch handlers, health checks, log files, etc.

For a Consul server agent, in addition to the above, you should plan on an incoming connection from each node in the cluster. This shouldn't be the common case, you would get 1/(number of servers), but in the worst case if there was some problem with the other servers you'd expect the other client agents to all connect to a single server.
",slackpad,st-isidore-de-seville
1627,2016-02-02 01:49:05,"Hi @ofbizbrazil - is this an official binary from https://releases.hashicorp.com/consul/0.6.3/ or from some place else? Now that Consul is 100% pure Go it should be easier to tweak the build settings if your platform is slightly different than our standard build.
",slackpad,ofbizbrazil
1627,2016-02-13 04:43:17,"Hi @ofbizbrazil - were you able to check if you were on 64-bit?
",slackpad,ofbizbrazil
1625,2016-04-13 06:09:13,"Hi @avishai-ish-shalom - thanks for opening an issue. We don't have any plans to add a Lua (or different) embedded interpreter at this time. We've been adding some super basic static query capability via [prepared queries](https://www.consul.io/docs/agent/http/query.html), but that's much easier to reason about vs. a full in-core script interpreter. This would be a major increase in complexity for Consul's core, and we have nearer-term things we'd like to work through first. Having scripting for data views would be pretty neat, I agree, but this isn't something we can support right now :-)
",slackpad,avishai-ish-shalom
1624,2016-02-02 01:38:36,"Hi @panda87 I took a look back through the code and these have been floats since the beginning. I'll tag @armon to see if he can lend any insight into why they were built this way, but I'll go ahead and close this out since it is the intended behavior and didn't change in 0.6.x.
",slackpad,panda87
1623,2016-01-18 07:14:42,"Hi @ctx0104 this is the intended behavior and things have been this way in previous versions of Consul (https://www.consul.io/docs/internals/sessions.html):

> To be clear, this locking system is purely advisory. There is no enforcement that clients must acquire a lock to perform any operation. Any client can read, write, and delete a key without owning the corresponding lock. It is not the goal of Consul to protect against misbehaving clients.

So you have to use the locking primitives in the proper ways in order to protect the integrity of the keys.

The only recent change to locking behavior came in 0.6.0:

> A KV lock acquisition operation will now allow the lock holder to update the key's contents without giving up the lock by doing another PUT with `?acquire=<session>` and providing the same session that  is holding the lock. Previously, this operation would fail.

Hope that helps!
",slackpad,ctx0104
1622,2016-02-02 01:45:31,"Hi @avishai-ish-shalom we'd definitely have to do this in a phased manner to avoid breaking folks. Will take a look at how much effort this is.
",slackpad,avishai-ish-shalom
1620,2016-12-02 14:28:43,"@DanielDent / @llevar : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,DanielDent
1620,2016-12-02 14:28:43,"@DanielDent / @llevar : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,llevar
1618,2016-04-05 19:00:28,"@deltaroe, it does failure detection too, as far as I know, and it is core to the whole distributed architecture. I wouldn't recommend trying to avoid it. Are you sure Consul is the tool you need?
",c4milo,deltaroe
1618,2016-04-12 08:40:05,"The gossip protocol integration goes pretty deep in Consul, so I don't think we'd ever completely disable it. In addition to the things listed by @deltaroe it's part of `consul exec`, it's how we manage protocol versioning and communication between agents, cross-monitoring of agents is tied into how sessions work, etc. I don't have a time frame at the moment, but we are looking into some possible options for supporting different network topologies within the same cluster.
",slackpad,deltaroe
1616,2016-01-16 00:27:30,"Hi @donaldquixote - you are right that the current license covers binaries you build. I'll check with folks here and see how we cover binaries we build.
",slackpad,donaldquixote
1616,2016-01-21 15:12:54,"Thanks @slackpad. Any new information on this?
",donaldquixote,slackpad
1616,2016-01-26 02:03:00,"@donaldquixote The license in the repository covers the binaries we provide as well. We are not planning on including the license in the archives themselves.
",armon,donaldquixote
1615,2016-01-22 17:47:25,"Hi @DanielDent the recursor sessions are used when Consul is acting as a DNS server but those errors look like Consul itself is having a hard time resolving those addresses. I think this might be a problem with the way DNS is configured on the host where Consul is running.
",slackpad,DanielDent
1605,2016-01-14 15:45:44,"Hi @Shinzu we made a non backwards compatible change to the go-reap library since we found a subtle way that it could cause race conditions. If you sync github.com/hashicorp/go-reap in your `GOPATH` back to e300e334a8de28a7931fc05331345f9e985128de things should start building again.

We haven't fully integrated `godep` yet, but you can find the required dependency versions for each tag in here: https://github.com/hashicorp/consul/tree/master/deps.
",slackpad,Shinzu
1596,2016-01-13 22:18:22,"Hi @JeanMertz is there any more information about why it's dying (possibly getting OOM-killed if you look in syslog)? We've seen one user with a huge amount of data have trouble because Consul can't page to disk like it used to be able to - https://github.com/hashicorp/consul/issues/1579.
",slackpad,JeanMertz
1596,2016-01-13 22:25:42,"ouch, that was indeed it. Our Kubernetes pod was set to a 256MB limit (which worked on 0.5.2). Now that I've increased it to 512MB, things work as expected.

Sad face for it taking so long for me to post this, as that would've saved me a couple of hours :disappointed: 

Thank you for helping out @slackpad!
",JeanMertz,slackpad
1596,2016-01-13 22:34:40,"@JeanMertz np and glad you got things working again!
",slackpad,JeanMertz
1594,2016-01-14 03:38:52,"Hi @luisbosque - closing this as a dup of https://github.com/hashicorp/consul/issues/294 - please take a look at that issue for more context, specifically https://github.com/hashicorp/consul/issues/294#issuecomment-170177259. Thanks!
",slackpad,luisbosque
1593,2016-02-13 04:45:44,"HI @quickwind thanks for opening an issue. Something like https://github.com/Cimpress-MCP/git2consul is probably a better way to go for this use case. We are thinking of adding a multi-KV API, but we don't have plans to add that to the UI at this time.
",slackpad,quickwind
1593,2016-04-13 08:03:42,"@jsr88f there's currently no way to statically configure keys similar to service definitions. Take a look at git2consul referenced above - it can load KV data based on input files.
",slackpad,jsr88f
1591,2016-01-13 04:10:49,"Hi @highlyunavailable since this was a totally new API we wanted to be more REST-y, similar to the KV store, but we decided to separate out the create from the update operation since the ID is always generated by the Consul and never passed in when the query is created. It definitely could have been a PUT, but was sort of a style choice.

The API options thing is a bug, thanks for finding that!
",slackpad,highlyunavailable
1590,2016-01-13 22:30:53,"Hi @mg03 can you provide some examples of the registration requests you are doing? If I can see how you are interfacing with Consul we should be able to figure out what's going on.

This use of Consul should be possible, though it's highly recommended to run Consul agents on each machine. With agents they manage many of the details for you, like checking the health of node and automatically keeping the catalog up to date.
",slackpad,mg03
1590,2016-01-14 02:14:54,"Hi James @slackpad 

I am using the python client for consul.

For example , im doing the following to test:
import consul
conn = consul.Consul(host=""172.31.10.8"",port=""8500"",token=""6678179e-3972-58e3-2ca5-ca4715d77134"")
svc = {""Service"": ""svctestwatch"", ""ID"": ""svc123""}
check1={""Node"": ""node1"", ""CheckID"": ""service:svc123"",""Name"": ""Redis health check"",""Notes"": ""Script based health check"",""Status"": ""passing"", ""ServiceID"": ""svc123""}
conn.catalog.register(""node1"",""1.2.3.4"",service=svc,check=check1) <----this returns true and the ui shows node registered
check2={""Node"": ""node2"", ""CheckID"": ""service:svc123"",""Name"": ""Redis health check"",""Notes"": ""Script based health check"",""Status"": ""passing"", ""ServiceID"": ""svc123""} 
conn.catalog.register(""node2"",""5.6.7.8"",service=svc,check=check2) <------ <----this returns true and the ui shows node registered

i,s = conn.catalog.service(""svc123"")
print s   <---- This is an empty array , this should give me the nodes in the service
",mg03,slackpad
1587,2016-01-13 21:38:40,"Hi @renrenfree can you add a little more detail about what you are looking to do? You can configure the domain that Consul responds to using https://www.consul.io/docs/agent/options.html#_domain.
",slackpad,renrenfree
1587,2016-01-18 05:54:24,"Thank you @slackpad . My issue is that ""I want to use consul as a dns server but not with 'service' or 'node' in a full domain"" https://www.consul.io/docs/agent/dns.html  .  How to config ?  
I want to use a domain like 'www.github.com'
",renrenfree,slackpad
1587,2016-01-20 06:11:32,"Hi @renrenfree, @shilov is correct that there's currently no way to configure Consul to support other name formats. You could look at using consul-template to populate your BIND or dnsmasq config (or even a /etc/hosts file).
",slackpad,renrenfree
1587,2016-01-20 06:11:32,"Hi @renrenfree, @shilov is correct that there's currently no way to configure Consul to support other name formats. You could look at using consul-template to populate your BIND or dnsmasq config (or even a /etc/hosts file).
",slackpad,shilov
1583,2016-02-09 01:53:44,"@fusiondog I think so as well. Do you mind adding a note about this to the docs as well? I'm happy to do that, too - just let me know.
",slackpad,fusiondog
1583,2016-02-09 19:36:27,"@fusiondog Thank you for your PR.  I'm going to take PR and update it so that an administrator can specify an `int` instead of a `bool` to limit the number of addresses returned.
",sean-,fusiondog
1583,2016-02-10 05:07:33,"@sean- Would the int be able to exceed the default 3 results?  The doc update should probably still make a point of the getaddrinfo bug and that using the setting at value 1 is needed to resolve.
",fusiondog,sean-
1579,2016-01-09 00:18:53,"Hi @nbrownus - do you know how close your 0.5.2 setup was to maxxing your machine's memory? If you were close before I could see the fairly large GC behavior differences from Go <1.5 to Go >1.5 causing a marginal situation to blip over and fail. If you weren't even close and it's way different in 0.6.1 that would be surprising.
",slackpad,nbrownus
1579,2016-03-11 06:45:27,"Hi @nbrownus closing this out as we've updated the docs and I think we understand the root cause. Please re-open if you need anything.
",slackpad,nbrownus
1576,2016-01-07 21:59:48,"@donaldquixote it's mostly correct that Consul hasn't been battle-tested as much on Windows as it has been on Linux (or at least not that we have seen). The Consul agents shouldn't have much trouble running in client-only mode on Windows hosts. The main concern is around the servers, which need to maintain the state of the whole cluster. We generally still recommend that all Consul servers should be run on Linux, but there have been significant improvements to the state store and on-disk storage in Consul that might alleviate many of the issues faced previously, though we haven't dedicated cycles to verifying that yet.

We do want Consul to run reliably on Windows, and that support will likely be at an official capacity by the time 1.0 is out. We just aren't there yet.

Let me know if you have any other questions!
",ryanuber,donaldquixote
1576,2016-01-07 22:10:15,"Thanks @ryanuber. Is there a ballpark ETA for 1.0? I know there is plenty to keep everyone busy. I'm just gathering as much info as I can to present to my managers.

Thanks again.
",donaldquixote,ryanuber
1576,2016-01-07 22:26:20,"@donaldquixote 1.0 will likely be 2016. I would say that thisshouldn't hold you back though, 0.6 is in use by some extremely large organizations and we're highly confident in it.
",mitchellh,donaldquixote
1576,2016-01-07 22:51:20,"Thanks @mitchellh. I personally have confidence in it, but we have a unique case of needing to straddle both the cloud and on-prem worlds, so we will either be redistributing Consul with our software or asking customers to install and run it on-prem, and we have a requirement to target Windows and Linux. Even with a list of large adopters, I can't imagine the customer being happy with ""Windows is not recommended as a Consul server"" printing every time a server goes up.

Anyway, thanks again, and keep it up. I'm excited to start working with Vault over Consul. :)
",donaldquixote,mitchellh
1576,2016-07-01 00:10:36,"Hi again @ryanu, @mitchellh. I following up to see if official Windows support for server is still likely to land in 2016. Our use cases keep piling up :)

Thanks. 
",donaldquixote,mitchellh
1576,2016-07-15 14:00:03,"@ryanu, @mitchellh   I have a client which is mostly windows. We are using AWS. We use packer, terraform already. We have under utilized windows servers I can use to start using Consul and Vault. I used chocolatey packages created by you guys to install consul as a service. I see a warning about lack of production support for consul on windows. A guide for consul on windows along with official support will help for sure. 
",rajinders,mitchellh
1576,2016-09-06 19:14:08,"Just wondering what is the current state of Windows support for the Consul Agent running in Server mode?  Is this a supported and stable configuration for v0.7?  

Is 1.0 still coming out this year?

@mitchellh @ryanuber @slackpad 
",daviddodsworth,mitchellh
1576,2016-09-06 19:14:08,"Just wondering what is the current state of Windows support for the Consul Agent running in Server mode?  Is this a supported and stable configuration for v0.7?  

Is 1.0 still coming out this year?

@mitchellh @ryanuber @slackpad 
",daviddodsworth,slackpad
1576,2016-09-06 19:14:08,"Just wondering what is the current state of Windows support for the Consul Agent running in Server mode?  Is this a supported and stable configuration for v0.7?  

Is 1.0 still coming out this year?

@mitchellh @ryanuber @slackpad 
",daviddodsworth,ryanuber
1576,2016-09-06 19:16:58,"@daviddodsworth I'll let others comment on Windows support with server mode.

1.0 is no longer likely coming out this year as we're working on some important stability improvements we've found from our biggest users (really, really massive scale) and we want to see those in production for some time. It is still a high priority target though. :) 
",mitchellh,daviddodsworth
1572,2016-01-07 16:53:39,"Hi @wyhysj are you using the Catalog API to update the tags (https://www.consul.io/docs/agent/http/catalog.html)? If you are not using the Catalog API and change them using the Agent API then the stale catalog value will overwrite it, which sounds like what might be happening here.
",slackpad,wyhysj
1572,2016-01-07 20:57:30,"@slackpad yes, I use Catalog API to update tags
One more thing, my consul server already upgraded to 0.6, but my consul client remains at 0.5.2 since lots of clients running
",wyhysj,slackpad
1572,2016-01-08 08:09:34,"@slackpad Thanks for the clarify
today I upgrade everything >0.6.0 and the problem still exists
First I think it's protocol version
As this page [https://github.com/hashicorp/consul/issues/1531](https://github.com/hashicorp/consul/issues/1531) explains it's irrelevant



I use /v1/catalog/register api and my body.json looks like this


",wyhysj,slackpad
1572,2016-01-08 23:24:52,"@wyhysj sorry about this - running through an example now I can see how this is confusing - I think we should beef up our documentation a bit.

Syncing of service registration usually happens from the agents up to the servers. The tag override feature is a rare case that goes the other way. When the agent is syncing, it fetches what's on the server, compares it with what it has, and then pushes up any changes. I think the problem you are seeing is that the agent doesn't have the `EnableTagOverride` flag set to true _in its local configuration_, you are setting that in the catalog, so the agent isn't respecting that setting.

Here's an example that shows how it works:

**Register the service on the agent using the agent API**

Note that we enable tag overrides when we register the service with the _agent_ here.



**Verify that the standby tag is set in the catalog**

Note here that the server captured the agent's tag override setting.



**Update the tag using the catalog**



**Verify that the agent doesn't overwrite it**



**Verify that the agent took the tags from the master into its local configuration**



Please let me know if this makes sense!
",slackpad,wyhysj
1572,2016-01-09 08:57:50,"@slackpad Thanks for such detailed explanation
After changing register service with EnableTagOverride: true
It works great !
",wyhysj,slackpad
1572,2016-07-04 12:02:58,"@slackpad , Thank you from me too.
Can you check if this is correct please?

There are two ways to change the tags of an existing service:
1. By the catalog - v1/catalog/register.
2. By re-registering the service on the agent - v1/agent/service/register.

If you want to use way 1, create the service with  EnableTagOverride: true. Because otherwise the tags will be run over.
If you want to use way 2, create the service with  EnableTagOverride: false (the default). Why? read on.

Advanced note:  It seems that v1/agent/service/register sends the new tags to the catalog regardless of EnableTagOverride. So if you use way 2 yet with EnableTagOverride: true, it will 99% work. The only problem is if you call v1/agent/service/register while the cluster is unavailable; then the registration on the agent will succeed, but it won't send the tag to the server upon re-connection!
",motty-stratoscale,slackpad
1572,2016-08-11 01:21:33,"@motty-stratoscale that sounds right, and is a bit subtle, unfortunately. The semantics of `EnableTagOverride` ended up being more complicated than I would have liked.
",slackpad,motty-stratoscale
1570,2016-03-25 17:26:16,"@beornf , thank you for this PR.  There is work that is landing soon that will address this issue.  This issue and the others referenced above are all targets for this pending work.  This is a problem we are aware of and will be addressing.
",sean-,beornf
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,nejtr0n
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,beornf
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,kylegato
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,fhaynes
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,Ashald
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,westsouthnight
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,ChrisLundquist
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,dcowden
1570,2016-12-02 14:34:20,"@beornf / @dcowden / @nejtr0n / @westsouthnight / @Ashald / @kylegato / @raykrueger / @ChrisLundquist / @fhaynes : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



With the [`sockaddr`](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr) command you can experiment with getting the right template syntax with the `eval` sub-command, for instance:



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,raykrueger
1567,2016-01-24 15:32:39,"@slackpad thanks for the comments!

In some very initial toying around, I already discovered that the 1 second `DefaultMonitorRetryTime` is a problem when trying to rolling upgrade, because `consul lock` died really fast.  I don't have the logs in front of me ATM, but IIRC the problem was that consul client was unable to talk to the agent, and thus tried to immediately release the lock which, again, it couldn't do.  I haven't had time to delve in to the source yet (out of round tuits for now :disappointed:) but hypothesized that increasing the retry time might avoid this.

Also, as you pointed out, there are a _lot_ of rough edges that I'm admittedly completely ignoring for now.  I just wanted to start with _something_ as a PoC.
",issacg,slackpad
1565,2016-01-05 21:34:06,"Hi @johntdyer is Consul's support for RFC 2782 close enough to support your use case? Please take a look at https://www.consul.io/docs/agent/dns.html and look for the ""RFC 2782 Lookup"" section. For that you'd just use ""udp"" as the tag and then you could look up `_ppid410._udp.service.consul`. Not sure if you need another layer for ""_sip"" in there though, because that's not currently supported with Consul's RFC 2782 support.
",slackpad,johntdyer
1565,2016-01-05 21:48:14,"@slackpad  in my case the service is **_sip**, the protocol is **_udp** and we use the subdomain to classify the cluster ( **ppid410** ).  Unfortunately in my use case I do need **_sip** or **_sips** ( for tls) to be there in addition to the protocol ( **_tcp** / **_udp** ).  
",johntdyer,slackpad
1565,2016-01-05 21:49:20,"@slackpad - Its worth mentioning that this is technically working today.... 


",johntdyer,slackpad
1565,2016-01-06 18:12:39,"@slackpad  any thoughts ? 
",johntdyer,slackpad
1565,2016-01-08 06:23:01,"@johntdyer it's unlikely that we'd change the existing DNS behavior to break you, but if you want to be better insulated against future changes and avoid the warning message you could register a prepared query to handle this (https://www.consul.io/docs/agent/http/query.html). You could set the name to `_sip._udp.ppid410` and then set up the query to perform whatever service selection you want, and the DNS name becomes `_sip._udp.ppid410.query.consul`. Prepared queries don't encode any functionality into the name so they are less picky about the formatting, and it's not likely at all we'd change that because prepared queries have all their behavior defined in the query definition itself.
",slackpad,johntdyer
1564,2016-01-06 04:34:10,"Hi @mqliang if you are using the HTTP API the watch should still work and you'll get a 404 response code if the key is deleted. There's still the X-Consul-Index header in that response so you can continue watching for that key again.
",slackpad,mqliang
1564,2016-01-06 06:05:22,"@slackpad Great thanks! Recently we are developing a distribute system using consul as our K/V storage.  
- How about TTL expired? Is it the same as deletion(a 404 response code with X-Consul-Index)?
- Is there any way we can know the previous value if we get a modify/delete/expire action when watch? 

Is there any documentation?
",mqliang,slackpad
1564,2016-01-06 06:18:49,"@mqliang for TTL expiration it depends on how your session is set up when you create it (https://www.consul.io/docs/agent/http/session.html). If you set the session's Behavior to ""release"" then it should clear the session component of the key, making it look like a modify action, leaving the Session field of the key empty when you query it. If you set the Behavior to ""delete"" it should look like a delete action.

The main documentation for KV is here - https://www.consul.io/docs/agent/http/kv.html. Though if you are making a distributed system you probably can benefit from Consul's built-in lock functionality, take a look at these guides:
- https://www.consul.io/docs/guides/leader-election.html
- https://www.consul.io/docs/guides/semaphore.html

In addition, Consul's Go client API has some pretty nice wrappers that implement these types of operations and provide the watching for you, closing a channel when a lock is lost so it's simple to interface with the rest of your application:
- https://github.com/hashicorp/consul/blob/master/api/lock.go
- https://github.com/hashicorp/consul/blob/master/api/semaphore.go
",slackpad,mqliang
1564,2016-01-06 06:53:59,"Sorry I missed your last question. Consul doesn't keep any history of values for KV entries so you'd have to manage that in some other way. 

> On Jan 5, 2016, at 10:05 PM, Liang Mingqiang notifications@github.com wrote:
> 
> @slackpad Great thanks! Recently we are developing a distribute system using consul as our K/V storage.
> 
> How about TTL expired? Is it the same as deletion(a 404 response code with X-Consul-Index)?
> Is there any way we can know the previous value if we get a modify/delete/expire action when watch?
> Is there any documentation?
> 
> â€”
> Reply to this email directly or view it on GitHub.
",slackpad,slackpad
1563,2016-01-05 02:42:40,"Hi @sboily can you try a command like this from that machine to see if openssl can connect:

`openssl s_client -connect scada.hashicorp.com:7223 -tls1_2 -CApath /etc/ssl/certs </dev/null`

There weren't any major SCADA-related changes in 0.6, though Consul keeps that connection open so you may have seen it during the upgrade because it was the first chance to connect in a while.
",slackpad,sboily
1563,2016-01-05 21:15:04,"Thanks for the update, @sboily. Are you ok to close this one down?
",slackpad,sboily
1562,2016-01-04 17:54:31,"Hey @discordianfish, the `consul members` and `/v1/status/peers` output come from different sources; the former being from the gossip layer and the latter being from the Raft layer. That explains why they may be showing different peer sets.

Are the old members fully dead (unreachable)? Were they forcefully terminated, or were they shut down gracefully? A graceful shutdown allows the node to announce its intention of leaving whereas a force shutdown leaves the member in the peer list for another 72h in case it comes back.

Can you share your full configuration and some of the logs from each server at start time? The bootstrap options are important here and this will help paint a more complete picture of what's going on.
",ryanuber,discordianfish
1562,2016-01-04 17:56:08,"To add to what @ryanuber said, it would also be useful to see the /peers output from each of the servers other than 10-1-24-247 to see if they look like they are in healthy state.
",slackpad,ryanuber
1562,2016-01-04 18:23:13,"I suspected something like that, but how is it possible that leader isn't included in peers?

I have a bunch of servers which didn't leave the cluster properly, so it's quite possible that this contributes to this problem (working on this issue right now).  Still, it looks to me like there is also some issue with consul itself leading to the inconsistency between leader and peers.

For the configuration I basically ask the aws api for instances for the instances stack (using cloudformation here). Additionally to that, I use another tag to figure out if an instance is suppose to be a server or now.
All nodes use this config:



...and I just realize that I still explicitly set `-protocol 2` on all nodes.

On servers nodes I start consul with those parameters:



... where the IPs are those of the other instances tagged as server.

On client nodes, I run:



...where again the IPs are those of the server instance _when consul got started_.

@slackpad: Here is the peers output from each server:



Here are a few lines from the log of 10.1.9.157:



And here some of 10.1.29.94:



^- Possibly when I did a rolling replacement of the instances.

Currently I only see the (excepted) serf issues due to the non-gracefully removed instances:



I can also provide the complete log (well those I still have, so only from the currently running instances) if necessary. Just need to spend some time scrubbing them.
",discordianfish,slackpad
1562,2016-01-04 19:18:32,"@discordianfish is it possible that you did a rolling restart of the servers without giving them time to rejoin and become peers again? That might have pushed your cluster into an outage state. If your config file has any use of `-bootstrap` you could end up in a split brain situation like this as well.

In any case, it looks like .157 is in a bad state where it has peers that are gone, and it hasn't added the other two good server nodes. I'd probably make that one leave and add a new server, or restart .157 with a clean data-dir, after making sure you are not using `-bootstrap` in your config.
",slackpad,discordianfish
1562,2016-01-05 09:56:45,"@slackpad It should have waited for the server nodes to successfully join the cluster. Before continuing with the next instance, I run:



That should make sure the node successfully joined.. And as far as I understand, `-bootstrap` should be okay as long as the nodes I point it to are already bootstrapped..
I see how it's simpler to reason about the state if `-bootstrap` is removed, yet that isn't that trivial to automate. 
",discordianfish,slackpad
1562,2016-01-08 22:14:10,"This is slightly off-topic, but since I came here looking for a robust way to wait for a consul cluster to self-assemble (in a context where I know it eventually will) perhaps others will be interested.

Right now I'm attempting to wait with a poll loop that explicitly asks for a lock: `consul lock -n 64 wait-for-consul echo Consul is up`.  It seems that if this command succeeds (in the exit code sense) then I am good to go.  @slackpad How would you rate this tactic vs. polling the peers list?
",phs,slackpad
1562,2016-01-08 22:34:32,"@phs I think your use of `consul lock` looks like it would work well - that will only pass if a write is able to get through (actually two since it has to make a session as well) so there needs to be a quorum of servers up and running to accomplish that. This should be more reliable than polling the peers list.

It's a good suggestion to make a first-class ""is consul up"" command - we can keep track of that here.
",slackpad,phs
1562,2016-06-02 15:04:30,"@slackpad We have a similar situation, where the `/v1/status/peers` endpoint shows (besides all current masters) a peer that has been deleted come time ago. `consul members` doesn't show that node. The output is the same for all three master nodes.

The outage recovery document (https://www.consul.io/docs/guides/outage.html) says I can fix that by stopping all masters, editing the peers.json file and starting the servers again. I was wondering if there is also a way to fix this while keeping the cluster alive?

I'd like to prevent downtime if I can. And except for some raft messages saying the peer cannot be found for voting `Failed to make RequestVote RPC`, the cluster seems to be operating fine otherwise...
",amochtar,slackpad
1562,2016-06-02 15:28:14,"@amochtar unfortunately there's currently not a way to force a peer out if they are no longer in the cluster's member list, so stopping and updating the peers list is the way to fix it. The danger with leaving it around is that it will increase your quorum size. For example, if you have 3 good + 1 zombie server then your quorum size would be 3, so losing one of your good servers could cause an outage. If you remove that zombie server then your quorum size drops to 2 and you will be able to handle the outage of a server as expected.
",slackpad,amochtar
1562,2016-06-02 18:07:58,"@amochtar that should work if you can give it the same IP. You can use `consul leave` to make sure it's gone from the cluster before you retire it.
",slackpad,amochtar
1562,2016-06-02 18:29:04,"@slackpad that worked :)
created a new node with the old IP address, started a new consul agent, joined the existing cluster, then left again and it nicely cleaned the peers list ðŸ‘ 
",amochtar,slackpad
1562,2017-03-09 01:47:51,"Hi @lswith it does show the current peers - the Raft library calls that the ""configuration"" - it doesn't have to do with any configuration files.",slackpad,lswith
1561,2016-01-04 16:45:21,"Hi @rtaborda there's https://github.com/leprechau/consul-backinator which is an open source tool that lets you do this. Also, some folks manage KVS in git and then push them in with tools like https://github.com/Cimpress-MCP/git2consul. If you have multiple datacenters, you can use https://github.com/hashicorp/consul-replicate to sync them. Hope that helps!
",slackpad,rtaborda
1560,2016-01-05 03:46:07,"Hi @sebi-hgdata - I'll have to take a deeper look on the Raft side, but I think you might be seeing some startup behavior that's allowed by Raft but noisy for your gating check. You might want to try polling the https://www.consul.io/docs/agent/http/status.html#status_peers endpoint and looking for that to have 3 entries (you could pipe through `jq` or similar). That should give you a good view of everything once elections have settled down and all the servers are joined.
",slackpad,sebi-hgdata
1560,2016-01-05 09:12:05,"@slackpad Thanks for the quick response.
I changed the post-script script to do a request for an inexistent key and check that it returns an empty string (returns 'No cluster servers' and/or 'No cluster leader' ) and it seems to do the job for me... Anyway... I assume that  the KV and the leader API's should have returned the same response... but they don't.. might be some inconsistent leader checks?
",sebi-hgdata,slackpad
1560,2016-01-05 18:21:27,"@sebi-hgdata I think there are times where multiple nodes think they are the leader, but only one will be able to perform writes, so looking at the leader endpoint for this application isn't a super reliable method to wait for Consul to get into a good state. Please take a look at the conversation on #1562 which has a way to check using the peers list.
",slackpad,sebi-hgdata
1557,2016-02-07 06:09:26,"Hi @dweomer thanks for opening a PR! We are actually in the process of converting our release build tooling to run in a Docker container so you should be able to make use of that soon to do the same thing!
",slackpad,dweomer
1556,2015-12-30 09:40:22,"@mthenw that is fair. I don't do a lot of setup on machines that I work on which means global gitignore entries are typically forgotten.
",dweomer,mthenw
1556,2016-01-06 04:40:59,"Hi @dweomer - thanks for the PR. The build fail wasn't you, but I'll close this out in favor of @mthenw's suggestion in https://github.com/hashicorp/consul/pull/1556#issuecomment-167966975 since there's quite a bit here unrelated to Consul.
",slackpad,mthenw
1556,2016-01-06 04:40:59,"Hi @dweomer - thanks for the PR. The build fail wasn't you, but I'll close this out in favor of @mthenw's suggestion in https://github.com/hashicorp/consul/pull/1556#issuecomment-167966975 since there's quite a bit here unrelated to Consul.
",slackpad,dweomer
1555,2016-01-13 19:34:10,"Hi @migueleliasweb if they are in the same datacenter from a Consul perspective, how would Consul know when to provide which address, or are you thinking you'd group them into two datacenters? There's a PR in review that might be useful if it's the latter - https://github.com/hashicorp/consul/pull/1547 - this would let you use the configured WAN addresses if you are going DC to DC and the LAN addresses internally.
",slackpad,migueleliasweb
1555,2016-01-14 13:33:16,"Hey @slackpad , the idea was all about improving inner-datacenter comunication, you are indeed right.The #1547 PR might solve this.
",migueleliasweb,slackpad
1553,2015-12-29 01:05:29,"Awesome, thanks for the quick merge @ryanbreen.
",peterfschaadt,ryanbreen
1552,2016-01-13 19:27:53,"Hi @ChristianKniep there's a PR in review that I think is very similar to what you are proposing here. How does this look to you for your use case?

https://github.com/hashicorp/consul/pull/1547
",slackpad,ChristianKniep
1552,2016-01-15 15:48:30,"@ChristianKniep I've never gotten a symlink to work properly with the go build tools. I know that cloning your dev repo and actually placing it at github.com/hashicorp/consul in your GOPATH will work, even though it's a little gross to have to do that.
",slackpad,ChristianKniep
1551,2016-01-13 03:09:56,"@gtmtech what did you end up doing? I'm weighing the same options you mentioned.
",shilov,gtmtech
1551,2016-01-14 03:34:53,"@gtmtech we will look into making this easier, or at least better documenting the process.
",slackpad,gtmtech
1551,2016-01-15 03:54:12,"@gtmtech thanks for the response, much appreciated. 
",shilov,gtmtech
1550,2016-01-05 17:49:26,"@slackpad comments addressed, PTAL!
",ryanuber,slackpad
1547,2015-12-24 20:37:47,"@evan2645 things have been a little flaky in Travis since some of our tests are time-dependent. I'll take a look and thanks for submitting this PR!
",slackpad,evan2645
1547,2016-01-13 21:40:20,"@ChristianKniep dropped a comment on #1552... It doesn't look like your build errors are related to the patch, afaict... more likely something in your dockerfile?
",evan2645,ChristianKniep
1547,2016-01-15 00:20:08,"Hi @evan2645 - there's a lot of interest in this change!

I've been thinking that it would be good to generalize this a little bit to put us in a good position for more features down the line. If instead of `WanAddress` we added a new member `Addresses` which is a map, keyed by a tag then we could auto-populate it with the tag `WAN` using the logic you have here. On the other side, I think we could generalize `translate_addrs` in the config to be a map keyed by DC with the tag to use to translate for nodes from that DC.

This will set us up to eventually register additional addresses and configure things as needed from the perspective of the other DC, which should be very powerful.

Any thoughts on these changes? I'm happy to help implement if you'd like.
",slackpad,evan2645
1547,2016-01-19 20:43:54,"@slackpad I like the idea of turning `translate_addrs` into a map of DC names. I'll do that.

I'm having a bit of trouble understanding your suggestion on the address configuration though - you're suggesting to add a `WAN` string element to the `AddressConfig` struct, and auto-populate it somehow? Would this take precedence over the pre-existing `AdvertiseAddrWan`, or be disjoint from it?
",evan2645,slackpad
1547,2016-01-19 20:54:08,"Here's the post: http://qnib.org/2016/01/16/consul-ambassador/
@evan2645 @slackpad To me the beatuy of the idea is to put it in a context where the targeted agent (the services within a different DC) is in control which address is given out to an DNS request by a remote agent. A map which is send over and the DNS resolver checks for a default (internal or external address) or an address specified for a given DC.



Just my 2 cents, since I didn't get my hands dirty in the code for now
Christian
",ChristianKniep,slackpad
1547,2016-01-19 20:54:08,"Here's the post: http://qnib.org/2016/01/16/consul-ambassador/
@evan2645 @slackpad To me the beatuy of the idea is to put it in a context where the targeted agent (the services within a different DC) is in control which address is given out to an DNS request by a remote agent. A map which is send over and the DNS resolver checks for a default (internal or external address) or an address specified for a given DC.



Just my 2 cents, since I didn't get my hands dirty in the code for now
Christian
",ChristianKniep,evan2645
1547,2016-01-19 21:01:38,"@ChristianKniep the only thing about that approach is that to fit the NAT use case, I'll have to enumerate every DC on that map. That map is stored on the node in the catalog, and will cause the node objects to bloat as the number of DCs grow. In order for that to fit the NAT use case, there would still need to be a `default` and `wanDefault` field... the other thing I wonder is that what happens when someone names a DC `default` or `wanDefault` :smile: 
",evan2645,ChristianKniep
1547,2016-01-19 21:09:46,"@evan2645 Ok, not the most complete thought ever written on Github. :)
Maybe more like this:



In which the `dc_specific` would overwrite the default `wan`, if it dares to exists.

The remote agent get this information, checks his DC against the DC of the remote service (since it's remote it's likely to be different :) and if so, he chooses the `wan` address if he can not find his DC in the map of `dc_specific`.
This would make sure that the client is in control who gets what IP address, since he might have special entry-points (loadbalancers) for different regions and this would cover it up.
",ChristianKniep,evan2645
1547,2016-01-19 22:43:51,"ok... what do you think @slackpad? Maybe this is what you meant? Or you also wanted arbitrary tags per DC? The latter doesn't mesh well with the agent-decides-which-address-a-dc-gets approach
",evan2645,slackpad
1547,2016-01-20 06:28:34,"Hi @evan2645 my thought on the addresses list was quite a bit simpler than @ChristianKniep initially, but it would open things up later for features like that if we wanted to expand things. Instead of this:



You'd do this:



Configuration-wise you wouldn't change anything, but you'd put the value you are currently putting into `WanAddress` into `Addresses['wan']`. We don't need to do it now but it gives us a structure to add other address tags later. This seems flexible enough to implement the DC-specific use-case later if people want to organize their tags that way. For now I think letting the agent be in control of which address tags to use is probably the way to go.
",slackpad,ChristianKniep
1547,2016-01-20 06:28:34,"Hi @evan2645 my thought on the addresses list was quite a bit simpler than @ChristianKniep initially, but it would open things up later for features like that if we wanted to expand things. Instead of this:



You'd do this:



Configuration-wise you wouldn't change anything, but you'd put the value you are currently putting into `WanAddress` into `Addresses['wan']`. We don't need to do it now but it gives us a structure to add other address tags later. This seems flexible enough to implement the DC-specific use-case later if people want to organize their tags that way. For now I think letting the agent be in control of which address tags to use is probably the way to go.
",slackpad,evan2645
1547,2016-01-26 18:33:25,"@slackpad I pushed a commit to add an `Addresses` map on the node struct. I was able to consume it nicely from the request side of things.

Note that I was unable to use this structure during node registration, serf tag etc, as the node struct is not present at that time. LMK if you think I'm missing anything
",evan2645,slackpad
1547,2016-02-07 21:51:51,"@evan2645 great work on this! I appreciate you getting this together, and I just realized you also fixed the RetryJoin unit test along the way which has been bugging me for a while :-)

:+1: 
",slackpad,evan2645
1546,2015-12-24 20:46:50,"Hi @feythin can you provide an example of how you are configuring the health check?
",slackpad,feythin
1546,2015-12-25 04:55:17,"@slackpad 
so sorry not give the configure informationsã€‚
I use consul as the backend registry of registrator .  and my service is in docker container.  So I set the docker start environment with the following settingsã€‚


",feythin,slackpad
1546,2016-01-09 02:13:50,"@feythin can I see the JSON that you are giving to Consul to configure the check? Thanks!
",slackpad,feythin
1546,2016-03-11 06:47:33,"Hi @feythin I'm going to close this out. If you weren't able to figure out what's going on, I'd suggest asking the registrator folks. It looks like it is somehow registering a script instead of an http check.
",slackpad,feythin
1545,2015-12-24 20:51:28,"Hi @subchen you'd use the https://www.consul.io/docs/agent/http/catalog.html#catalog_register API to register the service again with the same information except for the tags. It can definitely be used to update an existing service (it's also what the agents use during anti-entropy to sync up changes).
",slackpad,subchen
1544,2016-07-05 19:28:46,"@avishai-ish-shalom sorry for the delay on this one. Thanks for the contribution! A couple things I noticed:

This should probably be configurable, it would make sense to me if you could specify the TTL in the agent config, and if it is zero then don't wrap with cache headers.

We should have a test around adding the cache headers to ensure they are added properly.

We have a merge conflict because the static UI serving has changed since this PR was opened.

I'm also not super ""in-the-know"" about how the cache headers affect the behavior of the browser, but if this were optional and defaulted to ""off"" then that would prevent unexpected responses during upgrades.
",ryanuber,avishai-ish-shalom
1540,2016-01-20 20:09:34,"The PR #1566 does this without the bootstrap expect as I was doing the PR following the existing docs.  I think it would be possible to add another demo with this, but we'd need some extra scripts that get run manually, I think, whereas the PR is a simple ""vagrant up"" and you're done.  @hdeadman if you post a branch I can look at it as well.
",jzohrab,hdeadman
1538,2016-01-08 06:49:27,"Hi @jareksm I don't think we will add many more check types as scripts allow for basically anything, and it keeps Consul's core simpler and easier to maintain. With TTLs and #1208 covering the other request I'm going to close this one, but please let me know if you still have questions.
",slackpad,jareksm
1537,2015-12-22 02:26:29,"@ryanuber good call. We get a ""count"" metric for free with the gauge so no need for two metrics.
",slackpad,ryanuber
1537,2015-12-22 03:11:19,"@scalp42 ah yeah this will make that a little worse temporarily. I don't think this'll make it into the next point release but I'll try to get https://github.com/hashicorp/consul/issues/1241 in the release after that.
",slackpad,scalp42
1536,2015-12-21 19:37:36,"Hi @luisbosque good call! That language originally came from a more general version which supported other socket types but it eventually just became about TCP. Tweaked it in https://github.com/hashicorp/consul/commit/a1b69c6546b17abc3c2a37bfa27a8814beaef704. Thanks!
",slackpad,luisbosque
1534,2016-02-06 01:11:17,"Hi @shimshon-stratoscale sorry it took a while to get to this but I think it looks like writes are not making any progress and that's why things are stuck.

Here's one goroutine that has the local lock and is waiting on a catalog write to complete:



And here's your agent request waiting for that lock to free up:



Looking at the other goroutine stacks there are also a bunch of KV writes waiting to make progress at all. Since writes are stalled, these requests are piling up.

Sorry I didn't notice this in the thread before, but rebooting all 5 servers at once will put Consul into an outage situation that requires manual recovery and can result in data loss (Consul can only handle the failure of a minority of nodes in a multi-node cluster). In this situation, you'd need to choose one of the servers to be the new leader and start it up in bootstrap mode (you may have to clear peers.json if there are entries in there for the other servers). Then you can re-join the other servers with their data directories cleaned out and they will take on the state of the single leader, and expand the quorum as they are added.

The fact that it works some of the time probably depends on the state of quorum at the time the cluster was killed, but in general Consul can't automatically recover from this. When you are in this situation where requests are hanging, running https://www.consul.io/docs/commands/info.html on each server should show `num_peers` as too low on some of the servers, and nobody will likely be the leader.
",slackpad,shimshon-stratoscale
1534,2016-02-08 06:22:13,"Thanks @slackpad for the analysis. Indeed in this state we found out we cannot write to the KV store.
I had a correspondence on the outage issue with @armon in the past (see here: https://groups.google.com/forum/#!topic/consul-tool/k1ZnMHVwobA ), in which he said that if we restart each of the consul agents with the same flags they had in their previous run, we should be ok - has that changed?
BTW - we added a post-restart code that upon detecting that writes are stuck, it restarts the consul process. Sometimes it takes multiple restarts, but eventually it works. However, that's just a workaround. Appreciate your input on this.
",shimshon-stratoscale,slackpad
1534,2016-02-16 23:31:30,"@shimshon-stratoscale interesting these lines are strange and look like they might be causing the cluster to get walked down into an outage state:



It adds them back right away, but it looks like it thinks they have done a leave. Is it possible during power down that your servers get a few seconds to terminate processes? I'm wondering if setting https://www.consul.io/docs/agent/options.html#skip_leave_on_interrupt to `true` would help here?
",slackpad,shimshon-stratoscale
1534,2016-02-23 07:10:53,"@slackpad - we caused the crash in our test using an ""ipmi power off"" command, which as far as I understand is not graceful. In addition, our system is configured such that even in a graceful shutdown, we stop consul with SIGKILL, so that we never really leave the cluster (unless we specifically want to have that node leave the culster), so I don't think that's the case here.
",shimshon-stratoscale,slackpad
1531,2015-12-18 19:34:53,"Hi @scalp42 yeah this is a little confusing. Here's a list thread that talked about what's going on:

https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/consul-tool/dGTynOIQ33M/1ioEh-S5DgAJ

> This is correct and sorry it's a little confusing. To make a 0.5.x upgrade easier, we made 0.6 advertise that it speaks version 2 but that it understands version 3. This keeps older versions happy, but when a 0.6 instance sees that another version understands protocol version 3 it will automatically start sending it network coordinates and other 0.6-specific messages. No one will ever claim to speak version 3. 

I'll take this to either update the documentation or make the output of `consul version` a little clearer about the protocol, since several people have been confused about it. Glad to see you upgrade everything to 0.6.0!
",slackpad,scalp42
1531,2015-12-18 19:36:01,"@slackpad got it! 

Thanks for the quick answer :smile: 

Closing and happy Friday!
",scalp42,slackpad
1529,2015-12-18 06:44:23,"Hi @scalp42 this isn't something we've seen before during an upgrade. Can you run `consul info` on each of your three servers and make sure one shows `state = Leader`, two show `state = Follower` and all three have `num_peers = 2`? That'll provide a baseline that the servers are in a working configuration and not in some kind of split brain.

This line is suspicious:

`2015/12/18 03:10:34 [WARN] serf: Failed to re-join any previously known node`

If you run `consul members` on this agent does it show any other nodes in the cluster? Perhaps you need to run `consul join <one of the servers or any other cluster node>` to add it back into the cluster?
",slackpad,scalp42
1529,2015-12-18 19:19:04,"@slackpad thanks for the feedback, I'm not sure what happened to be honest.

Checked `consul info` and it's all looking fine on agents and servers, so going to close.

And open another issue actually :wink: 
",scalp42,slackpad
1528,2015-12-19 06:08:56,"Hi @c4milo sorry about the confusion on this one. I took a look through the DNS mux code and it doesn't look like it exposes a way to hook the default ""failed"" handler - it's all handled by the library and Consul doesn't see it. That's why there's no debug log output for this case. We can summarize that part of the config at startup though, along with the port information most likely.
",slackpad,c4milo
1528,2015-12-19 20:07:29,"It's ok, having the information logged upon startup will do it. Thanks for looking into this @slackpad!
",c4milo,slackpad
1527,2015-12-19 06:17:57,"Hi @nickmiller-wf I'm a little torn on this one - the extra information is sometimes useful (especially for error cases) and I'm a little hesitant to add more configuration complexity around this. For your application can you strip off the leading metadata and then parse the rest as JSON?
",slackpad,nickmiller-wf
1527,2015-12-21 18:09:24,"@slackpad Parsing out the JSON shouldn't be a huge issue. Only that we'll have a couple different services doing it. I've determined that the easiest way of adding in this configuration would be to stick it on the check definition itself (`HealthCheck` in `./consul/structs/structs.go`) so it could eventually get set as an unexported field on `CheckHttp` in `./command/agent/check.go`

TL;DR I agree that solving this from consul's side would add a fair amount of configuration complexity. I personally don't have the bandwidth to dedicate towards a refactor but if there is an opportunity to resolve this in any upcoming work, I would be greatly appreciative :) Feel free to close this issue, unless you want it around for future reference.
",nickmiller-wf,slackpad
1527,2016-01-09 01:52:52,"@nickmiller-wf appreciate the extra info. I'll go ahead and close this down but keep it in mind if we're in that area of the code, or if we get more requests for something like this.
",slackpad,nickmiller-wf
1524,2016-01-08 02:28:34,"@orivej thanks for the update! I'll flip the Travis config back to track the latest Go and make sure things look good there.
",slackpad,orivej
1521,2015-12-17 17:45:40,"Hey @sboily, you should be able to use the `CONSUL_HTTP_SSL=1` environment variable to control this. You can also use `CONSUL_HTTP_SSL_VERIFY=0` if you need to skip verification.

Admittedly I had to go code diving for this answer so we should definitely make it easier to find in the docs and CLI usage. Thanks for reporting this.
",ryanuber,sboily
1521,2015-12-17 18:21:29,"Hello @ryanuber, thank you it works :+1: 
",sboily,ryanuber
1510,2015-12-17 06:53:23,"Hi @vizanto it's base64 encoded! I added another step to that example that makes it clear :-) This is explained in more detail in this example - https://www.consul.io/intro/getting-started/kv.html. Thanks for opening a bug - I was confused when I saw this the first time, too.
",slackpad,vizanto
1509,2015-12-16 15:23:43,"Hi @jimonreal those messages are triggered by events in the Serf layer but I don't see any leader election activity in the log here, so those look like they might be stale log replays. Is your cluster eventually able to elect a leader? Can you describe your setup and process to get into this state in a little more detail? Thanks!
",slackpad,jimonreal
1509,2015-12-16 15:34:51,"@slackpad you mean that the logs of New leader elected are old logs that were sent to the syslog later?

Yeah, the setup are 5 nodes on each data center(3). After 2 severs died, they rebooted with consul and try to join the cluster. But this never happens and the cluster has no leader either. So all clients turn orphan because there's no leader.
",jimonreal,slackpad
1509,2015-12-17 14:32:13,"@slackpad But when running on bootstrap mode, only one server needs this parameter right?
and if a server goes down, next time it only needs to join, right? there's no need for the bootstrap-expect again.
",jimonreal,slackpad
1509,2015-12-17 14:57:04,"@jimonreal that's correct, once they are initially joined you don't need the bootstrap-expect parameter, though it's safe to always leave it on there so you can have a static configuration.
",slackpad,jimonreal
1509,2015-12-17 14:58:12,"@slackpad and do they all(5 servers of the cluster) need to have this parameter set?
",jimonreal,slackpad
1509,2015-12-17 15:16:15,"@slackpad that's odd. I followed the documentation, and that was not needed but only for the first server. And I did some testing on that, and it worked.
",jimonreal,slackpad
1509,2015-12-18 14:38:11,"@slackpad this is the scenario to replicate the error.
Having a cluster running, and communication with other 3 clusters.
Restart the whole cluster, then there's no communication between the nodes of the cluster restarted.

I had to remove the data dir for the cluster to work again.
",jimonreal,slackpad
1509,2015-12-18 19:00:01,"@jimonreal you might want to look at configuring your servers with `leave_on_terminate` set to `false` so your servers don't pull themselves out of the cluster when you restart them. Thinking about this more it looks like you may have just restarted all three servers at once, forcing the cluster into an outage. Take a look at this issue for some more context - https://github.com/hashicorp/consul/issues/454.
",slackpad,jimonreal
1509,2015-12-22 12:06:38,"Thanks @slackpad it was not the issue. But I will take that parameter into account.
",jimonreal,slackpad
1509,2015-12-22 17:53:37,"@jimonreal yeah you generally don't want to blow away the peers.json before starting Consul. Basically, the `leave_on_terminate=false` setting is designed so that the servers stay populated in the peers.json so that they jump back in and continue working when they start up. Deleting the contents of peers.json is usually only done when recovering from a full outage, or if you are removing a single server from there that's permanently failed.
",slackpad,jimonreal
1509,2015-12-22 20:26:37,"@slackpad I made the changes, started a new cluster, which connects to the other 2 over -retry-join-wan.

I am getting no cluster leader and the following logs:

docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:20:18 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:20:36 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:20:58 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:07 [INFO] serf: EventMemberJoin: vconsulmaster2wdc.wdc 172.17.0.1
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:07 [INFO] consul: adding server vconsulmaster2wdc.wdc (Addr: 172.17.0.1:8300) (DC: wdc)
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:20 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:22 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:43 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:44 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:46 [WARN] memberlist: Got ping for unexpected node vconsulmaster2wdc.wdc from=172.17.0.1:37051
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:46 [ERR] memberlist: Failed TCP fallback ping: EOF
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:48 [INFO] memberlist: Suspect vconsulmaster2wdc.wdc has failed, no acks received
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:21:49 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:13 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:32 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:41 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:53 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:56 [WARN] memberlist: Got ping for unexpected node vconsulmaster2wdc.wdc from=172.17.0.1:37379
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:56 [ERR] memberlist: Failed TCP fallback ping: EOF
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:57 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:22:58 [INFO] memberlist: Suspect vconsulmaster2wdc.wdc has failed, no acks received
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:23:09 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:23:26 [ERR] agent: failed to sync remote state: No cluster leader
docker/docker/registry.it.lan.com/latam/consul:0-svn19-trunk|consul-server|7abb71806d2c[1038]:     2015/12/22 20:23:26 [WARN] memberlist: Got ping for unexpected node 'vconsulmaster2wdc.wdc' from=172.17.0.1:8302

The consul is running inside a docker container.
",jimonreal,slackpad
1509,2015-12-23 13:13:00,"@slackpad Here I leave the config file and the command line parameters:

This is the node vconsulmaster1wdc and its the same config for everyone of them

server-config.json:



CLI parameters:


",jimonreal,slackpad
1509,2015-12-24 20:42:59,"@jimonreal when you restart a server you should be able to point it at the same data-dir. Is your IP address changing when you restart the server? That could require some special steps to deal with. Also, depending on how you are shutting down the servers you might also need to set https://www.consul.io/docs/agent/options.html#skip_leave_on_interrupt to true as well to keep the server from leaving.
",slackpad,jimonreal
1509,2015-12-29 16:28:59,"after I deleted the data-dir, and started all from scratch it started working even if nodes where disconnected. Thanks @slackpad 

Regarding the data-dir files, which ones must be backed up?
",jimonreal,slackpad
1509,2016-01-06 04:48:00,"Hi @jimonreal - glad you got things working again!

Here's an issue that has some details about backing up Consul - https://github.com/hashicorp/consul/issues/1254. You'll basically want to back up the whole data-dir, but there are some issues that could arise in restoring it that we are working on making better. There are tools mentioned there that can help you independently back up things like the KV store.
",slackpad,jimonreal
1508,2015-12-16 15:09:24,"Hi @shmizad - thanks for opening an issue! There is a 30 second limit enforced here - https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L175. We'd need to look through the surrounding code to make sure it's ok to tune this with a config, but we can definitely document this and provide a good error message (it gets emitted through a channel but not logged for the timeout case).
",slackpad,shmizad
1507,2015-12-19 03:12:07,"Hi @subchen the DNS resolution is being done down in here - https://github.com/hashicorp/memberlist/blob/master/memberlist.go#L218-L234. Is it possible that host has multiple IPs registered with DNS and maybe Go is picking a different one to try?
",slackpad,subchen
1507,2015-12-21 03:38:35,"Hi @slackpad, I only added some records in `/etc/hosts` to resolve the domain/FQDN.



I don't know whether the DNS resolve library only uses real DNS and skips the `/etc/hosts`.
",subchen,slackpad
1507,2017-02-03 09:13:10,"@slackpad We experience the same issue. It seems `tcpLookupIP` goes to dns server directly and bypasses `/etc/hosts`. IMO this is wrong because you should respect `resolv.conf` in host lookups. This behavior makes Consul to fail connecting other agents in Azure environment. (In our case azure FQDN's are resolved to public IP address from the DNS server, but internal IPs are saved under `/etc/hosts`. When Consul resolves FQDN from DNS, it gets a public IP where it is firewalled and Consul is not bound to. Hence, Consul fails to join.)

Is there a true benefit from performing`tcpLookupIP` instead of `net.LookupIP`? Can we simply ignore that logic and perform go's net package?",kaskavalci,slackpad
1507,2017-02-03 14:48:39,"@kaskavalci ok this makes sense now. We want to keep the behavior of using TCP to get the largest possible list of hosts, but you are right that it breaks `/etc/hosts`. I think the best thing here would be to use Go's lookup and then `tcpLookupIP` and then merge + dedup the lists.",slackpad,kaskavalci
1507,2017-02-03 14:53:40,"@slackpad hmm, wouldn't that include multiple IP addresses for the same host? Assume the following `/etc/hosts` file:



We expect loopback address when we use go's lookup only but `tcpLookupIP` will return google's address too which will cause Join errors.
",kaskavalci,slackpad
1507,2017-02-07 10:29:10,"Hi @slackpad , are you OK with using only go implementation? I can send a PR for that as well.",kaskavalci,slackpad
1502,2015-12-15 17:50:45,"Hi @far-blue that should be everything:



The last release inadvertently had a sub-folder called ""dist"" that we removed for this release:



But the contents are all there, just without that sub-folder. Sorry if that caused some confusion!
",slackpad,far-blue
1501,2015-12-15 23:30:35,"Hi @raitech this is the expected behavior if the servers are shutdown but they don't leave the cluster, so the Raft layer thinks there should be three servers but only one is available so it can't elect a leader. If you have the servers gracefully leave, or update your peers.json file to remove the failed servers then it should work (removing the Raft directory also works since the peers.json file is in there).

This issue has some more context - https://github.com/hashicorp/consul/issues/750.
",slackpad,raitech
1500,2015-12-19 07:11:41,"Hi @ErikEvenson take a look at https://github.com/sethvargo/atlas-demo - that's got an end-to-end demo with Consul that should be helpful (though be careful it is set up to allow open access for demo-ing). There are some ssh examples for key handling in there.

/cc @sethvargo 
",slackpad,ErikEvenson
1500,2015-12-21 16:07:46,"@slackpad @erikdubbelboer here are some more examples:
- https://github.com/sethvargo/terraform-workshop-atlas
- https://github.com/hashicorp/best-practices
",sethvargo,slackpad
1499,2015-12-17 01:39:45,"Hi @orivej - this looks like a good change, though we could get most of the benefit without disabling keepalives, since all API clients will share one underlying HTTP client by default. Wanted to see if you had some other rationale for including that, or if it was just an optimization. Thanks!
",slackpad,orivej
1499,2015-12-17 06:33:35,"@orivej the Travis failures are definitely not related to your change - we've been having trouble with CI today so I've been running things locally as well. Looking at the UNIX socket code in the Go library I don't think there's actually any support for keepalives for those, so it's probably not necessary to change.

I took a crack at doing pooling of all three of the cases here, drafting off your idea for the default transport variable and the other spots you identified - https://github.com/hashicorp/consul/pull/1517. What do you think?
",slackpad,orivej
1499,2015-12-17 15:56:16,"@orivej thanks for the clarification on the keepalives. Updating the insecure transport is a good improvement so I went ahead and added that and merged the change.
",slackpad,orivej
1499,2015-12-17 16:08:32,"@orivej See https://github.com/fsouza/go-dockerclient/pull/434#issuecomment-165495858 -- can we find a good way to fix this in `cleanhttp` so that everyone automatically benefits?
",jefferai,orivej
1498,2016-01-09 01:38:34,"Hi @autoric this is intentional. The watch does a check to make sure that the thing it is watching has indeed changed before it fires the handler:

https://github.com/hashicorp/consul/blob/master/watch/plan.go#L85-L87

In your case if you want to know if _any_ service has changed then making a blocking query to https://www.consul.io/docs/agent/http/catalog.html#catalog_services is the right way to go.
",slackpad,autoric
1498,2016-01-09 05:02:11,"@slackpad Thanks for the info and link to code. I appreciate the response.

I'll implement using my own watcher process and blocking queries.
",autoric,slackpad
1497,2015-12-16 02:04:45,"Hi @berendt,

Sorry about the issue with the URL.  I have a PR out to get this fixed.  https://github.com/hashicorp/consul/pull/1504

The correct URL for the demo is: https://atlas.hashicorp.com/hashicorp/environments/consul-demo

We will get this corrected in the getting started guide and thanks for creating this issue.
",pshima,berendt
1493,2015-12-11 15:58:08,"Woah, didn't realize we never updated this! Thanks @sethvargo, LGTM.
",ryanuber,sethvargo
1493,2015-12-14 19:43:10,"Thanks @sethvargo (and @tgwizard I fixed that)!
",slackpad,sethvargo
1489,2015-12-10 22:11:21,"Hi @c4milo do you know who's making these API calls?



It's odd there are HTTP requests to deregister it, those would come from some outside source.
",slackpad,c4milo
1488,2015-12-10 22:07:49,"Hi @ch-acctg - haven't seen that before - it looks like there are some strange bash errors in there. If you do `github.com/mitchellh/gox` does that work?
",slackpad,ch-acctg
1487,2015-12-10 18:56:02,"Hi @tzz this is a weird one :-) I looked through the code and the support is there and I can't seem to reproduce this locally (it respects the environment variable). What platform are you running on? Does `env` show the variable?
",slackpad,tzz
1485,2015-12-10 17:46:05,"Hi @omgold this is the expected behavior with just a single node. The graceful restart means that the single node never sees itself as unhealthy so it just snapshots its data with the session intact and then restores it, which is also when the node is healthy. If you had 3 servers, one of the other two would have taken over as the leader and then destroyed the session.
",slackpad,omgold
1484,2015-12-10 00:09:03,"@ryanuber it seems to me that if you don't specify `service` name in check, it will understand it as node-level check and apply to every service on that node. i got `docker` service says `passing 24` because it counts `docker` service itself + `serfHealth` + my own `dnsmasq` check, that doesn't have a `service` defined in the configuration. I am running 8 node cluster with `docker` on every instance. Am i getting it right?
",tpolekhin,ryanuber
1482,2015-12-09 17:07:39,"Hi @rbrutas I'll try to reproduce this locally and see what's going on. Are there any related log entries on your Consul servers around the time the agent is trying to register the service?
",slackpad,rbrutas
1482,2015-12-09 17:22:55,"Hi @rbrutas one other thing - that `curl` call will need to use a capable token to read the service back (the app token has sufficient rights as you've defined it so you could try `?token=<ID>`) if the anonymous token doesn't have read permissions to all services - see https://www.consul.io/docs/upgrade-specific.html. That might be it and ""app"" is just getting filtered for the anonymous token.
",slackpad,rbrutas
1482,2015-12-09 17:37:21,"thanks @slackpad 

the only reference i see on the cluster logs;



I am running the curl on one of the consul cluster node.
",rbrutas,slackpad
1482,2015-12-09 17:58:11,"Hey @rbrutas,

It sounds like you are seeing the effects of the new ACL enhancements in Consul 0.6. By default, service discovery is not wide-open as it was in the past. Instead, the services, nodes, and almost everything else in the `/v1/catalog` endpoints are filtered using the privileges of the ACL token being used. You can restore the exact same functionality that Consul 0.5.x had by configuring the ""anonymous"" ACL token, as outlined [here](https://consul.io/docs/upgrade-specific.html) in the 0.6 ACL Enhancements section.

I would also recommend reading the section about ""Blacklist mode and Service Discovery"" on the [ACL documentation](https://consul.io/docs/internals/acl.html) as it has a few good details to know about the new system.

Hope that helps!
",ryanuber,rbrutas
1480,2015-12-16 15:02:15,"Thank you for the tip @daveadams . Unfortunately this currently disqualifies the use of the official client https://github.com/Ecwid/consul-api or the puppet module https://forge.puppetlabs.com/KyleAnderson/consul since those do not offer such a way easily. The documentation also states here https://consul.io/docs/agent/checks.html that one is able to specify a name for the check. 
So, is there the idea of adding that? 
",das-vinculum,daveadams
1479,2016-01-09 01:07:26,"Hi @lukesteensen there's an open issue to make it configurable - we will fix the docs at the same time :-)

https://github.com/hashicorp/consul/issues/1435
",slackpad,lukesteensen
1479,2016-01-09 01:08:49,"Thanks @slackpad!
",lukesteensen,slackpad
1478,2015-12-08 22:02:29,"Hi @drankinn - previously Consul would basically just pick one, so it wasn't a very good mechanism to rely on. This is an interesting problem, though. If you can't bind to 0.0.0.0 then I think you would have to pull the address as things stand now, though this could be made better if Consul would let you bind to an interface name, looking up the address for you.
",slackpad,drankinn
1478,2017-03-27 19:34:26,"@sean- awesome, to bad it's not mentioned in https://www.consul.io/docs/guides/bootstrapping.html or https://www.consul.io/docs/agent/options.html",salzig,sean-
1477,2015-12-08 18:26:48,"Hi @calvinirwin - you should use the agent API to register the services that are running on a given agent. The agent will take care of syncing the service with the catalog, as well as tying that service to the node that the agent is running on. That way if the node becomes unhealthy, the service will get marked as unhealthy as well. It's pretty rare to write to the catalog directly - usually you use the agent API (or configuration files on the agent) to register services and then let the agent sync them up.

There's an example here - https://www.consul.io/docs/agent/http/agent.html, please see the ""/v1/agent/service/register"" section. Hope that helps!
",slackpad,calvinirwin
1476,2015-12-08 18:22:31,"Hi @jmealo the best way to see where the memory is going is to set the `enable_debug` option on one of your servers and then look at http://localhost:8500/debug/pprof/heap?debug=1 on that server to see the heap profile. Can you post the top few entries from there into a gist?

Consul 0.6 has a number of fixes to improve memory usage, including a new in-memory database that's more efficient as well as automatic reduction of large receive buffers for idle connections to the servers (these can definitely hit a few hundred megabytes if your servers have gotten a huge burst of RPC traffic).
",slackpad,jmealo
1476,2015-12-09 03:22:37,"@slackpad I'll definitely be documenting this as the OOM killer just took out one of my load balancers. This configuration worked flawlessly on 512mb ram prior to introducing Consul. Now even with a 1024mb box consul is able to take the whole node down.
",jmealo,slackpad
1476,2015-12-09 23:03:21,"@slackpad: I upgraded to 0.60 and the problem persists. Here's the output of /debug/pprof/heap?debug=1 after running for 8 hours 38 minutes.

[output.txt](https://github.com/hashicorp/consul/files/57456/output.txt)
https://gist.github.com/jmealo/fbae77eca68cca535fb9

**Output of `free -tm`:**



**Output of `cat /proc/meminfo`:**



**Output of `slabtop -o`:**



**Output of `vmstat`:**


",jmealo,slackpad
1476,2015-12-10 06:44:34,"Hi @jmealo - that latest dump looks pretty normal as well, and looking at the end `# Sys = 57092344` that looks like the Go runtime thinks it's using on the order of 60 megabytes, which is super reasonable for a Consul server. Can you run `ps -eo vsz,rss,comm | grep consul` so we can see what the RSS value is for Consul?
",slackpad,jmealo
1476,2015-12-10 18:20:16,"@slackpad We just hit 92% memory usage again, attached are the output of all of the commands that I've provided before as well as the `ps` output that you requested for consul, nginx, and all processes.

[consul_debug.txt](https://github.com/hashicorp/consul/files/58498/consul_debug.txt)
[free.txt](https://github.com/hashicorp/consul/files/58501/free.txt)
[meminfo.txt](https://github.com/hashicorp/consul/files/58500/meminfo.txt)
[nginx.ps.txt](https://github.com/hashicorp/consul/files/58503/nginx.ps.txt)
[ps.all.txt](https://github.com/hashicorp/consul/files/58502/ps.all.txt)
[slabtop.txt](https://github.com/hashicorp/consul/files/58499/slabtop.txt)
[status.txt](https://github.com/hashicorp/consul/files/58504/status.txt)
[vmstat.txt](https://github.com/hashicorp/consul/files/58505/vmstat.txt)
[consul.ps.txt](https://github.com/hashicorp/consul/files/58506/consul.ps.txt)
",jmealo,slackpad
1476,2015-12-10 18:39:18,"@slackpad: I don't think so, we're not heavily using it right now. We have 7 nodes and 48 health checks total.
",jmealo,slackpad
1476,2015-12-10 18:48:57,"@slackpad Thanks for all of your help/patience. This is what the memory usage looks like, it presents itself like a classic memory leak, however, it doesn't seem to be based on requests or traffic, but rather time.

![screen shot 2015-12-10 at 1 46 32 pm](https://cloud.githubusercontent.com/assets/1066536/11724859/8c3c21be-9f44-11e5-9214-e6e3a9742a15.png)

Due to consul running health checks at regular intervals, that might create enough traffic to influence the graph.
",jmealo,slackpad
1476,2015-12-15 00:12:49,"@slackpad: It certainly seems like it is raft using up the memory (see output below). I'm not sure why `pmap` is the only tool that knows that it is consul consuming the memory. I will dump telemetry if I'm able to sanitize it easily.


",jmealo,slackpad
1476,2015-12-15 00:22:38,"@slackpad `kill -s USR1 $(pidof consul)` doesn't seem to work for me when syslog is enabled in the consul server config file. Do I need to run the process in the foreground or pipe `stderr` to a file to dump telemetry?
",jmealo,slackpad
1476,2015-12-15 23:25:13,"@jmealo yes for telemetry it won't go to the syslog writer, it'll be written to your Consul server's `stdout` so you'll need to grab that wherever it is being logged.
",slackpad,jmealo
1476,2015-12-16 01:26:58,"@slackpad: It's been 1 day 20 minutes since I disabled consul on my cluster and we've experienced no memory issues. Prior to disabling consul I had to reboot the servers every 6 hours to clear memory. I'll rest easier if we let it go another couple of days, but, this configuration worked for 2-3 months without Consul and removing it seems to immediately solve the problem, so I can say with some certainty that Consul is the issue.

I don't know why only the load balancers have this issue, the only difference in their configuration is the allowed number of open files is significantly higher, which could possibly be allowing something to leak handles.

To me the `pmap` output makes it clear that raft.db is using a significant amount of memory. Perhaps log compaction is leaking memory?

If it helps at all this happened in 0.5.x and 0.6.x so the large changes in 0.6.x probably don't have anything to do with it.
",jmealo,slackpad
1476,2016-01-08 06:57:40,"@jmealo do you have any updates on this one? I think it's unusual in general to run application stuff like load balancers on your Consul server nodes, typically folks want to keep them isolated. In the pmap outputs above the RSS values for Consul look to be ~40 MB which is pretty reasonable.
",slackpad,jmealo
1476,2016-01-08 20:39:09,"@slackpad Thank you for following up. As excited as we were about consul we ended up reimplementing everything we needed from it in Node in about a day and have had zero infrastructure issues since we got rid of Consul.

My only update is that Consul was the cause of the OOM issues.

I guess it's safe to close this ticket; however, the problem exists and causes catastrophic failures that could take every node in a cluster down one-by-one within a few minutes of each other if consul is started at the same time on each node where this condition is present. This would obviously be bad but also likely require the user to redo the bootstrap process.

That might be a good thing, because if the cluster goes down and comes back up and consul isn't working, it won't take down the cluster again.

We sunk a couple of weeks of troubleshooting and hours of downtime in production into this and I hope that nobody else goes down that rabbit hole.

If you think of it whenever the problem is finally solved or encountered on your end please ping me :-)
",jmealo,slackpad
1476,2016-01-08 20:56:09,"I'm glad you found a solution @jmealo. If you ever get around to it we'd love to look into this further with you but if you're happy with your current solution its best to leave it as-is.

We work personally (1-on-1) with a handful of the largest websites that exist that run gigantic Consul clusters and in the past we have found memory leaks we've fixed straight away (none recently to my knowledge). These clusters generally run with a long uptime and their memory usage is stable. They use every feature of Consul (at least prior to 0.6, folks are still adopting 0.6 features) and have never experienced memory issues.

None of this means that you didn't have a real issue, but I'm confident that in the general case Consul is extremely stable and memory is well under control. There may have been something unique about your setup we missed through the back and forth here, though. I think @slackpad overall was correct and I mirror his view that all your debug output seems to point to Consul using a very reasonable amount of memory. So we must be missing some data somewhere.

Good luck and let us know if we can help in the future.

(EDIT: sorry ""james"" in GitHub for pinging you with this, I meant @slackpad)
",mitchellh,slackpad
1476,2016-01-08 20:56:09,"I'm glad you found a solution @jmealo. If you ever get around to it we'd love to look into this further with you but if you're happy with your current solution its best to leave it as-is.

We work personally (1-on-1) with a handful of the largest websites that exist that run gigantic Consul clusters and in the past we have found memory leaks we've fixed straight away (none recently to my knowledge). These clusters generally run with a long uptime and their memory usage is stable. They use every feature of Consul (at least prior to 0.6, folks are still adopting 0.6 features) and have never experienced memory issues.

None of this means that you didn't have a real issue, but I'm confident that in the general case Consul is extremely stable and memory is well under control. There may have been something unique about your setup we missed through the back and forth here, though. I think @slackpad overall was correct and I mirror his view that all your debug output seems to point to Consul using a very reasonable amount of memory. So we must be missing some data somewhere.

Good luck and let us know if we can help in the future.

(EDIT: sorry ""james"" in GitHub for pinging you with this, I meant @slackpad)
",mitchellh,jmealo
1476,2016-01-08 21:19:41,"@mitchellh I'd really like to see this fixed. My node solution simply parses my consul health checks and runs them using Node instead of Consul. The health checks are unchanged except for one that checked a socket.io server by requesting `/socket.io.js` which is 170kb uncompressed and seemed the likely cause of the issue.

I can say with high confidence that the health checks were not the issue as they are running from Node without issue. As part of our consul troubleshooting, the socket.io test was disabled without relief.

The issue at hand here is consul/go-raft/go was causing a memory leak that:
1. Consul's telemetry doesn't know about
2. Every ""normal"" way of checking memory and shared memory allocation in Linux provided no insight into the cause of the issue

My primary concern is that another enduser will go absolutely bonkers trying to figure this out. I myself was convinced that consul was not the issue based on our troubleshooting. I went to DigitalOcean, KVM, linux-kernel NGINX, OpenResty, consul trying to figure out the memory usage issue to no avail. 

If I can get a box setup and recreate the conditions can you delegate engineering time to work on this?I'm not sure if I can reproduce it without the other 7 nodes in the cluster but it might be worth a try.

The stack that caused this will be open sourced in the not so distant future (a year tops). I may be able to provide bootstrap scripts for an entire cluster identical to this one at some point if you want to test it internally.

Thanks,
Jeff

EDIT: Additional info on largest health check response and wording.
",jmealo,mitchellh
1476,2016-01-08 22:43:54,"@jmealo I'll go ahead and kick this one back open. If you can get a repro environment that won't disrupt your operations and that we can poke at I can give you some cycles to try to see what's going on. Appreciate you offering to set that up!

If you had a health check that was logging on the order of megabytes and churning it could cause some bad GC behavior possibly, depending on how often it was running. That would be something to take a look at.

With regards to a richer HTTP check we've gotten requests for that but generally avoided adding more features in favor of people just scripting their own with `curl` or `wget` if they need more features. There are so many possible options and we want to keep the Consul core as simple as we can, unless a new feature is a huge win for a lot of different use cases.
",slackpad,jmealo
1476,2016-04-07 01:09:03,"@slackpad @mitchellh From the looks of it this was a kernel leak caused by non-process code (which is why the memory could not be attributed to a process).

That being said, using OpenResty and consul together can reproduce the issue. Using either in isolation does not.

The issue did not happen when running vanilla NGINX with consul. The only difference is that OpenResty is serving 1-2k connections and NGINX was in the low hundreds. Since both the primary and failover load balancers would both fail after a set amount of time regardless of connection or load, I think it's safe to say that the network traffic has nothing to do with it. 

In the interest of saving everyone time (unless someone wants to learn how to diagnose kernel memory leaks in KVM on a cloud provider) I'd be willing to give it another go when Ubuntu 16 LTS is released.

**Does that sound like a good plan?**
",jmealo,mitchellh
1476,2016-04-07 01:09:03,"@slackpad @mitchellh From the looks of it this was a kernel leak caused by non-process code (which is why the memory could not be attributed to a process).

That being said, using OpenResty and consul together can reproduce the issue. Using either in isolation does not.

The issue did not happen when running vanilla NGINX with consul. The only difference is that OpenResty is serving 1-2k connections and NGINX was in the low hundreds. Since both the primary and failover load balancers would both fail after a set amount of time regardless of connection or load, I think it's safe to say that the network traffic has nothing to do with it. 

In the interest of saving everyone time (unless someone wants to learn how to diagnose kernel memory leaks in KVM on a cloud provider) I'd be willing to give it another go when Ubuntu 16 LTS is released.

**Does that sound like a good plan?**
",jmealo,slackpad
1476,2016-04-13 07:19:25,"Hi @jmealo thanks for the update - that sounds like a good plan!
",slackpad,jmealo
1472,2015-12-08 23:57:18,"Thanks for the great suggestion @taras!  Appreciate the work you do in the Ember community, too. The codebase for the UI has definitely lagged behind Ember releases substantially, and could use a dose of love.

However, I have a few worries about a large scale refactor and upgrade. Don't want to be too discouraging but want to be clear and respect your time.
- The current automated tests are _very_ shallow and don't cover a ton of the use cases. Upgrading and testing changes would require a lot of knowledge about UX for this UI and comparison with a full active instance of it. Something like http://demo.consul.io shows a set of the various states, but still lacks certain features (locks, ACLs).
- This UI is relied upon for critical infrastructure changes so there's not a lot of room for error and iteration â€“ we can't push breaking changes to things like k/v, full stop
- The packaging and dist scripts for our current release process are not npm backed, which might be a headache
- We have some bandwidth and Ember folks internally who can spend time reviewing this, but we can't make it a priority unfortunately, so timelines might be long there.

The intent here is really great, and I don't want to act like this isn't necessary, but just wanted to be up front that this requires a lot of Consul understanding and has some hidden complexity. If you're comfortable with that, you're welcome to work on a WIP of this and we can give you some early feedback.

Thanks again for thinking of the project.
",pearkes,taras
1472,2015-12-09 12:59:20,"@pearkes thank you for the detailed explanation - it's helpful in planning the mentoring and the process to make this code merge-able.

> The current automated tests are very shallow and don't cover a ton of the use cases. Upgrading and testing changes would require a lot of knowledge about UX for this UI and comparison with a full active instance of it. Something like http://demo.consul.io shows a set of the various states, but still lacks certain features (locks, ACLs).

Having some automated tests is helpful. We'll aim to not modify the HTML output to make it possible for you to run your test suite to verify the application. We're going to add acceptance tests to the application, so you'll have more tests when we're finished but it'll require manual checking on your part when we're finished.

> This UI is relied upon for critical infrastructure changes so there's not a lot of room for error and iteration â€“ we can't push breaking changes to things like k/v, full stop

We can keep this project fairly low risk and aim to have code ready for you to review. Your team can use the new app when you're ready.

> The packaging and dist scripts for our current release process are not npm backed, which might be a headache

This should be fine. We'll copy the Ember App code into a new EmberCLI project. With EmberCLI, we can run `ember build` which will generate 2 files: `vendor.js` and `application.js`. The only change that you'll need to make will be to copy the files into the main repo and link to these new files. 

> We have some bandwidth and Ember folks internally who can spend time reviewing this, but we can't make it a priority unfortunately, so timelines might be long there.

Our goal will be to upgrade the application to use all of the latest best practices in a new EmberCLI project. We'll speak to the demo API(likely via a proxy). You should be able to test the application by setting up a more complete cluster and point to it's API.

> Just wanted to be up front that this requires a lot of Consul understanding and has some hidden complexity

It would be difficult to go all the way with this project without your team being onboard to work with us, so we'll just do what we can.Refactoring the app into the latest best practices on EmberCLI seems like a fairly straight forward project. We can aim to have all of the features implemented that are currently visible on the demo site. The result will be a repo that'll build the app and talk to the demo API. At that point, you can take that code and integrate into your application when it becomes a priority.

What do you think?
",taras,pearkes
1471,2016-01-09 01:05:00,"Hi @wwalker do you have the full set of servers joined up if you do `consul members -wan`? This looks like all of your servers are getting pulled out of the Serf members list, which is very odd (unless you are having intermittent connectivity issues).
",slackpad,wwalker
1470,2015-12-04 19:43:05,"Hi @shore I think this will be fixed in Consul 0.6, which should be released next week - https://github.com/hashicorp/consul/pull/1222. We've got a release candidate build if you want to give that a shot on one of your agents - https://releases.hashicorp.com/consul/0.6.0-rc2/ - it will interoperate with 0.5.2 servers.
",slackpad,shore
1468,2015-12-04 22:02:21,"Hi @hadrienk can you elaborate on your use case a little more? I think you could get this behavior now if you register a script as a health check for service A that calls into Consul and checks the health of service B, but I'm not sure if I fully understand what you'd like to do.
",slackpad,hadrienk
1468,2015-12-07 11:36:19,"Hi @slackpad, I was thinking of doing this with a check scripts indeed but I came across this in the consul documentation about HTTP checks: 

> This type of check should be preferred over a script that uses curl or another external process to check a simple HTTP operation.

In my scenario, I have services that depend on other services to function properly. Registering a check script to check via HTTP something that is already checked and available to the consul cluster seems wrong. But maybe I am trying to achieve too much out of the tool? 

Actually, stretching this idea even further, the ideal thing would probably be to be able to register dependencies on other nodes health checks or service checks that are within the cluster don't you think?
",hadrienk,slackpad
1468,2016-02-26 08:27:16,"+1 
**/v1/health/service/<service-id>?passsing** should not return 200 when result is empty
Use case - AWS ELB health checks, but @hadrienk use case seams powerfull too.

It looks like previous will not cover AWS ELB node healthcheck
Could it be new agent api endpoint, something like **/v1/agent/service/<service-id>?passing** and **/v1/agent/self?passing** ?
",123BLiN,hadrienk
1467,2015-12-04 05:30:46,"Awesome - thanks @meirish!
",slackpad,meirish
1467,2016-01-14 23:59:22,"@slackpad where are you seeing this? on demo.consul.io I see the SVG icon in Chrome, but the old icon in Safari - any chance I'm just hitting a server running older ui code in Safari?
",meirish,slackpad
1466,2015-12-11 04:59:34,"@tongda Could you provide the output for the `curl`s, Consul and Consul-template `config` files, and logs?
",keyan,tongda
1466,2015-12-16 15:05:30,"@keyan Thanks for your reply. Here's the logs:

I have got 2 nodes consul cluster.



When I try to query services from master, it works well.



But if I query services from slave, services are missing.



I guess that a `service` is bound with an `agent`. But I'm not sure.
",tongda,keyan
1466,2015-12-19 03:07:37,"Hi @tongda - what's happening is that services are registered with the agents, either through agent configuration files or the agent API as you've used in these examples. The agents then periodically sync their configuration up with the Consul servers. From there, service information _for all nodes in the cluster_ is then available via the catalog (https://www.consul.io/docs/agent/http/catalog.html) and health (https://www.consul.io/docs/agent/http/health.html) apis, or via DNS queries. If you query the agent API you'll only see services configured on that agent, but basically everything else (like consul-template) queries these other endpoints to discover services.

You can find more details here - https://www.consul.io/docs/internals/anti-entropy.html. Hope this helps!
",slackpad,tongda
1466,2015-12-22 13:14:29,"@slackpad That's helpful! Thanks.
",tongda,slackpad
1465,2016-06-13 07:05:58,"@CpuID yeah that _seems_ to do the trick for me. 
",asheshambasta,CpuID
1465,2016-08-11 16:38:47,"We ran into the same issue @sam0737 with the Windows 2016 TP5 cross Azure boundaries. Will take a look into the heart-beating source code.
",sitano,sam0737
1465,2016-09-21 02:58:17,"@sitano that's a very interesting result. Is it possible for memberlist to become aware of the mapped ports by any direct means, or is that completely hidden because of the container wrapping? It would be nice if we could use some API to get this and configure accordingly without having to get feedback from peer nodes. TCP is possible for limited clusters, but won't scale well.
",slackpad,sitano
1465,2016-09-29 11:06:56,"@slackpad The question is about two things. 

> is that completely hidden because of the container wrapping?

I think this information is hidden from the environment of the guest (container), because this is exactly the point of the abstraction layer - transparent resource isolation. From the isolation standpoint, there is no sense to expose the information on how ports are mapped on a different level to the virtualized env.

> Is it possible for memberlist to become aware of the mapped ports by any direct means

Acquiring this information is possible, yet it is not very easy. The starter environment inside of the container may be organized by any means to obtain this information from the Docker daemon (requested mapping), host conntrack/nat configuration (Get-NewNATSession/StaticMapping) or any other way available; and then it should pass gathered info on mapped ports to the consul server agent start command line. And there are may exist other levels of indirection. Organizing all this is not very pleasant.

Personally, I would prefer MemberList to be able to detect miss-advertised ports automatically based on the stats of the incoming UDP traffic. The thing is the wrong port advertisement can be detected only from the outside of the container network host environment, so memberlist could reuse additional knowledge to at least detect such a cases.
",sitano,slackpad
1465,2016-10-01 16:34:36,"@slackpad I wanted to share another thought

This NAT issue is not a _BUG_. The bug is an error in implementation or environment. But a cause of this flapping behaviour is not an error, but wrong ports configuration. It's not a fault of the Consul, that it awaits properly declared ports to be available in advance. The fact of mismatching of advertised ports and mapped ports results into the situation where one side\or both of membership protocol does not see ping's acks.

Flapping behavior, in that case, is also normal, due to how MemberList is working. Suspect nodes can successfully refute its deadness. There is also a separation of MemberList operations between active and passive (ping ack is passive, refuting and resync is active).

Flapping is possible when behind a NAT, there is a still partial visibility (some ports are accessible and known, others dont) and is, due to the protocol best effort.

Maybe this issue (and all related) could be closed then, because the only way to organize valid networking for the Consul, is to know your ports, and not to advertise wrong ones. We run it on Linux docker like that:


",sitano,slackpad
1464,2015-12-12 19:54:11,"@rahul8590: Yup, https://www.consul.io/docs/agent/options.html#_bootstrap
",keyan,rahul8590
1461,2016-01-08 06:46:12,"Hi @zeldal have you tried Consul 0.6+? It should have better GC behavior and lower CPU usage owing to its new in-memory state store.
",slackpad,zeldal
1460,2015-12-01 20:35:55,"Hi @sflint - that error is embedded into Consul's [index.html](https://github.com/hashicorp/consul/blob/master/ui/index.html#L37-L51) and is displayed client-side if it has problems making requests to the Consul server. From the looks of things, 200 response code and getting the index page back, it looks like things are working. Can you try via a web browser and see how that goes?
",slackpad,sflint
1460,2015-12-01 23:19:54,"@slackpad  Than you so much for your help.  This came down to a subnet issue.  I am not sure why it would get a 200 back at all if it was on the wrong subnet, but it did.  I have since resolved the issue by creating another load balancer and placing it on the right subnet.  
",sflint,slackpad
1455,2016-03-22 17:15:06,"Agree - closing this out - please use the mailing list if you have any more questions @psihodelik, or re-open this. This issue tracks making the reap interval configurable - https://github.com/hashicorp/consul/issues/1435.
",slackpad,psihodelik
1454,2015-11-28 21:48:43,"@AlessandroEmm We use it to disambiguate between a service, node, or prepared query lookup. Otherwise the query is ambiguous as it could be any of those three, and we prefer explicit and non-ambiguous behavior.
",armon,AlessandroEmm
1454,2015-11-29 22:28:44,"@AlessandroEmm Unfortunately no. Consul is not really intended to serve public DNS requests, but you could probably hook something up with BIND to customize the DNS names.
",armon,AlessandroEmm
1452,2015-11-29 04:47:58,"@slackpad we may as well. It's a small change but should drop the memory foot print noticeably.
",armon,slackpad
1448,2015-12-21 23:19:56,"Hi @gozer - would you mind sticking the address at the end of the log message and using the new log functions from memberlist, so these will all look the same? Here's an example: https://github.com/hashicorp/consul/blob/master/consul/rpc.go#L86. There's a `LogAddr` function that should work for your use case here. Thanks!
",slackpad,gozer
1448,2015-12-22 23:29:22,"@gozer sorry I didn't realize that. In that case, it should be good enough to stick it at the end as `""... from=%s""` to match the memberlist format. Agree it's not worth converting to an address.
",slackpad,gozer
1448,2015-12-30 20:41:28,"@slackpad done as suggested
",gozer,slackpad
1448,2016-01-05 04:59:31,"@gozer thanks for the update! One other thing - I think your `split()` call will mangle IPV6 addresses - since it's just a string I'd probably just print it with the port number.
",slackpad,gozer
1448,2016-01-05 16:52:04,"@slackpad, you are absolutely correct, that address splitting had bothered me from the start, to be honest. Removed as suggested.
",gozer,slackpad
1440,2015-11-25 04:27:25,"@eladapps is the node actually still alive? If you are using the force-leave command, and the member is actually still up and running, it will eventually re-join the cluster. If the remote node is still running, shutting it off and making sure it has left should make this permanent. See the docs [here](https://consul.io/docs/commands/force-leave.html) for more detailed info.
",ryanuber,eladapps
1440,2015-11-25 06:19:41,"The node is long dead. And  machine hasb been turned off. But somehow it
gets back again. And im seeing tons of messages in the consul.log
On 25 Nov 2015 06:27, ""Ryan Uber"" notifications@github.com wrote:

> @eladapps https://github.com/eladapps is the node actually still alive?
> If you are using the force-leave command, and the member is actually still
> up and running, it will eventually re-join the cluster. If the remote node
> is still running, shutting it off and making sure it has left should make
> this permanent. See the docs here
> https://consul.io/docs/commands/force-leave.html for more detailed info.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1440#issuecomment-159488746.
",eladapps,eladapps
1439,2015-11-25 17:10:49,"@hridyeshpant does the curl succeed from inside of the container? If so this may be a docker networking issue. Otherwise, can you share the configuration?
",ryanuber,hridyeshpant
1439,2015-12-17 14:30:17,"@ryanuber sorry for the late reply.
i am using docker setup from https://github.com/gliderlabs/docker-consul/blob/master/0.6/consul-server/Dockerfile 

> > Running consul
> > docker run test  -bootstrap -ui-dir /ui
> > ==> WARNING: Bootstrap mode enabled! Do not enable unless necessary
> > ==> WARNING: It is highly recommended to set GOMAXPROCS higher than 1
> > ==> Starting Consul agent...
> > ==> Starting Consul agent RPC...
> > ==> Consul agent running!
> >          Node name: '23f87bf86c12'
> >         Datacenter: 'dc1'
> >             Server: true (bootstrap: true)
> >        Client Addr: 0.0.0.0 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
> >       Cluster Addr: 172.17.0.6 (LAN: 8301, WAN: 8302)
> >     Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
> >              Atlas: <disabled>

==> Log data will now stream in as it occurs:



==> Newer Consul version available: 0.6.0

> > inside the container 
> > curl  localhost:8500
> > <a href=""/ui/"">Moved Permanently</a>.

but if i ran curl  -L localhost:8500 , i am getting the output.

> > outside the container http://172.17.0.6:8500/ is not working , where 172.17.0.6 container ip 

i am able to see ui folder inside the container 

> > bash-4.3# ls /ui
> > index.html  static
> > 
> > docker ps
> > CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                  NAMES
> > 23f87bf86c12        test                ""/bin/consul agent -s""   8 minutes ago       Up 8 minutes        8300-8302/tcp, 8400/tcp, 8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp   sharp_wright
",hridyeshpant,ryanuber
1433,2016-08-13 01:25:18,"Hi @Unix4ever thanks for the PR! I'm going to take the ideas here and in #1432 and make a time-based control that works for any health check type. Will update.
",slackpad,Unix4ever
1432,2016-07-06 23:09:33,"@slackpad Thank you for response. This is quite demanded feature and everyone is too excited.
",t3hk0d3,slackpad
1432,2016-07-07 06:33:51,"Great! @slackpad let us know if we should rebase & fix this pull request to match the current master head
",adamdubiel,slackpad
1432,2016-08-07 22:55:06,"@dankraw We've discussed this a bit and are still discussing how best to proceed.  We've definitely come to agree that the agent is the authority for when a service should be dergistered and GCed.  For example, instead of:



Simplify it down to:



The key is a little word, but the behavior is explicit: after 60s of being in a critical state the service will be deregistered and automatically GCed.  The current default could be `0s` which matches the current behavior of an infinite duration on deregistration.  Does explicitly specifying a timeout in the critical state work for your scenario?
",sean-,dankraw
1432,2016-08-08 09:04:03,"@sean- Thanks for the response. I like your suggestion about changing the api as it's more human-friendly and unified for all types of checks. I'll have a look at the fresh source code of Consul and probably make some bigger rebase / refactor of this PR - please, give me some time for that.
I've noticed that my change doesn't affect the check registration at `/v1/catalog/register`, should it be promoted to the catalog api?

By the way, If anyone is interested, we've developed a custom tool for the Mesos/Marathon environment that does the automatic service (de)registration - https://github.com/allegro/marathon-consul.
",dankraw,sean-
1432,2016-08-12 20:16:24,"@dwelch2344 Unfortunately, due to lack of time, I haven't jumped into it yet. I'll do my best to work on it as soon as possible, next week hopefully.
If you'd like to contribute providing the final solution, feel free to take over this PR. Just let me know. :)
",dankraw,dwelch2344
1432,2016-08-12 20:26:02,"@dankraw I'll make a branch off your PR and see if I can get this finished up in the next day or two - will update. This won't need any interaction with the catalog - everything should be on the agent side.
",slackpad,dankraw
1432,2016-08-12 20:43:12,"@slackpad Awesome, I'm very happy to hear that! :) 
Maybe it'll be even better to start from scratch as `deregisterCriticalServiceAfter` property suggest a better / cleaner solution for service removal. A single job wiping out critical services should do better, so there will be no mess in the code responsible for ""check update"".
",dankraw,slackpad
1425,2016-01-08 06:44:04,"Hi @djieef - was this with Consul 0.5.2?
",slackpad,djieef
1423,2016-01-07 17:16:09,"Hi @Kr1sso sorry for the delay in looking at this - once we get 0.6.1 released (hopefully today) we will make a sweep through all the PRs, including this one.
",slackpad,Kr1sso
1423,2016-01-07 18:01:56,"@slackpad Awesome, great work by the way!
",Kr1sso,slackpad
1419,2016-03-05 02:59:59,"@slackpad I don't think we want to do that. In the case where you have tons of ACL tokens, you probably don't want to pre-load them all, and the cache is a pretty huge performance win. Given that the logic is already there, I don't see a compelling reason to remove it.
",armon,slackpad
1419,2016-03-05 05:20:49,"@armon are you thinking we'd still replicate the full un-compiled policy set from the servers but retain the cache of compiled policies (so you could still look up any ACL in the event of a partition)?
",slackpad,armon
1419,2016-03-07 03:04:59,"@slackpad I'm not exactly sure what you mean, but I meant this would act as a second cache tier, and would not affect the existing caches.
",armon,slackpad
1419,2016-03-07 03:11:10,"@armon I think the main thing I'm stuck on is what subset of ACLs would you use to warm the cache?
",slackpad,armon
1419,2016-03-07 04:26:34,"@slackpad I think there is basically 2 different caches. Cache 1 is the existing LRU/2Q of fixed size. Its keyed on the actual token and cannot be disabled. Cache 2 would be new, keyed on the hash of the id, and would contain the _full_ ACL set.

The idea is ACLLookup(token) -> Cache1(token) || Cache2(hash(token)) || ACLResolve(token)
",armon,slackpad
1414,2015-11-15 01:56:23,"@mitchellh agree this is weird to fix at the state store level but I couldn't find any clean place to put these up in the HTTP layer without doing a bunch of post-filtering up there (some of these are nested inside other structures). I looked at the JSON marshaling and didn't see a good way to hook it in there (though that would have changed the API on other ways because we do have some `null` arrays in the JSON). I think it'll be the common case that we are going to fill these slices anyway (we were already `append`-ing onto a nil which kind of sucks since we don't know the sizes beforehand) so this won't be too bad.
",slackpad,mitchellh
1414,2015-11-15 05:09:17,"LOL @mitchellh your spidey sense was right with this one.

The failing test was due to a slice weirdness when I converted KV to be consistent. When a unit test tried to use the same reply object multiple times we ended up getting the underlying arrays pointed incorrectly. Looking into this I realized that KV already dealt with nil slices up at the HTTP layer, so I just changed the other endpoints to match. It was dirty to enforce the HTTP interface via the state store, and we were just getting lucky before because we did things and different layers.
",slackpad,mitchellh
1408,2016-03-19 00:13:35,"Hi @njbennett sorry for the late reply on this one! This is a pretty low-level interface and not really intended for use by other applications. Are you using the AgentRPC directly in your app and not the HTTP endpoints?
",slackpad,njbennett
1408,2016-03-19 05:11:27,"@slackpad  The functionality we needed (rotating encryption keys) is not available in the HTTP API.  In https://github.com/hashicorp/consul/issues/1368 we were told that RPC interface was not internal.
",rosenhouse,slackpad
1408,2016-03-22 00:14:30,"@rosenhouse ah ok now I understand the full context. This RPC interface should eventually be replaced by HTTP endpoints, so I'd like to avoid adding more public stuff related to it (we will give a clear heads up before we deprecate anything). Would you have any issues switching to an HTTP endpoint if that was available? I'd prefer to not merge this and focus on that instead.
",slackpad,rosenhouse
1408,2016-03-22 19:24:19,"@slackpad speaking on behalf of @rosenhouse we would prefer to only interact with consul over HTTP if that were possible. We were only using the RPC client out of necessity.
",ryanmoran,rosenhouse
1408,2016-03-22 19:24:19,"@slackpad speaking on behalf of @rosenhouse we would prefer to only interact with consul over HTTP if that were possible. We were only using the RPC client out of necessity.
",ryanmoran,slackpad
1408,2016-03-22 21:09:43,"@ryanmoran ok thanks - I'll close this against https://github.com/hashicorp/consul/issues/1867 which tracks adding an HTTP endpoint for this.
",slackpad,ryanmoran
1407,2015-11-11 20:30:57,"Hi @msabramo - what version of Consul are you running? Can you turn on debug logging on the agent and/or server to see if that sheds any more light?
",slackpad,msabramo
1407,2015-11-12 11:17:57,"@slackpad: Thanks! Email sent with the log file.

Re: hashicorp/vault#679; How do I check how many keys I have under `/vault/core/leader`?

Whenever I try to do a query like curl 'http://consul01:8500/v1/kv/vault/core/leader?recurse', it times out and causes the Consul server to crash.
",msabramo,slackpad
1400,2015-11-10 18:27:23,"Hey @JeffChien 

Thank you for your reply. Would you be able to share a command sample of what behavior you would like to see? It is still unclear from your response what behavior you desire. Specifically:
- Which APIs are you referencing?
- What customizations are you requesting we add?
- What is a sample JSON response you would like to see?

Thanks and sorry for the confusion! :smile: 
",sethvargo,JeffChien
1400,2015-11-11 17:07:34,"Hey @JeffChien, I think I see the problem. You want to pass `?separator=/` to a recursive K/V fetch, but it is not supported. Is that right? Currently the semantics of `?recurse` are just to fetch the entire sub-tree and return it. It's possible that we could also provide filtering using `?separator` to return a subset of keys. Let me know if that's what you are looking for.
",ryanuber,JeffChien
1400,2015-11-12 02:52:37,"@ryanuber that is exactly what I want
",JeffChien,ryanuber
1400,2016-03-30 22:01:10,"@ryanuber Any updates on this?
",aanm,ryanuber
1397,2015-11-20 07:37:05,"Hey @captainill this is looking awesome!

Running this locally and clicking around I had a few questions for you.

###### You probably need to rebase. A ""Prepared Queries"" section will get added to this nav:

![image](https://cloud.githubusercontent.com/assets/673509/11294102/8e3ba64a-8f15-11e5-9782-c8baa35d6044.png)

###### I'm seeing one 403 for a Typekit-related resource:

![image](https://cloud.githubusercontent.com/assets/673509/11294127/bcfd7a26-8f15-11e5-8a51-6623693669ca.png)

###### What do you think about anchoring the ""edit this page"" link to the bottom? When I first landed on this page I thought ""oops this is a placeholder"". It looks fine for long pages but a little funky for short ones:

![image](https://cloud.githubusercontent.com/assets/673509/11294145/f110b0b2-8f15-11e5-9c8c-15454ab13866.png)

###### Not sure if it is related to the 403 error, but these headings on the main page ended up super light:

![image](https://cloud.githubusercontent.com/assets/673509/11294155/0a9f6fd2-8f16-11e5-8db5-01f77effd634.png)

(same for the Key Value Storage heading that follows this one)
",slackpad,captainill
1397,2015-11-20 20:59:40,"@slackpad Thanks for looking over!

-I'll do the rebase
-The failed to loaded resource 403 is on the live site so it'll be good to fix that anyhow. Not sure what the story is there
-Ah! I actually anchored it in the other sites as I was doing this but I missed it here. Good call.
-I think that the header issue (super light font color) is just a selector issue but I'll fix whatever it is
",captainill,slackpad
1397,2015-12-04 06:49:41,"@captainill any chance you can make a pass through here again before we ship 0.6? Thanks!
",slackpad,captainill
1397,2015-12-20 19:27:10,"@slackpad Along with 'by HashiCorp' logo in the header being correct now I

-merged maste into my branch
-pinned the EDIT THIS PAGE link to the bottom
-made the H2 headings on the homepage readable

I had to reach out to Typekit about the 403. As far as I can tell typekit is configured correctly (the correct domain is listed for usage and the embed code is right) so I'm not sure what the deal is. I can report back when I get that sorted but if the rest checks out I would merge this and i'll circle back with a 403 fix when I've got it.
",captainill,slackpad
1396,2015-11-09 19:17:52,"Hey @saromanov, thanks for the pull request. The best way to control the result of the health check is by using exit codes. Consul's health checks are Nagios-compatible, so exit codes 0 == passing, 1 == warning, and anything else is critical. I would recommend using the exit code instead.
",ryanuber,saromanov
1395,2015-11-09 17:34:21,"Thanks @highlyunavailable - this wasn't intended so I'll get a fix in and look through the other endpoints. 
",slackpad,highlyunavailable
1394,2015-11-09 16:25:41,"Hi @saromanov thanks for making a PR, though I think this would be kind of an unexpected behavior for the `rtt` command (we were trying to make it feel a little like a `ping`. Did you have a specific use case in mind?
",slackpad,saromanov
1389,2015-11-17 06:45:43,"@armon For the Sort option, with the failover options also using RTT it seemed too confusing/crazy UX-wise. I plumbed it as a Source parameter to the endpoint so it works like all the others with a `?near=` argument over HTTP (like all the other coordinate-aware endpoints), but his does preclude it over DNS since there's no way to activate that. It's an advanced feature that's possible to use if you are building on the HTTP API, but not part of the DNS response anymore.

It seems very tricky to use via DNS properly (no load balancing and the agent you are sorting based on can be unclear if you are proxying Consul's DNS, recursing, etc.) so WAN-only use of RTT seemed like the clear winner and less of a foot shooter. I'm definitely open to adding it back in the query definition if you think it's useful for DNS as well. It would be a minor change, might even be doable as an agent option. It might even be clearer as an agent option so it can be explained as ""if I serve a prepared query, sort the results relative to me"".
",slackpad,armon
1389,2015-11-17 16:02:03,"@slackpad looking good, I left some minor feedback and questions throughout.
",ryanuber,slackpad
1388,2015-11-06 17:37:51,"Hi @jsullivan3 - this looks very useful. I'll review this once we get 0.6 out the door, as this is probably too big of a change to make it into that release. Thanks!
",slackpad,jsullivan3
1388,2016-09-30 04:56:22,"@slackpad any chance this PR can get some love now that v 0.7 is out? cheers
",DanyC97,slackpad
1388,2016-11-17 22:38:01,"Hi @jsullivan3 sorry for the looong delay on this one :-) Any chance you can rebase this one and we can work towards getting it in?
",slackpad,jsullivan3
1387,2016-08-11 02:12:45,"@slackpad I'm not so sure they're related, the issue I had was related to the node acquiring leadership, then losing it straight away (within a second, when running with quorum of 1). The buffer thing was separate to that.

Either way, I haven't seen this recently, so could be worth closing, unless others are also experiencing it?
",BRMatt,slackpad
1384,2015-11-07 06:47:59,"Hi @pbitty - we've got a few tests that are flaky in Travis, unfortunately - your log level change didn't break this one. I've got a PR up for prepared queries that also affects this code and I went ahead and deleted this log print altogether - https://github.com/hashicorp/consul/pull/1389. It is possible to query the health endpoint directly, so we probably don't want this high-volume log message at all, even at the DEBUG level.
",slackpad,pbitty
1383,2016-01-08 07:00:04,"Hi @zeldal this didn't make it into 0.6.1 but we will try to get it into the next release.
",slackpad,zeldal
1383,2016-09-01 19:39:42,"@jwbennet that setup is behind a proxy.
",slackpad,jwbennet
1383,2016-09-22 15:35:17,"@claudio-viola it didn't make it into 0.7.0 - it's high on the list for a follow-on release.
",slackpad,claudio-viola
1383,2016-09-22 15:40:43,"thanks for letting us know @slackpad !
",claudio-viola,slackpad
1382,2015-11-05 07:07:16,"Thanks @highlyunavailable ! That was very helpful.

In case it helps anybody, I applied your workaround in HAProxy like so:


",kvz,highlyunavailable
1380,2015-11-18 21:08:38,"Yep this should be fixed by https://github.com/hashicorp/consul/pull/1341 - once we roll out 0.6.0 (very soon) this will be fixed. Thanks for reporting this @yoshuawuyts and your help @highlyunavailable. Sorry we can't push it sooner but we don't want to confuse people with the docs for 0.6.0. 
",slackpad,yoshuawuyts
1380,2015-11-18 21:08:38,"Yep this should be fixed by https://github.com/hashicorp/consul/pull/1341 - once we roll out 0.6.0 (very soon) this will be fixed. Thanks for reporting this @yoshuawuyts and your help @highlyunavailable. Sorry we can't push it sooner but we don't want to confuse people with the docs for 0.6.0. 
",slackpad,highlyunavailable
1379,2016-01-08 01:32:48,"Hi @saromanov thanks for the PR. I think we'd want to do some more up front design work before adding this system - there's a lot to think about such as how to rotate logs, should requests fail if auditing is not possible, etc. We can work this under #414 once we put auditing on the roadmap, but I think we will hold off for now.
",slackpad,saromanov
1374,2015-12-03 19:37:02,"@slackpad - I've been thinking that it would be great expose an HTTP agent endpoint at /v1/status/info and perhaps another at /v1/status/members that would provide the info currently emitted in difficult to parse format from `consul info` and `consul members`.

I'd be happy to contribute a PR for this type of change if there is some agreement that it makes sense/would prove useful.
",trumant,slackpad
1374,2016-06-08 01:21:20,"@slackpad or @sean- do either of you have any updates on this issue?
",CpuID,slackpad
1373,2015-11-02 22:29:22,"Hey @kvz,

This is possible by modifying the source of the UI in the `ui/` directory of the source tree. I don't know exactly where the insertion point would be, but that is definitely possible. Another option would be to just have like a general ""datacenters"" dashboard with hard-coded links to each one. Not quite as elegant-looking, but gives the same basic effect.

We don't have any plans on making this an officially-supported thing since it could cause confusion in the more general sense, so I'm going to close this out. Please let me know if you have any other questions though!
",ryanuber,kvz
1372,2015-11-02 23:00:23,"Hi @xmackex,

Can you confirm that just the one config file is in use? Maybe try starting with `-config-file=/etc/consul.d/bootstrap/config.json`. If there are any `bind_addr` settings, that can affect the address that the internal server RPC layer will bind to. Consul shouldn't be picking this address all on its own for this purpose.
",ryanuber,xmackex
1372,2016-01-08 01:34:26,"@xmackex did you figure this one out? Please re-open if you are still having trouble!
",slackpad,xmackex
1371,2016-01-06 04:42:57,"Hi @half-dead - thanks for the PR. It looks like you can do this globally - https://github.com/hashicorp/consul/pull/1556#issuecomment-167966975. That's probably a better solution so we don't have to accumulate these changes in each project for each IDE flavor.
",slackpad,half-dead
1370,2016-01-08 01:57:13,"Hi @half-dead do you have any logs or other debugging info related to this? I haven't been able to reproduce this.
",slackpad,half-dead
1368,2015-11-03 20:01:24,"@highlyunavailable We're attempting to create fakes in order to unit test consumers of the `agent.RPCClient`. The problem we have now run into is that `agent.RPCClient.InstallKey()` returns a `keyringResponse` which is unexported. It seems like significant portions of the `RPCClient` (really, any of the various methods around keys) are actually unexported and therefor not necessarily suitable for 3rd party use.
",zaksoup,highlyunavailable
1358,2016-01-20 06:31:39,"Hi @skiold not yet - there's an open PR for this that we will review when we get a chance.
",slackpad,skiold
1358,2016-03-11 04:24:49,"@tahoemph you are correct. We only show it in the Docker example, but it isn't called out very specifically. We can update the docs to reflect this.
",slackpad,tahoemph
1358,2016-07-26 15:56:28,"@slackpad seems like #1430 is dead, should we create a new one or is there something that you're not satisfied with?
",amenzhinsky,slackpad
1358,2016-08-22 15:16:39,"The issue mentioned by @duritong led to long troubleshooting for us when script checks that were working on all existing machines did not work on new ones (which had a slightly newer systemd).
When determining how to fix it, I'd just like to mention that we use a fair amount of shellism such as subshells and pipes (eg for Zookeeper `result=$(echo ruok | nc localhost 2181); echo $result; test ""zk-$result"" = ""zk-imok""`). I couldn't determine from the documentation if go-shellwords supported this? Requiring this to be deployed as a file to the agent would be a bit impractical, and can hopefully avoided.
",carlpett,duritong
1358,2016-08-22 15:45:31,"@carlpett you can always wrap it in `/bin/sh -c`.  You would not need to put it in a separate script.
",mfischer-zd,carlpett
1358,2017-02-27 05:31:45,"@slackpad your comment aligns with a recent breaking change in [consul-template v0.18.0](https://github.com/hashicorp/consul-template/blob/master/CHANGELOG.md#v0180-january-20-2017)
> A shell is no longer assumed for Template commands. Previous versions of Consul Template assumed /bin/sh (cmd on Windows) as the parent process for the template command. Due to user requests and a desire to customize the shell, Consul Template no longer wraps the command in a shell. For most commands, this change will be transparent. If you were utilizing shell-specific functions like &&, ||, or conditionals, you will need to wrap you command in a shell, for example:)",steve-jansen,slackpad
1347,2015-10-28 00:19:09,"@AjeetK You need to have Consul read the configuration files, either using the `-config` or `-config-dir` parameters so that it will load those JSON files.
",armon,AjeetK
1343,2015-10-26 20:21:47,"@salehe Not very different at all, but that depends on users generating scripts for every container running on the system. This exposes an API which makes this easy to run checks programatically, for example Nomad could use Consul agent to run health checks for a container that it is managing.
",diptanu,salehe
1343,2015-10-27 16:18:08,"LGTM @diptanu @slackpad Can we make sure the website docs get updated for this change as well
",armon,slackpad
1343,2015-10-27 16:18:08,"LGTM @diptanu @slackpad Can we make sure the website docs get updated for this change as well
",armon,diptanu
1343,2015-10-27 21:55:17,"@diptanu it looks like this change broke some of the BSD targets (from a full `make`):


",slackpad,diptanu
1337,2015-11-05 10:26:47,"Hi @half-dead what have you changed for tuning the conf ? (and where). We are currently facing the same problem with a cluster of 800 nodes.
",AlexisSellier,half-dead
1337,2015-11-19 10:19:41,"@AlexisSellier  After a long time watching, I think the cause of this in our situation is that we have clients from different datacenter(RTT approximately 5ms), and now we use different dc for clients from different datacenter, and it's stable now. 

Here is some log from before and after the changing :



So far our largest cluster have 220 nodes, so the flapping frequency are acceptable.
I'm guessing that one flapping node will infect other nodes in someway ( just guess, I'm not familiar with the gossip implementation in consul), since in our cluster, the 'marking health critical' log were from all nodes in cluster, not just the ones from another datacenter.

And to answer your question, Here is our modification at command/agent/agent.go#consulConfig()



not sure if this modification helps stablizing the cluster, please ping those Hashicorp guys for their thoughts before you make any change.
",half-dead,AlexisSellier
1337,2016-02-05 05:22:00,"@AlexisSellier thank you for the tip, we have been running into this issue as well, 0.6.3 helps a lot, we only received a few flapping a day, compared to before where we received a few flapping every 15 minutes. 
@slackpad I wonder if we can tune these values at the config file level ?
",changwuf31,AlexisSellier
1337,2016-02-13 01:52:34,"Hi @changwuf31 we are looking at possibly adding support for tuning these in an upcoming release, and we are working on some specific improvements in the next release to improve node flapping. I'll close this out since it looks like @half-dead got to a working configuration with the mod.
",slackpad,half-dead
1337,2016-02-13 01:52:34,"Hi @changwuf31 we are looking at possibly adding support for tuning these in an upcoming release, and we are working on some specific improvements in the next release to improve node flapping. I'll close this out since it looks like @half-dead got to a working configuration with the mod.
",slackpad,changwuf31
1336,2015-10-26 15:10:05,"@slackpad once I get all the sites updated, I'm going to move the fastly logo into middleman-hashicorp and compress it there :smile: I just didn't feel like doing it 8 times, and I can't do it until all the sites are updated :smile: 
",sethvargo,slackpad
1335,2015-10-26 03:45:55,"hi @wolftrouble, have you seen issue #1212?

Docker has a known issue with their connection table for agents stopping and starting quickly, something related to UDP packets being dropped.

If you do recall stopping and starting the Consul containers, you may want to try running:



I have had troubles with nodes flapping, but only when cluster sizes reach 30+ nodes. We've mitigated this issue by creating several smaller clusters. Doesn't sound like you have a cluster that big yet.
",djenriquez,wolftrouble
1333,2016-04-13 20:43:05,"@slackpad can confirm, removing everything from `/var/lib/consul/` seemed to fix a service that was registered by registrator. We ran registrator against the local consul-agent, so I'm assuming moving it to hit the consul-cluster instead may fix the issue...
",josegonzalez,slackpad
1326,2015-10-22 20:34:06,"@ryanbreen Yep! Fixed by #1318 
",armon,ryanbreen
1325,2016-01-08 01:05:49,"@frntn and in case anyone else looks at this ticket there's also a https://www.consul.io/docs/agent/options.html#only_passing config option that controls this.
",slackpad,frntn
1322,2015-12-12 20:02:29,"@JBodkin @bryanwb If the other server did not leave gracefully you might have to update the `/opt/consul/raft/peers.json` file manually as discussed here: https://www.consul.io/docs/guides/outage.html
",keyan,bryanwb
1322,2015-12-12 20:02:29,"@JBodkin @bryanwb If the other server did not leave gracefully you might have to update the `/opt/consul/raft/peers.json` file manually as discussed here: https://www.consul.io/docs/guides/outage.html
",keyan,JBodkin
1322,2016-01-08 01:58:22,"Hi @JBodkin please re-open this if the outage guide didn't fix the issue - editing peers.json is the right fix.
",slackpad,JBodkin
1320,2015-10-28 01:11:59,"Hey @bmonkman, is it possible that the timeout is being reached? At first glance, I noticed a possibly related upstream bug which was released in go 1.5.1: https://github.com/golang/go/commit/01b25600689250b3672465ae30b821086645013d.

I'm not sure why else this would happen off the top of my head. Marking as a bug, thanks for reporting!
",ryanuber,bmonkman
1320,2016-11-22 19:19:34,It seems like the most likely issue is that the app server takes a while to respond every once in a while - please re-open if that wasn't the cause of this. @loslosbaby I think your log looks normal - that's just things shutting down - please let us know if you still have any concerns.,slackpad,loslosbaby
1313,2015-10-16 17:40:32,"Hey @ManojaMishra,

What you are seeing is the expected behavior currently. Registrations to the agent don't validate the ACL with the servers, the ACL is only validated when trying to sync services from the agent to the central catalog. I can see how it would be useful to do the validation up-front, and there are also cases where allowing the service to register on the agent without validation could be desirable (for example, to allow the agents to continue functioning even in the face of temporary server failures).

We've thought about this a bit before, and I think the right answer is going to be to add an additional configuration flag on the agents that would toggle this behavior, like a `force_check_token` flag, so that either case can be handled.

Thanks for reporting this! Going to mark it as an enhancement for now. Thanks!
",ryanuber,ManojaMishra
1311,2016-01-08 00:51:17,"Hi @njbennett are you still having trouble?
",slackpad,njbennett
1311,2016-02-05 22:46:57,"Hey @slackpad 

Thanks for following up.  Yes, we're still having this issue.  We [guarantee data persistence when scaling up from 3 to 5](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L80-L100) whereas we [only guarantee the cluster is functional after scaling up from 1 to 3](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L28-L46). @ryanmoran and @zankich spoke with @mitchellh and some HashiCorp folks when they visited our office, sounded like this is something we have to live with for now.
",Amit-PivotalLabs,slackpad
1311,2016-02-13 00:23:36,"Hi @Amit-PivotalLabs - I was one of those folks :-) In that case I thought it was an issue with a TLS upgrade where you were going from 3 to 1 and then back up, and in particular it was possibly shutting down multiple nodes at the same time. Going from 1 to 3 should not be causing any data loss, so I'd like to track that down if that's still a problem.
",slackpad,Amit-PivotalLabs
1311,2016-02-13 22:44:18,"Hey @slackpad 

Those were two separate issues.  We've had users running a 3 node cluster, whom we've migrated to a 3 node TLS cluster, via a scale-down => turn on TLS => scale-up.  The scale-down can go south and requires manual intervention (usually blowing away data and starting from scratch, once we're wedged in an ""outage"" state)

Separately, we have continuous integration for our consul service that tests that it can be scaled up, down, and rolled in various ways.  One particular test deploys a 1-node cluster from scratch, then scales up to 3 by adding one node at a time.  Given the way we orchestrate this, we can't guarantee data from the 1 node persists on scale-up.
",Amit-PivotalLabs,slackpad
1306,2016-02-10 15:40:48,"+1 to track.

Running into this right now.

Re: Automating the editing of peers.son, I've got a setup where when a node goes down it likely knows the address of the peer it was replacing.  (network attached storage)  The script I have sets up a new container but also issues a ""force-leave"" on the prior node IP.  My understanding is that this impacts the upper layer but not the raft layer (peers.json).

@josdirksen - how are you using force-leave?  I'm trying to use it as mentioned in the prior statement, yet I don't see peers.json updated on the remaining/healthy nodes.  And thus, run into leader election issues. 
",jmspring,josdirksen
1302,2016-03-22 08:54:00,"@slackpad please reopen
",rtoma,slackpad
1299,2016-08-12 19:03:40,"@ross I think you are hitting the current behavior - the configured key is designed to be an initial one only - https://www.consul.io/docs/agent/options.html#_encrypt:

> Specifies the secret key to use for encryption of Consul network traffic... The provided key is automatically persisted to the data directory and loaded automatically whenever the agent is restarted. This means that to encrypt Consul's gossip protocol, this option only needs to be provided once on each agent's initial startup sequence. If it is provided after Consul has been initialized with an encryption key, then the provided key is ignored and a warning will be displayed.

Consul does this because there are commands to update the keys later and users won't want to revert to the initial key when restarting. You probably want your CI pipeline to blow away that state before baking an image.
",slackpad,ross
1298,2016-01-08 00:48:48,"Hi @huikang unfortunately now it's only possible to specify one or the other, as @akmalabbasov said. You do get the result that's being watched over stdin into your handler though, so you can do filtering there with some scripting.
",slackpad,akmalabbasov
1298,2016-01-08 00:48:48,"Hi @huikang unfortunately now it's only possible to specify one or the other, as @akmalabbasov said. You do get the result that's being watched over stdin into your handler though, so you can do filtering there with some scripting.
",slackpad,huikang
1297,2016-01-07 23:47:24,"Hi @adpande - it still seems like it would be subject to race conditions if different agents are seeing if they are the leader and then reacting (such as if leadership changes right in that time), even if one call had both pieces of information. It seems like you might want to make a more robust synchronization mechanism to make sure the API is only hit once. One idea I had is possibly having the contenders try to lock a key based on the event name with `?cas=0` or something similar (https://www.consul.io/docs/agent/http/kv.html)?
",slackpad,adpande
1295,2017-02-04 06:56:41,"Hi @joneepenk sorry we haven't gotten to this - it's not hard but there's a large backlog of small things like this and limited resources, so we have to focus our resources on higher priority things. Hopefully the summary above helps in the meantime.",slackpad,joneepenk
1295,2017-03-22 11:36:28,@philsttr which is the best chooice in Distributed Systems? spring cloud supported the both.,andChow,philsttr
1291,2015-10-20 06:19:39,"@armon and @ryanuber all the outstanding comments have been addressed so please take another look.

I'm going to leave the TODO in `PrefixWatch.Notify()` for now since it's an existing bug and clean that up on another PR if I have time. I think it'll need a periodic sweep kind of cleanup, or else the notify groups will have to be able to tell the parent `PrefixWatch` once they have become empty.
",slackpad,armon
1291,2015-10-20 19:32:30,"@slackpad this all looks super solid! We should also remove the entry in the FAQ that mentions Consul's use of LMDB. I wasn't able to get a diff of the changes on the state store from where I left off and you picked up (because they are so large), but I perused the file and things looked sane. :+1:
",ryanuber,slackpad
1290,2015-11-16 23:13:47,"Hi @isamuelson can you provide some more details about your test setup (are all three nodes in the cluster Consul servers)?
",slackpad,isamuelson
1290,2015-11-17 02:14:39,"@slackpad I've seen this before in normal operation - if the server that the agent is connected to dies, the agent freaks out and loses all sessions. I know I commented on it somewhere in github but the search doesn't find it.
",highlyunavailable,slackpad
1288,2015-10-13 00:47:52,"@talwai We will fix this for the Consul 0.6 release, but currently build 0.5 against Go 1.4
",armon,talwai
1287,2015-10-14 08:17:12,"@SPARTAN563 watch out for checks that are not idempotent and change output each time you run them. Depending on your https://www.consul.io/docs/agent/options.html#check_update_interval and number of services in your cluster, you could be causing enormous number of writes to the K/V.

EDIT:

>  I suspect this has something to do with Go trying to reuse the same socket for subsequent HTTP requests (ala Keep-Alive).

AFAICT since consul 0.5.1 Keep-Alives are disabled for http checks, so this seems to be caused by something else.  https://github.com/hashicorp/consul/blob/42aa817456910bdd7c37f496f151c3037eabf5cc/command/agent/check.go#L317
",wuub,SPARTAN563
1284,2015-10-08 22:10:09,"Thanks a lot @nbrownus :+1: 
",scalp42,nbrownus
1284,2015-11-03 18:48:51,"Any chance to look at this @slackpad following @nbrownus PR ? Would be greatly appreciated.
",scalp42,nbrownus
1284,2015-11-16 22:58:28,"Hi @nbrownus - thanks for this! Once we get 0.6 rolled out I'll work with you to review this so we can get it into the following release.
",slackpad,nbrownus
1284,2016-01-26 15:30:33,"@slackpad Aside from the merge conflict, is there anything stopping this PR from being merged? I have some time this week and could having a shot at rebasing it if @nbrownus is busy.
",BRMatt,nbrownus
1284,2016-01-26 15:30:33,"@slackpad Aside from the merge conflict, is there anything stopping this PR from being merged? I have some time this week and could having a shot at rebasing it if @nbrownus is busy.
",BRMatt,slackpad
1284,2016-01-30 00:25:33,"thanks a lot again @nbrownus much appreciated
",scalp42,nbrownus
1284,2016-02-01 14:19:32,"Thanks @nbrownus! :heart: 
",BRMatt,nbrownus
1283,2015-10-08 15:58:14,"Hi @foca - this is they key to what's going on:

> Since sentinel does not run in the same nodes as the redis instances, I can't perform the update against the agent (since I can't specify the Node, or at least can't find in the API docs how to), so I'm updating the catalog directly.

Currently, the agent is the source of truth so the next time anti-entropy sync runs it overwrites the changes you make to the catalog. Fortunately, there's a fix coming in 0.6 that will let you override tags (motivated by the Redis use case, actually) - see #1102. That should be released in a few weeks.
",slackpad,foca
1281,2015-11-16 22:55:19,"Hi @Esya - this is a weird one. It looks like maybe the advertise address isn't getting populated into the catalog correctly. Can you see what the output of the `/v1/catalog/nodes` HTTP endpoint shows for the address?
",slackpad,Esya
1278,2015-10-08 18:37:32,"@wwalker Yeah this is a terrible case for Consul in general. All the transactions against Consul are applied atomically, so a large scale delete is just devastating. This effectively fans out to about ~6 million key updates that must be done in an atomic update. 

Hopefully some of the architectural changes in 0.6 will ease this pain, but ultimately any transaction involving millions of entries will be very sad for Consul, and likely the cause of instability.
",armon,wwalker
1278,2015-10-08 20:27:30,"@armon could we add chunk=true to delete endpoint so that recursive deletes will be done in smaller chunks, sacrificing the atomicity of the overall delete for performance?  For me I saw a 7.8 X performance improvement doing 10 separate 10,000 key deletes serially (8.5 seconds each, total time 84.6 seconds) versus doing a 100,000 key delete (660 seconds).   Then I ran 10 deletes of 10,000 keys each in parallel, and the last of them finished within 17 seconds.

So if the system did chunks in separate go routines, at the sacrifice of overall DELETE atomicity, could provide 40X improvement.  I could look into writing this,but only if it has a chance of being accepted :-) 
",wwalker,armon
1278,2015-10-13 00:37:00,"@wwalker Not sure why the smaller deletes took longer, that is odd... I think we could certainly support something like `chunk` which would break the promise of atomicity, but I think it's hard to understand the implications of that in the case of things like blocking queries and consul template. E.g. if those systems see a partial delete, they will be in a bad state, due to how the indexing is done.

e.g. Records [A B C] exist. Delete is issues at time T. Consul template does a read of keys [A B] at time T (partial delete). It now does a blocking query to wait for T+1, which may happen at some arbitrary point in the future, even though the state of the world it has is wrong.

That may be a bit terse (apologies), but I hope it makes sense!
",armon,wwalker
1278,2015-11-19 04:48:44,"I like @mitchellh's idea of providing some kind of paging in the APIs. That would allow tools to delete in chunks and it would be obvious that atomicity is not guaranteed across the entire set.  The paging could possibly be useful for other uses too if it applies to GET and not just DELETE. I'm imagining some kind of key browser like the Consul UI for instance. In fact, the Consul KV UI started timing out like crazy when I had millions of keys, so it could probably benefit from being able to do queries with paging. 

I would think that it would be very, very good if Consul could refuse to delete more than a certain number of keys, say 1000 or something. That way if you have millions to delete, you would be forced to use paging and wouldn't be able to hang yourself like @wwalker and I did by attempting to mass delete millions in one query. 
",msabramo,mitchellh
1278,2015-11-19 04:48:44,"I like @mitchellh's idea of providing some kind of paging in the APIs. That would allow tools to delete in chunks and it would be obvious that atomicity is not guaranteed across the entire set.  The paging could possibly be useful for other uses too if it applies to GET and not just DELETE. I'm imagining some kind of key browser like the Consul UI for instance. In fact, the Consul KV UI started timing out like crazy when I had millions of keys, so it could probably benefit from being able to do queries with paging. 

I would think that it would be very, very good if Consul could refuse to delete more than a certain number of keys, say 1000 or something. That way if you have millions to delete, you would be forced to use paging and wouldn't be able to hang yourself like @wwalker and I did by attempting to mass delete millions in one query. 
",msabramo,wwalker
1278,2015-11-19 05:13:47,"So assuming I missed @wwalker's warning and did `curl -X DELETE 'http://localhost:8500/v1/kv/vault?recurse'` and my Consul is now stuck like his was, is there anything I can do to undo that; make Consul forget about that or abort it and release any associated locks?
",msabramo,wwalker
1278,2015-11-19 07:10:42,"Hi @msabramo unfortunately this is on the wrong side of the Raft log so the quorum has accepted the huge KV delete operation and it's now trying to commit to the state store which is taking a huge amount of time, and locking up all the rest of the writes because it's occurring in a transaction with the database. There's currently no mechanism to cancel something like this, though I opened https://github.com/hashicorp/consul/issues/1418 which might be a possible automated way out of this situation in the future. We also plan to enable huge deletes via paging or some other mechanism after we get 0.6.0 out.

Reads should still be working so you should be able to get your data out using the APIs and then rebuild your cluster. I know this option is super painful but it's probably the cleanest way to get moving again.

If you've safely backed up your data and you are considering rebuilding the cluster, you could give the 0.6.0-rc2 build a try (see https://groups.google.com/forum/#!topic/consul-tool/VqPBuSIjFTI for details). It should be an easy upgrade from 0.5.2 where you basically update to the new binary and then restart the Consul server. I was able to chug through 2M keys on an m3.large in about 34 seconds, though on about 2 out of 5 runs I ran into out-of-memoy panics and one kernel OOM kill of Consul, as written up in #1421. If your server is a beefy machine with lots of RAM this might be worth a shot. The 0.6.0-rc2 build is much faster because Consul 0.6 has a completely new in-memory state store that's much more efficient.

If you wanted to give a 0.6 build a little better chance of succeeding you could even try patching this:



You'd have to make a build to get that change, but it will prevent Consul from making tombstones during the delete which makes the delete a lot less costly memory-wise. This will keep blocking queries from working properly for these keys, but you don't care in this case since you just want to delete them. The tricky thing about doing this is that you'd have to wait for Consul to kick out a snapshot before you restart it with an un-patched version so that you don't run into the same problem when the server starts up and replays the Raft log. Once it snapshots and gets that huge delete out of the Raft log it should be fine.

Definitely apologize that this has caused you all this trouble, and we've captured several ideas for fixing this in the release following 0.6.0.
",slackpad,msabramo
1278,2016-01-04 16:00:39,"@slackpad is the patch above part of 0.6.0?

I just got hit with this again (1.6 M vault/core/leader/\* entries....)
",wwalker,slackpad
1278,2016-01-04 16:37:59,"@wwalker unfortunately that patch isn't in there since it breaks the tombstone behavior for those keys, so it's not a good general solution.
",slackpad,wwalker
1278,2016-01-05 21:14:16,"@wwalker I don't think there's a very good recovery option if that huge delete is queued up in the Raft log, you may have to reinitialize Consul. Sorry about running into this again. 
",slackpad,wwalker
1278,2016-01-05 22:45:52,"@wwalker I think the cluster should return to being healthy once it finishes chewing through the operation, but let us know if not. With 0.6.0 the operation should take on the order of minutes now instead of hours.
",armon,wwalker
1277,2015-11-13 08:22:20,"Hi @Nirkus,

Thanks for the response. Unfortunately, it doesn't work :cry:. It results in Consul just GETting `/api/aliveness-test/%252F`.

It's a good idea, though. I'll have a play around and see if I can get `net/http` to comply...
",JayH5,Nirkus
1276,2015-11-16 22:43:22,"Hi @akmalabbasov can you describe what's failing in a little more detail? There aren't any uniqueness checks on address that should cause things to fail.
",slackpad,akmalabbasov
1274,2015-11-16 22:45:11,"Hi @rgl thanks for the PR! Once we get Consul 0.6 rolled out I'll help review this and get it in for the following release.
",slackpad,rgl
1274,2015-11-30 20:02:12,"Hey @rgl, this definitely looks good. I started the same thing in a branch (see [here](https://github.com/hashicorp/consul/compare/f-ui-static?expand=1)) before I realized you had already done this. If you want to finish this up I'll just close out my branch.

One idea, let's try to avoid the hard requirement on ruby/bundler and compiling the web UI assets in the typical build pipeline for Consul. The UI very rarely changes so I think we should just have a separate make target like `static-assets` to update the bindata_assetfs file and check in the `bindata_assetfs.go` file. You can see the linked branch for an example.
",ryanuber,rgl
1274,2015-12-01 19:38:12,"I would like to finish it up. I think that always generating the file is better for early catching build errors. But I can implement it either way. Lets see what @ryanbreen and @slackpad have to say.
",rgl,ryanbreen
1274,2015-12-01 19:38:12,"I would like to finish it up. I think that always generating the file is better for early catching build errors. But I can implement it either way. Lets see what @ryanbreen and @slackpad have to say.
",rgl,slackpad
1274,2015-12-01 19:51:37,"Yeah I'd go with @ryanuber's suggestion and just check in the go file - adding Ruby/bundler to the default build path is pretty heavy so this'll keep things fast and simple for most people who aren't updating the web UI.
",slackpad,ryanuber
1274,2015-12-01 20:03:19,"Seems fair. As the @ryanuber branch already has that done, I'll retract this PR.
",rgl,ryanuber
1271,2015-10-26 17:04:24,"@djenriquez 
This issue is not docker-related. It is 100% reproducible on bare metal.
There is also no ""flapping"" observed. Furthermore, there is inconsistency and not just nodes going down and up.
",jakubzytka,djenriquez
1271,2015-10-27 04:15:11,"@jakubzytka take a look at this: https://consul.io/docs/guides/outage.html
In my opinion, when the majority of a cluster have failed, simply restart all the servers will not bring the cluster back, and I've tried many times to verify this.
You can either restart all the servers with bootstrap-expect 3 flag or follow the steps in the Outage Recovery guide.
Btw, in your test scenario, I think the problem is not that the servers didn't know about each other, it's the election can not be started.
",half-dead,jakubzytka
1271,2015-10-27 09:10:23,"@half-dead

I'm sorry, but I believe you are wrong in pretty much every sentence. Please point any mistake in my reasoning if you see one.
- ""take a look at this: https://consul.io/docs/guides/outage.html""

The outage recovery guide describes a solution for a situation when a **majority** of cluster is **permanently dead**, so there is no quorum anymore (the yellow box on the page tells this in different words).
This requires manual intervention and it is perfectly understandable. This is a different case that I reported here though, because in my case all 3 nodes are back alive.
- ""In my opinion, when the majority of a cluster have failed, simply restart all the servers will not bring the cluster back, and I've tried many times to verify this.""

I believe you are mixing **failed** nodes with **dead** ones (or, possibly, with nodes that **left**). The outage recovery guide you mentioned tells in case of failed nodes it is enough to just restart the servers. In fact what the guide recommends is to fail all nodes, change config, and just restart them:
""At this point, you can restart all the remaining servers. If any servers managed to perform a graceful leave, you may need to have then rejoin the cluster using the join command""
Once again, it is perfectly understandable - those nodes that left need to rejoin. There is no need to join failed nodes, because they are part of the cluster and know all their raft-peers. Even if the cluster evolved once they were down they will update their raft-log after restart.

In fact the cluster will work if you start servers in a certain order (i.e. in the reverse order of getting failed). But the order should not matter, as each node has full raft-peers knowledge. I believe it is the root cause of this issue.
- ""You can either restart all the servers with bootstrap-expect 3 flag or follow the steps in the Outage Recovery guide.""

bootstrap-expect 3 is no good, because some node can still be down. Bootstrap-expect 2 is a better solution, because quorum is 2 anyway.
It wouldn't work though, as bootstrap-expect will not influence visibility of nodes in serf layer, which seems to be the problem.
- ""Btw, in your test scenario, I think the problem is not that the servers didn't know about each other, it's the election can not be started.""

You are mistaken. Election did start, and a new leader was elected:

2015/10/05 07:55:50 [DEBUG] raft: Votes needed: 2
2015/10/05 07:55:50 [DEBUG] raft: Vote granted. Tally: 1
2015/10/05 07:55:50 [DEBUG] raft: Vote granted. Tally: 2
2015/10/05 07:55:50 [INFO] raft: Election won. Tally: 2
2015/10/05 07:55:50 [INFO] raft: Node at 192.168.9.2:8300 [Leader] entering Leader state
2015/10/05 07:55:50 [INFO] consul: cluster leadership acquired
2015/10/05 07:55:50 [INFO] consul: New leader elected: sles12_2

The problem is that according to raft all peers are there (so election works), but according to serf each node is in isolation. It is inconsistency even within a single node.
As I stated before, the node that acquired leadership reapes a node that voted for him few seconds earlier.
",jakubzytka,half-dead
1271,2015-10-27 11:11:34,"@jakubzytka Sorry I wasted your time, I didn't read it thoroughly.
Seems to me that this is by design, simply add -retry-join when restarting servers will solve this problem.
",half-dead,jakubzytka
1271,2015-10-27 11:33:52,"@half-dead 
I suppose rejoin will work, but this means I (and everybody else) need to parse raft/peers.json to get the addresses which is some inconvenience and perhaps not the best solution in general (e.g. suppose you are a client - I suppose you do not know about raft peers).
I browsed consul and serf code and proposed some more general solution in hashicorp/serf#333

I hope it doesn't have loopholes and doesn't break serf in some other regard.
",jakubzytka,half-dead
1266,2015-10-02 17:26:02,"@jaredcurtis is it possible there are any other configuration files at play, or any CLI args that might affect this? I copy-pasted your configs onto a test box and started Consul a few times with them, but I consistently see the 192.x address for the ""asterisk"" service.

It is also possible that this service definition can be updated from the `/v1/agent` API's. If the service has indeed been updated from the API at some point, then the service definition becomes cached in Consul's data-dir under the ""services"" sub-directory. I would check the data-dir/services directory (just cat the files, they are named by the MD5 of their service names) to see if something might be going on there.

Hope that helps!
",ryanuber,jaredcurtis
1266,2015-11-02 23:49:29,"@jaredcurtis can you show me how you are querying Consul for the service address? (DNS query with `dig`, HTTP request with `curl`, etc).
",ryanuber,jaredcurtis
1266,2016-11-22 19:23:30,Hi @jaredcurtis are you still experiencing this issue - any updates? Thanks!,slackpad,jaredcurtis
1265,2015-10-13 03:31:33,"@spheromak I think #1296 is a partial fix at least. Do those services have checks associated, or are there just 10K services without checks?
",armon,spheromak
1265,2015-10-13 04:15:45,"Hi @spheromak sorry for the delay on this, and thanks @armon. Your change in #1296 looks good but iirc there were no health checks for these services. Looking at the code I'm surprised there's not an n^2 loop over services so I'm not sure this alone will fix it.
",slackpad,armon
1265,2015-10-13 04:15:45,"Hi @spheromak sorry for the delay on this, and thanks @armon. Your change in #1296 looks good but iirc there were no health checks for these services. Looking at the code I'm surprised there's not an n^2 loop over services so I'm not sure this alone will fix it.
",slackpad,spheromak
1265,2015-10-13 12:29:20,"No agent checks. We were planning on doing http callbacks for service
status.

On Mon, Oct 12, 2015 at 9:15 PM James Phillips notifications@github.com
wrote:

> Hi @spheromak https://github.com/spheromak sorry for the delay on this,
> and thanks @armon https://github.com/armon. Your change in #1296
> https://github.com/hashicorp/consul/pull/1296 looks good but iirc there
> were no health checks for these services. Looking at the code I'm surprised
> there's not an n^2 loop over services so I'm not sure this alone will fix
> it.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1265#issuecomment-147597716.
",spheromak,armon
1265,2015-10-13 12:29:20,"No agent checks. We were planning on doing http callbacks for service
status.

On Mon, Oct 12, 2015 at 9:15 PM James Phillips notifications@github.com
wrote:

> Hi @spheromak https://github.com/spheromak sorry for the delay on this,
> and thanks @armon https://github.com/armon. Your change in #1296
> https://github.com/hashicorp/consul/pull/1296 looks good but iirc there
> were no health checks for these services. Looking at the code I'm surprised
> there's not an n^2 loop over services so I'm not sure this alone will fix
> it.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1265#issuecomment-147597716.
",spheromak,spheromak
1265,2015-10-13 12:34:50,"This may have been causing the slowdown. I am traveling this week but will
try to get a test run with the patch
On Tue, Oct 13, 2015 at 5:29 AM Jesse Nelson spheromak@gmail.com wrote:

> No agent checks. We were planning on doing http callbacks for service
> status.
> 
> On Mon, Oct 12, 2015 at 9:15 PM James Phillips notifications@github.com
> wrote:
> 
> > Hi @spheromak https://github.com/spheromak sorry for the delay on
> > this, and thanks @armon https://github.com/armon. Your change in #1296
> > https://github.com/hashicorp/consul/pull/1296 looks good but iirc
> > there were no health checks for these services. Looking at the code I'm
> > surprised there's not an n^2 loop over services so I'm not sure this alone
> > will fix it.
> > 
> > â€”
> > Reply to this email directly or view it on GitHub
> > https://github.com/hashicorp/consul/issues/1265#issuecomment-147597716.
",spheromak,armon
1265,2015-10-13 12:34:50,"This may have been causing the slowdown. I am traveling this week but will
try to get a test run with the patch
On Tue, Oct 13, 2015 at 5:29 AM Jesse Nelson spheromak@gmail.com wrote:

> No agent checks. We were planning on doing http callbacks for service
> status.
> 
> On Mon, Oct 12, 2015 at 9:15 PM James Phillips notifications@github.com
> wrote:
> 
> > Hi @spheromak https://github.com/spheromak sorry for the delay on
> > this, and thanks @armon https://github.com/armon. Your change in #1296
> > https://github.com/hashicorp/consul/pull/1296 looks good but iirc
> > there were no health checks for these services. Looking at the code I'm
> > surprised there's not an n^2 loop over services so I'm not sure this alone
> > will fix it.
> > 
> > â€”
> > Reply to this email directly or view it on GitHub
> > https://github.com/hashicorp/consul/issues/1265#issuecomment-147597716.
",spheromak,spheromak
1264,2015-10-06 06:42:28,"@highlyunavailable I think we should improve the documentation for `force-leave` then
",omribahumi,highlyunavailable
1259,2015-09-24 16:55:33,"@rfyiamcool This is already supported. See the [session](https://consul.io/docs/internals/sessions.html) documentation. What you need to do is [create a Session](https://consul.io/docs/agent/http/session.html#session_create) with the `delete` behavior and [acquire](https://consul.io/docs/agent/http/kv.html) the key with it, then when the Session expires or is destroyed the key will be deleted. One caveat: If you release the key, then destroy the session, the key will _not_ be deleted because the session is no longer associated with the key.

This also means that you can create one session, associate it with multiple keys, then when the single session is deleted, all the keys associated with it will be deleted.
",highlyunavailable,rfyiamcool
1256,2015-09-25 19:28:46,"Hi @ssenaria this seems like a possible bug. When you say ""restart consul"" do you mean a config reload via https://www.consul.io/docs/commands/reload.html/SIGHUP?
",slackpad,ssenaria
1254,2015-09-28 21:50:57,"@highlyunavailable What would be the recommendation for persisting that data, and in the case of a cluster outrage what would be the recovery process? Would it be pointing the new server nodes' `-data-dir` to the old data directory that was backed up in one way or another (e.g. a persistent volume that was mounted to the old instance)?
",calvn,highlyunavailable
1254,2015-10-05 19:07:03,"Interesting topic. We are currently backing up our dockerized Consul servers using [Convoy](https://github.com/rancher/convoy), but it appears that this will cause issues if we were to restore this data onto a new Consul server on a machine with a different IP address, as @highlyunavailable noted. We followed this as recommened by @armon in this [Google Group topic](https://groups.google.com/forum/#!msg/consul-tool/cbe_W_SClog/u3PhFlDlyaAJ).

We know that [Consulate](https://github.com/gmr/consulate) exists, but we are striving for a service-agnostic back up solution, which is why we settled with Convoy. 

Our main goal was to backup the K/V store. Is there a subdirectory we should be backing up instead of the `/data/` directory in its entirety?
",djenriquez,highlyunavailable
1254,2015-10-05 19:36:53,"@djenriquez Thanks for the link on that GG topic. We also use consul-replicate, but only clone out a specific subset of the KV's for each datacenter. 

So far all the KV data that we use is populated by [git2consul](https://github.com/Cimpress-MCP/git2consul) so there is no issue with repopulating that to an entire new cluster. 

We also wrote [consul-migrate](https://github.com/Cimpress-MCP/consul-migrate) for exporting and importing ACLs, and used it when we transferred `acl_datacenter` from one DC to another. Do keep in mind that the gem is not quite polished, but it got the job done. PR's always welcomed :)
",calvn,djenriquez
1254,2015-11-03 18:40:46,"Sorry for the late reply on this one. The snapshots contained in the data-dir should be useful for providing you a good state checkpoint in the event of a disaster, but as @highlyunavailable noted, the peers list would probably need surgery and there's no consistency guarantees for the Raft log post-snapshot, so that data could be lost (if it was corrupted you'd probably have to delete it and/or zero it out). Also, the frequency of snapshots is hard to control so it's hard to control the amount of data that's exposed.

We are going to look into adding a new snapshot API and/or CLI that would let you kick out a snapshot so you could have a known restore point. The Raft log post-snapshot would always be at risk, but at least you could control when the snapshot occurs.

Not sure which release this would be targeted for, but will update this ticket once it's slotted on the roadmap.
",slackpad,highlyunavailable
1252,2015-09-22 18:38:03,"Hi @kureikain - sorry about that - bintray is experiencing issues. We will update the status here - https://twitter.com/hashicorpstatus.
",slackpad,kureikain
1250,2015-09-21 17:37:30,"Hi @half-dead - the anti-entropy syncs will get routed through to the leader since they are writing to the data store, so if the newly-added servers handle an anti-entropy sync request from an agent they will just proxy it through.

For a read query, it would depend on the consistency mode selected in the request. (https://www.consul.io/docs/agent/http.html). For `default` or `consistent` you should generally be ok, but for `stale` you could definitely get back an inconsistent set of results as the server catches up.
",slackpad,half-dead
1249,2015-09-21 18:17:41,"Hi @macb - thanks for opening this. I think we are going to take a look at doing something along these lines across more than just Consul, so you should probably hold off on ""going rogue"" :-) We will update this once we've got a plan.
",slackpad,macb
1249,2015-09-21 20:43:01,"Awesome @slackpad, looking forward to it.
",macb,slackpad
1249,2016-02-02 07:54:03,"Hi @bastichelaar still nothing yet, we've had too many other things ahead of this on the roadmap. I'll ping this up internally and see if we can get some discussion going.
",slackpad,bastichelaar
1249,2016-02-02 10:19:36,"@slackpad if you can come up with a recommendation (I'm personally a fan of [logrus](github.com/Sirupsen/logrus)), that might be the kind of thing a community contributor could tackle.  I'm personally irked by the logging output of consul-template, consul, and vault; if you could settle on a framework across all your products, that'd be a really great experience for us ops-y folk!
",blalor,slackpad
1249,2016-02-02 18:32:45,"Thanks for that recommendation @blalor.  It's something that has come up several times internally and isn't a resolved issue yet.  Stay tuned.
",sean-,blalor
1247,2015-09-21 16:49:56,"Hi @zhouzhongmi - are you running consul-template, or any other service that does a high number of watch queries against Consul? There are some known read performance issues that we are working to fix now - https://github.com/hashicorp/consul/issues/1150.
",slackpad,zhouzhongmi
1247,2015-09-22 09:14:04,"Hi @slackpad - Thank you for your considering with my questions. I just running a consul cluster without consul-template. As I have registered about 400 services and checks, I suspect whether the 400 checks cause the problem. Each of my checks registered with a interval as 2 seconds by the HTTP method. Now I will try to register my services and checks randomly into the cluster and enlarge my cluster with more servers. Thank you very much. I'm looking forward to a more powerful version of consul.
",zhouzhongmi,slackpad
1245,2015-09-18 17:55:39,"Yup, @highlyunavailable  traffic is open both ways for ports 8300, 8301/udp, 8301, 8302/udp, 8302, 8400, and 8500.



I tried adding a timeout, but as far as i know, netcat's lowest timeout is 1 second, which passes everytime for all ports in both directions...
",djenriquez,highlyunavailable
1245,2015-09-21 17:02:27,"Hi @djenriquez - it does look like you have the right set of ports. Do things work for a while and then fail sporadically, or do they always fail?
",slackpad,djenriquez
1245,2015-09-21 17:43:10,"Looks right, I think. :stuck_out_tongue_closed_eyes: 

us-west-2



us-east-1



I appreciate your time on this @slackpad.
",djenriquez,slackpad
1245,2015-09-23 18:10:55,"Ah, I don't remember @slackpad, sorry.

I noticed that the consul DCs attempt to join each other, then give up for a period of time and then retry again later. I came to this conclusion because when I navigate to 10.179.3.152:8500, there are periods of time where US-EAST-1 does not appear in the datacenter list, then it'll eventually come back. Maybe 8300 wasn't showing up because I dumped the session when one of these cases was happening?

In no case does clicking on that datacenter load successfully.

Are there any scenarios you would like me to capture? I would post all of the tcpdump in here, but theres just a ton of records.
",djenriquez,slackpad
1245,2015-10-02 21:47:14,"@slackpad Is there a way to ""cancel"" the `join -wan` command? Since this isn't working for us at the moment, i'd like Consul to just stop trying to join. Its been trying to join for a little under two weeks now!
",djenriquez,slackpad
1245,2015-10-02 22:01:03,"@djenriquez that doesn't sound right! The `join` should be a one-shot thing. Did you run it with `consul join -wan`.
",slackpad,djenriquez
1245,2016-11-09 19:18:41,"Hi, @slackpad. Could you please elaborate leave process for the WAN pool in details?
I also need to disjoin datacenters.
You mentioned two ways to do it.

### Issue  'consul leave' or 'consul force-leave' command and restart Consul.

If I do this, I suppose that I need to do it on each node and it is hard to do it by a script in an automated way since I need to restart Consul.

Even if I do this manually, will this leave just WAN protocol but keep LAN protocol as it were before joined to another datacenter?

### Cut off the traffic and let Sert declare them dead.

Does this mean I need to update some configuration for raft or consul?
For example, take out serf_wan from consul.conf?



I would appreciate your answer in advance.
",hosunghwang,slackpad
1245,2017-01-27 12:59:40,@djenriquez did you solve the problem with this UDP packets on eu-west-1? It look like I am facing the same problem with Consul on AWS.,maciekciolek,djenriquez
1244,2015-09-16 10:44:19,"Hi @agemooij 

What is the motivation for selecting such a large index? Consul is going to keep returning until it hits that index. Your first request should always use index 0. Then, the response will include a response index that you add to the next query. You can see the Go-version of this here: https://github.com/hashicorp/consul-template/blob/a020700c8ed8ea70450460f0eedef21197738ef2/watch/view.go#L120-L170. 

You need to add some logic to check the return values, specifically the stale and last index values and then store those results for comparing in the next request.

What version of Consul are you running? Can you restart your cluster with debug logging and send us a gist?
",sethvargo,agemooij
1244,2015-09-16 11:27:57,"@sethvargo just to be clear, what we do for all requests except for the first one is to set the `index` query param to the value of the `X-Consul-Index` of the previously received response, indicating that we are interested in receiving a response only if something has changed since that specified index. AFAIK this is  straight from the Consul Http API docs.
",agemooij,sethvargo
1244,2015-09-16 16:55:40,"Hi @agemooij - the Consul health checker isn't aware of any format for the check outputs so it does a simple string compare to see if they have changed; this would definitely cause write and index churn even if the health status is stable. Go intentionally randomizes map iteration order which I think causes the non-determinism in our JSON output.

If you can filter your health check outputs to make them deterministic before Consul sees them, then they should be truly idempotent:

https://github.com/hashicorp/consul/blob/master/command/agent/local.go#L241-L244
",slackpad,agemooij
1244,2015-09-17 10:54:42,"Hi @slackpad and @sethvargo, we ran some tests and this is the current situation:
- we checked several services and their health checks and we can verify that their health checks consistently and continuously produce exactly the same responses (i.e. the same status and the exact same http entity).
- we can see that **all (!)** indexes, or at least all the ones for all `/v1/health/service/<service>` and `/v1/catalog/service/<service>` endpoints for all our services are being incremented almost continuously. this includes the ones for which we have verified that their health checks are returning idempotent responses.

The big question is therefor: what could be triggering index increments for those two endpoints for every single service we have running? Especially if we can verify that their individual health checks do in fact return idempotent responses.

Just to be sure, does Consul guarantee that each individual service has its own index and that changes to one service don't trigger an index increment to another service?
",agemooij,slackpad
1244,2015-09-17 10:54:42,"Hi @slackpad and @sethvargo, we ran some tests and this is the current situation:
- we checked several services and their health checks and we can verify that their health checks consistently and continuously produce exactly the same responses (i.e. the same status and the exact same http entity).
- we can see that **all (!)** indexes, or at least all the ones for all `/v1/health/service/<service>` and `/v1/catalog/service/<service>` endpoints for all our services are being incremented almost continuously. this includes the ones for which we have verified that their health checks are returning idempotent responses.

The big question is therefor: what could be triggering index increments for those two endpoints for every single service we have running? Especially if we can verify that their individual health checks do in fact return idempotent responses.

Just to be sure, does Consul guarantee that each individual service has its own index and that changes to one service don't trigger an index increment to another service?
",agemooij,sethvargo
1244,2015-09-17 16:54:35,"Hi @agemooij it's complicated, that's why I had to go look in the code :-)

Each entity (node, service, check, kv) has a separate table, and Consul tracks an index per table, so there's no inherent coupling between these tables. If you delete a node that has a service and a check, though, it will bump all three of those indexes because it hit all three tables. For the KV table, we store extra index information associated with each key so that watches can be smarter about determining if a write to the table (which always bumps up the table's index) applied to the key or subtree you were watching. This hasn't been implemented for all the other entity types yet, though we intend to do that soon, so any check update will wake up all the watches on health checks right now.

I traced through the path where the agents push check updates to the server and it's through the `Catalog.Register` RPC call, which will update the service _and_ check tables at the same time (even if the service part of the definition didn't change) so it makes sense that those indexes are going up as well.

This definitely looks like there's a check with an output that's non-deterministic spamming up your Raft log and waking up your watches. We are actively working on improving the granularity of these queries so you won't get this behavior (only the churn-ey service would be waking). Sorry for the confusion on this! Also let me know if you don't find the culprit or think it's something else and I can help you track it down.

I'll leave this open as a reminder to improve the docs. We should definitely add some notes about how output is handled.
",slackpad,agemooij
1244,2015-09-21 08:37:00,"Thanks @slackpad for the update. A fix to make the granularity of updates match with expectations and documentation would be very much appreciated. 

We are actively looking for all sources of non-identical health check responses and we have already found some obvious sources; mostly of health checks running against software we don't control, like Cassandra and Prometheus. Those services have timestamped health check responses. In my experience this is quite common behavior so finding out that Consul is not compatible with such situations is troubling. 

I think a lot of people using consul-template or other forms of watches might be running into this same problem, probably without even noticing except for some mysteriously high loads on their Consul clusters.

It seems some subtler, more configurable behavior is probably called for here. Perhaps some way of either ignoring or semi-interpreting the health check responses?
",agemooij,slackpad
1244,2015-09-21 17:57:39,"Thanks for the updates and I appreciate the ping on registrator.

@agemooij - I'd hesitate to make Consul aware of the format of any output; wrapping a check in a script that preps and filters is probably better for keeping Consul complexity low. We can make the documentation way better, though, and it might be worth a periodic warning if a healthy service is churning its output so it's more obvious what's going on (and easy to find and fix without having to run through all your checks manually).
",slackpad,agemooij
1244,2015-09-22 14:43:27,"@mbroome as far as I understood the granularity of writes is cross-service at the moment. I'm not exactly sure where the granularity borders of these ""tables"" are but in practice for us this means that any write for service X on any Consul endpoint (catalog, health, etc.) will also trigger all watches for all other services on all other endpoints.

@slackpad It would be great if we could get a better insight of the current granularity of writes/watches. An initial high-level generalization would already be very helpful. 
",agemooij,slackpad
1244,2015-09-22 14:43:27,"@mbroome as far as I understood the granularity of writes is cross-service at the moment. I'm not exactly sure where the granularity borders of these ""tables"" are but in practice for us this means that any write for service X on any Consul endpoint (catalog, health, etc.) will also trigger all watches for all other services on all other endpoints.

@slackpad It would be great if we could get a better insight of the current granularity of writes/watches. An initial high-level generalization would already be very helpful. 
",agemooij,mbroome
1244,2015-09-22 14:47:10,"@slackpad I agree that interpreting health check responses would be the last possible choice I expect you guys to make. I simply threw it into the discussion as an extreme alternative.

If the granularity of writes would increase, the side-effects of a chatty/flappy service would be greatly reduced. Next to that I agree that ""writes per minute"" or something similar would be a very helpful metric to have for a service so you can quickly debug problems like this.
",agemooij,slackpad
1244,2015-09-23 17:32:35,"@mbroome Yeah @agemooij summarized it correctly ""any write for service X on any Consul endpoint (catalog, health, etc.) will also trigger all watches for all other services"". It doesn't sound like your `cat` check would cause churn, but some other check causing churn could affect that one.

@agemooij We will see what we can do to make this better - improved granularity of watches plus some better visibility for churn.
",slackpad,agemooij
1244,2015-09-23 17:32:35,"@mbroome Yeah @agemooij summarized it correctly ""any write for service X on any Consul endpoint (catalog, health, etc.) will also trigger all watches for all other services"". It doesn't sound like your `cat` check would cause churn, but some other check causing churn could affect that one.

@agemooij We will see what we can do to make this better - improved granularity of watches plus some better visibility for churn.
",slackpad,mbroome
1244,2015-09-23 20:19:39,"@mbroome - this is on our list. I'm not sure of the exact time frame but hopefully shortly after Consul 0.6 ships; we are trying for near the end of the month with that.
",slackpad,mbroome
1244,2015-09-24 09:19:13,"@mbroome for us watches do still ""work"" but only because both consul-template and out own watches always compare the new response to the old response and only trigger reconfiguration when something has actual changed. The main impact we are seeing is the load produced by all these watches constantly being triggered and then resubscribing. This is not practical unless you have an extremely stable environment that hardly ever changes.

@slackpad Great news! Glad to hear it is on your list.
We are talking to some teams at other companies we know about the impact of this issue on their systems. We expect that a lot more people will have made the assumption that watches will only be triggered by writes to the service they are watching and that the impact of this assumption has so far been relatively low for most teams only because they either have more stable clusters or because the load/request spikes have not been spotted or correctly identified. We only found out ourselves because its turns out our cluster was extremely chatty due to registrator so the load spikes were big enough to trigger us to dive into it.
",agemooij,slackpad
1244,2015-09-24 09:19:13,"@mbroome for us watches do still ""work"" but only because both consul-template and out own watches always compare the new response to the old response and only trigger reconfiguration when something has actual changed. The main impact we are seeing is the load produced by all these watches constantly being triggered and then resubscribing. This is not practical unless you have an extremely stable environment that hardly ever changes.

@slackpad Great news! Glad to hear it is on your list.
We are talking to some teams at other companies we know about the impact of this issue on their systems. We expect that a lot more people will have made the assumption that watches will only be triggered by writes to the service they are watching and that the impact of this assumption has so far been relatively low for most teams only because they either have more stable clusters or because the load/request spikes have not been spotted or correctly identified. We only found out ourselves because its turns out our cluster was extremely chatty due to registrator so the load spikes were big enough to trigger us to dive into it.
",agemooij,mbroome
1244,2016-01-14 03:37:21,"Hi @rytutis we are still tracking this and hoping to get it into Consul 0.7.
",slackpad,rytutis
1244,2016-03-22 00:28:02,"@mrwilby this may not make it into 0.7 given our current scope, but I think Q2 seems pretty likely. Will update this when I have a better estimate.
",slackpad,mrwilby
1244,2016-05-20 23:47:57,"@Loushu when you see that, is the output of the failing check changing run to run?
",jhmartin,Loushu
1244,2016-06-20 15:57:47,"@jhmartin : We've tracked down index churn to 2 distinct causes. First one is related to failed health checks for non-running services on Windows, where the text message of failed check would vary between 2 messages. One is a timeout message and the second one is connection refused message.
Second cause of index churn is more interesting. In our setup we use ACL tokens for service registration, which are passed with registration request as a query string parameter. We also have configured consul to deny registrations without ACL token by default. What seems to be happening in this case is when agents do a periodic entropy sync, they try to read the catalog and the read request gets denied access to all services except 'consul' service, and the agent writes to catalog, because services returned from catalog and its state don't match. Each agent does this once a minute, and given enough agents this causes pretty frequent index churn. The workaround was to include a token with ""read"" access to all services in each agent's configuration.
",Loushu,jhmartin
1244,2016-10-18 09:25:58,"@slackpad any updates on delivery? version ? The problem exists on 0.7 but less often than 0.6.4. I wonder what has been changed.
",rohitjun,slackpad
1241,2015-09-14 21:54:06,"Hi @scalp42 it doesn't look like that's exposed via any Consul configuration right now. Unless that gets added, you'd have to make a mod here and build Consul:

https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L572
",slackpad,scalp42
1241,2015-10-08 17:51:44,"Having the hostname in the metric kill us and it ends up duplicating a shit ton of metrics (vs datadog where you would pay per host for example).

@slackpad any chance we can see @nbrownus ported to consul as well?
",scalp42,nbrownus
1241,2015-10-08 17:51:44,"Having the hostname in the metric kill us and it ends up duplicating a shit ton of metrics (vs datadog where you would pay per host for example).

@slackpad any chance we can see @nbrownus ported to consul as well?
",scalp42,slackpad
1239,2015-09-14 22:05:04,"@vitalyisaev2 Thanks for the report. This is kind of a heuristic-y timeout, but it is set at 30 seconds which is quite a long time. Can you describe your environment a little more and the kinds of workloads you put on your Consul servers?
",slackpad,vitalyisaev2
1238,2015-09-14 21:21:39,"Hi @half-dead - can you configure your cluster so KV writes for the clients are default deny, and then just open up the KV space for the areas they should access? This should prevent them from choosing some other prefix to exec on.
",slackpad,half-dead
1238,2015-11-04 03:24:54,"@slackpad what's the latest on this one? I would really like to adopt Consul, but can't put it into production until we're able to prevent remote execution via this method.
",arobson,slackpad
1238,2015-11-04 03:35:17,"Hi @arobson this didn't make the cut for 0.6 (we've already got a huge scope) but we will try to get this into the next release.
",slackpad,arobson
1238,2016-03-10 06:52:44,"@rajkashikar the admin nodes should be the only ones allowed to fire the ""_rexec"" event via ACLs and that should allow them to trigger execs and still have other nodes be able to carry out the exec operation.
",slackpad,rajkashikar
1237,2015-09-14 22:03:20,"Hi @JeanMertz sorry for the confusion. You are correct that this is kind of a degenerate mode for Consul that it doesn't handle in the most friendly way. This ticket has some context on how this came to be - https://github.com/hashicorp/consul/issues/750.
",slackpad,JeanMertz
1237,2015-09-24 12:46:49,"@slackpad so we've been running with the above config for a while now on Kubernetes.

When a container stops, it starts again with the same name (but a different IP).

We now see logs like these:



`consul members` shows the correct IPs, but `peers.json` has the above mentioned _wrong_ IPs _on top of_ the correct IPs.

Does this mean we'd have to write a script that fetches the current node IPs and puts those in `peers.json` before starting Consul?
",JeanMertz,slackpad
1236,2015-09-11 19:16:15,"Cool, makes sense.  @scalp42, if you want to update the PR to restrict the changes to errors in comments and docs, it'll be safe to merge.
",ryanbreen,scalp42
1235,2015-09-17 09:55:50,"@slackpad 

> Want to take a crack at preventing multiple reloads as well?

I'm pretty sure `handleReload()` is only called from `handleSignals()`, and AFAICT handleSignals is fully synchronous (https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L797) and as such doesn't need a mutex to prevent multiple reloads.  (/cc: @ryanuber ?) 

It seems that all the interference was caused by `handleReload` and `antiEntropy` fighting with each other NOT multiple configuration reloads running simultaneously.  It's just easier to trigger a Pause/Resume conflict with `antiEntropy` if you force consul into contant reload mode by spaming SIGHUP for a while. 
",wuub,slackpad
1233,2015-09-10 21:56:33,"Thanks @slackpad ! That's what I get for not running the full set of tests at the end.
",ryanuber,slackpad
1232,2015-09-11 00:37:20,"@anoopengineer The Consul model is that the agent handles that for you. You just communicate with the local agent, and it manages routing to healthy servers transparently.
",armon,anoopengineer
1232,2015-09-11 01:48:13,"What about scenario were agent goes down? If the API supported having a
list of servers/agents rather than a single hostname, we can afford
downtime of a few nodes without bringing down the entire application that
depends on consul.

-Anoop
On Sep 10, 2015 7:37 PM, ""Armon Dadgar"" notifications@github.com wrote:

> @anoopengineer https://github.com/anoopengineer The Consul model is
> that the agent handles that for you. You just communicate with the local
> agent, and it manages routing to healthy servers transparently.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1232#issuecomment-139418917.
",anoopengineer,anoopengineer
1232,2015-09-11 05:32:13,"To expand on what @armon said, in the vast majority of cases, there's a Consul agent on the same host as your code that will communicate with the Consul servers on your application's behalf. This means that usually, the scenario where the ""agent goes down"" means that the specific host that is running the code that created the Client is also down. Further, some of the calls in the client API are agent-specific (everything in `Client.Agent()`, e.g. the list of services on the local agent) so in my opinion it would be bad API semantics to have some sort of ""fallback"" agent that might return a completely different set of services, health checks, etc.

If you want to have a fallback Client if for some reason you cannot run a Consul agent on the same server as your application, I'd suggest creating a slice or map of Clients and handling failover between them in your application logic - this will ensure that you can handle any edge cases caused by calling Agent APIs against a remote agent in an appropriate way.
",highlyunavailable,armon
1232,2015-09-11 15:15:48,"> To expand on what @armon said, in the vast majority of cases, there's a Consul agent on the same host as your code that will communicate with the Consul servers on your application's behalf.

I don't think having an agent on the same (and every) host where your app is running is a realistic architecture in most places. Even if it were, there is no way I can have rolling upgrade of Consul servers without bringing my entire application down. At least won't be able to bring down the consul agent without bringing down the application on that node.

> If you want to have a fallback Client if for some reason you cannot run a Consul agent on the same server as your application, I'd suggest creating a slice or map of Clients and handling failover between them in your application logic

Yes - this is definitely possible at the application side. But I believe for a critical system like consul which is used often as the infrastructure backbone and should be having high availability, it makes sense to have this made available in the standard API itself.
",anoopengineer,armon
1231,2015-09-21 18:16:45,"@slackpad that isn't a bad option. I'd probably need someone's assistance to make that happen though. 

However my only counter comment is that we could make the `local` tag configurable and change it to something like `local-agent` by default, something that has a low probability of being used already. 

This method just leaves all the existing conventions as is, but if you or someone else can/will help with the path you suggested, I'm all for it.

I just really need a way to get the IP/port into for ""local"" services to the agent and I think there is a pretty good use case in general for it.

Thanks!
",ekristen,slackpad
1231,2015-09-21 19:17:04,"@slackpad thanks! My golang experience is limited (as evident by the PR) but if you can make this work, or you need my help, please let me know.
",ekristen,slackpad
1231,2015-09-28 16:36:15,"@slackpad any progress on this by chance? Thanks!
",ekristen,slackpad
1231,2015-10-02 05:35:36,"@ekristen not yet - I'm hoping to get to prepared queries next week.
",slackpad,ekristen
1230,2015-09-10 21:43:31,"Picked this up when @sfncook rebased and built #1187 - @ryanuber I think we missed a couple spots:


",slackpad,ryanuber
1230,2015-09-10 21:57:43,"@slackpad - Actually I hadn't done a rebase/merge from the master branch for a while.  Just did so and pushed to my PR #1187 It's building now.
",sfncook,slackpad
1228,2015-11-16 22:33:26,"Hi @cdosso can you provide an example that gets into this state? Your issue should probably be filed separately from this one, which looks like an enhancement.
",slackpad,cdosso
1228,2015-11-24 08:27:36,"+1 @nilsotto 
Adding --recursor do not fix for me : 
Consul v0.5.2
Consul Protocol: 2 (Understands back to: 1)
",goacid,nilsotto
1228,2016-01-14 15:47:46,"@goacid that's fair - changing to a bug.
",slackpad,goacid
1226,2015-09-09 05:51:52,"Hi @btrepp if you plumb DNS like you've said here then you could find a Consul server using the built-in consul service, which would be something like http://consul.service.consul:8500/v1/...
",slackpad,btrepp
1226,2015-09-09 05:54:52,"Yep, what @slackpad said is what you could easily do.

Note that the HTTP API by default only binds to loopback, so if you want to run HTTP queries, you'll need to [rebind the HTTP address](https://www.consul.io/docs/agent/options.html#addresses).

I'm not sure what the port in the SRV record would be though for the `consul` service, but you could just assume it's on 8500 by default.
",highlyunavailable,slackpad
1226,2015-09-09 06:01:35,"Interesting detail @highlyunavailable - the port for the built in Consul service is set to the internal RPC port, not the HTTP server, so you're right you'd have to assume it's 8500 (or whatever it's configured for), or put it in KV, etc.

https://github.com/hashicorp/consul/blob/master/command/agent/agent.go#L170
",slackpad,highlyunavailable
1225,2015-09-09 00:21:39,"Hi @scalp42 are you running `dig` against the server node or a node running an agent? I believe the DNS TTLs are added in by the agent that services the DNS request and don't come from the server's configuration.
",slackpad,scalp42
1225,2015-09-09 00:32:31,"Hi @slackpad 

I'm running `dig` locally against the node agent (`dig @127.0.0.1 -p 8600`).

I see the TTLs only when `dig` is pointed at our Consul server nodes (`dig @consul.example.com -p 8600`) :



In this case does it mean that the local agent **cannot** get stale data ?

Correct me if I'm wrong but it would make any downstream caching impossible if TTLs are not specified.
",scalp42,slackpad
1225,2015-09-09 02:38:24,"@slackpad sorry for the delay:



I see the service TTL being `null`, this is interesting.
",scalp42,slackpad
1225,2015-09-09 02:40:37,"@slackpad just found the issue. So we've always been reloading consul instead of restarting it.

Looks like a restart actually fixed it. Is it expected that `consul reload` does not actually pick up the `dns_config` part when changed?
",scalp42,slackpad
1225,2015-09-09 05:47:56,"Wow totally missed that (and also means we've been pushing Chef changes for ""nothing"" trying different values etc when it was just not applied due to reload).

Thanks a lot @slackpad for the feedback and the issue opened :smile: 
",scalp42,slackpad
1224,2015-09-09 01:15:58,"Hi @ophiradi - thanks for the PR. These metrics will be a little unusual because they have the configuration-dependent name in them, so some people could end up with a ton of new metrics. Right now there's a relatively stable/fixed set of metrics and not much in there that's dependent on user-configured values, so it's a simple interface.

Can you describe how you want to use these in a little more detail? Maybe there's another way to get that data without adding a bunch of new metrics.
",slackpad,ophiradi
1224,2015-09-09 14:55:39,"Hi @slackpad, Consul is already emitting configuration-specific metrics here:
https://github.com/hashicorp/consul/blob/master/consul/health_endpoint.go#L101

As for the PR from @ophiradi, we are interested in graphing historical health-check passes/failures from consul's perspective on a service-by-service basis. It would be another source to alert from when our failures go above a certain rate or to be able to see another measure of quality over time.
",victortrac,slackpad
1224,2015-09-09 14:55:39,"Hi @slackpad, Consul is already emitting configuration-specific metrics here:
https://github.com/hashicorp/consul/blob/master/consul/health_endpoint.go#L101

As for the PR from @ophiradi, we are interested in graphing historical health-check passes/failures from consul's perspective on a service-by-service basis. It would be another source to alert from when our failures go above a certain rate or to be able to see another measure of quality over time.
",victortrac,ophiradi
1224,2016-01-15 01:12:03,"Hi @ophiradi any thoughts on just using service name?
",slackpad,ophiradi
1212,2015-09-09 06:48:35,"@slackpad Sorry for the late response! Pinging between the three AZs in us-west-2 is roughly 1.3ms.

Nothing interesting is happening in the logs or being reported in Sysdig. Our nodes are pretty under-utilized right now, but the highest traffic belongs to Consul and Consul-template with an average rate of about 7 KiB/s, spiking to 20KiB/s about every 30 seconds. Our nodes are reporting an average rate of 7KiB/s, so yea pretty much all Consul traffic.
",djenriquez,slackpad
1212,2015-09-16 20:31:03,"so @jsternberg, just to clarify, you're still having the flapping problem, but have solved the bad metrics issue you were having?
",djenriquez,jsternberg
1212,2015-09-16 20:52:51,"@djenriquez yep. I'm now attempting to get more data to try and find some kind of root cause. I'll be running with it in this state and will likely be able to confirm after monitoring the metrics for a couple of days about what is happening. I already see that one probe failed, but no dead node happened.

Since this is such a common issue, it may be worth adding some additional logging for when probes fail or a test command for environment validation.
",jsternberg,djenriquez
1212,2015-09-16 21:20:16,"> Since this is such a common issue, it may be worth adding some additional logging for when probes fail or a test command for environment validation.

This is definitely a good idea and we've been talking about this internally as well. Given the randomized nature of the pings, and the fact that it will try indirect pings via other nodes Serf/Consul can pave over a lot of different types of failures and configuration issues in ways that can be confusing.  In Consul 0.6 we have added a TCP fallback ping which helps keep the cluster stable while providing some log messages about a possible misconfiguration (""node X was reachable via TCP but not UDP"").

I forgot to ask, @djenriquez are you running Consul inside Docker containers as well?
",slackpad,djenriquez
1212,2015-09-16 23:23:07,"@slackpad Yes sir.
",djenriquez,slackpad
1212,2015-09-17 07:23:47,"@winggundamth I do not believe that this is the same issue. I am actually very familiar with the conntrack fix and have experienced it with Consul before in the past. The UDP issue fixed by conntrack is much more consistent in failures than the flapping problem that we are having here.

The flapping issue that we are seeing is downtime for roughly 30-90 seconds for probably every few hours; the nodes are up 90-95% of the time. But when you start increasing the amount of nodes, your cluster will see failures more often because the chances of a single node being in that 5-10% failure time increases.
",djenriquez,winggundamth
1212,2015-09-17 07:37:32,"@djenriquez So does it means that work around can not fix the problem for you?
",winggundamth,djenriquez
1212,2015-09-17 08:09:34,"@winggundamth correct, this does not fix the problem for us.
",djenriquez,winggundamth
1212,2015-09-17 18:28:09,"I retract my previous comments from this thread. It appears our core problem was something mentioned in a Google Groups mailing list message about this.

After resolving network errors in our testing environment, I looked at our staging environment. Our staging environment was repeatedly failing. Luckily, the logs messages mentioned a node that I know has been having trouble due to having too much IO load. I'll have more data within the next couple of days, but I think this will probably fix our issue. I'll report back if I'm wrong and there is still an issue, but otherwise assume that we're fine and have no issues.

The testing environment has been working perfectly with no node flapping. The PR I referenced above helped in figuring out which nodes were having problems and were failing their UDP ping checks. I also made another fix to the metrics that I'll open an issue for that caused ""alive"" metrics to get reported at invalid times.

@djenriquez I'm not sure if my issue is the same as yours, but I would suggest looking at the metrics and see if you can make any heads or tails of them. It may point you to the problem.
",jsternberg,djenriquez
1212,2015-09-17 18:41:48,"Thanks for the update @jsternberg - could you link to that Google Groups thread here?
",slackpad,jsternberg
1212,2015-09-17 21:20:00,"Awesome, glad to see its working better for you @jsternberg. Unfortunately in our case, its not a single node but a completely random node that will fail for a short period of time, including nodes in the same VPC as the consul servers. We have all traffic set up to pass through the required consul ports across all servers.

At first I had thought there was a VPN issue between our AZ, but that wouldn't answer why the nodes in the same AZ and VPC as the consul servers would also flap periodically.

I haven't spent much time analyzing the data because the issue is minor, just more of an annoyance. I'll go ahead and start looking deeper at this issue.
",djenriquez,jsternberg
1212,2015-09-17 21:26:38,"@djenriquez to clarify what happened to us, it _was_ a random node that would fail. That's the reason why it was so hard to find was because the server that was failing would not be the one that actually failed.
1. Loaded node A sends out ping to node B
2. Node B responds to ping with an ack
3. Node A doesn't respond to the ack before 500 ms timeout
4. Node A _thinks_ the ack failed, even though it succeeded
5. Node A tries fallback methods, somehow they fail too
6. Node A sends out suspect message about Node B to the cluster
7. Node C receives suspect message about Node B
8. Node C hits suspect timeout and declares Node B dead

A single instance of this happening isn't too bad, but if it happens with _every_ ping you get a bunch of random suspect messages being sent to the cluster. Even if it's only sent to a fraction (5%) of them, you get 3 suspect messages a minute. Eventually, the suspect timeout gets hit before the node can refute the message and you end up with dead nodes.

Unfortunately, I don't have enough evidence that this is exactly what happened, but removing the loaded node from our cluster seems to be making our cluster healthier. There could also be other reasons why the probe has failed.
",jsternberg,djenriquez
1212,2015-09-17 22:45:03,"Ah, @jsternberg seems logical. The other problem with my issue however, is that none of our nodes are reaching over 50% CPU utilization, with the average utilization ~15% for our entire infrastructure, with the heaviest traffic in our nodes belonging to Consul at a whopping 40KiB/s average (sarcasm :stuck_out_tongue: ). These are all new nodes that we're looking to utilize soon.
",djenriquez,jsternberg
1212,2015-10-01 19:02:18,"Hi @djenriquez - haven't forgotten about this but working through a backlog.
",slackpad,djenriquez
1212,2015-10-01 20:07:32,"hey @djenriquez I'm not sure if you follow the list serve (https://groups.google.com/forum/#!forum/consul-tool) but there are a number of threads on the topic. 

I saw some flapping issues but they are now massively reduced through a few tweaks (if this helps):
- moved to M4.large instances for the consul servers; the network performance, for my case, was much improved, even for a consul cluster that spans AZs.
- allowed for dns, service, and node stale caches.  This helps keep things up and running during leader-flapping
- I was routing all dns through consul, but I now use dnsmasq to only put `*.consul.` requests through consul.
- I use `--net host` for the consul docker containers.  Before I added that flag to docker, I was running into issues with docker dropping UDP packets, which I noticed quite a bit when I was running all dns requests through consul.  using `--net host` has helped quite a bit (though of course you lose all the iptable benefits when you do that)

I'm now seeing 1-2 leader elections a day on a small cluster (3 consul servers, another 6-12 agents, and ~ 16 services)

feel free to ping me if you want to dive into details.
",skippy,djenriquez
1212,2015-10-02 02:53:18,"Thanks @slackpad.

Hi @skippy, yes this issue actually was born in the Google group. As far as the flapping nodes, I'm having a hard time justifying allocation an m4.large, especially 5 of them for Consul. Sysdig shows that Consul uses an average of 40 KiB/s network traffic, with some spikes to 70 KiB/s, but thats it. This is in a cluster of ~30 nodes /w ~40-50 services between the nodes. 

Now, maybe larger/stronger instances can increase stability, but why? Smaller instances, even t2.micros should be more than capable of handling that kind of network traffic.

How does one set up service/node stale caches? Is this a feature in Consul that I enable? This is a setting I have not yet fiddled with, maybe it can help. I'm not using Consul DNS at all.

I had someone else just yesterday recommend `--net=host`. I've transitioned the server containers to use that option and am slowly transitioning the agents to use that as well. Its too soon to report whether its helping, I feel that it has, somewhat, but I have noticed some nodes with `--net=host` still flapping. 

Once I transition all agents to use that option, i'll report back. Thank you!
",djenriquez,slackpad
1212,2015-10-02 02:53:18,"Thanks @slackpad.

Hi @skippy, yes this issue actually was born in the Google group. As far as the flapping nodes, I'm having a hard time justifying allocation an m4.large, especially 5 of them for Consul. Sysdig shows that Consul uses an average of 40 KiB/s network traffic, with some spikes to 70 KiB/s, but thats it. This is in a cluster of ~30 nodes /w ~40-50 services between the nodes. 

Now, maybe larger/stronger instances can increase stability, but why? Smaller instances, even t2.micros should be more than capable of handling that kind of network traffic.

How does one set up service/node stale caches? Is this a feature in Consul that I enable? This is a setting I have not yet fiddled with, maybe it can help. I'm not using Consul DNS at all.

I had someone else just yesterday recommend `--net=host`. I've transitioned the server containers to use that option and am slowly transitioning the agents to use that as well. Its too soon to report whether its helping, I feel that it has, somewhat, but I have noticed some nodes with `--net=host` still flapping. 

Once I transition all agents to use that option, i'll report back. Thank you!
",djenriquez,skippy
1212,2015-10-02 16:05:53,"@blalor, are you using t2.small within the same AZ or spanning AZs?  

@djenriquez great point about moving to m4.  The challenge with AWS is there are lots of other variables; how many azs are being spanned, which region are you in, etc.  And then lots of guessing (are the t2 and m4 families on better internal network hardware?)

@djenriquez here is part of a sample json config that may help:



you'll see some of these settings on https://www.consul.io/docs/agent/options.html#node_ttl
",skippy,blalor
1212,2015-10-02 16:05:53,"@blalor, are you using t2.small within the same AZ or spanning AZs?  

@djenriquez great point about moving to m4.  The challenge with AWS is there are lots of other variables; how many azs are being spanned, which region are you in, etc.  And then lots of guessing (are the t2 and m4 families on better internal network hardware?)

@djenriquez here is part of a sample json config that may help:



you'll see some of these settings on https://www.consul.io/docs/agent/options.html#node_ttl
",skippy,djenriquez
1212,2015-10-02 16:15:34,"Awesome @skippy, I'll take a look at those configs.

As far as AWS regions, we have one datacenter per region (us-west-2, us-east-1, eu-west-1), but having the flapping issues only in the west. Granted, our us-east-1 and eu-west-1 datacenters only house the 5 agents with 5 services vs us-west-2 with 30 agents, and many many more services. 

In each region, we've split up our agents equally to establish HA as much as possible.
",djenriquez,skippy
1212,2015-11-01 15:05:06,"@sander-su I had previously tested m3.medium servers and they still had the same issue, just to a lesser extent. 
",sstarcher,sander-su
1212,2015-11-02 17:18:11,"Hi @sstarcher, i'm not sure why I missed your original post, but I did. Sounds like a solid idea. We are currently not have any flapping at the moment because we fragmented our infrastructure such that the maximum number of nodes in a cluster we have right now is 15 nodes.

When we get back to the amount where flapping happens (~20-25+), I'll try this out. 

If anyone else is experiencing flapping and would like to give this a shot for the sake of resolving this issue, please do so.
",djenriquez,sstarcher
1212,2016-01-08 02:10:49,"Looks like you're doing some work to closing out some issues @slackpad. I've tried to replicate this flapping in 0.6.0 and have fortunately, been unsuccessful. Looks like all the network optimizations in 0.6.0 did the trick.

Closing, and hoping this stays closed.
",djenriquez,slackpad
1212,2016-01-08 02:14:02,"@djenriquez thanks much for the follow up report!
",slackpad,djenriquez
1212,2016-01-08 02:41:53,"@sstarcher we can re-open this issue if you'd like, or try to work the details of your setup in another one - please let me know.
",slackpad,sstarcher
1212,2016-01-08 03:31:36,"@slackpad I'll have more time next week to dig into the consul consensus.  After I dig into it I'll get back in touch.
",sstarcher,slackpad
1212,2016-01-11 17:35:15,"@MrMMorris, have you tried upgrading to 0.6? There were enormous changes to the internals that, for me, solved the flapping issue.

I believe this specific github issue is tied to 0.5.2, if people are still having flapping issues with 0.6, I recommend opening a new issue specifying that. This will help the dev team isolate the problem.
",djenriquez,MrMMorris
1212,2016-01-11 20:14:30,"@MrMMorris sorry about the down time. Looking through these logs it seems like there was a pretty bad communication failure between the Consul servers that disrupted the TCP traffic between them, not the usual node health checking. Do you have any network metrics you can look at during this time for packet loss or other signs of connectivity trouble?
",slackpad,MrMMorris
1212,2016-01-11 20:18:30,"@slackpad thanks for the quick response! I did notice this morning when one of the servers went down that I couldn't ssh in so that makes me think this may be an EC2 problem as well. I am getting some network and consul metrics set up now. Will report back.
",MrMMorris,slackpad
1212,2016-01-12 17:21:12,"@slackpad I have determined that it is a cron.daily task that is causing high disk io. Might be logrotate, still looking into it.

<img width=""879"" alt=""screen shot 2016-01-12 at 12 15 57 pm"" src=""https://cloud.githubusercontent.com/assets/1494248/12270882/51e8a572-b926-11e5-9424-3d4508b72fc2.png"">

**However**, I am experiencing a different issue now. On the same server, I have been seeing these logs since 9:30am UTC (not when cron.daily is run). Any idea why this is happening and how to prevent or have it recover automatically? or does it require manual intervention with a peers.json edit?


",MrMMorris,slackpad
1212,2016-01-13 05:52:01,"@slackpad scratch that last issue. It was due to some port not being open, although I'm not sure which.

This is my SG for Consul Servers. What am I missing that would cause the previous election timeouts?

<img width=""759"" alt=""screen shot 2016-01-13 at 12 49 28 am"" src=""https://cloud.githubusercontent.com/assets/1494248/12286183/d2ba2626-b98f-11e5-9012-80d0f4cee2cd.png"">
",MrMMorris,slackpad
1212,2016-01-14 03:32:55,"@MrMMorris the server-to-server Raft traffic should be going over 8300/tcp in with the default configuration.
",slackpad,MrMMorris
1212,2016-01-20 15:37:58,"@slackpad After relaunching all of our consul servers on larger nodes we are still seeing significant problems.  Would you like me to create a new ticket or document it here.  An overview is as follows
- AWS EC2 - m3.medium
- 5 Servers
- 100 Clients
- Consul running in a docker container with --net=host - Docker 1.9.1
- Ubuntu 14.04
- DNS forwarding is setup on our DNS servers to forward requests for *.service.consul to our 5 servers
- Vault is in use, but running on separate servers.  

Config



Our logs show the following over the past 12 hours.  Certainly below over the past 12 hours only one server has had failed to reconnect problems and it's possible that, that node is having issues, but over the next 12 hours I suspect I'll see other servers have issues as has consistently been the case.  Over the past week I have moved the servers from t2.micros to t2.mediums and now to m3.mediums to see if it was any performance problem.  The CPU utilization is 15% on the servers.




",sstarcher,slackpad
1212,2016-02-02 02:38:12,"Hi @sstarcher checking in on this one to see how things are going. If you are still seeing flaps I'd probably start looking at details on what your cluster load is like and/or other things happening on the server boxes. That would probably be best done on another issue, linked to this one, since there are several things mixed on here.
",slackpad,sstarcher
1212,2016-02-02 02:40:34,"@slackpad I have documented several times what my server load is.  The load on the server nodes is pretty much non-existent.  The only role of those boxes are to be consul masters.  We ship logs off the box and collect metrics, but that's it.
",sstarcher,slackpad
1212,2016-02-02 02:53:43,"@slackpad Thanks for the clarification.  We don't currently use consul template.  We do use vault, but only in a very minimal sense and our vault usage is newer, but the flapping issue has been around for a very long time.  We use consul for service discovery, the cache TTLs are all around 5 seconds I believe to eliminate excessive load.

I'm currently testing our consul servers on CoreOS to see if they exhibit the same flapping problem.
",sstarcher,slackpad
1212,2016-02-02 03:24:45,"@slackpad After migrating the nodes to CoreOS if the flapping continues I will run everything outside of docker and report back.  I do run with --net=host which is why I have kept running in docker, but it could still be related.
",sstarcher,slackpad
1212,2016-02-08 19:05:09,"@sstarcher - did running outside docker help? We are seeing infrequent 'random' flapping with a very small <25 node AWS EC2 cluster. We see nodes timeout for <10 seconds and then reconnect, as well as occasional ""no cluster leader"" errors. 

Unfortunately we're on AWS ECS which doesn't support docker's --net=host so we almost certainly have to migrate to direct EC2. Just wondering if that will help or whether there is something else at play. Thanks!
",mrwilby,sstarcher
1212,2016-02-08 20:39:44,"@mrwilby I am running on EC2 outside of docker and still get flapping. I actually had an outage just last night. Still have no idea what's going on.
",MrMMorris,mrwilby
1212,2016-02-26 17:50:02,"@mrwilby GOMAXPROCS changes haven't done anything for me. I was running docker with prometheus exporters on my consul servers, so I have stopped docker to see if that helps.
",MrMMorris,mrwilby
1212,2016-02-26 18:12:30,"@romansky there's a debug log level that might help there -https://www.consul.io/docs/agent/options.html#_log_level.
",slackpad,romansky
1212,2016-02-26 18:25:39,"@slackpad thanks, I already have `debug` set, does this take effect during monitor? I don't seem to see any messages with `[debug]` prefix. If the process is indeed crashing will it produce any relevant logs?
",romansky,slackpad
1212,2016-02-26 18:31:05,"@romansky yes `consul monitor` can set the log level to debug, though if it looks like the process is crashing you might want to set that on the Consul agent itself and observe its output directly - the `consul monitor` command is doing an RPC call to the agent so it might miss any final logs related to a panic, etc.
",slackpad,romansky
1212,2016-02-26 19:06:11,"@slackpad so if the config file is set with the following-



Is this enough?
",romansky,slackpad
1212,2016-02-26 19:09:18,"@romansky your issue is probably worth splitting off into a new Github issue since it's not related to the flapping others are seeing here. That'll help keep the noise down since there are quite a few threads going on this one.
",slackpad,romansky
1212,2016-02-26 19:13:31,"@slackpad rgr
",romansky,slackpad
1211,2015-09-01 20:22:46,"@ryanbreen Sure, I will update soon. I did just copy and paste from the source project. :/

I will came back later with a better title! 

Thanks
",kikitux,ryanbreen
1211,2015-09-01 20:51:42,"@ryanbreen done it. Thanks for checking this
",kikitux,ryanbreen
1208,2015-08-31 22:43:53,"Hi @huxos there have been some requests for more sophisticated health check filtering, can you describe your use case in a little more detail, and how you'd imagine ""max_fails"" would work?
",slackpad,huxos
1207,2015-08-31 22:40:37,"Hi @wyhysj those failed servers are probably still in the Raft peers file. Can you see if removing them helps? See https://www.consul.io/docs/guides/outage.html for details about the peers.json file.
",slackpad,wyhysj
1207,2015-09-01 02:05:40,"Thank you @slackpad , that resolves the problem.
",wyhysj,slackpad
1207,2016-01-26 16:55:07,"Question on this -- according to #911, this should only be necessary if the quorom was lost. According to @wyhysj he originally had 3 servers, add 2 more, then removed those two. There should still be a quorum of the original 3 servers, right?
",joelthompson,wyhysj
1207,2016-01-26 21:45:42,"@joelthompson Provided the nodes had a chance to sync up before the other nodes were removed, yes, that is correct.  Raft requires, as a distributed finite state machine, continuity of quorum in order to make forward progress when adding log entries to Raft.  We have seen cases where servers will attempt to connect to failed servers that have been removed, but only when there are still outstanding entries in the Raft replay log that have yet to be received by the failed node.
",sean-,joelthompson
1203,2016-01-08 00:48:58,"@brycefisher yep! In almost all cases, the hierarchy should be:

CLI argument > Environment variable > Config files (lexical order by file name when parsed)

During the parsing, usually sets are merged, and single-value options are replaced. Bools are overwritten only when they are specified ""true"" (e.g., false can't merge over true).
",ryanuber,brycefisher
1202,2015-08-28 00:45:13,"This is on our roadmap for a V2 API where we can redesign some of the assumptions of V1. As @highlyunavailable said, the DNS perspective makes it very difficult. That said, we have some ideas as to how to tackle it, but we are probably a few Consul versions away from this.
",armon,highlyunavailable
1202,2016-12-29 00:51:57,"@teenageorge no, you would have to have a proxy that can reroute the port traffic from one to the other. Consul doesn't do that.",lord2800,teenageorge
1202,2016-12-29 01:00:34,"@lord2800 thank you for your reply. If I may ask, in your opinion, what would be the ideal tool for mapping HTTP requests from port 80 to any assigned random port? I believe I should be able to do this from start.sh of my micro service. Thanks again.",teenageorge,lord2800
1202,2016-12-29 02:45:46,Nginx is good. HAProxy is also good. @josdotso's comment above yours suggests that nginx might be the best option if you have nginx plus (as it can automatically configure itself from `SRV` records).,lord2800,josdotso
1202,2016-12-29 02:56:05,@lord2800 thank you! Let me have a look at Nginx.,teenageorge,lord2800
1200,2015-08-31 22:14:06,"Hi @ryotarai - code looks good. Can you please also update https://github.com/hashicorp/consul/blob/master/website/source/docs/commands/lock.html.markdown as part of this change?
",slackpad,ryotarai
1200,2015-09-01 02:02:37,"Hi @slackpad 
Thank you for reviewing. I updated the doc: https://github.com/ryotarai/consul/commit/b2755d026e25071f645c76a071069c242ab2a800
",ryotarai,slackpad
1198,2015-08-26 01:38:24,"Hi @mushixun I can't seem to reproduce this crash. I used Vagrant to spin up the chef/centos-7.0 box and it seems to work fine (from a clean `vagrant up`):





Can you provide more details and maybe confirm the version you are running (I've got the sha256 of the one I downloaded in the dump above). If that doesn't shed light you might want to fire up `gdb` and/or `strace` and see if those yield any clues.
",slackpad,mushixun
1198,2016-01-08 23:26:14,"Hi @loslosbaby which version of Consul were you running on there?
",slackpad,loslosbaby
1193,2015-08-28 16:37:05,"@slackpad Thanks, I think you saved the day. `-join` docs mention how many times it will be tried at all. My expectation from this sort of distributed software was to have `-retry-join` as the default behavior.

![image](https://cloud.githubusercontent.com/assets/159209/9551800/36776b0e-4d68-11e5-8bf9-c53a77334b0b.png)
",ahmetb,slackpad
1191,2016-12-01 16:27:44,"@slackpad sorry, but i try to do that by multiple ways, i think we need in consul normal DNS interface. Cannot work with service discovery with normal way. We need full DNS functional.",westsouthnight,slackpad
1188,2015-12-04 09:20:54,"Hello,

I got similar problem trying to deregister services created with [registrator](http://bit.ly/1O7fRCH) for docker container. It tooks me a half a day to notice that the ServiceID was generated with special characters and I had to call the API endpoint with an **`URL-ENCODED`** string !  @milosgajdos83 , if I take your previous example you should call the API like this:  



`CONSUL_AGENT_URL` should be the node hostname/ip where the agent registered the service.

hope It will help some people :-)
",thpham,milosgajdos83
1188,2015-12-07 16:15:15,"It would appear as though the error checking in the consul http api is not complete.  (I have not looked at the code to verify this).  Hence why a successful response from a failed deregistration.  @milosgajdos83 I was able to successfully register and deregister your service by changing the format of the json and by using the [`/v1/catalog/`](https://www.consul.io/docs/agent/http/catalog.html) endpoint.

**To register a service**



where consulServiceRegister.json is:



**To deregister a service (note the Address is required):**



where consulServiceDeRegister.json is:



At this point the registered service has been successfully deregistered and after 15 minutes the service has not returned:


",codelotus,milosgajdos83
1188,2016-01-05 08:15:20,"The example from @codelotus works as long as you register with the catalog and not with the agent.
If you do the following call:



Where consulServiceRegisterAgent.json is:



And then do a deregister:



where consulServiceDeRegister.json is:



The service will respawn in a minute or so :(
",cjhkramer,codelotus
1188,2016-02-18 23:20:42,"Wanted to clarify - I think there are a few things going on here in this issue:
1. The original problem posted by @drsnyder looks to be an issue with services registered on the _Consul servers_ - that is an outstanding thing we need to track down.
2. The error checking problem pointed out by @volkantufekci needs to be fixed because that adds to confusion by returning bogus success responses.
3. The problems encountered by @milosgajdos83 and @cjhkramer look like a common source of confusion around using Consul. We need to beef up the docs on this - an explanation of this follows.

In Consul it's extremely rare to use the Catalog API directly. The Agent API (https://www.consul.io/docs/agent/http/agent.html) should almost always be used. For services running on Consul agents, the _agent_ is the source of truth, not the catalog maintained by the servers. Periodically, the agents perform an anti-entropy sync and use the Catalog API internally to update the servers to have the correct state. This means that if you use the catalog API to deregister a service, it will disappear for a little while then the agent will put that back on the next sync. If you use the Agent API it will take care of removing the service from the catalog for you.

The call to https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister should be made _on the agent where the service is registered_.
",slackpad,cjhkramer
1188,2016-02-18 23:20:42,"Wanted to clarify - I think there are a few things going on here in this issue:
1. The original problem posted by @drsnyder looks to be an issue with services registered on the _Consul servers_ - that is an outstanding thing we need to track down.
2. The error checking problem pointed out by @volkantufekci needs to be fixed because that adds to confusion by returning bogus success responses.
3. The problems encountered by @milosgajdos83 and @cjhkramer look like a common source of confusion around using Consul. We need to beef up the docs on this - an explanation of this follows.

In Consul it's extremely rare to use the Catalog API directly. The Agent API (https://www.consul.io/docs/agent/http/agent.html) should almost always be used. For services running on Consul agents, the _agent_ is the source of truth, not the catalog maintained by the servers. Periodically, the agents perform an anti-entropy sync and use the Catalog API internally to update the servers to have the correct state. This means that if you use the catalog API to deregister a service, it will disappear for a little while then the agent will put that back on the next sync. If you use the Agent API it will take care of removing the service from the catalog for you.

The call to https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister should be made _on the agent where the service is registered_.
",slackpad,volkantufekci
1188,2016-02-18 23:20:42,"Wanted to clarify - I think there are a few things going on here in this issue:
1. The original problem posted by @drsnyder looks to be an issue with services registered on the _Consul servers_ - that is an outstanding thing we need to track down.
2. The error checking problem pointed out by @volkantufekci needs to be fixed because that adds to confusion by returning bogus success responses.
3. The problems encountered by @milosgajdos83 and @cjhkramer look like a common source of confusion around using Consul. We need to beef up the docs on this - an explanation of this follows.

In Consul it's extremely rare to use the Catalog API directly. The Agent API (https://www.consul.io/docs/agent/http/agent.html) should almost always be used. For services running on Consul agents, the _agent_ is the source of truth, not the catalog maintained by the servers. Periodically, the agents perform an anti-entropy sync and use the Catalog API internally to update the servers to have the correct state. This means that if you use the catalog API to deregister a service, it will disappear for a little while then the agent will put that back on the next sync. If you use the Agent API it will take care of removing the service from the catalog for you.

The call to https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister should be made _on the agent where the service is registered_.
",slackpad,drsnyder
1188,2016-02-18 23:20:42,"Wanted to clarify - I think there are a few things going on here in this issue:
1. The original problem posted by @drsnyder looks to be an issue with services registered on the _Consul servers_ - that is an outstanding thing we need to track down.
2. The error checking problem pointed out by @volkantufekci needs to be fixed because that adds to confusion by returning bogus success responses.
3. The problems encountered by @milosgajdos83 and @cjhkramer look like a common source of confusion around using Consul. We need to beef up the docs on this - an explanation of this follows.

In Consul it's extremely rare to use the Catalog API directly. The Agent API (https://www.consul.io/docs/agent/http/agent.html) should almost always be used. For services running on Consul agents, the _agent_ is the source of truth, not the catalog maintained by the servers. Periodically, the agents perform an anti-entropy sync and use the Catalog API internally to update the servers to have the correct state. This means that if you use the catalog API to deregister a service, it will disappear for a little while then the agent will put that back on the next sync. If you use the Agent API it will take care of removing the service from the catalog for you.

The call to https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister should be made _on the agent where the service is registered_.
",slackpad,milosgajdos83
1188,2016-06-20 08:10:18,"@alexykot Actually the checks are registered by nomad in my case
",skyrocknroll,alexykot
1188,2016-06-21 12:39:36,"@alexykot 

> And when I deregistered service on the same agent it was created on with DELETE /v1/agent/service/deregister/test-service1 - it has gone away instantly from catalogs on all three nodes.

have you tried to deregister from other nodes different than the one you have used to register? That's when they come back. I'm not sure if it is supposed to work this way though.
",webertlima,alexykot
1188,2016-06-21 13:37:55,"@webertlima
You cannot deregister a service from the agent on a different node, service only exists on the agent you have registered with. It also exists in the catalog on all nodes, but that is not related to the agent itself. And to be honest I don't understand why there is a `catalog/deregister` endpoint at all, in my opinion catalog should be a read-only service list.
",alexykot,webertlima
1188,2016-06-21 13:47:26,"@alexykot thanks for clearing that up.
",webertlima,alexykot
1188,2016-06-22 21:33:12,"Hi @flypenguin sorry you are having trouble. There are some issues called out in https://github.com/hashicorp/consul/issues/1188#issuecomment-185977469, but Consul's behavior is definitely deterministic. I think you are running into problems because of this:

> I use only one central agent to register services with

Consul's really not designed to run all registrations through a central set of agents. In Consul, the agent holds the information about which services are registered, and then takes responsibility for syncing that information up to the catalog maintained by the servers. If you delete a service from the catalog, the agent will put it back (which I agree is confusing and we need to document that more clearly). To remove a service you always need to remove it using the [Agent API](https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister) and it will remove it from the catalog for you.

If you run an agent on each node and always register/deregister using that agent for the services on that node then things should work properly (and if that node dies all of its services will eventually be reaped automatically). If you are running a small number of agents and registering everything through those, setting the addresses manually, it is easy to lose track of where a service was registered, making it hard to remove it. I'd strongly recommend against running Consul like this - it also prevents reaping as described above, and things like sessions from working properly. Consul is designed to have the agent running on each node in the cluster.

The other issue on here where you get a 200 when deleting even if a service doesn't exist adds to the confusion; we will also fix that. Sorry for the trouble - hopefully you can get things working well in your setup!
",slackpad,flypenguin
1188,2016-06-24 19:10:27,"@flypenguin 
Hi, I see you are (or were) making some of the same confusions I was making using the Consul Agent.
Picture this:
If you have ONE Consul Server ONLY (the Master), you use this instance to register and deregister your services through the HTTP API, no matter how many services and nodes you have. This MUST work, unless you are doing something wrong with the request.

Now if you have MORE THAN ONE Consul servers (Like 1, 2 or 3 Consul Masters and Other Consul Clients), if you use the instance 2 to REGISTER, you HAVE to use the same instance 2 to DEREGISTER. It doesn't matter what instance of Consul you use to Register A service, as long as you use the same instance to deregister that same service (same ID).

Good practice: run the Consul Client in every machine that runs services and use 127.0.0.1 to register/deregister. It'll work. If the Service is in a Docker container, use it's default route.
",webertlima,flypenguin
1188,2016-09-29 12:05:05,"@Keets2016 you should use [Agent Deregister API](https://www.consul.io/docs/agent/http/agent.html#agent_service_deregister) to deregister the service instance **on the same consul agent** that your service instance registered.
",lowzj,Keets2016
1188,2016-09-29 12:22:16,"@lowzj yes and that's exactly what should change. Consul is a distributed system but can't be used in a distributed way.
",flypenguin,lowzj
1188,2016-09-29 19:03:24,"@flypenguin yeah, at first I was totally confused by the mechanism that consul using, and spent a lot of time on this. IMO, a service should be able to be deregistered by using the same way if it can be registered by using 'catalog api`.

But consul is much different from other system I used before, for example `zookeeper`. It's more like `SmartStack`, but simpler.  `Consul server` like `zookeeper at SmartStack`, a `key/value` distributed store system.  And `consul client` like `Nerve at SmartStack`, manage local services, perform health checks and report infos to the `consul server/zookeeper`. 
So why I cannot de-register a service from consul using 'catalog api'? It just like that I directly delete an service(represented by ephemeral znode) from zk, but Nerve will recreate the ephemeral znode because of the health checking of the service is succeed.

Why consul works in this different way? From my experience, I think the biggest reason may be that consul is much easier and more convenient for services to use. From a service's point of view, the local consul client is God, everything could be done through it, and don't care anything else. But it's a little difficult to maintain the whole consul cluster(one agent per node). We must write tools to deploy/monitor/auto-restart consul agents. Yes, I also wrote a shell scripts to deregister critical zombie services.-_-!! 

Sorry for my poor English, please don't mind.
",lowzj,flypenguin
1188,2016-09-30 16:27:27,"I agree with @flypenguin 's point of view about infrastructure. I had 2 system outages because of kernel panics, because the services were not deregistered on the machine that died, and I couldn't deregister them until I brought that machine back online.
",webertlima,flypenguin
1188,2017-03-19 18:14:42,"Hi @AjitDas iConsul provides solutions to the problems you mention _if you run the agent on each node in your cluster_. Consul's not designed to run just as a set of servers behind a load balancer; running it that way means you take on solving these problems yourself. When you run agents on each node and have your applications register themselves, they will sync up the catalog on the servers for you, and health checks can be performed locally on the agent, the results of which will get synced automatically as well. The agents perform checks against each other, forming an efficient failure detector which will arrange to have the catalog cleaned up in the event that a node dies and doesn't deregister itself. Applications only need to talk to their local agent, and Consul will route requests to a healthy server automatically with no load balancer. Many, many folks are successfully running Consul clusters with thousands of nodes in this fashion. Hope that helps!",slackpad,AjitDas
1187,2015-08-31 21:30:25,"@sfncook the basic logic looks ok to me - can you please add a unit test that exercises the new functionality?
",slackpad,sfncook
1187,2015-09-10 21:32:37,"@slackpad @ryanuber - Thanks for the review, guys.

@slackpad - I have added a couple test cases in TestAgentAntiEntropy_EnableTagDrift.  But perhaps you can see in this conversation that the Travis failing with errors that don't appear to be related to my updates.  I'm not sure why they are failing - they seems to be complaining that an interface is being used. (in code that I did not modify)  Perhaps you guys have seen these errors before?  Known issue?

Travis errors:
command/maint_test.go:48: not enough arguments in call to a1.agent.EnableServiceMaintenance
command/maint_test.go:53: not enough arguments in call to a1.agent.EnableNodeMaintenance
",sfncook,slackpad
1187,2015-09-10 22:47:35,"@sfncook can you please update the docs along with this change?
",slackpad,sfncook
1187,2015-09-10 23:40:29,"@sfncook - looking good! I noted a few small things but I think this is almost ready to go.
",slackpad,sfncook
1187,2015-09-11 01:07:28,"@slackpad - Thanks so much for the thoughtful and thorough review!  I will make these updates tomorrow.
",sfncook,slackpad
1187,2015-09-11 16:36:43,"@slackpad I just pushed updates in response to your comments.  (thank again)  Note that the title of this pull request and branch still refer to the old config item name ""EnableTagDrift"", though the code has been updated per your request.
",sfncook,slackpad
1187,2015-09-11 22:27:06,"@slackpad Awesome, just pushed those changes.  Thanks.
",sfncook,slackpad
1186,2015-08-19 00:53:30,"@armon I see. Is there a location on the filesystem where the ACLs are stored, or do I have to query it via the API and export like like so?

On a separate, but related question, if I were to decommission dc1, would I have to restore KV's too? What if they were already replicated to dc2 and dc3 with consul-replicate?

What other data do you suggest exporting, raft or serft from the `data-dir`?
",calvn,armon
1186,2015-08-19 01:39:33,"@armon One last thing, what would be the correct procedure to migrate the ACLs? It is like so:
1. Export ACLs on dc1
2. Write exported ACLs to dc2
3. Change `acl_datacenter` on all server nodes from dc1 to dc2 (including dc1 itself?)
4. Shut down dc1 cluster
5. ???
6. Profit

On step 2, `acl_datacenter` on dc2 still points to dc1, so would there be a conflict there? Also, on step 3, once dc1's `acl_datacenter` is changed to dc2 would there be a conflict (although it wouldn't matter so much in this case since it's going to be taken down)?
",calvn,armon
1186,2015-08-19 15:39:19,"Edit: This question is throughly answered in https://www.consul.io/docs/internals/acl.html

@armon You mentioned that dc2 would end up forwarding to dc1, are you talking about requests that needs ACL tokens for permissions, or the ACL tokens themselves? If it is the former, what would happen during an outrage on dc1? Would dc2 just not able to perform anything if its under a deny-by-default policy? Or does it have the ACLs cached locally so that accessing the KV store and service registration is still possible?

In other words, what is the actual flow for checking if the ACL is valid in clusters where it's not the `acl_datacenter`? Does dc2 (or dc3) asks dc1 every time a request is made to check whether the ACL token used is valid?
",calvn,armon
1186,2015-08-19 17:55:16,"@armon If the dc1 was to be decommissioned, what would be the process of moving clients that are currently part of dc1 to dc2? Would that imply cluster merging issues and other weirdness along the way?
",calvn,armon
1186,2015-09-11 17:14:32,"@armon In the case of doing the `acl_datacenter` swap, is it safe to assume that the services that have been registered before in dc2 with with a particular ACL token will not disappear? Is it just that I can no longer use ACL to register new services?

What would happen if I disable ACLs on dc2 entirely? Would service still be able to register regardless of whether `?token` parameter is provided? Ideally I would want zero downtime on services that are registered to dc2. How would this ACL migration process affect services (whether on dc1 or dc2)?
",calvn,armon
1186,2015-09-11 18:47:18,"@armon Cool! What do you mean by 'issues' during the time between enabling ACLs and importing the old tokens? Is it actions that require ACLs such as new service registration and KV queries? I think I can live with that temporarily as long as I am not taking down existing services.
",calvn,armon
1185,2015-08-18 17:17:39,"""Address"" in this case is shorthand for ""IP address"" since Consul doesn't presuppose the existence of other DNS servers. @aidanhs method would work, or look up the address via some other method like checking the interfaces.
",highlyunavailable,aidanhs
1184,2015-08-25 23:49:55,"That's a good point @ryanbreen - even headers brings to mind complexity around supporting multiple, etc. I'll change this to thinking for now, because we don't want to introduce a bunch of complexity. If there are a few extra options that are highly useful, it might make for a better experience, but we don't want a `curl`-level of stuff for sure.
",slackpad,ryanbreen
1184,2016-03-16 15:08:03,"Hi @truszkowski this was added in https://github.com/hashicorp/consul/pull/1819 which will be going out in today's release of Consul 0.6.4.
",slackpad,truszkowski
1184,2016-09-21 02:58:50,"Hi @Ashald we'd take a PR for this - thank you!
",slackpad,Ashald
1183,2015-08-18 18:06:21,"@aidanhs It's not just the ""few hundred KB"" that's the issue, though I on principle don't like unnecessarily adding lots of unnecessary bloat to avoid this small amount of code. The bigger issue is that it complicates building a container for Consul by requiring pulling in and building packages for another Init, or setting up an inittab for something like Busybox, when the issue can be avoided entirely with <10 lines of code in Consul.

This is a step that, by searching for ""consul"" on Dockerhub and checking the Dockerfiles, almost nobody are aware they need to take: At _least_ 8 out of the first 10 available Consul containers I checked has this problem. 

Which means a lot of people are going to run into slowly building zombies, and potentially containers locking up when the process table fills. 

Fixing that either requires educating everyone who builds these containers, or making Consul resilient to it. And while the ideal situation might be to educate everyone about it anyway, I'm a big fan of defensive programming when the cost is low...
",vidarh,aidanhs
1183,2015-08-18 18:10:08,"@aidanhs That's great, but you're paying that cost to avoid 6-7 lines of code in Consul. Seems like a really bad tradeoff to me. Especially given that to fix this issue it'd still be necessary to convince everyone building Consul containers to do it right in every Dockerfile. And it clearly in that case needs to be documented, as it's clear it's totally non-obvious to pretty much everyone who tries to package Consul..

(edit: I really appreciate the example of using an Alpine container to build stuff against musl, though - I'm definitively stealing that)
",vidarh,aidanhs
1182,2016-04-15 14:10:15,"Hi @batjko sorry about that. The problem is that Atlas dropped support for public infrastructures which can be viewed without signing in, so the problem is bigger than just fixing the link :-) We will update the static content so you can see a screenshot in the mean time.
",slackpad,batjko
1181,2015-08-17 18:11:28,"Hey @zanedeg,

The URL in question here is actually supposed to link to a public infrastructure which exists in HashiCorp's [Atlas](https://atlas.hashicorp.com) product. While Consul does ship its own stand-alone Web UI, Atlas provides many additional features above and beyond the open source offering, which you can read about [here](https://atlas.hashicorp.com/learn/consul).

I'm going to close this PR, but I'll open an issue to get the 404 fixed. Thanks!
",ryanuber,zanedeg
1179,2015-08-17 21:52:19,"Hi @piersy take a look at #954 which I think is a duplicate of this issue.
",slackpad,piersy
1177,2015-08-17 20:15:50,"Hi @feniix any chance you are running your own build of Consul, or a non-official one? What does `consul version` report?
",slackpad,feniix
1177,2015-08-17 20:48:48,"Hi @slackpad, no, I did not build consul, it is getting downloaded from mitchellh's bintray (https://dl.bintray.com/mitchellh/consul/)

see: 



if it is any help:
`fc35735a636f0d5c9d62ae1c537c8b2e2ed1960fb34fe810f6b9431f7646e9f1  /usr/local/bin/consul`


",feniix,slackpad
1177,2015-08-17 23:09:54,"@slackpad sadly, I forgot to run an strace before and now when I run it with or without strace it does not do it any more. Otherwise I would have more info.
",feniix,slackpad
1173,2015-08-26 15:11:28,"@wuub thanks that would be great! Just for science can you run 0.5.2 on another node just to make sure I'm not missing anything and it shows the problem, too? Looking at the diff 0.5.1->0.5.2 doesn't seem to have anything related but it would be good to be sure. Then I'll give you a patch (or patched build if you like) of 0.5.2 that locks out the server updates during the pause for a reload. Running 0.5.2 along with other 0.5.1 nodes should not be a problem.
",slackpad,wuub
1173,2015-08-27 08:43:36,"@slackpad we are now on 0.5.2, I'll try to confirm that the problem still occurs ASAP.

I'll can build a debug binary myself, just point me to a commit/branch :)
",wuub,slackpad
1173,2015-09-11 16:27:02,"Hmm this is interesting - so it's basically looking like sending another HUP before the first reload is done triggers this behavior. I think we could also guard this by using a `sync.Mutex` in `handleSignals` so we can be sure we only process one at a time. It seems a bit chaotic to have two config reloads going at the same time. Thanks for all the detailed information @wuub! I'm marking this as a bug, and I think the fix should be pretty simple. We'll get this in for 0.6's release!
",ryanuber,wuub
1173,2015-09-11 16:35:10,"@ryanuber  two config reloads should be guarded against as well, but during the investigation I did today I was able to trigger deregistration even with a single, well behaved SIGHUP. 

I'm pretty confident that I got to the bottom of this, and AFAICT #1235 fixes the root cause of the problem we are experiencing. 
",wuub,ryanuber
1173,2015-09-11 17:43:19,"Thanks for nailing this down @wuub - nice work! I'll take a look over your PR, and I'll double check my original patch to see if there's anything in there worth saving since that never made it to master.
",slackpad,wuub
1172,2015-08-13 16:47:22,"@half-dead This is done on purpose. The contract of the TTL is that it will not expire before that value, but could expire after. There are number of reasons for that (complexity during leadership transition), but we also add a grace period to account for clock skew and network delays. This is to shield the application from dealing with that.
",armon,half-dead
1171,2016-02-17 05:22:23,"Hi @youngking and @kamaradclimber you are correct, the current key goes to both WAN and LAN. We will take a look at making this more flexible.
",slackpad,kamaradclimber
1169,2015-08-14 00:24:34,"Hi @mtougeron - that metric looks like it's only emitted when the Serf layer handles broadcast events in the cluster. These are used for leadership election or with the `consul event` mechanism, but I don't think these will be firing if the cluster is operating normally. I looked on our production cluster and don't see these very often. Do you see some when you run `consul event`?
",slackpad,mtougeron
1167,2015-08-20 17:16:53,"@railsguru this looks good, sorry for the delay! If we can just add the test case for the option, as well as update the CLI and HTTP documentation I think we can merge this.
",ryanuber,railsguru
1167,2015-09-01 21:44:34,"@railsguru, this needs to be documented here: http://www.consul.io/docs/agent/options.html.  Can you update `docs/agent/options.html.markdown` to cover this?
",ryanbreen,railsguru
1167,2015-09-02 04:30:34,"@ryanbreen ah missed that cue, done!
",railsguru,ryanbreen
1164,2015-08-14 00:02:26,"Hi @marenzo can you give a little more information about your intended use case? There are a lot of ways this could be done, but I think I'd want to understand what you are trying to do before we add features to Consul itself.
",slackpad,marenzo
1162,2015-08-07 17:22:53,"@jeinwag It is not intended behavior, we just need special case handling of the ""no cluster leader"" return. The `consul lock` command err's on the side of caution and aborts if it encounters any error, but the lock is still ""held"" even if a leader election happens.

From the perspective of the servers that client still holds the the lock, but the client is not teasing apart different errors to determine if its safe to continue. Makes sense?
",armon,jeinwag
1159,2015-08-06 17:40:45,"@bacoboy This is an interesting idea! We are working on a new feature for Consul that allows for richer lookup logic when resolving services, and this notion of a linear resolution order could definitely fit in there. That mechanism will be more flexible than the meta-DC and much easier than modifying logic in the existing APIs. The basic idea is to create APIs for creating custom DNS endpoints which dynamic behavior, things like this. I'm going to tag this as an enhancement so we keep this use case in mind as we are working on that feature.
",armon,bacoboy
1159,2015-12-31 20:24:16,"Even with the new tomography features in 0.6, I think this feature still has its place where specific fallback is desired.  However, I'd be interested in your thoughts @armon...
",bacoboy,armon
1159,2016-01-01 02:42:40,"@bacoboy did you have a chance to look at prepared queries? You can use network tomography to select the next best N datacenters, or you can give an explicit list of fallback datacenters, or both.

https://www.consul.io/docs/agent/http/query.html
",slackpad,bacoboy
1159,2016-01-01 21:54:05,"Hi @bacoboy if you set `NearestN` you can give a specific list of fallback datacenters - you aren't required to use nearness at all.

Also, clients don't typically create their own queries, they are created once and then clients just get the id of the query to execute. Those fields in the link above are for _defining_ a query, but you don't need anything other than the id to _execute_ the query. The client can just look up `<id>.query.consul` via DNS or make an HTTP request to fetch the results, they won't be exposed to any details of the fallback logic or any other parts of the query. You can alter existing queries on the fly to change the behavior without any changes to your clients, or you could register new queries and give clients the new query id.
",slackpad,bacoboy
1159,2016-01-03 19:45:58,"@bacoboy Our goal is that prepared queries would be the solution to this, in a more generic way. As @slackpad said, you can use the tomography for a ""zero touch"" failover configuration, but you can also specify the specific fallback order if you care to.
",armon,slackpad
1159,2016-01-03 19:45:58,"@bacoboy Our goal is that prepared queries would be the solution to this, in a more generic way. As @slackpad said, you can use the tomography for a ""zero touch"" failover configuration, but you can also specify the specific fallback order if you care to.
",armon,bacoboy
1159,2016-01-09 03:18:11,"I agree that the queries allows control from the `client`, but in cases where I don't want the client to know anything other than the local consul agent (because updating a zillion client configurations would be bad), the crux of this request is to move this fallback logic to the consul agent configuration.  

Yes, tomography allows server side fallback if you want ""closeness"" to be your fallback mechanism, but that not what I want.  I want a server-side way of saying which way to go if not found.  @armon you said:

> but you can also specify the specific fallback order if you care to

Are you referring to the client side query again or is there a configuration server-side I'm unaware of to specify fallback?  I looked again, but didn't see anything.
",bacoboy,armon
1159,2016-01-09 03:33:19,"Hi @bacoboy I think you might be misunderstanding how prepared queries work. You define the query one time and it's stored on the servers. Clients just execute the query by name so they don't know _anything_ about how the query is defined. It works like this:
1. You register a new query with the servers by calling https://www.consul.io/docs/agent/http/query.html#general - note that you can define a list of datacenters in the `Failover` section.
2. You give your query a name, or use the ID that's returned when you complete step 1.
3. All you share with your clients is the name or ID of the query. They then lookup `<id>.query.consul` using DNS, or they execute the query using https://www.consul.io/docs/agent/http/query.html#execute over HTTP.

The clients don't have any idea what the query does or how it's configured (remember they don't have to post any of the information you gave the servers in the first step, they just use the ID you gave them). If you change the query's setup later using https://www.consul.io/docs/agent/http/query.html#specific then any client that executes again with that ID will get the new configuration, you don't have to update them at all.

Please let me know if this helps, or if you have any more questions about how these work. If I understand what you are looking for, I think it sounds really close.
",slackpad,bacoboy
1159,2016-01-13 21:24:45,"@bacoboy ok I understand the difference for the case where there are many, many services and you have good parity between DCs and it makes sense to fallback queries for any service. 
",slackpad,bacoboy
1157,2015-08-11 14:05:40,"Hey @ryanuber,

Unfortunately I thought the same thing and tried these approaches already.  The problem is a chicken and egg issue.  You can't register a check to a service if that service doesn't exist yet, you will get an error.

I also tried to register the ""maintenance mode"" check by using the naming convention when the service itself is registered, but those values are ignored and a new checkId is generated for it when combined in the service registration.  The only way I was able to accomplish was the method I mentioned earlier about the TTL.
",hopperd,ryanuber
1154,2015-08-05 22:15:31,"@darron Hmm this is odd. I haven't seen that before. @slackpad is looking into this.
",armon,darron
1154,2015-08-06 01:30:33,"@darron What version of Consul are you guys running? Two things are odd here. A blocking query is capped to 10m on the server side, but the fact that no query is going through and ""failed to start stream"" is being logged means we are blocking trying to open a new stream to the server (single TCP stream, multiplexed per-request). 

We apply back pressure on new streams to prevent overwhelming the servers, and it seems like the clients are waiting for a new stream to be available. This is causing the blocking query to go for a very long time.

Not sure yet why clients are blocking. Do you see anything odd on the servers around those times? Specifically the leader is likely to be the culprit.
",armon,darron
1154,2015-08-06 01:47:59,"@darron Could you also check  the value of /proc/sys/net/ipv4/tcp_keepalive_time
",armon,darron
1154,2015-08-07 04:11:53,"A thorough review of the receive side in the server hasn't found any smoking guns, so my current working hypothesis is that you are seeing TCP connectivity issues and this known mode with the client is causing things to hang. I think the next thing on my side would be some stress testing to try to get it to repro without messing with the TCP stream.

@darron it would be super useful to get some `tcpdump` for Consul RPC traffic from the agent to the server during one of these events (preferably showing things working properly and then into the failure) - would something like that be possible? Also, I think we could make this a lot better behaved with write timeouts on the client side - would it be possible to run a slightly patched agent in your environment?
",slackpad,darron
1154,2015-08-10 22:00:32,"@slackpad Do you need anymore tcpdumps? either:
1. Working to non-working.
2. Non-working to working.

Let me know - I have both types of nodes right now that I can grab data from. All server nodes.
",darron,slackpad
1154,2015-08-10 22:14:06,"@darron I think I'm pretty good with what you've sent so far. Your last round of pcap files led to #1165, which I don't think will actively harm anything but will create a small flurry of network traffic and probably some extra load on the servers when it happens (spins up 3 goroutines per connection, etc.).

If it's easy to get a two-sided pcap of a good to bad transition that would be useful, but I don't want to take too much of your time trying to get that if it's a hassle.
",slackpad,darron
1154,2015-08-11 07:58:26,"We're seeing the same behaviour at our cluster. One of the nodes doesn't respond anymore, calls to /agent are fine, but to /catalog just hang forever. Our cluster is much smaller, but we're querying the API quite a bit. We're running [Prometheus Consul exporter](https://github.com/prometheus/consul_exporter), which polls the API quite often, and our own gateway, which is using Consul as well.

I turned on the debug level, but the only thing I could see is that the health checks via http are not being processed anymore. 

Let me know if I can help debugging this! @darron, could it be that you're also using the Prometheus Consul exporter?
",bastichelaar,darron
1154,2015-08-14 23:12:27,"Hi @bastichelaar thanks for offering to help debug this (and sorry for the late reply)! Here's what we know so far:
1. Through @darron's data drops we realized that yamux (the library Consul uses to multiplex RPC requests over a single TCP connection) had the potential to stall on the client or server side. There was coupling between the send and receive loops due to the way it can try to send window updates to apply back pressure or send replies to ping requests during reads. We cleaned these up and added a fallback timeout here - https://github.com/hashicorp/yamux/pull/9.
2. We also realized that heavy RPC traffic during TCP connects would create a ton of new connections and kill off all but one, we fixed that here - https://github.com/hashicorp/consul/pull/1170. This wasn't directly involved in the stalls but it wasn't helping anything and created a bunch of useless network traffic at a critical time.

I merged those fixes, along with some minimal cherry picks to get the build working, to a branch based on the 0.5.2 tag, which is here - https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches. I ended up rolling back both memberlist (6025015f2dc659ca2c735112d37e753bda6e329d) and serf (668982d8f90f5eff4a766583c1286393c1d27f68) to versions near the 0.5.2 release date since there are protocol version bumps that you definitely don't want in there, so a build in this configuration is very close to 0.5.2, but includes the above fixes.

@darron is doing some testing with this new binary and it is behaving better (shorter stall periods), but alas it's hitting the new timeouts we added so there's still something we need to figure out.

If you'd like to try out this binary and/or send some logs from this happening in your configuration you can email support@hashicorp.com and CC me at james at hashicorp.com and I'll give you the build. We will keep this issue posted with what we find and with the fix once we figure it out.
",slackpad,darron
1154,2015-08-14 23:12:27,"Hi @bastichelaar thanks for offering to help debug this (and sorry for the late reply)! Here's what we know so far:
1. Through @darron's data drops we realized that yamux (the library Consul uses to multiplex RPC requests over a single TCP connection) had the potential to stall on the client or server side. There was coupling between the send and receive loops due to the way it can try to send window updates to apply back pressure or send replies to ping requests during reads. We cleaned these up and added a fallback timeout here - https://github.com/hashicorp/yamux/pull/9.
2. We also realized that heavy RPC traffic during TCP connects would create a ton of new connections and kill off all but one, we fixed that here - https://github.com/hashicorp/consul/pull/1170. This wasn't directly involved in the stalls but it wasn't helping anything and created a bunch of useless network traffic at a critical time.

I merged those fixes, along with some minimal cherry picks to get the build working, to a branch based on the 0.5.2 tag, which is here - https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches. I ended up rolling back both memberlist (6025015f2dc659ca2c735112d37e753bda6e329d) and serf (668982d8f90f5eff4a766583c1286393c1d27f68) to versions near the 0.5.2 release date since there are protocol version bumps that you definitely don't want in there, so a build in this configuration is very close to 0.5.2, but includes the above fixes.

@darron is doing some testing with this new binary and it is behaving better (shorter stall periods), but alas it's hitting the new timeouts we added so there's still something we need to figure out.

If you'd like to try out this binary and/or send some logs from this happening in your configuration you can email support@hashicorp.com and CC me at james at hashicorp.com and I'll give you the build. We will keep this issue posted with what we find and with the fix once we figure it out.
",slackpad,bastichelaar
1154,2015-08-20 18:52:57,"OK - to summarize where this particular issue is at - we've now had a 24 hour period where no nodes have gone deaf, couldn't communicate with the master and needed to be bounced. We haven't seen that for a long time given we're at 900 fairly busy nodes - busy with services, DNS lookups and KV traffic.

A key understanding for me was recognizing that:
1. Server nodes were all of a sudden unable to talk to the leader.
2. As a result, all of the client nodes that were talking to them were effectively cut off as well.

Bouncing the server would resolve it for all the nodes - but that's an unsustainable strategy.

There have been 3 things that have changed this status and helped to hopefully solve it:
1. [The Yamux patch for deadlocks](https://github.com/hashicorp/yamux/pull/9) - we're running that on the server nodes.
2. [The Consul patch for connection throttling](https://github.com/hashicorp/consul/pull/1170) - we're running that on the server nodes.
3. Making sure the server nodes were immune to the ""Rides the Rocket"" Xen/EC2 networking bug. For future reference - this is what did it for us:

`/sbin/ethtool -K eth0 tso off gso off sg off`

1 and 2 helped a ton - but what seems to have made it much more consistent is 3.

We had thought we had fixed the Xen/EC2 bug - but it was an incomplete solution on the Consul server nodes and only came to light through some excellent ""reading-the-pcap-leaves"" by @slackpad. 

Basically - the leader was sending things to the server nodes that it never got - and so that put it into a strange state that took a while to come out from.

There's [another patch to yamux](https://github.com/hashicorp/yamux/pull/11) - but we're going to give this current state a week and then think of changing out the Consul binary cluster wide.

I'll update this next week after I'm done traveling and we have more data to back up the current conclusion.
",darron,slackpad
1154,2015-08-20 19:04:33,"Same here: we also applied the ""Rides the Rocket"" Xen/EC2 fix and we build a new version of Consul using the deadlock fixes branch (https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches). The cluster is stable now, and the /v1/catalog API endpoint doesn't become unresponsive anymore. We're still monitoring the cluster, but it looks good! I'll keep this issue updated if we encounter any issues. 

Thanks @darron and @slackpad for your help!
",bastichelaar,slackpad
1154,2015-08-20 19:04:33,"Same here: we also applied the ""Rides the Rocket"" Xen/EC2 fix and we build a new version of Consul using the deadlock fixes branch (https://github.com/hashicorp/consul/tree/v0.5.2-deadlock-patches). The cluster is stable now, and the /v1/catalog API endpoint doesn't become unresponsive anymore. We're still monitoring the cluster, but it looks good! I'll keep this issue updated if we encounter any issues. 

Thanks @darron and @slackpad for your help!
",bastichelaar,darron
1154,2015-08-28 15:40:46,"@slackpad It looks like those patches have pretty much solved this problem for us.

In the last 8 days we have had a single instance of things going deaf - but it was short and corrected itself:

http://shared.froese.org/2015/0hrr9-17-16.jpg

I wonder if we need to try the other [Yamux patch](https://github.com/hashicorp/yamux/pull/11) - but pretty happy with where we are at the moment.

Worth a 0.5.3 release?
",darron,slackpad
1154,2015-08-28 16:27:26,"@darron thanks for the update. If things are performing well you probably don't need that last patch as that was kind of a catch all for any TCP errors; you've got a high enough request load that one of your streams is likely going to try to send a header and time out (the patch will time out even if it's not trying to write a header) As for 0.5.3 I think at this point we should focus on 0.6 which will have the performance fixes, too. Are you ok running the patch release for a little while longer?
",slackpad,darron
1154,2015-08-28 18:25:13,"Yeah - it should be OK. I will build a package and install across my cluster.

Thanks for all your help @slackpad - really appreciate it.
",darron,slackpad
1154,2015-08-28 18:28:20,"@darron my pleasure - I totally appreciate all your efforts repro-ing this and mechanizing and supplying the debug data - you put in some major effort to track this down!
",slackpad,darron
1153,2015-08-04 17:53:51,"Hi @sielaq this is a bug that came up in another thread recently and is being tracked at #1144 - thanks for the report!
",slackpad,sielaq
1152,2015-08-04 18:32:14,"@half-dead it's effectively a cache invalidation problem. The granularity of our invalidation is too large and is something that must be handled inside the core. You need something like DeepEqual on the client to de duplicate. It's a very difficult problem but one we are working on.
",armon,half-dead
1152,2015-08-05 02:13:03,"@armon thanks for answering, will consul support small-granularity invalidation in future version?
",half-dead,armon
1152,2015-08-05 21:59:15,"@half-dead Yep! We've been improving steadily ever since Consul 0.1. It used to be all blocking queries triggered with any write. The contract between Consul and the client is purposely designed so that we can make improvements server side without the client re-writing. The signal just gets less noisy over time.
",armon,half-dead
1152,2015-08-10 09:41:47,"@armon Have you ever benchmarked the '/v1/agent/check/pass/xx' endpoint? It seems that it will trigger all server node's disk write, right?
",half-dead,armon
1152,2015-08-11 17:16:39,"@half-dead In the Consul architecture, checks are edge triggered, so we only do RPC traffic from clients to servers if something changes. If a check in in a steady state, then we don't need to update the servers. So typically even with a large volume of checks, there is only a small amount of updates taking place on the servers. For example the `'/v1/agent/check/pass/` endpoint is only doing a request to the local agent to prevent the TTL from expiring, so the load on the servers is not affected until the TTL fails.
",armon,half-dead
1150,2015-08-06 01:15:04,"@evanccnyc Could you provide some more information? Specifically more of the following:
- Consul configurations
- Version
- Deployment setup
- Potentially relevant networking details
- Debug level log traces
- Telemetry output (SIGUSR1)

It is pretty hard to diagnose or understand the issue with the given information.
",armon,evanccnyc
1150,2015-08-06 03:32:16,"@slackpad That may well be it. It was our cluster that showed the elections as I said, I dont remember nodes leaving and joining every minute but they well could of been joining and leaving.

@armon More details, it was a 0.5.2 cluster with 3 nodes running m4.medium's one in each az zone. We rolled out consul-template to 100+ nodes and consul never recovered.

First thing we noticed was that one our nodes ran out of open files, consul had something like 5000+ open files when we ran lsof. Most of them looked like connections from clients requests the consul template data.

We recycled the node and turned off consul template but that node never seemed to recover, with the other nodes often complaining of timeouts to that one (500ms or more).  

At that point we recycled the entire cluster and kept consul-template turned off, it appears stable.

The debug logs were not much help unfortunately, they showed little more than what we had above. Again, this broke a huge amount of things in our setup, so I grabbed what I could before completely redoing the cluster.
",evanccnyc,armon
1150,2015-08-06 03:32:16,"@slackpad That may well be it. It was our cluster that showed the elections as I said, I dont remember nodes leaving and joining every minute but they well could of been joining and leaving.

@armon More details, it was a 0.5.2 cluster with 3 nodes running m4.medium's one in each az zone. We rolled out consul-template to 100+ nodes and consul never recovered.

First thing we noticed was that one our nodes ran out of open files, consul had something like 5000+ open files when we ran lsof. Most of them looked like connections from clients requests the consul template data.

We recycled the node and turned off consul template but that node never seemed to recover, with the other nodes often complaining of timeouts to that one (500ms or more).  

At that point we recycled the entire cluster and kept consul-template turned off, it appears stable.

The debug logs were not much help unfortunately, they showed little more than what we had above. Again, this broke a huge amount of things in our setup, so I grabbed what I could before completely redoing the cluster.
",evanccnyc,slackpad
1150,2015-08-06 17:34:55,"@evanccnyc Cool, this helps. CT is the likely culprit. Can you share the template that you rolled out? I want to just get a feel for how many depedencies / watchers it had.
",armon,evanccnyc
1150,2015-08-11 17:47:36,"@evanccnyc Hmm, so this looks like about ~35 services queries, and sounds like a few hundred nodes were involved.

My guess is this is similar to the issue #1154 #1165 and the other is the repro case @darron provided us. We are tracking those separately, but this seems like a related issue. We are working to address some of the read pressure issues CT causes in Consul 0.6 to increase the stability of the cluster under that kind of load.

A big improvement to his is the approach of running CT on a single node (or a few under `consul lock`) and storing the result template in a KV entry. Then the 100+ nodes only need to watch a single key for updates instead of 35+ endpoints. This dramatically reduces the load on the servers and helps with overall performance and stability.
",armon,evanccnyc
1150,2015-08-11 18:10:01,"To build on what @armon said - we were never able to run Consul Template with service queries across our cluster reliably once we hit around 100 nodes. Leadership transitions over and over that were really unstoppable.

If you can build the template on one of the server nodes - running under `consul lock` - and put the result into the KV store - a [simple JSON watch](https://gist.github.com/darron/7dcacaedf0793f3dc38c) on each node can easily pull it out and reload haproxy.

A few things to watch out for:
1. Be careful you're not reloading a blank config file if something goes wrong with the CT build.
2. Make sure to add a ""wait"" to Consul Template so that it can't happen every second if something's flapping - that can be painful.
3. Build a ""stop"" mechanism so you can freeze the KV from being updated automatically - push out a known good one by manually updating the KV - and then fix the automatic process.
4. Add some external logging so that you can see when it's updating and the changes. We are throwing an event and a diff at Datadog so that we can see precisely what's changing and when.
5. We are also checksumming the version that is created and then syslogging the checksum that we write on each host - [it's pretty fast](https://gist.github.com/darron/885c5056d0e88e0a6dcb) and the addition of that data helps to make sure it's happening properly.
",darron,armon
1150,2015-09-03 15:49:59,"I am fairly certain that I just ran into this case with around 35-40 nodes, but also making attempts to use Consul Template pretty heavily. Normally the cluster has handled it well up until yesterday where the cluster of 3 was never able to be queried and all the log output made it appear that networking issues were the culprit. It has since sorted itself out with lower traffic, usage, and fewer nodes up.

@darron a few questions for you if you are able to answer:
1. What kind of templates are you building with Consul Template? Are you doing larger files with multiple queries, using ranges, or a lot of smaller template files with few key queries?
2. Are you building all templates for all nodes in your data centers on your consul server nodes? 
3. In [your example watch](https://gist.github.com/darron/7dcacaedf0793f3dc38c) what is the `consulkv get hostsfile/data` utility you are using to get the values?
4. Are you using any prefix queries? Does a watch on a prefix have any difference in performance over using Consul Template with a range query over a directory?
",mtchavez,darron
1147,2015-08-13 01:32:45,"@sfncook This should be done on a per-service registration basis, not globally. I think we want to support `enable_tag_drift` in the JSON files or the APIs that register services with the agent. Sorry for the review delay, things are very busy here.
",armon,sfncook
1145,2015-07-30 16:23:44,"@jrgarcia Can you trim the prefix itself so that it fixes both lock and semaphore?
",armon,jrgarcia
1145,2015-07-30 16:25:06,"@armon Sure thing
",jrgarcia,armon
1145,2015-07-30 16:43:03,"@jrgarcia Can you move it to line 103? The issue is that this is in `setupLock` which means the bug affects `setupSemaphore`. Moving it into `main` fixes it for both cases (e.g. -n > 1)
",armon,jrgarcia
1145,2015-07-30 16:45:31,"@armon Gotcha, I understand what you meant by that now. Thanks!
",jrgarcia,armon
1143,2015-07-29 21:31:53,"@ryanbreen Could you add a test to verify the behavior is as we expect?
",armon,ryanbreen
1138,2015-07-27 22:36:33,"Hey @saulshanabrook, are there multiple nodes in your cluster which provide the `birds` service? The catalog is a global view of the cluster and available services. If there are any nodes providing the `birds` service, then it will show up in catalog and health endpoint responses. If you deregister the service definitions from all of the agents, you should see the entry in the catalog go away.
",ryanuber,saulshanabrook
1138,2015-08-11 02:56:47,"@saulshanabrook I dont believe so with the catalog and agent api you must know which service a node/agent its registered on:
https://www.consul.io/docs/agent/http/agent.html
https://www.consul.io/docs/agent/http/catalog.html

what does `curl  -s -S 10.128.1.54:8500/v1/health/service/bird` look like?

Here is an example:
`curl -s -S http://10.60.1.76:8500/v1/health/service/account-service | jq .`



to deregister you could do something like either of these:
- `curl -XPUT http://10.60.1.76/v1/agent/service/deregister/51f8bdad52e5:account_service-1:3213`
- `curl -XPUT http://10.60.1.19:8500/v1/catalog/deregister -d '{ ""Datacenter"": ""dev"", ""Node"": ""ip-10-60-1-76.us-west-1.compute.internal"", ""ServiceID"": 51f8bdad52e5:account_service-1:3213""}'`
",majormoses,saulshanabrook
1138,2015-10-02 15:35:08,"@ryanuber thanks for clarifying here. So services cannot be deregistered from many nodes in a single call, is this the same for key/value pairs or no?
",bhurlow,ryanuber
1138,2015-10-02 17:07:04,"@bhurlow you can delete by prefix in the key/value store, so if your keys are nested under a common prefix that can be destroyed that would be the way to go.
",ryanuber,bhurlow
1136,2015-07-30 04:39:25,"@porterjamesj @armon This does give a proper error in master now. Feel free to reject this if the proper error is good enough (see b5f6451). I couldn't find a way to test this given the tests you have for the `lock` command, because they use `touch` and it will work properly with a leading slash. I'm open to suggestions of how to test given the testing facilities that are already in place.
",jrgarcia,armon
1136,2015-07-30 04:39:25,"@porterjamesj @armon This does give a proper error in master now. Feel free to reject this if the proper error is good enough (see b5f6451). I couldn't find a way to test this given the tests you have for the `lock` command, because they use `touch` and it will work properly with a leading slash. I'm open to suggestions of how to test given the testing facilities that are already in place.
",jrgarcia,porterjamesj
1133,2015-07-27 16:20:03,"@lindane The health checks are run by the agent, so if the agent is killed it will be unable to run the mysql health check. The health of a service is transitively defined by the health of the node it is running on. So this is expected, the last known state of the mysql service was ""passing"", however the SerfHealth (e.g. agent / machine health) is ""critical"". That instance of mysql is thus considered unhealthy because the machine it is running on is unhealthy.
",armon,lindane
1133,2015-09-23 12:49:09,"@armon We were debating with our colleagues what would be the correct way to mark a consul service check in case the node disappears, and it seems to us that the most appropriate thing to do is to mark the service check as unknown(similar to Nagios behaviour). It avoids any confusions for users and it is the actual state of that check.
",nustiueudinastea,armon
1133,2015-12-31 15:33:26,"Hello!

@armon ""The health of a service is transitively defined by the health of the node it is running on.""

If service's health is transitively defined by the health of its node, why the services related to a 'critical' node aren't marked 'critical' (or 'unknown', as suggested) too?

I can see the same behavior with the 0.6.0 compilation, and it took me hours to detect it running Ansible contrib/inventory/consul_io.py script, that depends on the health of a service to tell if it is up or down - but don't check the health of the node itself.

Can I consider a mistake of that script to not check the node's health? (I'll do it by now for my current needs.)

Thank you, and a Happy New Year!
",raitech,armon
1133,2015-12-31 19:12:27,"@raitech The APIs and UI will show the last known status of the service health checks, e.g. they are not updated when the node is detected as having failed. However, DNS requests will not route to a service if the host is critical, and if you use the APIs with filter parameters `?passing=1` on endpoints that support it, then the filtering logic applies the transitive checks. Hope that helps!
",armon,raitech
1132,2015-07-27 16:24:24,"@half-dead I recommend exporting the Consul telemetry (https://consul.io/docs/agent/telemetry.html) and using that to help monitor these various aspects of the system. Those will give pretty deep visibility into latency, flapping, network and resource utilization.

That said, doing 1K QPS of service registration is a rather strange use case for Consul, services typically don't flap that often. For the KV benchmarking take a look here: https://github.com/hashicorp/consul/tree/master/bench
",armon,half-dead
1132,2015-07-27 21:20:11,"@Kosta-Github The telemetry cannot be exposed that way currently. It is really meant as a stream based ""push"" since Consul does not retain it, merely streaming it out to an external system. We could do something with web sockets and pushing of metrics, but it would be overly complex and not really the best approach.
",armon,Kosta-Github
1132,2015-07-28 09:41:38,"@armon Some of the telemetry output I don't understand, do you have any documents? 
",half-dead,armon
1132,2015-07-28 16:03:46,"@half-dead the service registration from the agent HTTP endpoint will block until the registration has been committed in the Raft log. The response will always be 200 if the registration completes on the agent side, so the catalog sync is always best-effort and will be retried later on if needed.
",ryanuber,half-dead
1132,2015-07-30 17:38:37,"@ryanuber Are there any documents for the telemetry output? some of those I don't quite understand, like below:
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.udp.received': Count: 19 Min: 22.000 Mean: 26.684 Max: 33.000 Stddev: 5.121 Sum: 507.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.tcp.accept': Count: 2 Sum: 2.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.tcp.sent': Count: 2 Sum: 2058.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.msg.alive': Count: 2 Sum: 2.000
[2015-07-30 17:42:50 +0000 UTC][C] 'consul.memberlist.udp.sent': Count: 19 Min: 20.000 Mean: 27.263 Max: 33.000 Stddev: 6.252 Sum: 518.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.serf.queue.Event': Count: 10 Sum: 0.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.serf.queue.Query': Count: 10 Sum: 0.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.serf.queue.Intent': Count: 10 Sum: 0.000
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.memberlist.gossip': Count: 50 Min: 0.008 Mean: 0.021 Max: 0.076 Stddev: 0.012 Sum: 1.058
[2015-07-30 17:42:50 +0000 UTC][S] 'consul.memberlist.probeNode': Count: 10 Min: 1.042 Mean: 1.738 Max: 4.459 Stddev: 1.076 Sum: 17.380

And another question, how can I measure the max latency when a new service registerd on one client, I mean, how long does it take to sync this service to all server nodes.

Many thanks!
",half-dead,ryanuber
1131,2015-07-27 16:26:56,"@rprieto This is a duplicate of #697 in ways. With a V2 API we wan tot have a richer K/V tagging on services, and then you could simply have a 'version' metadata. We don't want to make this a first-class thing as everybody and every org has their own opinionated way of doing things.
",armon,rprieto
1130,2015-07-23 21:35:21,"I'm particularly not in love with the naming either.  @armon can I ask why a UDP health check doesn't make sense?  It does support UNIX sockets too BTW.
",pdf,armon
1130,2015-07-23 22:39:48,"Hey @pdf,

UDP checks wouldn't entirely make sense because of the connectionless nature of the protocol. You would need to send packets and wait to receive packets in order to determine a successful transmission, which would require specialized logic on the remote end.

We should still be able to check IP4/IP6. Looking at the [`net.Dial`](http://golang.org/pkg/net/#Dial) function, you can see how passing either format of address is accepted.
",ryanuber,pdf
1130,2015-07-24 17:50:00,"@pdf This is looking great. Would you mind updating the documentation as well? I think that is all that is missing.
",armon,pdf
1126,2015-07-22 20:01:18,"@fraenkel This should go away, it can happen sometimes when a new leader takes over. Does this message persist forever?
",armon,fraenkel
1126,2015-07-23 01:40:46,"@armon We have seen the Skipping message appear when the leadership changes.
The only time I have truly seen it go away was when we leave and join after rolling updates.
In theory, nothing should have changed.

Now that we have simplified our config and removed all the auto-join behavior, we haven't seen these messages for at least 1 day.
",fraenkel,armon
1125,2017-02-06 21:38:59,"@ryanuber @slackpad Any thoughts on this? We're now in need of a solution here as well.

Would it make sense to create a DNS A record in, say, the `.private.consul` domain to represent the service IP, then make the SRV answer point to that A record?",mfischer-zd,slackpad
1125,2017-02-06 21:38:59,"@ryanuber @slackpad Any thoughts on this? We're now in need of a solution here as well.

Would it make sense to create a DNS A record in, say, the `.private.consul` domain to represent the service IP, then make the SRV answer point to that A record?",mfischer-zd,ryanuber
1125,2017-02-06 22:05:44,"@mfischer-zd that went out in 0.7.1, but had an issue we just fixed in 0.7.4 that released today (https://github.com/hashicorp/consul/pull/2695).  I think you might be right that this is a dup of https://github.com/hashicorp/consul/issues/1228 (at least solution-wise).",slackpad,mfischer-zd
1125,2017-02-07 19:36:10,"I'm a coworker of @mfischer-zd. I downloaded Consul 0.7.4 and tried to reproduce the problem.  I registered a service like:



and then did a SRV lookup.  As desired, the SRV lookup returned a record that resolved to the service IP, rather than the Node IP.



So as far as I can tell, this issue is fixed in 0.7.4. ",jonmoter,mfischer-zd
1125,2017-02-07 20:01:16,@jonmoter thanks for the confirmation!,slackpad,jonmoter
1123,2015-07-22 20:22:44,"@gmr This should be happening already! At the bottom of the stack, it ends here: https://github.com/hashicorp/memberlist/blob/master/memberlist.go#L156
",armon,gmr
1123,2016-08-18 01:04:36,"@jason-riddle looks like it's only using A records right now - I think it would need a few tweaks to work with SRV records.
",slackpad,jason-riddle
1120,2015-07-22 20:15:13,"@highlyunavailable It's not documented or available through the HTTP API since its a bit of a highly nuanced dance to get it to work. There is a lot of API calls due to the streaming nature of responses that makes it hard to package as a single convenient API call. That said, it _is_ possible, we are just using the API under the hood, so take a look at the exec code. It's just not simple.
",armon,highlyunavailable
1120,2015-07-22 21:26:58,"@highlyunavailable As a heads up, we do want to improve the performance of the system by allowing output to stream directly to the client instead of via KV. This will probably shift some things, but the current stuff should continue to work for backwards compatibility.
",armon,highlyunavailable
1120,2015-07-22 22:07:28,"@armon I'm actually rebuilding the entire remote exec system in C# as part of my [Consul API](https://github.com/PlayFab/consuldotnet) so that I can do remote execution from an administration web site without the admin server having to set up direct connections (e.g. PowerShell remoting) to service instances, so any pointers on how you'd design it to be more performant without going through KV would be interesting.
",highlyunavailable,armon
1120,2015-07-22 22:09:18,"@highlyunavailable The idea is that the Consul agent would setup a temporary TCP listener and send that address as part of the exec payload. Then clients can connect and stream results back directly. Alternatively, a server based approach allows servers to act as brokers without going through K/V and using Raft.
",armon,highlyunavailable
1120,2015-07-22 22:12:10,"@armon Ah okay, so that would be part of the Consul agent and would be handled entirely through it rather than leveraging the event system + storage like the current method does. I assume there'd be some sort of endpoint on the agent that the `consul exec` command would connect to in order to stream down the output from the TCP connection as well, or would you be setting up the TCP listener in Go directly inside the `consul exec` command?
",highlyunavailable,armon
1120,2015-07-22 22:19:23,"@highlyunavailable Likely it would be through the agent as you are saying. The exec process would not do the listening.
",armon,highlyunavailable
1116,2015-08-31 13:32:40,"Hey @armon,

I got somehow a similar remark. I would like to make the deployment agnostic to the underlaying docker machines and therefore I thought having
- an inter-machine DC (dc1) for which all consul ports are pinned to the physical eth0 address
- an intra-machine DC (vmX) which is comprised of the  containers running on top of the physical machine. 

Registrator exposes all internal services to all the other nodes in the dc1-cluster. And the internal containers are able to access services exposed on different machines, by accessing the dc1 namespace.
So far, so good.

![screen shot 2015-08-31 at 15 31 30](https://cloud.githubusercontent.com/assets/1420201/9579791/6724b952-4ff5-11e5-9d1f-62299f0351d2.png)

But the consul servers (the green once), expecting to talk to the DC ontop of the other machines as well.
The log from consul ontop of VM2.



The internal consul server is hooking himself in - all good.
But...



... kibana4 was started on vm1, I would have expected that a consul server only listens to his own datacenter and the DC of his WAN server.

But maybe that's the problem, that the agent listens to **all** DCs of the WAN server?

Cheers
Christian

**UPDATE**:
Hmm.. looking at the memberships they present themself different:
- **VM1** seems only to care about itself (as I would expect).
  This bugger is bootstraped.


- **VM2** is also looking out for the first VM-DC.
  This one joins the first one.



Is there a way to prevent agents to look beyond there own and a common DC?
I also skipped the `registrator` w/o a change in behavior.  The second dc1-consul sees the local containers, the first one doesn't. :(
",ChristianKniep,armon
1116,2015-08-31 23:11:48,"Hi @ChristianKniep  - it's weird that kibana4.vm1 would bleed into the WAN pool, so I'm a little confused about your setup. I'd imagine that all the green Consul servers would be in one DC (as you've got), and that you'd see the red Consul servers in your -wan query (consulVM1.vm1, consulVM2.vm2, etc.). In your example is kibana4.vm1 also another Consul server, or just a registered service running on that machine?
",slackpad,ChristianKniep
1116,2016-04-13 07:40:58,"Hi @ChristianKniep the WAN address translation feature shipped in 0.6.4 should solve this - https://github.com/hashicorp/consul/pull/1698 by allowing you to have separate DCs with differing internal/external addresses. Some other discussions about asymmetric WAN connectivity are happening under #1871.

Closing this out in favor of those. Please re-open and/or let me know if you need anything else!
",slackpad,ChristianKniep
1113,2015-07-17 17:03:33,"Definitely agreed - we should hide token existence from prying eyes. Thanks @gmr!
",ryanuber,gmr
1110,2016-12-02 14:26:44,"@cruatta / @jness / @bof : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,jness
1110,2016-12-02 14:26:44,"@cruatta / @jness / @bof : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,bof
1110,2016-12-02 14:26:44,"@cruatta / @jness / @bof : Please give the latest code in `master` a twirl.  The syntax for supporting IP addresses or getting the first ""usable"" IP address on an interface is included below and can be passed to any address parameter within Consul (e.g. `-bind` or `bind_addr`, or any other `*_addr`-like parameter):



There is now a configurable template language for examples and docs) behind this that you can use to create a customizable heuristic that should allow you to get whatever it is that you need from your environment when using an immutable image (see [hashicorp/go-sockaddr/template](https://godoc.org/github.com/hashicorp/go-sockaddr/template) and [cmd/sockaddr](https://github.com/hashicorp/go-sockaddr/tree/master/cmd/sockaddr#sockaddr-eval).",sean-,cruatta
1107,2016-09-15 10:29:26,"@armon Is this still a target for 0.8 as you mentioned it might be above?
",jhickson,armon
1107,2016-10-18 14:34:32,"@hwatts That's an interesting approach. 
How would you compare storing those data as KV entries with parsing them on ""client"" side?
Do the templates still manageable?
",roman-gliffy,hwatts
1105,2015-07-13 18:39:58,"@aj-jester The `/v1/agent` endpoint prefix is generally used to instruct the local agent to do something, e.g., ""broadcast a leave message"", or ""enter maintenance mode"". I think we should probably keep the concerns separate, and maintain the scope of the `/v1/agent` endpoints to the local agent. Because of the way [Consul is architected](https://consul.io/docs/internals/architecture.html), we currently don't have a clean way to toggle maint mode on arbitrary agents, but it should be easy enough to dial the node you want to talk to using the DNS discovery interface (e.g., `PUT mynode.node.consul:8500/v1/agent/maintenance`).
",ryanuber,aj-jester
1105,2015-07-13 19:11:44,"@ryanuber Ah ok! that makes sense :+1:  so the `force-leave` is an outlier :stuck_out_tongue_closed_eyes:  

Is there any plan to incorporate something like ""control any node from every node"" from the API perspective?

Thanks.
",aj-jester,ryanuber
1105,2015-07-14 00:27:19,"@aj-jester yeah exactly, force-leave just directly submits a message into the gossip layer (serf). There is no plan as of now for forwarding non-server requests for things like maintenance mode, sorry!
",ryanuber,aj-jester
1104,2015-07-17 17:13:32,"@omribahumi I think there may be a misunderstanding here. The cap is the maximum amount you may _extend_ the life of a session at a time, and not the total time a session may be valid for. It is the responsibility of the client to ""renew"" the session before this time period expires using the [renew api](https://consul.io/docs/agent/http/session.html#session_renew). More info on session internals can be found [here](https://consul.io/docs/internals/sessions.html).

I _think_ the 1h cap is in place to prevent dead client sessions from lingering around as a security practice. It seems reasonable to require clients to renew their session liveness each hour at least, but I'll let @armon comment here in case there are other reasons we cap it there.
",ryanuber,omribahumi
1104,2015-07-17 17:50:01,"@ryanuber I understood that. The thing is, because Consul will be used for address allocations, this limits the time the software (that is in charge of renewing the sessions every <1h) maintenance windows to a maximum of 1h.
Also, a good practice in address allocations is not to immediately re-use a recently freed subnet. This also limits the grace period to 1h.

I think this shouldn't be limited to such a small value, unless there's a performance reason for this.
",omribahumi,ryanuber
1104,2015-08-02 12:39:03,"@armon any chance this could be in the next consul release?
",omribahumi,armon
1104,2015-08-04 00:17:05,"@omribahumi Yep! Easy enough!
",armon,omribahumi
1102,2015-07-13 19:40:18,"Interesting approach. @armon do you think this would basically just be a flag to disable tag sync during anti-entropy altogether? Sounds like the easiest way might be to just sync the tags if we are doing a registration, but not if we are ensuring later on.
",ryanuber,armon
1102,2015-07-14 01:25:12,"@ryanuber I think the flag would just nil-out the tags for the purpose of checking if the two service entries are the same. This way if the service registration is missing, then the client side tags are used. Otherwise, the service side tags are used.
",armon,ryanuber
1098,2015-07-10 00:24:10,"@gtmtech The clients are almost entirely stateless. Any query involving a "".consul"" TLD is ultimately transformed into an RPC call to the servers, where as all other queries are forwarded to a resolver if specified. 
",armon,gtmtech
1098,2015-07-13 19:44:32,"@gtmtech the docs do mention recursors, but this could probably use some clarification. If you have any cycles to submit a PR for the docs, that would be great to have! Otherwise, I'm tagging this as a docs enhancement, and will do a pass at some later point to add it. Thanks!
",ryanuber,gtmtech
1097,2015-07-09 14:49:13,"@omribahumi by design Consul uses sessions to apply TTL's to keys in the K/V store. By creating a session, you get back a session ID, which you can pass in as the `?acquire` value when setting a key. When creating the session, you can pass in the TTL and behavior for when the session expires (either release or delete). If you use `delete` as the behavior, then the key will be deleted when the session expires. Docs on the session create endpoint can be found [here](https://consul.io/docs/agent/http/session.html#session_create).

I realize its not as simple as ""create a key with this TTL"", but by tying key TTL's to sessions, we get some added benefits, like having multiple keys under the same session handle, and ephemeral keys.

Consul doesn't impose a cap on session lifetime. The 10-3600s is just the time range in which a session renewal must happen to keep the session alive. Basically a client must renew its session within the window if it wants to extend the session expiration. You can renew with the [session renew](https://consul.io/docs/agent/http/session.html#session_renew) endpoint.

Does that help?
",ryanuber,omribahumi
1097,2015-07-09 14:52:03,"@ryanuber There is actually a [check](https://github.com/hashicorp/consul/blob/master/consul/session_endpoint.go#L44-L54) to determine both min and max TTL.

There is no explicit cap on _session lifetime_, but there is a cap on _TTL length_.
",highlyunavailable,ryanuber
1097,2015-07-09 15:32:12,"@ryanuber I see. I missed the release/delete part.

What about having higher TTL values, for those cases you just want to ""create a key with a TTL"".
Also, would I be able to rewrite that key with a new session, without a prior release?
I'm thinking about that the app (flannel in this case) might be killed and lose its session. Will I have to wait for the TTL to expire prior to re-acquiring it?

Again, the use-case here is https://github.com/coreos/flannel/blob/master/subnet/registry.go#L95
",omribahumi,ryanuber
1097,2015-07-09 15:53:17,"@highlyunavailable thanks!

I think this should be pointed out in the documentation.

As for the options you suggested, 1 is problematic because, theoretically, the address pool might be re-assigned to another node during the time it's deleted.
About the session TTL, having it limited to 1h limits the maximum node downtime possible. The current etcd implementation uses 24h, which makes sense in this scenario.

Why was the 1h value chosen?
",omribahumi,highlyunavailable
1096,2015-07-09 10:36:06,"@tgwizard No it doesnt work
",avinashkolluru,tgwizard
1095,2015-07-17 17:20:32,"Hey @lra, This is an unfortunate panic. Consul internally checks for this potential deadlock scenario and bails in this way if a transaction can't be started. Usually this is because of a leaked transaction which will never close. The timeout is pretty conservative at 30 seconds, so you are definitely hitting this nasty little bug. I would expect that this could be worse on systems which perform poorly. Fortunately, we plan to mitigate this by moving the state store into a pure in-memory store for Consul 0.6, so this type of issue should be completely gone once that lands.

Thanks for the detailed report, and let me know if I missed anything.
",ryanuber,lra
1095,2015-08-21 23:34:47,"@lra yes, definitely soon, though there is not a firm date at this point. 0.6 aims to be a massive performance and stability improvement release. It is odd that you are hitting this deadlock so often, though, and we haven't heard many reports of it happening in the wild. Anything unusual about your setup(s)?
",ryanuber,lra
1092,2015-07-16 07:22:05,"@fraenkel Do you just mean when a client has sync'd all the services/checks or do you mean when a server has sync'd the Raft transactions? I don't think we expose the client sync state, but you could always query the agent info with `/v1/agent/services` and then cross-check with `/v1/catalog/node/` to ensure they match. For the Raft transactions, using `consul info` to check the `last_log_index` is the easiest way.
",armon,fraenkel
1092,2015-07-16 11:43:35,"@armon When we roll an upgrade, we are trying to determine when it's safe to move to the next server. We have noticed that if we roll too early, we either lose quorum (very bad), or we maintain quorum but lose data (bad).
Currently we are watching the consul service on a given node and when we see the Tags go from nil to [], we know the Synced service 'consul' message has appeared and it seems to be safe to move on.

If we can compare the last_log_index with the commit_index, then I would go with that. Just trying to find a safe and sane way to automate install and upgrades.
",fraenkel,armon
1092,2015-07-22 22:33:50,"@fraenkel Oh yeah, I would use the `last_log_index` and `commit_index` between the existing leader and the new nodes to check.
",armon,fraenkel
1089,2015-07-07 15:23:17,"@VaradDeolankar you cannot retrieve the tags using the DNS interface, but you can filter results by them. Take a look [here](https://consul.io/docs/agent/dns.html), specifically the ""standard lookup"" section. It might not be exactly what you were looking for. If you really need to retrieve the tags for a given service, you can use the HTTP API to do that.
",ryanuber,VaradDeolankar
1089,2015-07-08 05:43:43,"@VaradDeolankar the randomization in the DNS responses is in no way special. You can pick any random entry you receive from the API response if you query the /v1/health/service endpoint and use the `?passing` flag to filter the result down to only healthy nodes. If your requirement is to retrieve tag values, then currently the only way to do this is using the HTTP API, and as far as I know, we don't have any plans to support returning them from the DNS interface.
",ryanuber,VaradDeolankar
1089,2017-01-30 17:04:42,"@ryanuber 
I would also like to see the option to attach a custom TXT record and support RFC 2782 at the *domain* level, i.e. answer to look-ups of _<service>._<protocol>[.service][.datacenter]<.domain> for SRV and _<service>[.service][.datacenter]<.domain> for TXT.

The use case in mind is for a [kerberized cluster using only DNS](http://web.mit.edu/Kerberos/krb5-1.5/krb5-1.5.4/doc/krb5-install/Hostnames-for-the-Master-and-Slave-KDCs.html) for realm and service discovery.",sodre,ryanuber
1089,2017-01-30 18:58:28,"PR #2690 adds support for SRV queries at the datacenter level. @ryanuber, can you review is and see if it is okay?",sodre,ryanuber
1088,2015-07-22 22:36:12,"@eloycoto I think unfortunately to do this the right way, we need to support arbitrary K/V attributes on nodes and services. This lets us much more cleanly support something like ""dns_weight=2"" and then have that parsed and respected. Anything built on the existing API would be a huge hack like ""dns-weight-2"" tag, which I'd oppose.

So unfortunately, I think to do it right requires a lot more rethinking of things outside the scope of this one feature. We want to get there, but it will take a little more time for us to firm up the foundation.
",armon,eloycoto
1088,2015-07-23 06:08:30,"Hi @armon, 

Make sense, it's a big change. Ping me if you need help I can spend time on this + QA time. 

Regards
",eloycoto,armon
1088,2015-10-07 22:19:33,"@eloycoto Out of curiosity how did you do the `_sip._udp` part with Consul ? Did you call your service `_udp` and give it the tag `_sip` ?
",Esya,eloycoto
1088,2016-03-22 16:33:14,"@epcim about HA environments, nowadays I'm doing like this https://www.youtube.com/watch?v=t3O5b2sweYs

Regards
",eloycoto,epcim
1088,2016-04-13 05:12:07,"@gfrankliu weights are currently not supported. Right now Consul randomizes the results of DNS queries for load balancing, and removes nodes with failing health checks, but does not allow you to set the weights and priorities.
",slackpad,gfrankliu
1088,2016-04-14 22:38:11,"@slackpad that's too bad. It will make the DNS SRV less useful. Is the support on the road map? I guess the workaround is not to use DNS but use http, and create tags to store ""weight"", etc. information. 
",gfrankliu,slackpad
1088,2016-08-26 08:43:39,"+1
@epcim I built a solution that uses Consul as part of a solution for DB failover for Postgresql. Postgresql is managed by Repmgr which will failover if the master becomes unresponsive, elect an new master and cause any additional slaves to follow the new master. Once this process is complete it triggers a call to Consul which updates any apps. If the old master comes back it doesn't trigger a consul update so you can avoid split brain. The approach is valid for other replication managers such as MHA Manager for MariaDB or MySQL.
",paradoxbound,epcim
1088,2016-11-15 00:16:16,"@slackpad any update on this? I'm guessing there hasn't been any progress in this area.
",thehydroimpulse,slackpad
1085,2015-07-23 15:18:32,"@armon I understand the confusion that this solution may cause in particular, but we need to address this problem in some form. The idea of nodes being marked critical before running checks causes severe problems on startup if you have long check intervals, as per #954. Perhaps there could be a configuration option for which ""initial"" state nodes are put in. 

I'd be happy to open a new ticket with an outline of that suggestion, if you'd like. 
",siddharthist,armon
1085,2015-07-23 20:43:43,"@siddharthist Agreed, could you make a ticket for the initial state in that case?
",armon,siddharthist
1085,2015-07-23 20:56:36,"#859 actually should solve this case by allowing the ability to provide the check status when registering the check. The confusion is probably that we forgot to document it on the web docs, so we can probably just create a ticket for that instead. @siddharthist does that satisfy your use case?
",ryanuber,siddharthist
1085,2015-07-23 21:38:35,"@ryanuber It does, thank you for pointing that out! I'll comment with the same pointer on issue #954 for reference, and then both this and that are probably ready to close. 
",siddharthist,ryanuber
1084,2015-07-06 16:01:37,"Thanks for your response @ryanuber. I share your concern regarding the individual environment variables. Maybe I go with the wrapper script approach. I didn't consider that before. 

`service.port` was a mistake on my side. I mean the ports for the service registration. That could be as well handled in a wrapper script.
",i0rek,ryanuber
1083,2015-07-06 16:01:34,"@juaby If the services were registered from configuration files, then simply removing the services from the configuration and sending the agent a HUP would do exactly as you mentioned. However, if they were registered from the API endpoints, then they would need to be deregistered one at a time.
",ryanuber,juaby
1083,2015-07-07 02:43:17,"@ryanuber thank you. I get it.
",juaby,ryanuber
1082,2015-07-06 16:48:04,"@juaby See the ""consistency mode"" section here (https://consul.io/docs/agent/http.html). You just need to provide the `?stale` or `?consistent` query parameters in the request.
",armon,juaby
1082,2015-07-07 02:42:41,"@armon thank you very much. next time I'll read doc more carefully
",juaby,armon
1081,2015-07-13 16:37:29,"@bung87 thanks for the PR. Some before / after screenshots might be helpful to see the difference here. 

/cc @pearkes
",ryanuber,bung87
1081,2015-07-13 17:52:15,"@ryanuber hmm...,I did it with chrome inspector,then modified the scss files,thought It would be easy for you compiling and run,well ,It would be good to have screenshots,I just didnot noticed at that time.next time maby....
",bung87,ryanuber
1080,2015-07-22 22:27:48,"@babbottscott Does this change the behavior? It seems like the same behavior as before
",armon,babbottscott
1079,2015-08-14 23:49:13,"@bhourigan do you mean it was advertising 127.0.0.1, or that it was actually _just_ binding to 127.0.0.1 when you specified 0.0.0.0?
",aidanhs,bhourigan
1079,2015-08-15 14:46:40,"@aidanhs It was binding to 127.0.0.1. I didn't get to see what address it wanted to advertise.
",bhourigan,aidanhs
1078,2015-07-13 16:14:38,"@mfischer-zd thanks for opening this, makes sense to me. We use environment variables for a few other things, including the HTTP address and RPC address. I'm thinking we should do the same for the token with a `CONSUL_TOKEN` environment variable.
",ryanuber,mfischer-zd
1076,2015-07-13 16:05:58,"@ashish235 what @highlyunavailable described is accurate. It's reasonable to add an authentication proxy layer like Apache or Nginx in front of Consul. It sounds like your needs are very basic, so keep in mind that there are also HTTP basic auth modules that work in the same way that the oauth modules do.

Hope that helps!
",ryanuber,ashish235
1076,2015-07-13 16:05:58,"@ashish235 what @highlyunavailable described is accurate. It's reasonable to add an authentication proxy layer like Apache or Nginx in front of Consul. It sounds like your needs are very basic, so keep in mind that there are also HTTP basic auth modules that work in the same way that the oauth modules do.

Hope that helps!
",ryanuber,highlyunavailable
1076,2015-07-15 05:24:31,"Thanks @highlyunavailable  and @ryanuber. Cheers!
",ashish235,ryanuber
1076,2015-07-15 05:24:31,"Thanks @highlyunavailable  and @ryanuber. Cheers!
",ashish235,highlyunavailable
1075,2015-07-02 05:29:15,"@highlyunavailable Sweet that worked great! thanks. Also While I got you here may I ask for a feature request? Can we have a flag on put to write the data to consul regardless if there's a change? (right now it will only update if the value is different.)
",ThomasAlxDmy,highlyunavailable
1075,2015-07-13 16:09:02,"Thanks for fielding this one @highlyunavailable!
",ryanuber,highlyunavailable
1073,2015-07-01 19:06:18,"Hi @VaradDeolankar are you sure you need to modify Consul itself? Could you build a service that wraps calls to Consul's existing APIs or possibly use additional information in Consul's KV store for your application?
",slackpad,VaradDeolankar
1073,2015-07-02 07:24:13,"Hi @slackpad ,

To add to what @VaradDeolankar mentioned, 

We are planning to use Consul as an distributed service discovery mechanism within our infrastructure.
To make this happen, we want to modify the way consul responses to service requests. We can write our API/Code that overrides the way consul responds to service discovery requests.

Does consul provide any interface that we can implement to override default behavior?

We simply want to know the place in consul code which we need to modify or where we need to plugin our APIs.

Thanks
Pratik
",pratikbatua,slackpad
1073,2015-07-02 07:24:13,"Hi @slackpad ,

To add to what @VaradDeolankar mentioned, 

We are planning to use Consul as an distributed service discovery mechanism within our infrastructure.
To make this happen, we want to modify the way consul responses to service requests. We can write our API/Code that overrides the way consul responds to service discovery requests.

Does consul provide any interface that we can implement to override default behavior?

We simply want to know the place in consul code which we need to modify or where we need to plugin our APIs.

Thanks
Pratik
",pratikbatua,VaradDeolankar
1073,2015-07-02 12:09:45,"You could still achieve that by wrapping the responses from Consul in another service, as @slackpad says.  There's no need to modify Consul itself to achieve that, and you're signing up for more of a development burden if you try to accomplish this by rolling a custom version of Consul.
",ryanbreen,slackpad
1073,2015-07-03 16:25:02,"Correct me if I'm wrong @pratikbatua, but you say:

> User will register for the service, service name : MYService and then different instance ,1 and 2.
> 
> When any other client sends a request for MyService We want to return, MyService:1 or MyService:2 in round robin.

Isn't this the same as just registering multiple instances of the same service on different machines? If so, why can't you use the existing mechanism of DNS returning a random instance of a service every time you query for that service name? E.g. if you have MyService on S1 and MyService on S2, Consul will pick the IP for S1 or S2 randomly every time you make a DNS request. That's the idea of picking a _random_ server rather than using round robin - over a large number of requests, random would average out to the same amount of traffic to each server.

Also, I'm not sure why there is specifically HTTP is mentioned so much here - DNS seems like a much more simple interface to look up a service by, unless you absolutely need the full list of service instances to pick from. Take a look a the [DNS interface documentation](https://www.consul.io/docs/agent/dns.html) - it might be exactly what you need.
",highlyunavailable,pratikbatua
1073,2015-07-04 08:52:42,"thanks for your response @highlyunavailable .

Yes you are right. We have considered the DNS approach as it best fits our requirement.
Only concern I have is about support and ease available around https vs dns.

We have clients across multiple languages - java/c#/c++/kdb etc.. and may have more clients on other technologies as well.

As http end point is easy to implement and support is available across each language/technology in the market hence we preferred http over dns.

Thanks
",pratikbatua,highlyunavailable
1073,2015-07-13 16:32:01,"@pratikbatua the languages you mention should have solid support for DNS client functionality, so if possible I would probably take that route. It will end up being much easier to report any issues you bump into if you stick with running the supported code base as well, especially at the scale you are talking about.

That said, there is no single class or interface, or place you can simply drop code in to modify the service discovery globally in Consul. The DNS and HTTP interfaces are a part of the Consul Agent, which is all located in the `command/agent` directory. You will need to dig through that code if you insist on making changes to Consul itself.

I'm going to close this one, but let us know if you need any other help. Thanks!
",ryanuber,pratikbatua
1072,2015-07-01 19:22:32,"Hi @ketzacoatl - you are right, we should beef up the documentation to make this more clear. I found this thread which gives some info about the format of the token from @armon:

https://groups.google.com/forum/#!topic/consul-tool/lN3jZRbS2-g

> If the `acl_master_token` is not supplied, then the servers do not create a master token. If they did,
> there would be no way to programmatically provide it safely. When you provide a value, it can be
> any string value. Using a UUID would ensure that it looks the same as the other tokens, but isnâ€™t
> strictly necessary.
",slackpad,ketzacoatl
1072,2015-07-01 19:49:06,"Thanks for the assistance @slackpad!
",ketzacoatl,slackpad
1071,2015-07-09 23:36:12,"@darron hmm, this is interesting, the service discovery ACL's shouldn't affect this, and I couldn't reproduce this locally. Did you ever figure out what was going on? If you have a config I can reproduce with, then I'll definitely get this fixed before a new release.
",ryanuber,darron
1071,2015-07-09 23:49:10,"I think I've actually seen this before now that I look at it closer. If you aren't using a token while browsing around the UI, the javascript code still tries to send the `?token` parameter, and javascript's `undefined` value gets passed. Thus, when trying to look up the `undefined` token, Consul responds with an error that it can't find the token. Not sure if what you were seeing is the same thing.

@darron can you share any of the other ACL issues? Consul 0.6 is going to have a number of ACL enhancements, so if we can catch any bugs early on that would be great!
",ryanuber,darron
1071,2015-12-16 21:37:36,"@oswell thanks for finding that - I merged it and I think you got them all (the service discovery ACL was added to that internal endpoint in 0.6). 
",slackpad,oswell
1071,2015-12-16 21:54:10,"@oswell @darron @slackpad I can confirm that this worked for me.  I updated my application.min.js locally on a single node (both under /var/lib/consul/ui/application.min.js and /var/lib/consul/ui/static/application.min.js), restarted consul on that node, and able to see the UI as expected.  Updating my token key in my local session data from empty, to an invalid token properly gives me a 403, and setting a correct token under this key provides me with the access I expect from my acl.
",pauzed,slackpad
1071,2015-12-16 21:54:10,"@oswell @darron @slackpad I can confirm that this worked for me.  I updated my application.min.js locally on a single node (both under /var/lib/consul/ui/application.min.js and /var/lib/consul/ui/static/application.min.js), restarted consul on that node, and able to see the UI as expected.  Updating my token key in my local session data from empty, to an invalid token properly gives me a 403, and setting a correct token under this key provides me with the access I expect from my acl.
",pauzed,darron
1071,2015-12-16 21:54:10,"@oswell @darron @slackpad I can confirm that this worked for me.  I updated my application.min.js locally on a single node (both under /var/lib/consul/ui/application.min.js and /var/lib/consul/ui/static/application.min.js), restarted consul on that node, and able to see the UI as expected.  Updating my token key in my local session data from empty, to an invalid token properly gives me a 403, and setting a correct token under this key provides me with the access I expect from my acl.
",pauzed,oswell
1071,2015-12-16 22:42:14,"Thanks @pauzed!
",slackpad,pauzed
1067,2015-06-29 18:12:04,"@rmt Agreed, I think we need a suffix or something to indicate a non-greedy match. Marking as enhancement.
",armon,rmt
1063,2015-06-30 23:33:47,"Hi @isamuelson - can you provide more details about your setup and what you are seeing in the logs?
",slackpad,isamuelson
1062,2015-08-14 15:12:20,"I was thinking similar @pchojnacki where he noticed that all the the messageJoin logs were from the other cluster - was curious if you saw only nodes with the older version of Consul.
",slackpad,pchojnacki
1062,2015-08-25 08:38:27,"Hi, sorry for such late update. But since creating this ticket I was able to clear this issue that affected our setup. 
So after digging into consul source code I decided that the easiest approach would be to momentarily stop some of the affected nodes wait for the issue to clear up and then restart them.

tl; dr I'm pretty sure the issue is too small `recentIntent` buffer size that is checked in this [method in Serf](https://github.com/hashicorp/serf/blob/master/serf/serf.go#L1481) 

IIRC there were around 220 distinct messageJoinType messages passed around in the cluster and the default length of recentIntent buffer is 128 so given enough hosts communicating with each other it seems possible that it would cause for such messages to be rebroadcasted indefinitely. 

I thought about increasing the recentIntent buffer length and deploying modified consul to affected hosts but since it was a dev cluster so I could just stop them for the required time.

PS
@slackpad all nodes were running consul 0.5.2 at that time
",pchojnacki,slackpad
1062,2015-08-25 18:12:56,"@pchojnacki This theory makes a lot of sense. We should probably do a combination of increasing the queue size, but also gating just dropping intents if they are ""too old"" to avoid the infinite broadcasts.
",armon,pchojnacki
1062,2015-08-31 21:43:37,"@jaredcurtis Probably the best short term fix is a custom build that sets the intent buffer to a much larger size. That is a bit of a hack, and we need to think through a longer term solution, but there isn't an obvious answer.
",armon,jaredcurtis
1062,2015-12-14 23:32:31,"Notes on a possible solution from @armon: move the intent data to be stored with the node records instead of a shared pool. Need to use care with join intents and uncertainty in node joining and message timing (might need a shadow node or something).
",slackpad,armon
1061,2015-06-26 09:39:22,"@Kosta-Github This appears to be an issue for Docker issue, as it's not Consul related.
",armon,Kosta-Github
1059,2015-06-26 16:01:24,"@Kosta-Github Very nice! But since the consul server already needs to react to the changes, it could easily send the stats, that's what I'm requesting.
",nicholascapo,Kosta-Github
1058,2015-06-25 16:11:24,"Hi @siddharthist,

Characters allowed in services as well as tag names can include any alpha-numeric characters as well as dashes. You can use other characters to do registrations, but they won't work with the DNS interface. I've added a small documentation section on the service definitions page to make this more clear in 6290cb9. The Consul agent should also throw a warning in the logs if a non-compliant name is registered.

Let me know if I missed anything!
",ryanuber,siddharthist
1058,2015-06-25 17:13:43,"@ryanuber That looks awesome. Thank you!
",siddharthist,ryanuber
1057,2015-10-02 00:46:04,"hi @achille-roussel I've not got time to dig into this issue and it seems like neither the Consul team ... I am looking forward to the 0.5.3 release (current master) since it fixes the UDP loss issue by using TCP heartbeat as a fallback.It is a great help in multiple IDCs with unstable links. In 0.5.3 they used a new protocol among agents for communication and maybe consensus, just to be sure that your work shall base on the new protocol.

Good luck
",imcom,achille-roussel
1057,2016-02-17 04:09:18,"@kisscool that's probably not a good fix because it will always sync the output so there will be a lot of churn in the cluster state to repeatedly sync the same output. I think we will either rate limit these so they eventually get synced, or we can do a check when we perform anti-entropy sync with the servers like we do for other values. We will get a fix in for the next Consul release.
",slackpad,kisscool
1057,2016-03-22 14:56:21,"Hi @Blatwurst a fix for this did not make it in time for the 0.6.4 release - sorry about that. We will update this once we've got it fixed. Sorry about the delay as well, there's another issue #1069 in this area and we want to make sure we don't make that worse as part of this fix.
",slackpad,Blatwurst
1056,2015-06-26 14:58:14,"Agreed with @highlyunavailable.  I'm going to close this because I don't see a need to burden Consul with this, but I'm happy to be overridden if others disagree.
",ryanbreen,highlyunavailable
1054,2015-06-23 04:39:55,"Hi @VaradDeolankar - Consul does a randomized load balance for DNS if there are multiple healthy nodes with a given service:

> The DNS query system makes use of health check information to prevent routing to unhealthy nodes. When a service query is made, any services failing their health check or failing a node system check will be omitted from the results. To allow for simple load balancing, the set of nodes returned is also randomized each time. These mechanisms make it easy to use DNS along with application-level retries as the foundation for an auto-healing service oriented architecture.

See [DNS Interface](https://www.consul.io/docs/agent/dns.html) for more details.
",slackpad,VaradDeolankar
1052,2015-06-22 17:24:17,"Hey @denislins, the endpoints used are `/v1/agent/check/pass/<id>` and `/v1/agent/check/fail/<id>`. They are documented in the HTTP API docs [here](https://consul.io/docs/agent/http/agent.html#agent_check_pass). I also updated the documentation to include these links on the checks page in c8b3e48. Thanks for the suggestion!
",ryanuber,denislins
1051,2015-06-25 16:18:13,"@highlyunavailable I'm confused on how I can use it that way. Isn't <-leaderCh going to block until the locks returns? What I really need to do is execute some operation while I'm holding the lock and then releasing it when I'm done. 
",ThomasAlxDmy,highlyunavailable
1048,2015-06-22 19:20:54,"@fidian with respect to your statement: ""On boot they will query for mongodb.service.consul and join the cluster.""

Can you describe this a bit more, since I want to setup something similar for a redis cluster. Do you use some handcrafted script (e.g., via consul-tenplate or the REST API) for querying for mongodb.service.consul to get all registered nodes for that service or are you relying on the DNS mechanism for that? At least one problem with solely relying on the DNS mechanism is, that if the node registeres itself (e.g., with registrator) within the consul cluster before it does the DNS lookup for mongodb.service.consul it might get back its own IP address, which would not be helpful to join the cluster... :-)
",Kosta-Github,fidian
1048,2015-06-23 15:05:21,"@Kosta-Github asked how I manage to auto cluster my mongo instances.
1.  Consul is hooked up through dnsmasq.
2.  Consul is started before mongo.
3.  The health check fails unless mongo reports success and mongo is part of a cluster.  This second part is vital - the health check fails until mongo is in a cluster.
4.  The init script for mongo queries DNS for other members in the cluster.  This will only report mongo instances that are already in a replica set.
   - If IPs are found, become a slave and connect to the IP that we found.
   - With no IPs, configure as a master and enable the replica set, which then makes the health check pass.

The only snag is that I must start one instance of mongo initially so it will bootstrap the replica set.  Once it is running I am able to add and remove instances to my replica set.
",fidian,Kosta-Github
1048,2015-06-23 16:19:04,"@fidian thanks for the explanation; just one more question: how does your `dnsmasq` config look like? :-)
",Kosta-Github,fidian
1048,2015-06-23 16:30:41,"@Kosta-Github it looks like the following.  I'd also answer questions off this issue.  Feel free to email me directly at fidian@rumkin.com so we don't continue to pollute this thread.


",fidian,Kosta-Github
1047,2015-06-19 16:31:30,"What @highlyunavailable suggests should work nicely, good idea!
",ryanuber,highlyunavailable
1046,2015-06-30 00:57:37,"@ryanuber Left some comments, but LGTM!
",armon,ryanuber
1045,2015-09-23 18:36:05,"@hatmatter - do you know how long it has been in this state? It looks like it should eventually reap the dead peer, but there could be a bug in that path. We saw a similar report from another Consul user today.
",slackpad,hatmatter
1045,2015-09-28 11:20:25,"I'm also seeing similar behaviour on our Kubernetes infrastructure.

@slackpad: you say `force-leave` would work, but in our scenario:
- we have five consul servers running
- I kill one server on purpose
- kubernetes brings a new one online, using the same name as the killed one
- the new server joins the cluster, and works as expected
- other servers correctly see the new server, using the old name but a new IP address
- however, they also start to log every ~20s:
  
  
- at this point in time, there doesn't seem to be a way to let them forget about this node, because `force-leave` requires a node name, but that name is already working again, it's just the old IP in `peers.json` that should be forgotten.
",JeanMertz,slackpad
1041,2015-09-11 18:39:34,"@rboyer Sorry about the delay. Could you please add a test case?
",armon,rboyer
1036,2015-06-16 02:36:42,"I think the answer @ryanbreen gave probably _is_ the universal answer, at least currently. Consul uses a simple fork/exec mechanism to run script-based health checks, so the child process is spawned as the same user who started Consul. We could add something to this effect in the health checks documentation.
",ryanuber,ryanbreen
1036,2015-06-16 02:37:17,"@siddharthist yeah, please do!
",ryanuber,siddharthist
1035,2015-06-15 15:48:41,"Hi @mechanicalduck - I am able to use this link with command line tools. What kind of error are you seeing?
",slackpad,mechanicalduck
1034,2015-06-15 18:39:29,"Hi @jacobat, Was this working previously? I don't think we have supported the `?token` query parameter on the catalog register/deregister endpoints. Internally we embed the token into the JSON payload when registering/deregistering from the catalog. Since the catalog is mostly used as an internal endpoint by the agent, we never parse the `?token` field out of the request. You should be able to pass in the token field for catalog register/deregister like this:



I can see how the inconsistency with the other methods is a bit confusing. We could maybe support the `?token` flag as an ""override""-type mechanism.
",ryanuber,jacobat
1034,2016-12-30 10:47:34,"Ok, I'm really confused - apparently ...?token=mytoken *does* work in 0.7.0 and as @kamaradclimber points out, WriteRequest no longer does...",AntonOfTheWoods,kamaradclimber
1033,2015-06-15 18:51:30,"Hi @jiangshengwu, this is normally a sign of UDP routing issues. Docker has a well-known ARP cache issue that is discussed at length in #352.

You might try some of the solutions suggested there to see if it helps.
",ryanuber,jiangshengwu
1033,2015-06-16 06:03:50,"@ryanuber Thanks for your reply. I've read the issue you referred to. It helps a lot.

So I'll just close this one.
",jiangshengwu,ryanuber
1030,2015-06-14 06:10:54,"Oh good - we definitely want to run these for each test run. Thanks @gogolok!
",ryanuber,gogolok
1023,2015-06-11 23:30:23,"Hey @divideandconquer,

Could you tell use what version of Consul you are running or if there have been any modifications? I noticed that it looks like a custom build and it seems like an odd spot to cause a nil pointer dereference, which is why I ask. Can you try the current stable build from the downloads page on http://consul.io and see if you get the same result?
",ryanuber,divideandconquer
1019,2015-06-10 16:36:36,"Hi @feiyang21687, Consul uses health checking information to enhance the DNS interface. Basically what this means is that if a node is unhealthy (in your case you shut the node down, so the basic internal ping tests are failing), it will not be returned in DNS responses. Since you have no other nodes which can provide the ""master.redis.service.consul"" service, the DNS response comes back empty. If you have two or more instances of the service, then the DNS interface provides an easy way of always returning a healthy, working node to connect to. You can read more about the DNS interface [here](https://consul.io/docs/agent/dns.html).

Hope that helps!
",ryanuber,feiyang21687
1019,2015-06-11 02:54:17,"Hi @ryanuber , thank you for your reply.

But I mean how could I create a `HA` consul cluster. The `HA` means services dns lookup will not be affected by whichever consul agent down.

For example:

I registry a service through any one of the consul agent, like below:

`curl -X POST -d service.json 10.0.0.4/v1/agent/service/register`

Expect:

I could nslookup through other consul agent when `10.0.0.4` is down.

Actual:

I couldn't nslookup through any of other consul agent.

BTW, I checked the API doc, and I found `/v1/catalog/register` could work like what we expect. But in the doc, it recommends to use `/v1/agent/service/register`. But `/v1/agent/service/register` says Registers a new **local** service. local??? I'm confused, why it is local? How to register a distributed service?

> Note: it is usually preferrable instead to use the agent endpoints for registration as they are simpler and perform anti-entropy.

The service configuration which register by `/v1/agent/service/register` is sync by serf protocol. So why not other node handle over the services dns when the agent which handle `/v1/agent/service/register` is down?
",feiyang21687,ryanuber
1019,2015-06-11 06:43:26,"@feiyang21687 sorry, let me explain a bit more.

High availability in Consul refers to our ability to service a request, not only resolving DNS names. The health checking system is integrated with the service discovery mechanisms, and DNS service discovery will only return nodes with no failing health checks. This is by design, and allows clients to easily tolerate partial service interruptions without tight coupling by simply routing requests using Consul's DNS server.

WRT ""local"" services, consul has two different types of registrations:
- The ""local"" registration, which means a service on node A is registered to the consul agent running on the same node.
- The global service catalog, which is maintained by the server nodes using the replicated log, and accessible via the `/v1/catalog` and `/v1/health` endpoints. The local registrations from each agent sync in to the catalog periodically. The catalog then provides a consistent view of the available services and their health status on all nodes to the rest of the cluster.

It is possible to register a service directly into the global service catalog using the `/v1/catalog/register` API's, however that class of registration is limited in that they are not updated by an agent's health status updates.

Hope this helps!
",ryanuber,feiyang21687
1019,2015-06-11 08:16:25,"@ryanuber Thank you very much.

So what's the best practice to deploy that consul cluster? Run client agent on every **service** machine, is that right?

But I have some worries:

A: DNS lookup performance. I check the code, dns lookup request will be hand over to the client which hold the service. If there are many client agent, like thousands, will dns lookup performance be affected?

B: Server agent workload. If there are many client agent, will server agent sync heavily?
",feiyang21687,ryanuber
1019,2015-06-11 22:24:09,"@feiyang21687 the most typical deployment case has an agent installed on each node, that is correct. Most of these agents can be run in client mode, which has a very light workload compared to the server nodes.

When you make a DNS query for a service in Consul, internally the query is forwarded to a server node to handle the request. The servers maintain the global catalog, so it would not be necessary to reach out to each client to get the result. DNS performance should not be affected by the number of connected clients.

As more clients are added, the workload on the servers does increase, yes. However, to mitigate this, each client uses a random stagger interval to avoid a thundering herd of updates. Also, once your cluster size grows beyond certain bounds, the anti-entropy sync delay is increased so that the server nodes do not become overwhelmed. You can see the sync interval and how it is affected by cluster size on the [anti-entropy documentation](https://consul.io/docs/internals/anti-entropy.html) page, specifically the ""Periodic Synchronization"" paragraph.
",ryanuber,feiyang21687
1017,2015-06-10 15:57:03,"@discordianfish We already to this internally! The protocol negotiations allow a Consul 0.1.0dev instance in our fleet (so we won't judge) to still talk with the 0.5.2 masters.
",armon,discordianfish
1017,2015-06-10 16:10:24,"@armon So there is a internal consul version doing that, just not the public / open source one? Or did I miss something?
",discordianfish,armon
1017,2015-06-10 16:26:10,"@discordianfish I mean the public version should be doing this already. There should be no interoperability issues. Are you running into a problem with something currently?
",armon,discordianfish
1017,2015-06-10 17:57:39,"@armon I did, I tried to upgrade the cluster to #971 and ran into this issue (other nodes were running 0.5.0). Unfortunately I ended up destroyed the cluster and can't verify. Are there integration tests to test this compatibility?
Beside that, should this also work for downgrades / rollbacks?
",discordianfish,armon
1017,2015-06-10 18:31:04,"@discordianfish it sounds like you built from master and picked up the pending protocol bump to v3 in the process. There's a change in there that adds a new TCP ping mechanism that required a change to the protocol.

This sounds like a regression because v3 only extends v2, so it should allow a v2 node to join a v3 server, but it currently does not:



I'll take a look.
",slackpad,discordianfish
1015,2015-07-15 02:43:56,"@ckim0419 Looks like this was fixed in 0.5.1 https://github.com/hashicorp/consul/issues/611
",robinpercy,ckim0419
1012,2015-07-31 19:38:53,"@highlyunavailable this is very clever. A couple of questions.
1. How do you determine the endpoint names like `/recomendation/`? Are those the consul service names?
2. What if some services are private? Do you tag the specific ones you want to expose as ""public"" in the consul service registration?
",ray-,highlyunavailable
1012,2015-07-31 20:54:20,"@ray- The endpoint names are mapped to whatever you want in the nginx config file. You could make a mapping like:



or whatever. It's totally up to you what you map them to.

For private services you would need to bind them to a different listener or add authentication.

Re: Kong: what you'd be building is basically portions of that thing.
",highlyunavailable,ray-
1011,2015-06-07 05:02:18,"Hey @sirvon Glad to hear you are enjoying the tooling!

It looks like the Terraform module in this repository currently just installs some files using the `file` provisioner. The upstart script and consul config are both uploaded to the instances using this method. What you could do is add an extra `file` provisioner to push a configuration file into `/etc/consul.d/atlas.json`, with contents like this:



With that configuration in place, your cluster should be able to successfully register in Atlas!
",ryanuber,sirvon
1011,2015-06-08 14:32:19,"This project is sooo sweet.
thanks.
 On Jun 6, 2015 10:02 PM, ""Ryan Uber"" notifications@github.com wrote:

> Hey @sirvon https://github.com/sirvon Glad to hear you are enjoying the
> tooling!
> 
> It looks like the Terraform module in this repository currently just
> installs some files using the file provisioner. The upstart script and
> consul config are both uploaded to the instances using this method. What
> you could do is add an extra file provisioner to push a configuration
> file into /etc/consul.d/atlas.json, with contents like this:
> 
> {
>   ""atlas_infrastructure"": ""myorg/myproject"",
>   ""atlas_token"": ""xxxxxxxxxxxx"",
>   ""atlas_join"": true
> }
> 
> With that configuration in place, your cluster should be able to
> successfully register in Atlas!
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/1011#issuecomment-109694155.
",sirvon,sirvon
1010,2015-06-06 23:53:55,"@stevendborrelli it would be nice to not allow it. Consul will actually log a warning message if a service is registered with a `.` in the name, since it makes other parts of Consul non-functional (like querying DNS for the service due to the convention we use for tags). Unfortunately though, there are quite a few users who rely on dots being allowed in service names, so for now we can't expressly disallow that for now.
",ryanuber,stevendborrelli
1008,2015-06-09 11:59:27,"@highlyunavailable Ahh got it! That is subtle indeed, but it does the trick! Thanks!
",armon,highlyunavailable
1007,2015-06-05 17:54:05,"Hey @polds, We have seen this issue crop up on occasion in various networks. Many times there is simply an intermittent connectivity problem when talking UDP between nodes. Other times, some people have success after stopping/flushing iptables and conntrack.

Just recently the constant failed/joined cycle was addressed in the underlying gossip layer by adding code to fall back to a TCP probe if both direct and indirect UDP pings fail. This should stabilize environments which suffer from this kind of issue so that the nodes do not enter a hard failed state. We hope to have a new Consul release soon which would include this feature, but you could try building the master branch of Consul (make sure all deps are up-to-date) to see if this improves.
",ryanuber,polds
1007,2016-02-02 02:40:13,"Hi @kopax have you tried Consul 0.6.x? This included the new TCP pings.
",slackpad,kopax
1007,2016-02-03 17:47:40,"@slackpad I have Consul 0.6.3, I have created a post on this issue [here](https://github.com/eBayClassifiedsGroup/PanteraS/issues/182)
",kopax,slackpad
1007,2016-02-13 02:01:07,"@mrwilby you'll see a message like this in the consol when the TCP pings were the only way the node could be contacted:



Both nodes (ping-er and ping-ee) need to be running Consul 0.6.0 or higher and this feature will enable itself.
",slackpad,mrwilby
1007,2016-03-10 16:28:35,"@adamlc could you check your consul protocol version with 
`consul version`
command?
",123BLiN,adamlc
1007,2016-03-10 17:26:58,"@adamlc @123BLiN that's normal for the protocol version (sorry if it's a little confusing). Consul 0.6.x speaks version 2 but understands version 3, so the ""speaking"" version what's being reflected in the `consul members` output, and `consul version` shows what version it understands.
",slackpad,adamlc
1006,2015-06-09 02:19:29,"So @highlyunavailable hit this exactly dead on. The semaphore implementation does not have the lock-delay while the lock does (by design). The simplest approach was to just wait 5 seconds but I agree this is a bit heavy handed.
",armon,highlyunavailable
1004,2015-06-05 17:35:01,"Hey @i0rek, I took a quick look through what you have so far and I think you're on the right track. We are missing a few things. See my comment above. We will also need to add the new config fields to the `Merge` method in a *Config, so that the new config options may be specified in any configuration file and not just the first one on the list.
",ryanuber,i0rek
1004,2015-06-06 05:27:36,"Thank you very much for the suggestions @ryanuber! I will take care of them beginning next week.
",i0rek,ryanuber
1004,2015-06-08 16:00:46,"@ryanuber I think I added everything you suggested. Still have to test it though.
",i0rek,ryanuber
1004,2015-06-08 20:29:38,"@i0rek this is looking good. Ping me when you feel it is complete and I'll give it another once-over!
",ryanuber,i0rek
1004,2015-06-09 12:32:24,"@ryanuber I added RPC to the mix, because that was missing. I also added a little bit of documentation, not sure how you handle that. I was planning to rebase a last time after you looked at it so that you have a nice commit you can merge. I am not sure how you handle that either.
",i0rek,ryanuber
1004,2015-06-12 18:56:21,"@i0rek this looks good, just some minor notes about test coverage but overall this is really close! The documentation looks right. Also, no need to rebase this, since it can be cleanly applied against master in its current state.
",ryanuber,i0rek
1004,2015-06-13 22:40:29,"Thanks for the review @ryanuber. I added the tests.
",i0rek,ryanuber
1004,2015-06-14 00:42:18,"Great! Will review again soon!

On June 13, 2015 3:40:35 PM PDT, Hans Hasselberg notifications@github.com wrote:

> Thanks for the review @ryanuber. I added the tests.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/pull/1004#issuecomment-111757900

## 

Sent from my Android device with K-9 Mail. Please excuse my brevity.
",ryanuber,ryanuber
1004,2015-06-23 17:46:28,"@ryanuber any progress on this? Seems ready to merge to me. Thanks
",i0rek,ryanuber
1004,2015-06-23 18:01:27,"@i0rek sorry for the delay! It's been busy. Left a super-minor comment but otherwise let's get this merged. Great work!
",ryanuber,i0rek
1004,2015-06-23 19:24:14,"@ryanuber no worries. I changed the typo!
",i0rek,ryanuber
1002,2015-06-05 05:26:18,"@sathiyas it's definitely not related to your changes. Unfortunately Consul has a hard time with its unit tests on Travis-CI sometimes.
",ryanuber,sathiyas
1001,2015-06-04 15:54:08,"Hey @blalor, this sounds like it could be a regression. I'll crack into this one very soon. Thanks for reporting it!
",ryanuber,blalor
1001,2015-06-05 18:03:41,"@blalor I remembered wrong, we were never restoring the previous status up to this point. I've started a branch for this. I think it will need to be optional and off by default so as to not disrupt clusters which depend on the current functionality. I'll update here when I'm closer to having something usable.
",ryanuber,blalor
1001,2015-06-08 16:39:30,"@blalor the above merged PR should fix the TTL checks and restore their status on later agent start. No config option needed for this case since it is only the TTL checks that get this new behavior.
",ryanuber,blalor
999,2015-06-03 16:16:02,"Hi @gingi99, the problem is that the compiled binary you downloaded was not built for your CPU architecture. We don't currently offer pre-compiled versions for ARM, but we will starting with Consul 0.6. In the meantime, you can compile Consul yourself following the directions [here](https://github.com/hashicorp/consul#developing-consul). Hope that helps!
",ryanuber,gingi99
998,2015-06-03 14:15:10,"Hi @amorken - thanks for the report. This enumeration is pretty obscure - agree we should at least document it; since it's baked into Serf's core operation it'll be pretty stable. If we do a v2 API it would also be worth changing this to a string so we hide that Serf implementation detail, the `String()` method is already right there below the code you cited!
",slackpad,amorken
997,2015-06-03 08:41:32,"@brommer We want to move to labels eventually, its just ""legacy"" decisions. You can either overload the tags currently or use the KV store.
",armon,brommer
997,2015-06-03 17:01:04,"Hi @armon thanks for your answer. Great hearing about that decision. I am just curious, how you would integrate that by still having valid DNS names. Is there any idea for that already? 

Thanks!
",brommer,armon
997,2015-06-03 21:40:23,"@brommer It should work fine if you use letters and numbers, for example, ""arch-x86"" label can be used like ""arch-x86.api.service.consul""
",armon,brommer
997,2015-06-04 07:51:34,"@armon Ok, great, thanks.
",brommer,armon
993,2015-06-08 18:09:28,"@eirslett what did you change to get it to work?
",reversefold,eirslett
993,2015-06-09 22:07:50,"@reversefold Those look like the same node's log got pasted three times - can you grab the logs for the other two nodes?
",slackpad,reversefold
993,2015-06-09 22:14:28,"@slackpad Apologies, I've updated the comment above with the other 2 logs.
",reversefold,slackpad
993,2015-06-10 00:25:30,"@reversefold - After digging more I think you are seeing the same thing as is being discussed on #750 and #454.

I was able to reproduce your situation locally and verify that the consul.data/raft/peers.json file ends up with `null` inside on all three servers. That's why a `TERM` sig doesn't lead to this because it doesn't formally leave the set of peers (see [leave_on_terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate), which defaults to false).

I'll let @armon and/or @ryanuber weigh in on the best practice to follow to get into a working state. Maybe we should add a new ""Failure of all Servers in a Multi-Server Cluster"" section in the outage recovery docs since this seems to be confusing to people. I think it will end up being something similar to the manual bootstrapping procedure, picking one of the servers as the lead. In my local testing I was able to get them going again by manually editing the peers.json file, but I'm not sure if that's a safe thing to do.
",slackpad,reversefold
993,2015-06-10 01:39:08,"@slackpad is correct here. @reversefold when you delete the entire data directory, you are also deleting the raft log entirely, which is why you get the error about the voting terms not matching up (servers with data joining a leader with no data). Editing the peers.json file and leaving the raft data intact is the current best practice for recovering in outage scenarios, and the `null` is described in #750, TL;DR being that it is purposely nulled out during a graceful leave for safety reasons.
",ryanuber,slackpad
993,2015-06-10 01:39:08,"@slackpad is correct here. @reversefold when you delete the entire data directory, you are also deleting the raft log entirely, which is why you get the error about the voting terms not matching up (servers with data joining a leader with no data). Editing the peers.json file and leaving the raft data intact is the current best practice for recovering in outage scenarios, and the `null` is described in #750, TL;DR being that it is purposely nulled out during a graceful leave for safety reasons.
",ryanuber,reversefold
993,2015-06-18 23:04:49,"Hi @orclev - there's a sample in the [Outage Recovery Guide](https://www.consul.io/docs/guides/outage.html). It's basically a list of IPs and port numbers for the peers:


",slackpad,orclev
993,2015-06-19 18:16:05,"@slackpad thanks, I somehow missed that. I figured it was probably somewhere in the docs and I was just missing it.
",orclev,slackpad
993,2015-07-02 06:53:58,"@slackpad 
can you give a patch build to fix this issue instead of manually fix it since it is almost impossible to mannually fix something on production env?
",juaby,slackpad
993,2015-07-02 15:48:59,"Hi @juaby. Unfortunately, there's not a good way we could automatically recover from the case where the servers have all left the cluster. I was just going to improve the documentation on how to recover from this case by manually editing the peers.json file per the comments above.
",slackpad,juaby
993,2015-07-06 20:29:27,"Perhaps we should always start with --bootstrap-expect=1.  That way we would work around the bring up problem.  The remaining servers will join subsequently, so in the end we'll get our redundancy back.  I believe joining servers need to nuke their raft data.  I know this is not recommended but in our case, manual fiddling with descriptors is not an option. @slackpad do you see any issues with this approach?
",elephantfries,slackpad
993,2015-08-17 21:33:43,"I hit the same issue than @reversefold in https://github.com/hashicorp/consul/issues/993#issuecomment-109661347 

I made multiple tries on my computer (here is a summary to help you ;)).

### Config

I have 3 nodes, and the configuration is the same on all hosts:



And here is my upstart script:



And finally, I use ubuntu 10.04 in lxc.

### Benchmark

Benchmark steps (play many times, and make an in memory average ;))



### Results

For my initial test, I uncommented `#kill signal INT` from upstart script.
- if the stop/start is fast enough (<3 sec) => OK
- if the stop/start slow (>3 sec) => always broken.

For the second test, I commented `#kill signal INT` from upstart script.
then I played `for i in`seq 0 2`;do ssh ansible-monitoring-es-$i.lxc  'sudo rm -rf /var/lib/consul'  ; done`
- if the stop/start is fast enough (<3 sec) => OK
- if the stop/start slow (>3 sec) => OK.

_Note:_ I also played the rm command severals time during the same setups, in order to start again in a clean state.
",lyrixx,reversefold
993,2016-02-06 11:47:40,"@kongchen same issue here
I gracefully(SIGINT) restarted my 3 consul server cluster 1by1, IPs stayed the same
all nodes came back, same ips, same instances - all nodes are shown as alive in `consul members` output
NO leader :(
",let4be,kongchen
993,2016-09-16 14:17:03,"@michaelmcguinness 

I was having to do that on all my nodes after un-graceful restarts.  So I took it one step further and added this to my consul.service systemd file and I have had no trouble since:

ExecStartPre=/usr/bin/bash -c '/usr/bin/rm -rf /var/lib/consul/*'

the full contents of my systemd service file are:
`[root@util-swarm-000 ~]# cat /etc/systemd/system/consul.service 
[Unit]
Description=Consul is a tool for service discovery and configuration.
Documentation=https://consul.io
After=network-online.target
Wants=network-online.target
After=rsyslog.service
Wants=rsyslog.service

[Service]
User=consul
Group=consul
EnvironmentFile=/etc/sysconfig/consul
ExecStartPre=/usr/bin/bash -c '/usr/bin/rm -rf /var/lib/consul/*'
ExecStart=/usr/bin/consul agent -config-dir=${CONFIG_DIR} -data-dir=${DATA_DIR} $EXTRA_OPTS
ExecReload=-/bin/kill -HUP $MAINPID
KillSignal=SIGINT
LimitNOFILE=65536
Restart=on-success
IgnoreSIGPIPE=yes

[Install]
WantedBy=multi-user.target
`
",cnoffsin,michaelmcguinness
993,2016-09-24 14:31:38,"@markhu 

That's cool but the issue is essentially we want consul to elect a cluster leader in the event of a graceful or ""un-graceful"" restart of a server.  
",cnoffsin,markhu
992,2015-06-02 18:59:20,"@phinze, thanks for asking, I should have mentioned it, RHEL AMIs are HVM based and do not take m1 instances. 
",sathiyas,phinze
992,2015-06-02 19:01:44,"@sathiyas ah okay - can you go t2.micro instead then? we want to keep the defaults in the examples relatively cheap :grinning: 

Ideally we can switch the ubuntu AMIs to HVM as well just to keep it simpler.
",phinze,sathiyas
992,2015-06-02 19:58:38,"@phinze , thanks for quick review, I made changes to reflect latest AMIs for HVM for both ubuntu and rhel6 and tested both.
",sathiyas,phinze
990,2015-06-01 10:54:43,"@ashish235 Check the log files on the Consul servers or whatever machine is hosting the UI. My guess is that you have lost quorum / leadership due to the servers failing. This means there is no leader node in the cluster and requests cannot be serviced.
",armon,ashish235
990,2015-06-01 11:30:57,"@armon yeah, it was a quorum issue which I could see from the logs. But I don't get this my one node (consul server) was always up, so in that case it should have elected itself as a leader and other nodes should join it later. This was my understanding but I think I am missing something here. But  can you confirm that if only one server is running it can be elected as a leader.

I think I need to find some way to find the new leader and join it instead of joining a failing server. 
",ashish235,armon
990,2015-06-01 16:05:45,"Hi @highlyunavailable, cool Thanks for the awesome response. My queries are answered. 
",ashish235,highlyunavailable
988,2015-06-01 20:39:15,"@rafikk we generally recommend against using any non-DNS compatible characters in service names. That said, as long as it's allowed in Consul, the UI should support it too. @pearkes any thoughts on this?
",ryanuber,rafikk
988,2015-06-02 21:55:22,"@rafikk This _should_ be fine to merge but I think @ryanuber is just waiting on me double checking Ember won't mind. Will do that shortly and give a :+1:.
",pearkes,ryanuber
988,2015-06-02 21:55:22,"@rafikk This _should_ be fine to merge but I think @ryanuber is just waiting on me double checking Ember won't mind. Will do that shortly and give a :+1:.
",pearkes,rafikk
988,2015-06-02 22:06:37,"Sounds like this is G2G, so I'm going to merge this in. Thanks, @rafikk!
",ryanuber,rafikk
987,2015-05-31 05:40:05,"@falzm I've reproduced this, thanks for the report! The problem is definitely that the service ID is specified improperly in the first invocation of Consul. If the `service_id` field is not specified, then the check is assumed to be a node-level check, so the check registers correctly. In order to fix this, you should first register a service definition using configuration files or by using the API. See the ""Service Definitions"" page in the Consul Agent documentation [here](https://consul.io/docs/agent/services.html) for details.

This is definitely a bug though - Any panic in Consul is a bug. I'll take a look at this.
",ryanuber,falzm
985,2015-06-26 09:55:04,"@highlyunavailable Thanks for finding this! My guess is there is a channel blocking somewhere as well in the tear down path. I've tagged this as a bug. As it should just kill the child process in scenario 3.
",armon,highlyunavailable
985,2015-06-26 09:57:58,"@sean- If the client is partitioned off from one of the servers, who happens to be the leader, then things should still work. Clients pick a random server to talk to for RPCs for load balancing, and then the servers do internal request forwarding if they are not the leader. Given some time, the client should detect that server as partitioned via Serf and remove it from the list of eligible servers. So when the client makes an RPC call, it will be to one of the non-partitioned servers and that server should be able to forward to the leader. At least, thats how it should work :)
",armon,sean-
985,2015-08-05 10:01:57,"@armon So is the behaviour that highylunavailable described in scenario 1 the intended one? Meaning loss of the leader and election of a new one implies loss of all locks?
",jeinwag,armon
982,2015-06-03 07:14:54,"@artushin it's hard to say without a bit more context on your scenario. Could you provide any details on what happened during the service registration, if the check was registered separately, what version of Consul you are running, if you are running any custom patches, etc? Some debug-level logs would also go a long way in helping us diagnose the problem.
",ryanuber,artushin
982,2015-06-03 21:32:49,"@ryanuber We're on v0.5.2 on 5 servers and 66 agents and v0.5.0 on 30 other agents. This started happening when we switched from http status checks to ttls and got some other issues. In the end, we switched back but this INFO log still occurs and load looks like its higher than it was before. 

Here are the debug logs from a single host starting with a few of the messages and ending in the same messages (they come in groups). Nothing seems out of the ordinary. I've dropped our service names but each request was for a different service.

Is EnsureRegistration called only when a service is attempting to register? I'm just worried that we have some kind of flapping registration we're not seeing.


",artushin,ryanuber
982,2016-04-13 05:40:41,"@artushin I'm going to close this out since this code path was completely rewritten in Consul 0.6.0 (it looks from the debug log that the state store got corrupted). Please re-open and/or let us know if there's any lingering part of this issue.
",slackpad,artushin
978,2015-05-27 20:29:23,"Hey @nevins-b,

All known services will show up in the catalog. If you want to see only healthy/routable services from the HTTP API, you should use the `/v1/health` endpoints instead. There is also a `?passing` parameter you can pass in to get only passing services. Here is some more documentation: https://consul.io/docs/agent/http/health.html

Hope that helps!
",ryanuber,nevins-b
977,2015-05-27 01:43:09,"@ryanbreen yeah, tend to agree, it's kinda horrible to condense comparisons into a single case statement. reverting that bit...
",sdboyer,ryanbreen
976,2015-05-28 19:52:16,"@ryanuber nice trick! Although, I was thinking more in being able to monitor RDS instances from Consul. 
",c4milo,ryanuber
976,2015-05-28 20:03:19,"@c4milo I use TCPing to do just that:

`/bin/tcping -t 1 rds.hostname.goes.here 1433`
",highlyunavailable,c4milo
976,2015-05-28 20:12:06,"What @highlyunavailable suggest should work too! Both commands would take a hostname and port, which should allow you to do exactly what you need.
",ryanuber,highlyunavailable
976,2015-07-16 06:20:28,"i agree with @Kosta-Github 
",DanyC97,Kosta-Github
975,2015-05-26 19:05:38,"@spuder Easiest way I found is to install `nagios-plugins` package and set up your checks with consul for what you want to manage. But really the checks are as simple as any executable script that you want to have run at a certain interval.

Here is a sample of using some of the nagios plugin scripts as consul checks: https://gist.github.com/mtchavez/e367db8b69aeba363d21
",mtchavez,spuder
975,2015-05-26 21:13:19,"@spuder yes you would need to install that per node or provision your nodes with the necessary scripts to use in your checks. 
",mtchavez,spuder
975,2015-07-23 15:13:37,"@spuder Not to shamelessly self-promote, but you might also take a look at [Distributive](https://github.com/CiscoCloud/distributive). It was designed to work with Consul, and documents how to use it with Consul health checks on the wiki.
",siddharthist,spuder
973,2015-05-26 16:24:19,"Hey @eirslett,
What version of Consul are you using? Was the cluster ever running a pre-0.5.x build? Between 0.4.x and 0.5.2 (latest), there were a number of significant enhancements made to avoid this kind of thing. Is it possible that at some point a node from one datacenter was accidentally joined to one from the other datacenter?
",ryanuber,eirslett
973,2015-06-03 07:03:03,"@eirslett thanks for updating us. Let us know if this issue crops up again. For now I'll close it out. Thanks!
",ryanuber,eirslett
972,2015-05-26 15:40:38,"@highlyunavailable thanks for the tip!
",MrMMorris,highlyunavailable
971,2015-05-27 18:52:51,"@grobie @epipho It's been a while... But if memory serves, the compression issue hit when doing recursion for clients. The actual responses we generate didn't cause issues, but I think some of the more edge case record types did. Never saw it with A, AAAA, CNAME or SRV.
",armon,grobie
971,2015-05-27 18:52:51,"@grobie @epipho It's been a while... But if memory serves, the compression issue hit when doing recursion for clients. The actual responses we generate didn't cause issues, but I think some of the more edge case record types did. Never saw it with A, AAAA, CNAME or SRV.
",armon,epipho
971,2015-05-29 01:34:31,"Thanks Armon. We don't do any recursion on our service discovery DNS
servers (yet), good to know.
On May 27, 2015 2:52 PM, ""Armon Dadgar"" notifications@github.com wrote:

> @grobie https://github.com/grobie @epipho https://github.com/epipho
> It's been a while... But if memory serves, the compression issue hit when
> doing recursion for clients. The actual responses we generate didn't cause
> issues, but I think some of the more edge case record types did. Never saw
> it with A, AAAA, CNAME or SRV.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/971#issuecomment-106034649.
",grobie,grobie
971,2015-05-29 01:34:31,"Thanks Armon. We don't do any recursion on our service discovery DNS
servers (yet), good to know.
On May 27, 2015 2:52 PM, ""Armon Dadgar"" notifications@github.com wrote:

> @grobie https://github.com/grobie @epipho https://github.com/epipho
> It's been a while... But if memory serves, the compression issue hit when
> doing recursion for clients. The actual responses we generate didn't cause
> issues, but I think some of the more edge case record types did. Never saw
> it with A, AAAA, CNAME or SRV.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/971#issuecomment-106034649.
",grobie,epipho
971,2015-06-05 02:06:34,"@discordianfish I build consul 0.5.2 with this patch and removed my ""search ec2.internal"" from /etc/resolv.conf along with setting only a single nameserver of 127.0.0.1.

Even with compression turned on I still get ""FATA[0000] Get https://registry-1.docker.io/v1/repositories/library/busybox/tags: dial tcp: lookup registry-1.docker.io on 127.0.0.1:53: cannot unmarshal DNS message"" from docker
",sstarcher,discordianfish
971,2015-06-05 10:15:52,"@sstarcher Yes, looks like the responses are still too large. This PR doesn't fix the actual issue, it just makes it less likely to hit it.
",discordianfish,sstarcher
971,2015-06-05 14:32:04,"I have not been able to craft a decent test that validates this fix as I cannot get the test DNS server to reliably return a response that is too large. We have been using it without issues but it sounds like @sstarcher still sees some.

@discordianfish do you believe miekg/dns#216 will fix that issue as well? 
",epipho,discordianfish
971,2015-06-05 14:32:04,"I have not been able to craft a decent test that validates this fix as I cannot get the test DNS server to reliably return a response that is too large. We have been using it without issues but it sounds like @sstarcher still sees some.

@discordianfish do you believe miekg/dns#216 will fix that issue as well? 
",epipho,sstarcher
971,2015-06-05 14:35:43,"Oh I missed that, I tried the fix and it worked for me - at least for my test tool.
@sstarcher Are you sure you used the patched version?

Beside that, I'd consider this a bug in miekg/dns (see the issue I opened). It seems idiomatic to write the dns message received from Exchange() to the client, but since miekg/dns doesn't set the compress flag even if it was compressed, it yields a message to large.
",discordianfish,sstarcher
971,2015-06-05 14:59:10,"@discordianfish  I'm sure I compiled turbine's compress-dns branch
""./command/agent/dns.go:    m.Compress = true
./command/agent/dns.go: m.Compress = true
./command/agent/dns.go:     r.Compress = true
./command/agent/dns.go: m.Compress = true
""

I also checked the version of my binary it was something along the lines of 0.5.2.#####

I will re-attempt on monday.
",sstarcher,discordianfish
971,2015-06-05 15:08:14,"@sstarcher I just confirmed that it fixes the problems for me: master is broken but with this branch it works.
",discordianfish,sstarcher
971,2015-06-08 14:24:46,"@discordianfish I again rebuilt it using the compress-dns branch from turbine and I still get 
`FATA[0000] Get https://registry-1.docker.io/v1/repositories/library/busybox/tags: dial tcp: lookup registry-1.docker.io on 127.0.0.1:53: cannot unmarshal DNS message`


",sstarcher,discordianfish
971,2015-06-08 16:55:54,"@sstarcher That's weird.. Maybe you can provide a tcpdump?
",discordianfish,sstarcher
971,2015-06-08 17:01:35,"@miekg suggests to set the compress flag in consul, not wait for him to change this upstream.
@armon Can we get this merged soon? Even if it's not fixing the issue for all, it's definitely a pretty clear bug which breaks everyone using docker and consul as recursor.
",discordianfish,armon
971,2015-08-20 17:35:55,"Just checking in here - I think we can get this in if some tests could be crafted to ensure that we are actually compressing the messages. I also think it would be worthwhile to make the adjustments @miekg suggests rather than just compressing everything and hoping the messages fit into the buffer. This would also ease the hesitation, since most messages should be small enough to fit without compression.
",ryanuber,miekg
971,2016-01-15 01:04:45,"Hi @epipho checking in on this one - is there still interest in getting this merged?
",slackpad,epipho
971,2016-01-27 15:21:50,"@slackpad indeed. Sorry I had github notifications turned off and didn't see it.  I just merged 0.6.3 into my fork and am doing testing to make sure there are no regressions.
",epipho,slackpad
971,2016-02-17 21:07:56,"@epipho , found this PR after running into this problem at work. Wondering if this will be merged soon. Is there anything I can do to help push this along?

This is kind of an edge case for us (only happens in our dev environment, and we're not sure why,) but it would make our lives a lot easier if this were merged?
",jordan-acosta,epipho
971,2016-05-31 17:37:14,"@slackpad I've been doing some testing as I'm hitting this same docker + consul bug. I don't think the DNS library makes the compressed state of the incoming message available.
",alexjh,slackpad
971,2016-05-31 17:45:42,"No it doesn't because compression is hop by hop so it doesn't make sense to
relay this when you are a proxy.

I don't get why consul just compresses everything. Compression has been in
the DNS standard since 1984.
On 31 May 2016 7:37 p.m., ""Alex Harford"" notifications@github.com wrote:

> @slackpad https://github.com/slackpad I've been doing some testing as
> I'm hitting this same docker + consul bug. I don't think the DNS library
> makes the compressed state of the incoming message available.
> 
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/hashicorp/consul/pull/971#issuecomment-222762646, or mute
> the thread
> https://github.com/notifications/unsubscribe/AAVkW_3zhBkwprX1sN0VSn7gdJW6QZhVks5qHHHigaJpZM4Elqx3
> .
",miekg,slackpad
971,2016-05-31 22:34:44,"@epipho:

> Compress udp messages that come in that are already over 512 bytes (non-conforming server?)

Like miekg said, it makes sense to compress everything. I think that would be a good start and would fix the docker bug that a lot of people are seeing.

@ryanuber: I don't think tests for compression are needed as that's already covered by the tests in the dns library.
",alexjh,ryanuber
971,2016-05-31 22:34:44,"@epipho:

> Compress udp messages that come in that are already over 512 bytes (non-conforming server?)

Like miekg said, it makes sense to compress everything. I think that would be a good start and would fix the docker bug that a lot of people are seeing.

@ryanuber: I don't think tests for compression are needed as that's already covered by the tests in the dns library.
",alexjh,epipho
970,2015-05-22 18:17:23,"@artushin Looks like its coming from LMDB, hopefully this class of issue goes away with 0.6
",armon,artushin
968,2015-05-22 03:11:09,"@highlyunavailable The ""behavior"" of a session affects what is done during invalidation of a session to any keys associated (""locked"") by that session. So I guess the confusion here is between the behavior of a key ""lock"" in Consul vs the `api.Lock` client library.

The `api.Lock` will create the key if it does not exist, and in either case attempts to associate or ""lock"" the key with a session. On `Unlock` the client dis-associates the session (""unlock""), but does not delete the key. The `api.Lock` exposes a separate `Destroy` operation instead. The intended use case for that library was for locks that are longer lived than the sessions. For example, multiple services contending for the same lock as a leader election mechanism.

That said, you can get the behavior you want by doing the lock with a session with `delete` behavior, acquiring the lock, and then doing an explicit session invalidation. The session invalidation will cause the lock to be deleted / released without it lingering.
",armon,highlyunavailable
968,2015-05-22 17:52:19,"@highlyunavailable I agree. The downside of overloaded terminology and complex systems. But I'm happy to help clarify!
",armon,highlyunavailable
965,2015-05-20 21:42:10,"@jdrago999 Managing historic state has been out of scope for Consul traditionally. That is something we like to see built on top of Consul, like we have done with Atlas, or others with open source tooling. This allows Consul to focus on just the emergent current state problem.
",armon,jdrago999
964,2015-05-20 20:18:24,"Hi @sathiyas - thanks for this contribution!

I think the `egress` rule confusion is just a matter of using the latest version of Terraform. In 0.5.0 we changed the behavior of security groups to avoid the implicitly created egress rule, so it needs to be in the config now.

As for the provider variables, it's actually important to leave those out of the module definition to support users who are configuring their provider via environment variables.

I think the name tag is a good idea though. Can you re-push this PR with just the name tag stuff?
",phinze,sathiyas
964,2015-05-20 20:28:46,"Sure @phinze,will do shortly
",sathiyas,phinze
964,2015-05-21 00:41:38," @phinze, modified, tested and submitted. Thanks for quick review
",sathiyas,phinze
964,2015-05-26 15:00:07,"Looks good - thank you @sathiyas!
",phinze,sathiyas
964,2015-05-26 17:47:02,"Answering a question from @sathiyas here for public record.

> I have question on why you think the Provider info is not needed to run the stack.
> Without the follwowing block in my TF file, I cannot run the stack.

There are two ways to configure the provider without a `provider { ... }` declaration inside the module.

**One**: provider config inherits into modules, so you can simply configure the provider in the place where you invoke the module.



**Two**: provider config can be provided solely via environment variables, so you can completely omit any `provider { ... }` blocks and simply set these environment variables:



Either of these methods should work for you.

The important thing is that we omit the provider config from _inside_ the official Consul Terraform module, so that callers can choose which provider config style they prefer.

Hope this helps to clarify - let me know if you have any further questions!
",phinze,sathiyas
963,2015-05-20 18:05:16,"Hi @looprock,

Could you provide some debug logs from Consul? It would be helpful to know what is going on from that perspective. Nodes which are considered unhealthy (1 or more failing node-level checks) would be dropped from the output, so that part is intended behavior.

Any logs, especially with the `-log-level=debug` verbosity option, would help a ton.
",ryanuber,looprock
963,2015-05-28 20:18:40,"Hey @looprock,

Were you able to resolve this? If you are still having trouble, providing some logs would definitely help us figure out what's going on here. Thanks!
",ryanuber,looprock
959,2015-05-19 22:46:17,"@Shinzu I've marked this as a bug, but the datacenter names should all be lowercased. Moving every agent to 0.5.2 should fix this as well.
",armon,Shinzu
958,2015-05-19 22:42:47,"@mohitarora It is hard to tell given this information what happened. Do you have the log files during when the restart happened? Can you tell if the nodes did leave and join again?

When you say none of the nodes had consul running, that sounds like the machine didn't start Consul agent during the boot process. We typically recommend running Consul under a process supervisor like upstart, runit, or systemd.
",armon,mohitarora
956,2015-05-19 22:28:56,"@sean- Can you tell if its hung or just migrating? Our own servers took like 90 seconds to finish the migration. Or did they just sit there forever?

/cc: @ryanuber any ideas why it would be hanging?
",armon,sean-
956,2015-05-19 22:33:03,"That is interesting - the migration utility only uses the Raft interfaces, so I'm not sure where this might be stemming from. @sean- how large is the original LMDB data directory?
",ryanuber,sean-
956,2015-05-19 22:43:44,"@ryanuber For the upgrade utility, can we have it output incremental process (e.g. 5%..10%...) so that it's clear something is happening at least?
",armon,ryanuber
956,2015-05-19 22:54:34,"@armon, yeah I think we can update some counter after each raft log is converted over. I'll take a stab at that.
",ryanuber,armon
956,2015-05-20 01:08:59,"@armon the total size was ~1MB, it should have been tiny.  I `truss`'ed the process and it was working, but not doing anything.  It looked like it was spinning in place forever.  I see it was opening have the `truss` logs available.



and this continues for a while, but then it stops and the output changes:



And the process basically loops forever.  I still haven't chased this in to code, but this is what I recorded before employing the workaround.
",sean-,armon
956,2015-05-20 02:46:15,"Yeah this definitely sounds like a problem - 1MB should have flown through very quickly. I've added progress indication to Consul's master branch, which might help to understand which phase the migration hangs at. It will dump some output like this:



@sean- correct me if I'm wrong, but it looks like you are using FreeBSD? In the meantime, I'm going to set up a FreeBSD machine and give the migrator a test.
",ryanuber,sean-
954,2015-05-18 22:43:17,"@onnimonni We never considered the case of such long intervals. Most of the checks are definited on fairly short intervals. We purposely stagger start the checks to avoid a thundering heard, but in this case the stagger may be spread over a 30 minute period which is rather long. Tagging as bug, so we can add a cap to the stagger period.
",armon,onnimonni
954,2015-05-18 23:39:03,"I'm running rather intensive security scanning check for wordpress using consul and it's ok if node is under a pressure during the start for this, but after that it's ok to run it only seldomly

Thanks for considering it :)

On Tue, May 19, 2015 at 1:43 AM, Armon Dadgar notifications@github.com
wrote:

> ## @onnimonni We never considered the case of such long intervals. Most of the checks are definited on fairly short intervals. We purposely stagger start the checks to avoid a thundering heard, but in this case the stagger may be spread over a 30 minute period which is rather long. Tagging as bug, so we can add a cap to the stagger period.
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/954#issuecomment-103238880
",onnimonni,onnimonni
954,2015-07-23 21:53:08,"@onnimonni Solution posted in issue #1085:
""[#962] actually should solve this case by allowing the ability to provide the check status when registering the check. The confusion is probably that we forgot to document it on the web docs, so we can probably just create a ticket for that instead. @siddharthist does that satisfy your use case?""
",siddharthist,siddharthist
954,2015-07-23 21:53:08,"@onnimonni Solution posted in issue #1085:
""[#962] actually should solve this case by allowing the ability to provide the check status when registering the check. The confusion is probably that we forgot to document it on the web docs, so we can probably just create a ticket for that instead. @siddharthist does that satisfy your use case?""
",siddharthist,onnimonni
953,2015-09-13 18:58:00,"**TL;DR**: Expose 8301 and 8302 ports explicitly for both protocols (TCP and UDP).

This is not a Consul issue but related to the way Docker exposes ports.

I encountered a similar problem: I could create a cluster of 3 Consul servers (DigitalOcean machines, Consul server running as `gliderlabs/consul-server` Docker image), the nodes could see each other and elect a leader, but would fail right after election.



I had exposed the appropriate ports in `docker-compose.yml`:



...but this did not seem to work. Explicitly defining tcp/udp ports as @ChristianKniep suggested did the trick:





This might be due to the fact that by default, Docker only exposes a TCP port, so you need to expose each port twice, but with different protocol switches.

> Additionally, all of these publishing rules will default to tcp. If you need udp, simply tack it on to the end such as -p 1234:1234/udp. ([source](https://labs.ctl.io/docker-networking-rules))

Related: #1465 and https://github.com/hashicorp/memberlist/pull/37.
",anroots,ChristianKniep
953,2016-06-11 11:28:21,"@anroots I've tried explicitly adding the ports and it doesn't seem to make any difference whatsoever.

I'm suspecting it has something to do with the SG (since I'm trying this on EC2 instances and only one of the instances keeps failing)
",asheshambasta,anroots
949,2015-05-18 22:40:44,"@haf Might have been an issue with 0.5.1 build. I don't see that with 0.5.2, and at this point there is a newer version available :)
",armon,haf
949,2015-05-19 22:32:07,"@haf Is this an official build or did you compile it yourself?
",armon,haf
949,2015-05-19 22:32:47,"@haf What is the output of `consul version`?
",armon,haf
949,2015-05-20 06:20:08,"Turned out it was competing versions on the global bin path. Shit behind the keyboard, sorry.

@armon Thank you for this project; looking forward to using it more.
",haf,armon
948,2015-05-19 22:38:08,"@tiwilliam My only concern now is Windows. I have a suspicion it will not play nice... 
",armon,tiwilliam
948,2015-06-29 21:57:46,"@highlyunavailable Thank you! I wonder if it works with the Windows Loopback Adapter installed.
",tiwilliam,highlyunavailable
948,2015-06-30 12:27:10,"@highlyunavailable Good catch, I've added `127.0.0.0/8` and we now treat it as a private block, which I think in this case is perfectly fine.

I guess you can change address of your Windows Loopback Adapter manually to 127.0.0.1 if you really want that?
",tiwilliam,highlyunavailable
948,2015-09-02 14:45:05,"It doesn't look like the 169.254 case is a problem since Consul will [bail out](https://github.com/hashicorp/consul/blob/iface-down-fix/consul/util.go#L255) if it is presented with multiple private IPs.

This could only be a problem if the machine a. has 1 APIPA-addressed DHCP adapter b. public IP adapter(s) - this would mean that consul would try to auto-bind to the APIPA adapter, but that's already a thing - Consul won't bind to a public IP. I'm fine with how it works in Windows right now as well.

if @armon approves it would be cool to get this merged - there are multiple open bugs that this would fix it looks like: #934, #928.
",highlyunavailable,armon
947,2016-02-23 15:32:17,"@dpkirchner there's one outstanding thing with the PR and it needs a rebase. I'll try to get this in before the next release - it's super close.
",slackpad,dpkirchner
947,2016-09-16 06:45:50,"+1 would love to have this in :)

@slackpad _bump_ :)
",CpuID,slackpad
946,2015-05-16 05:01:52,"@tgwizard I think we could also remove the datacenter from the node name when listing WAN members, now that we have a column dedicated to that.

![](https://cldup.com/DJPGFOzAbH.png)
",c4milo,tgwizard
946,2015-05-16 10:22:43,"Hmm, @c4milo I don't think that is the datacenter but part of the actual node name. If I run it locally I get


",tgwizard,c4milo
942,2015-05-15 21:03:09,"@c4milo perhaps using the `-detailed` flag would be good enough?
",tgwizard,c4milo
942,2015-05-15 21:57:26,"I submitted a PR to add this. @c4milo I'm very sorry if this was something you wanted to do and I just rushed into this :/
",tgwizard,c4milo
942,2015-05-15 22:11:05,"@tgwizard how dare you :)
",c4milo,tgwizard
942,2015-05-15 23:14:25,"@ryanbreen Good problems to have :)
",armon,ryanbreen
939,2015-05-15 01:23:48,"@armon everything looks great, just one untested method. Otherwise LGTM!
",ryanuber,armon
939,2015-05-15 01:32:28,"@ryanuber Added test!
",armon,ryanuber
938,2015-06-02 22:19:13,"@rafikk Agreed about the nested scrolling, but unfortunately it's for performance. In large clusters (thousands of services/nodes) the UI chokes without ember listview.
",pearkes,rafikk
938,2015-06-02 22:45:16,"@pearkes Does that mean removing ListView is a non-starter? Is pagination an option?

Is there a good way for me to test the UI against such a cluster?
",rafikk,pearkes
938,2015-06-03 13:02:07,"@rafikk Best way to test the UI is to replace the JSON endpoint to a json file on disk (the ui dir serves a directory, so you can just copy a file in there). Then give the file a fake response of some 1000s of nodes. That's the best way I remember. Proper fixtures would be nice though. Ember has a come a long way since this UI was made, so there are a number of ""better"" tools now as well.
",pearkes,rafikk
937,2015-05-18 21:26:44,"Hey @cruatta,

For checks which apply to the system as a whole (like memory or cpu utilization, etc), these should actually just not be associated with any service. If they are associated with the node only, when they start failing, all services on that node are considered ""unhealthy"" and are not returned from the service catalog when using a passing filter, and will also not be returned from the DNS interface. Using node-scoped checks for general system-level tests should allow deduplicating most things.

Does that help?
",ryanuber,cruatta
935,2015-05-29 17:31:23,"Hey @wkennington, Consul 0.5.2 allows specifying tokens when registering services, which should make it possible to do this kind of configuration in the Consul configuration files. More info on that [here](https://consul.io/docs/agent/services.html). Does that satisfy your use case?
",ryanuber,wkennington
933,2015-05-18 22:51:54,"@highlyunavailable That is what the `Destroy` command is for!
",armon,highlyunavailable
932,2015-05-12 20:15:37,"@highlyunavailable I think this is okay actually. Lock makes use of the `?acquire` operation which may be affected by a lock-delay, while semaphore uses `?cas` which does not have the same sort of deferral mechanism. 
",armon,highlyunavailable
925,2015-05-11 18:34:12,"@lindane This is happening due to how the gossip based failure detector works. When ""rhel64-mysql2"" sends a ping to ""rhel64-mysql1"", the response is being dropped by iptables. Eventually ""rhel64-mysql2"" marks ""rhel64-mysql1"" as failed, which causes the session to be invalidated.

The gossip system requires that UDP packets not be dropped, otherwise you will get a very high rate of failure detection. 

See for more details: https://consul.io/docs/internals/gossip.html
",armon,lindane
924,2015-06-03 23:43:12,"@mainframe thanks for reporting this. This is happening in the gossip layer. After reading the code, it appears this is intentional. The gossip layer uses logical time only in its state which makes it more resilient to clock differences between the agents. My best guess at why the timers aren't restored is to avoid writing the local system time into the agent state to make this behavior more predictable. @armon can probably clarify here for us.

As for the peers.json file, that is intentionally left populated. You can read more about these types of failure scenarios in [this guide](https://consul.io/docs/guides/outage.html). Of particular interest here is the section on failed servers, which explains how this scenario may be recovered from.

I think the TL;DR is that this is working as intended, but I'll leave this open for now in case I missed something.
",ryanuber,mainframe
924,2015-06-04 06:04:26,"@ryanuber - correct me if Im wrong - but outage guide deals with recovering consul cluster and restoring the quorum after full outage. I have no problem with restoring the quorum and getting consul cluster working again - once enough nodes for quorum are up again. I have a problem that consul cluster members list is changed/reduced after outage recovery - when not all nodes are back up again. 

But let me illustrate the problem with the real use case - and why Im thinking its a problem:

1) Lets say we have 3 node consul cluster



2) Now the full poweroff / outage happened
3) Lets say that after outage we manage to boot-up / recover nodes 1 and 2 - and node3 still stays down
4) Consul cluster forms with nodes 1 and 2 - quorum reached and cluster is operable - BUT nodelist is reduced/changed now to this (after reaping the node3 when node1-2 form the quorum):



5) Our problem is that we are running Ceph cluster on top of consul cluster - and we are using consul member list in order to provide local host resolution (and generated configuration) to it. There would be no problem if after outage consul cluster would recover with nodes 1 and 2 up only - and members list would look like this (providing correct status overview of a cluster - with the member list as it was before outage):



6) Ceph cluster would recover perfectly when node3 is still down yet present in members list (in failed state) - but it fails to recover when we are loosing node3 from nodelist/host resolution.

You could say that coupling local host resolution and ceph with consul members list is our problem :) But why Im thinking its a more generic problem for everyone? Because currently after outage and consul cluster auto-recovery you will end up with totally NEW cluster (changed member list) - in case enough nodes for quorum are up - but not all previous server nodes are up. I would expect that I will get OLD cluster status with failed nodes after outage - like it is also normally presented in case of node(s) failure (when still having quorum) - ie after outage I would expect to see this as members list (if node3 is still down):



Bottom line - I think if outage re-defines my cluster topology - its very wrong :) That basically means that we cant auto-recover stuff on top of consul cluster from outage.
",mainframe,ryanuber
924,2015-06-04 09:12:39,"@mainframe I think the problem is that the node reaping is ""best effort"" in Serf. We do not persist the failed nodes, and their 72h grace period is only in memory. This means during a full cluster shut down, that state is lost. When the cluster comes back online the ""failed"" nodes are gone and so they are immediately reaped.
",armon,mainframe
924,2015-06-04 09:18:53,"Thank you for explanation @armon. Would it be possible to make it persistent in the future releases or its by design?
",mainframe,armon
916,2015-05-07 19:02:48,"@Amit-PivotalLabs That is certainly strange. Could you attach some log files during one of these losses? It is generally useful to see both sides of the log (e.g. the node that was suspected of failure, and the node that did the suspecting, it should be clear which two nodes are involved via the logs). This may also expose some pattern of pairs.

With respect to the questions:

1) There is no current way to tune the underlying Gossip values, but that is a goal for 0.6 to expose the low-level tunable of both Raft and Serf. We've tried to just ship very conservative defaults for now. You could always do a custom build and update those values however.

2) This is totally possible. When a session is created, it associates with the ""serfHealth"" by default, but that is not necessary. You can just override the default and not associate with that check. That way it will not be used to automatically invalidate the session. Instead you can use the TTL-based sessions which are not susceptible to UDP issues.

3) Logs primarily. Enabling telemetry is generally useful as well, since you can look for correlations between various metrics that may be impacting the system. E.g. any spikes in the gossip metrics would be interesting.
",armon,Amit-PivotalLabs
916,2015-05-08 02:12:49,"Thanks @armon, that's great info.  We'll look into overriding the serfHealth check association and TTL-based sessions.  And enabling telemetry.

Here's a few examples of log snippets:










",Amit-PivotalLabs,armon
916,2015-07-12 09:26:17,"@Amit-PivotalLabs @armon 

I can confirm we see the same frequent membership loss issue in AWS. I will try to get some logs.
",aj-jester,Amit-PivotalLabs
916,2015-07-12 09:26:17,"@Amit-PivotalLabs @armon 

I can confirm we see the same frequent membership loss issue in AWS. I will try to get some logs.
",aj-jester,armon
916,2015-07-22 22:49:50,"Thanks @armon.

/cc @fraenkel @ematpl @luan see above comment from @armon re UDP routing issues.
",Amit-PivotalLabs,armon
916,2015-07-22 22:52:02,"@Amit-PivotalLabs As a heads up, the newest Consul builds from master do an additional TCP based health check. They will provide more debug output to help indicate a UDP routing issue and potentially help debug. Might be worth building from master to debug.
",armon,Amit-PivotalLabs
916,2015-07-22 22:54:07,"Thanks, @armon and @Amit-PivotalLabs!
",ematpl,Amit-PivotalLabs
916,2015-07-22 22:54:07,"Thanks, @armon and @Amit-PivotalLabs!
",ematpl,armon
916,2015-08-26 19:26:21,"Hi @ematpl, @armon  and @Amit-PivotalLabs did you finally find the root cause of this error? we are seeing the same error in our systems, also having 3 consul servers (one of them on-prem) in different AZ. Same errors appear in AWS hosts as well as in on-prem consul server. Is there any way to increase Timeout. 
Checking the logs, it is almost happening every hour in each client in our case. So, it's ""frequent"" enough.

We are seeing same errors in our logs:


",bruno-loyal3,armon
916,2015-08-26 19:26:21,"Hi @ematpl, @armon  and @Amit-PivotalLabs did you finally find the root cause of this error? we are seeing the same error in our systems, also having 3 consul servers (one of them on-prem) in different AZ. Same errors appear in AWS hosts as well as in on-prem consul server. Is there any way to increase Timeout. 
Checking the logs, it is almost happening every hour in each client in our case. So, it's ""frequent"" enough.

We are seeing same errors in our logs:


",bruno-loyal3,ematpl
916,2015-08-26 19:26:21,"Hi @ematpl, @armon  and @Amit-PivotalLabs did you finally find the root cause of this error? we are seeing the same error in our systems, also having 3 consul servers (one of them on-prem) in different AZ. Same errors appear in AWS hosts as well as in on-prem consul server. Is there any way to increase Timeout. 
Checking the logs, it is almost happening every hour in each client in our case. So, it's ""frequent"" enough.

We are seeing same errors in our logs:


",bruno-loyal3,Amit-PivotalLabs
916,2015-08-28 01:22:15,"@bruno-loyal3 This symptom almost always indicates a UDP routing issue. The best bet is to go to the nodes being marked as failed, and their logs should indicate which peer suspected it of failure. e.g. node ""ip-10-44-93-21"" will have a log saying something like ""refuting [suspect|dead] message from <other node>"". This indicates a routing issue between ""ip-10-44-93-21"" and <other node>
",armon,bruno-loyal3
916,2015-09-04 23:16:43,"@aj-jester: Everything we (myself, @ematpl, @fraenkel, @luan) have done has been in a VPC.
",Amit-PivotalLabs,aj-jester
916,2015-09-04 23:16:43,"@aj-jester: Everything we (myself, @ematpl, @fraenkel, @luan) have done has been in a VPC.
",Amit-PivotalLabs,ematpl
916,2015-09-04 23:40:30,"@aj-jester VPC here as well.  Can't figure this one out...yet.
",pl1ght,aj-jester
916,2015-11-15 02:04:10,"Just want to say that issue #1335 is connected to this also.

@djenriquez I've tried setting mtu to 1500 on all nodes where consul is installed, but we still face this issue, currently running on around 17 consul members, with just 1 leader (so we can say that this has nothing to do with any leader election problem)
",changwuf31,djenriquez
916,2016-01-25 15:14:06,"Running 0.6.3 on AWS as well (using Docker 1.9.1) and see serf membership leaving/joing such as has been described throughout this post. Does the 0.6.3 version of Consul ""expose low-level tunable of both Raft and Serf"" @armon ?
",draxly,armon
916,2016-01-26 02:18:08,"@draxly Likely 0.7 will expose more of the low level tunes, 0.6.3 does not. A high level of flapping almost certainly still indicates a network configuration problem as there are customers with thousands of nodes in AWS without issue. Later versions of Consul try to provide more helpful diagnostic log messages particularly in the case of misconfigured UDP connectivity.
",armon,draxly
916,2016-01-26 02:20:30,"@armon I would love my issue to be a configuration issue.  I have been running the cluster for over a year and it has been a consistent low level of annoyance.  Over the weekend it went 2 days without any flapping, but lost connection on sunday evening.
",sstarcher,armon
916,2016-01-26 03:17:48,"@sstarcher It's hard to give any real blanket answer unfortunately. Without access to a lot more information, there are so many potential root causes. The most common issue is simple misconfiguration. We've seen everything from Xen hypervisor bugs, to SYN floods, to driver bugs, to CPU/NIC exhaustion, and Serf bugs be the issue.

If its a very low level of flapping on a large cluster, often times it falls into the acceptable level of false positives, since no failure detector is perfect (its a trade off of time to detection vs FP rate). If its a very high level of flapping its likely misconfiguration as Serf works pretty well. If its somewhere in the middle, then a fairly extensive forensics needs to take place.

Unfortunately, we have only so much time to do support for the community in addition to the development on the core. Given reproduction cases or detailed reports we do our absolute best to solve the issue. Reports that are open ended with many possible root causes are much harder as they consume an enormous amount of time and are not necessarily an issue with Consul at the root.
",armon,sstarcher
916,2016-01-26 12:41:46,"@draxly We are running m3.mediums on Ubuntu 14.04.2LTS running inside of docker 1.9.2
We have UDP,TCP,ICMP fully open without our subnets and see similar issues.
",sstarcher,draxly
916,2016-01-26 18:13:25,"@sstarcher @draxly What you want to look for is the source of the flapping in the cluster. The failure detector works in roughly a ping/ack model, so Node A is pinging Node B and if that fails gossiping that Node B has failed (at a high level summary).  This log:



Indicates that `ip-10-7-1-190` is being marked as failed (Node B). That same node is refuting the claim about 20 seconds later and is marked as healthy again. I would check the logs on `ip-10-7-1-190` to see which peer is suspecting it of failing (Node A). There maybe a network issue between A <-> B. Alternatively, maybe there is some correlated issue with either A or B (high load, IO starvation, process crashed, etc).
",armon,sstarcher
916,2016-01-26 18:13:25,"@sstarcher @draxly What you want to look for is the source of the flapping in the cluster. The failure detector works in roughly a ping/ack model, so Node A is pinging Node B and if that fails gossiping that Node B has failed (at a high level summary).  This log:



Indicates that `ip-10-7-1-190` is being marked as failed (Node B). That same node is refuting the claim about 20 seconds later and is marked as healthy again. I would check the logs on `ip-10-7-1-190` to see which peer is suspecting it of failing (Node A). There maybe a network issue between A <-> B. Alternatively, maybe there is some correlated issue with either A or B (high load, IO starvation, process crashed, etc).
",armon,draxly
916,2016-01-26 18:26:22,"@armon I'm using docker with --net=host to remove the ARP problems.  My servers are highly over provisioned and run at 15% CPU for Consul.  I do see sporadic jumps in CPU every day or so randomly.   I was hoping my issue was #1592 , but after upgrading to 0.6.3 I still see issues, but it's starting to look like the issue is less often.
",sstarcher,armon
916,2016-01-26 18:43:08,"@sstarcher One trick I've used is to grep the logs for the Failed/Join events and use awk to aggregate by the node. See if the failures are random (each node is equally likely to fail) or if you see a concentration, sometimes it points to some problem node. We've sometimes had to just recycle EC2 instances that were particularly problematic.
",armon,sstarcher
916,2016-01-26 19:08:06,"@armon in the past 24 hours I have 2,907 occurrences of `EventMemberFailed`, but the large majority of these are members and not the 5 leader nodes.

On just my 5 leader nodes I have 253 occurrences of `EventMemberFailed` At one point in time in the last 24 hours every leader node has had someone report that EventMemberFailed for that node.

4 of the 5 nodes have reported at certain times that every other node has `serf EventMemberFailed`  Only a single node has no entries for EventMemberFailed.

This does raise an interesting point the 4 nodes that are complaining about each other are complaining about each other within 30 seconds of each other.

Jan 25th 19:50:43, 23:08:55, 23:09:11, 23:10:00
Jan 26th 00:17:09
",sstarcher,armon
916,2016-01-26 19:27:46,"@sstarcher when chasing these down sometimes it's useful to also look for strings like `Suspect node-10-0-1-8 has failed, no acks received` which will show the point in time when the ping failed and which node did the probe. Sometimes these events are correlated with things that starve I/O on the probe-er or the probe-ee.
",slackpad,sstarcher
916,2016-01-26 20:09:57,"@slackpad I see `no acks received` in a handful of occurrences, but never around a leader election issue.

The issue with the leaders is always related to `Failed to contact` In the below log 10.0.20.175 was the current leader it loses leadership and reaquires it.



On a node it failed to contact.


",sstarcher,slackpad
916,2016-01-27 09:04:29,"@armon, thanks for the pointers on how to look for potential errors.
Regarding using Docker, I have now tested to run Consul (both server and rest of agents) without Docker and experience the same problem. :/

A, perhaps unrelated question: On one of the servers, I saw a one-time message that I have not seen before:
[ERR] memberlist: Failed TCP fallback ping: read tcp 10.7.1.9:58713->10.7.1.224:8301: i/o timeout
Does this imply that TCP is used as fallback when UDP checks fail (I believe I have seen that mentioned somewhere as well)? If that is the case, shouldn't I see this regurlarly in my logs when encountering serf issues? Before a server is considered dead I mean?
",draxly,armon
916,2016-01-27 14:20:59,"@draxly yes a recent version added TCP as a fallback when UDP fails
",sstarcher,draxly
916,2016-01-27 14:32:16,"@sstarcher, is that fallback mechanism is enabled by default? If that is the case, both the UDP and the TCP checks have to fail in order for a node to be considered critical with regards to serf?
",draxly,sstarcher
916,2016-01-27 15:03:37,"@draxly I believe it is enabled by default and that both have to fail.
",sstarcher,draxly
916,2016-02-19 12:20:32,":+1: exactly @sstarcher's problems here as well :(
",doertedev,sstarcher
916,2016-03-08 11:57:46,"@draxly consul 0.6.x don't need GOMAXPRC due to golang 1.5.3 I believe
",sstarcher,draxly
916,2016-03-08 16:35:34,"@sstarcher, that was my understanding as well. @hack-s, can you please tell which version of Consul you are using where GOMAXPROCS helped? 
I will also run a test with setting GOMAXPROCS to 2 just in case =) 
",draxly,sstarcher
916,2016-03-08 16:35:34,"@sstarcher, that was my understanding as well. @hack-s, can you please tell which version of Consul you are using where GOMAXPROCS helped? 
I will also run a test with setting GOMAXPROCS to 2 just in case =) 
",draxly,hack-s
916,2016-03-11 16:07:39,"@hack-s any conclusions as to what might be the cause on 0.5.2 that is triggering nodes to flap? Did you have a mix of 0.5.2 and 0.6.3 nodes before? I am also experiencing nodes flapping from time to time. The cluster contains a mix of the versions.
",calvn,hack-s
916,2016-03-17 15:35:28,"@draxly can you vet the connectivity between those two hosts TCP and UDP in both directions on port 8301? It looks like there's something black holing the traffic so it doesn't refuse to connect but it times out trying.
",slackpad,draxly
916,2016-03-21 07:50:24,"@slackpad, I believe I have verified that by using netcat on both servers and seeing that tcp and udp connections are successfull. 
Also, this problem occurs a couple of times per day for the entire environment (10 servers) so it is a pretty infrequent problem. I'm starting to believe it might be something with the network between the Amazon EC2 instances but not sure how to verify this.
",draxly,slackpad
916,2016-03-21 18:12:17,"@draxly I am also seeing TCP fallback errors and the cluster is on AWS if that helps. Looking at the CloudWatch logs, I don't see any network i/o issue when the error appears. As you mentioned this issue only occurs from time to time, so it's definitely not a blocked port on anything of that sort. I also suspect that it could be a network issue between the EC2 instances, but am unsure as well how to verify this theory.
",calvn,draxly
916,2016-03-31 16:59:52,"@draxly This is probably for the same reason, but I do not see the flapping within our VPC that is set to dedicated tenacity. Just another data point that points to it being network related. Unfortunately, we use smaller instance types. I don't see why I need to run such a beefy machine with enhanced networking for consul to work properly. Seems like we just need some tunable thresholds within consul.
",blakeblackshear,draxly
916,2016-04-17 20:39:23,"@byrnedo We we previously using t2 instance types and noticed our cpu credits were never being used up.  Due to this we assumed the load on the server was not high enough to matter.  After we moved to m3.medium servers we immediately noticed we were wrong.  We also see significantly less leader elections.
",sstarcher,byrnedo
916,2016-04-26 11:30:13,"@rgardam, have you tried using EC2 instances with enhanced networking enabled? It does require a larger instance size, for example  m4.large, but it solved the problem for us.
It seems that 0.7 of Consul will include settings for configuring the agents to be more ""forgiving"".
",draxly,rgardam
916,2016-04-26 11:41:43,"@draxly I get that this potentially fixes the issue, but this is a big increase in cost that I feel shouldn't need to happen. I am running other systems without any issues on t2.micro's

I'm hoping that 0.7 reduces this issue.
",rgardam,draxly
916,2016-04-26 12:41:03,"@rgardam with any amount of real load Consul requires cpu.  We were seeing constant leader election even with m4.larges under our workload.  The moment we moved to c4's pretty much all elections went away.  If you want to lower CPU load instead of using consul template for individual keys store the entire config inside of one key.
",sstarcher,rgardam
916,2016-04-27 09:17:50,"@sstarcher That seems to have solved our problems (moving to `m3.medium`), thanks!
@rgardam I'm with you on the increase in cost
",byrnedo,sstarcher
916,2016-04-27 09:17:50,"@sstarcher That seems to have solved our problems (moving to `m3.medium`), thanks!
@rgardam I'm with you on the increase in cost
",byrnedo,rgardam
916,2016-08-10 20:53:14,"@rgardam we don't do any packet magic in Consul, that's an interesting presentation, though. We've spent some effort to make this better in the upcoming release of Consul - https://github.com/hashicorp/consul/pull/2101. A given host experiencing problems may still flap, but we've worked to reduce the damage that host is able to cause to the rest of the cluster.
",slackpad,rgardam
916,2016-08-17 02:46:32,"@rgardam Without spending time looking into it my guess would be it's related to gomaxproc/docker/t2 instance types.  When running inside of docker on a t2 instance type consul seems to use very little CPU, but the moment I move to a m3.medium the cpu usage shot up.
",sstarcher,rgardam
916,2016-08-21 22:45:31,"@paladin8 An overloaded agent can definitely cause another node to show as failed.  All the nodes randomly healthcheck each other, so bad node B that is overloaded and attempts to check good node G can erroneously timeout and gossip that G is down.  

My understanding is that other nodes will then recheck G, so it takes a confirmation to actually mark it as dead. However, if you have multiple overloaded nodes then there is a chance that both the primary and secondary check could land on overloaded nodes and mark G as down. 
",jhmartin,paladin8
916,2016-08-22 03:17:09,"@jhmartin Thanks for the reply. If that's the case, I would guess that a specific node or set of nodes would appear to be frequently marking random other nodes as failed/dead, but we aren't observing any patterns among the nodes that are doing the marking (i.e. those logging messages like ""memberlist: Marking {host} as failed, suspect timeout reached""). Does that sound like it rules out any issue related to an overloaded machine performing a check?
",paladin8,jhmartin
916,2016-09-16 23:05:17,"@paladin8 if it doesn't look like there's a small set of source hosts then that seems like it might be a network issue. That timeout reached message is the right one to look for in the logs to see who's actually detecting another node as failed.
",slackpad,paladin8
915,2015-05-07 17:44:08,"@devinrsmith not at this time. A pretty common use case is to use a `service/` top-level key, and namespace services within it, like:



Using ACL's you could also protect each keyspace with a different token if isolation is a concern. Does that cover your use case?
",ryanuber,devinrsmith
913,2015-05-07 17:48:55,"@Kosta-Github this sounds like a bug, thanks for reporting!
",ryanuber,Kosta-Github
912,2015-05-08 18:38:49,"@rojojo23 Great catch! Thanks!
",armon,rojojo23
911,2015-05-06 18:19:24,"@kaelumania The explanation given by @highlyunavailable is dead on. The peers file is only ever edited during an outage, which is defined as a loss of quorum for Consul. This means a majority of servers are offline or cannot communicate. In that case, the cluster cannot safely make changes to the peer set because it is unable to coordinate. Typical operation of adding/removing servers does not require that process.

Closing the ticket, but please re-open if you have an issue!
",armon,kaelumania
911,2015-05-06 18:19:24,"@kaelumania The explanation given by @highlyunavailable is dead on. The peers file is only ever edited during an outage, which is defined as a loss of quorum for Consul. This means a majority of servers are offline or cannot communicate. In that case, the cluster cannot safely make changes to the peer set because it is unable to coordinate. Typical operation of adding/removing servers does not require that process.

Closing the ticket, but please re-open if you have an issue!
",armon,highlyunavailable
911,2015-05-06 19:41:21,"@armon @highlyunavailable thank you very much. Can you say something about my second comment?
",kaelumania,armon
911,2015-05-06 19:41:21,"@armon @highlyunavailable thank you very much. Can you say something about my second comment?
",kaelumania,highlyunavailable
911,2015-05-06 20:03:22,"Any ""server"" can serve a read, but depending on how consistent you require your read to be, there may be round-trips needed to `N/2+1` members of the cluster to verify the value is current. Check out the [HTTP API](https://www.consul.io/docs/agent/http.html) docs, specifically the ""Consistency Modes"" section.

The short answer is: The leader is involved in ""default"" and ""consistent"" level reads though it may not directly service the read. The ""consistent"" mode involves N/2+1 servers, one of which must be the current leader. The ""stale"" consistency mode allows any server immediately service a read. In other words, yes, all non ""stale"" consistency mode reads will eventually talk to the leader though other servers may actually be servicing the request (that is, actually have an open TCP connection to the client).

Watches are a special case - as I understand them (and correct me if I'm wrong, @armon), the state change events are what trigger watches to complete, so the act of writing to the local state machine as part of replicating an update across the cluster will cause the server to send out the data - this is not the same as a request to the leader and a response from the leader.
",highlyunavailable,armon
911,2015-05-06 22:10:05,"@kaelumania The explanation by @highlyunavailable is almost perfect. Watches actually aren't a special case, and are just like normal reads and even will respect the consistency modes. Raft is implemented like the paper, and the Serf/Gossip data is not used for replication.

In the ""default"" read mode, all reads are serviced by the leader. The ""consistent"" read mode forces an additional heartbeat round trip on read. The ""stale"" mode allows any server to service the read, and thus does load shedding from the leader.

Hope that helps!
",armon,kaelumania
911,2015-05-06 22:10:05,"@kaelumania The explanation by @highlyunavailable is almost perfect. Watches actually aren't a special case, and are just like normal reads and even will respect the consistency modes. Raft is implemented like the paper, and the Serf/Gossip data is not used for replication.

In the ""default"" read mode, all reads are serviced by the leader. The ""consistent"" read mode forces an additional heartbeat round trip on read. The ""stale"" mode allows any server to service the read, and thus does load shedding from the leader.

Hope that helps!
",armon,highlyunavailable
911,2015-05-07 07:28:33,"@highlyunavailable thanks once again. If I understand you right, any server can answer a request, but internally checks the value with the leader?

@armon Does that mean that if I have 1000 nodes with each 2 watches (via `consul watch`) there are 2000 blocking queries to the leader node? Further for stale reads how is decided which server answers the request or does the client address a specific server? For example, when a read request is send out via serf and arrives multiple servers. How is ensured that only one server answers or is the client responsible for de-duplication? How do I configure watches to use stale consistency mode?

Thanks.
",kaelumania,armon
911,2015-05-07 07:28:33,"@highlyunavailable thanks once again. If I understand you right, any server can answer a request, but internally checks the value with the leader?

@armon Does that mean that if I have 1000 nodes with each 2 watches (via `consul watch`) there are 2000 blocking queries to the leader node? Further for stale reads how is decided which server answers the request or does the client address a specific server? For example, when a read request is send out via serf and arrives multiple servers. How is ensured that only one server answers or is the client responsible for de-duplication? How do I configure watches to use stale consistency mode?

Thanks.
",kaelumania,highlyunavailable
911,2015-05-07 19:30:22,"@kaelumania That is correct, there would be 2K blocking queries. A client can't pick the server that answers, instead a random server is always selected under the hood. The requests are not sent via Serf, the client uses a dedicated TCP connection for RPC requests so you only ever get one response, no need to handle de-duplication

Blocking queries take the ""?stale"" flag to enable that mode, I'm not actually sure this is exposed for watches however. I'll make a ticket for it!
",armon,kaelumania
911,2015-05-08 08:22:07,"@armon thanks, it might be useful to add an article to the consul documentation about which parts use serf and which parts use raft etc. Do you think 2000 blocking queries to the leader might be problem?
",kaelumania,armon
907,2015-05-05 20:46:56,"@ingardm Consul handles running out of file descriptors in a really poor manner currently. The best solution is to increase ulimit to something insane such that it's never reached.
",armon,ingardm
906,2015-05-05 20:47:41,"@marc- This should already be fixed in master. Can you confirm? It will go out with Consul 0.5.1
",armon,marc-
905,2015-05-06 18:29:23,"@maver1ck Is this something that you guys need? To me prefix-based on service name seems a bit odd. I think exact match is simpler to reason about, but I'd appreciate the feedback
",armon,maver1ck
905,2015-05-06 19:02:28,"@maver1ck This makes sense to me!
",armon,maver1ck
904,2015-05-05 01:05:32,"@josephholsten this looks much better, thanks! RE: command naming, I think `configtest` is fine. I left some minor comments, and it looks like we are missing the middleman documentation, so if you want to add that feel free. Otherwise, we can also take care of it after a merge.
",ryanuber,josephholsten
904,2015-05-05 18:14:59,"@ryanuber care to review the code again? I'll get the middleman doc ready
",josephholsten,ryanuber
903,2015-05-04 19:14:51,"Hey @josephholsten,

I think we can test the configuration relatively easily by making just a single call to `ReadConfigPaths` from the `agent` package. You can basically just pass it an arbitrary path, so I think the CLI could even just accept a `[]string` for the args, and we can directly pass it into `ReadConfigPaths`.

This shouldn't require any code copying or anything like that. Make sense?
",ryanuber,josephholsten
903,2015-05-04 19:31:30,"@ryanuber please check #904, it's free of code copying.
",josephholsten,ryanuber
900,2015-05-04 00:04:38,"@ryanbreen feel free to merge this and move the link to the section you feel fits best
",ryanuber,ryanbreen
899,2015-05-04 04:01:57,"@ryanbreen that is a neat approach! Automatically mirroring git commits into Consul via a webhook is a very interesting idea.
",rhelmer,ryanbreen
899,2015-05-04 21:28:08,"@rhelmer, yeah, I thought this might be a good fit for you because it seems our usage is pretty similar.  We have a bunch of configuration files we want to splat out onto the filesystem of remote hosts, so we use git2consul because we want to manage / version those in git and distribute them using Consul.  We then use http://github.com/cimpress-mcp/fsconsul to write them to disk on remote systems.  It makes a nice complement to git2consul.

If that seems like a good fit for you, it might make sense to close this ticket.  It's up to @armon and @ryanuber, of course, but IMHO it seems unnecessary to modify Consul itself if the constellation of tools around Consul can provide the desired functionality.
",ryanbreen,rhelmer
897,2015-04-30 22:58:03,"Hey @devinrsmith,

It looks like you may have found an oversight in our getting started guide. In order to get this to work, you can pass the `-config-dir=/etc/consul.d` argument to the agent (documentation on that option is [here](https://www.consul.io/docs/agent/options.html#_config_dir). Once that is done, then using `SIGHUP` should allow Consul to reload its configuration files. If no `-config-dir` is specified, then Consul won't know where to load the files from.

We'll get this fixed up in the guide. Thanks!
",ryanuber,devinrsmith
897,2015-10-26 08:15:04,"@ryanuber: I just ran into this one as well.. it was fixed in #1127 but that commit has not made it to the website yet.
",robinroestenburg,ryanuber
895,2015-04-29 20:18:32,"@grantr eventually! We've had requests for it before so I think it makes sense to add it as long as the JSON format is preserved. The main want seems to be around adding comments to configs/service definitions etc which seems reasonable. Marking as an enhancement.
",ryanuber,grantr
895,2015-04-29 20:34:30,"Yep, comments would be great. Thanks @ryanuber!
",grantr,ryanuber
894,2015-05-06 19:09:49,"Hi @domrod, were you able to get this sorted out? At first glance it does sound like a network issue, as @Erfane pointed out above.
",ryanuber,Erfane
894,2015-05-06 19:09:49,"Hi @domrod, were you able to get this sorted out? At first glance it does sound like a network issue, as @Erfane pointed out above.
",ryanuber,domrod
893,2015-05-03 22:29:21,"Hey @petemounce,
I'm not sure I follow entirely, but there currently isn't an officially supported repo for anything like this. Any official Consul releases and code will be found either on this GitHub repo, or on the consul.io website. Please do let us know if you have found another source claiming to be officially HashiCorp supported.
",ryanuber,petemounce
893,2015-05-03 23:21:25,"Hi @ryanuber 
- [this is the link to the chocolatey package](https://chocolatey.org/packages/consul)
  - the comments (scroll down) are what I'm talking about.
- I _think_ the package source is https://github.com/sitano/chocolatey-packages, and I would guess community-provided.
  - this is the maintainer: https://chocolatey.org/profiles/mirthy

However, the chocolatey package lists @mitchellh and @armon as authors, so I assumed it was owned by Hashicorp.

I've used the package to bootstrap my use on Windows nodes - it saved me needing to figure out a service wrapper and so forth.
",petemounce,ryanuber
892,2015-05-07 18:59:59,"It should persist past refresh, that would be a bug. It's saved in local storage.

The only conceivable way to share it would be to tack it on to the query param, which as @armon noted would be pretty unsafe. But it's an option and doable.

Otherwise, don't know how you could share.
",pearkes,armon
890,2016-02-13 01:17:20,"@nicholascapo, this was completed in #1714 .
",sean-,nicholascapo
890,2016-02-13 01:51:58,"Excellent! Thanks for following up.

Nicholas

On Fri, Feb 12, 2016, 19:17 Sean Chittenden notifications@github.com
wrote:

> @nicholascapo https://github.com/nicholascapo, this was completed in
> #1714 https://github.com/hashicorp/consul/pull/1714 .
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/890#issuecomment-183552261.
",nicholascapo,nicholascapo
889,2015-04-29 04:39:36,"Hey @mikerobins,

Internally, we are just using Go's `net/http` to do the request, which always parses and unescapes the URL (you can follow this in the codepath [here](http://golang.org/src/net/http/request.go?s=15726:15798#L482)). To avoid this we would need to do some hand-crafting or dissection/replacement of certain parts of the request, so I would say that the best way to handle this for now is to just use a script.
",ryanuber,mikerobins
887,2015-04-29 04:46:10,"Hi @ambiguous,

This is a dupe of #741. We do have plans to support controlling the low-level timing values for the gossip layer via the configuration file. Let's track this over in the other issue.

Thanks!
",ryanuber,ambiguous
886,2015-04-29 23:11:51,"@ryanuber Thanks, this feature will be much appreciated.

For anyone's interested: atomicity can also be achieved in the watcher handler level with an implementation close to the following:

Consider that there are N keys we would like to update atomically, at once: 
Create each key value in the following format:
`<value1>:1:N:<uuid>`
`<value2>:2:N:<uuid>`
`...`
`...`
`<valueN>:3:N:<uuid>`

Where `<valueN>` is the actual value of the Nth key in the bulk and `<uuid>` is a unique identifier we assign to the bulk to differentiate it from other bulks.

The watcher handler keeps a map of uuids to a list of KVs.
When a KV update occurs, the handler peeks at it's value and seeks for the format mentioned above.
In case there's a match: it will add the KV to list of KVs which is mapped by the 'uuid'.
It will then check if this list reached the size of N (the handler knows what N is since its part of the above format as well).
If the list reached the bulk size then we can safely execute some action (in our use case it was a curl command which sends the the entire KV list in one bulk to a web server endpoint).
",mikeys,ryanuber
885,2015-05-03 22:35:23,"Hi @timothysc,
I'm not aware of any comparisons in this sense. We have a general feature comparison against various solutions available on the consul.io website, but otherwise I don't know that there have been any performance comparisons published for recent versions of consul vs. etcd.
",ryanuber,timothysc
882,2015-04-29 04:52:36,"@jsternberg this involves both serf and the even lower-level memberlist package. As @armon mentioned the changes required will be deep and involved, so before starting any work it would be best to start brainstorming in a Google Docs document about the design, as there are certainly a very large number of considerations to make here.
",ryanuber,armon
882,2015-04-29 04:52:36,"@jsternberg this involves both serf and the even lower-level memberlist package. As @armon mentioned the changes required will be deep and involved, so before starting any work it would be best to start brainstorming in a Google Docs document about the design, as there are certainly a very large number of considerations to make here.
",ryanuber,jsternberg
882,2015-06-25 14:41:23,"Please include me (@armon), @ryanuber and @slackpad. 
",armon,armon
882,2015-06-25 14:41:23,"Please include me (@armon), @ryanuber and @slackpad. 
",armon,ryanuber
880,2015-04-23 10:22:21,"@armon Great, thanks! I think this should be documented? I'd say this is a concern everyone who is replacing nodes in the cluster automatically has. But I'm good, so feel free to close this ticket if you want.
",discordianfish,armon
876,2016-01-27 02:31:42,"@armon, has this been implemented in 0.6.0?

We have a unit test that tries to call api.client.KV().Acquire() twice, expecting the first to succeed and the second to fail. This is the behavior seen in agent v0.5.2, but agent v0.6.0 allows the 2nd Acquire() to succeed.

How exactly has the semantics of Acquire() changed?
",chnrxn,armon
876,2016-01-27 03:09:35,"@chnrxn indeed this changed in 0.6.0, sorry to leave this issue open! The details are here:

https://github.com/hashicorp/consul/blob/v0.6.0/CHANGELOG.md#060-december-3-2015
",slackpad,chnrxn
875,2016-06-21 15:36:58,"@slackpad - Would love your feedback on the above PR! I could also use advice on inconsistent test failures that I'm seeing in Travis - all tests are passing consistently in my local dev environment. 
",tshak,slackpad
871,2015-04-20 13:57:16,"Hi @alex-leonhardt 

Thank you for opening an issue. This is a duplicate of https://github.com/hashicorp/consul/issues/61, but the short version is that we prefer to focus on building new features at this time. The nature of the static binary distribution makes it very easy to distribute and install without native OS packages. Perhaps this will be something we can revisit in the future, but it is not a top priority at this time. Please let me know if you have any questions.
",sethvargo,alex-leonhardt
867,2015-04-23 01:50:00,"@deadjoe You can just re-register the services with the updated tags. No need to deregister first.
",armon,deadjoe
866,2015-06-18 23:20:42,"@williamsjj You should just stand up a sandbox environment and try it out. It is very unlikely that the raft size will be an issue. The file grows to accommodate a ""working set"" which is usually on the order of tens of megabytes.
",armon,williamsjj
866,2015-09-14 14:26:51,"To clarify @activars's post: Our situation is subtly different, in that it's the snapshots that take up the bulk of the space:


",pdpi,activars
866,2015-11-18 16:25:27,"Hi @chnrxn - hundreds of gigs is super unusual. Can you summarize which files are taking up all the space in the `raft` directory in your Consul data-dir? It would be interesting to see if snapshots are not being cleaned up or something.
",slackpad,chnrxn
866,2015-11-18 16:51:35,"Hi @slackpad, 

It's actually (just?) 100G, which is all raft.db.

Using strings tells me that it seems to be full of KV data and consul-replicate statuses. We are writing about 20 numeric values into the KV every 20 seconds and doing peer-replication with another consul DC.

Snapshots are really just 60k.

$ ls -lh /var/lib/consul/raft
total 100G
-rwxr-xr-x  1 consul consul  107 Oct 12 08:26 peers.json
-rw-------  1 consul consul 100G Nov  4 04:10 raft.db
drwxr-xr-x 17 consul consul 4.0K Nov  4 04:12 snapshots
$ ls -lh /var/lib/consul/raft/snapshots
total 60K
",chnrxn,slackpad
866,2016-01-09 00:30:44,"@chnrxn that's super weird since the raft db should get compacted periodically. Do you see any new snapshots being created in your logs and in your data-dir?
",slackpad,chnrxn
866,2016-01-11 05:09:30,"@slackpad, not any more after I cleared those huge ones and restarted Consul. (and those happened 2 out of maybe 30 machines).
",chnrxn,slackpad
866,2016-01-26 18:09:18,"@freeseacher The raft.db itself its a B-Tree that only grows. Once it compacts, it manages free space internally, but the actual file is never reduced in size. Under heavy write load the file grows, and then we internally truncate and re-use space within the file. Its a limitation of the BoltDB underneath, and typically the file size settles to support the steady state of the cluster.
",armon,freeseacher
866,2016-02-02 02:59:37,"@chnrxn in theory something like that should work if you were to stop Consul first. Once Consul has done a Raft snapshot / compaction it might be easier to just swap out a sever, though. Newly-added servers will only get the actual working contents of the Raft log, and shouldn't have the size bloat from the previous benchmarking.
",slackpad,chnrxn
866,2016-02-02 05:23:59,"@slackpad, if I understand you correctly, I could just have an external process control (e.g. daemontools) stop Consul, remove the Raft DB, and restart Consul (of course one host at a time)?
",chnrxn,slackpad
866,2016-02-02 05:44:33,"@chnrxn potentially, though it would be tricky because you'd need to wait for the cluster to take a snapshot after the expensive load testing / etc. If you take a server out, clear out its state in the data-dir, and join it back with the other servers then it should receive the snapshot + the much smaller compacted Raft log.
",slackpad,chnrxn
866,2016-02-02 07:28:57,"@slackpad how can I tell when a snapshot has been taken, or when a compaction has been done? Is there anything in the logs I can watch out for, or something?
",chnrxn,slackpad
866,2016-04-25 06:27:59,"HI @Omeryl currently the only workaround is to replace the servers after a snapshot. It sounds like it could be tricky to compact the DB automatically, so we will need to do some investigation there.
",slackpad,Omeryl
866,2016-10-07 21:14:52,"@slackpad couldn't I just remove server one by one from cluster, delete the entire data directory, then add back the particular machine back into the cluster.

We are facing a similar issue and need to resolve this quickly.
",myusuf3,slackpad
866,2016-10-10 21:16:46,"any ideas here, other than deploying new cluster? @armon 
",myusuf3,armon
866,2016-10-10 21:32:49,"@myusuf3 you are correct that rolling the servers one-by-one should correct this. I was thinking that you'd want to wait for it to snapshot so the newly-added servers wouldn't get a bunch of raft log entries replayed, but the leader will fall back to a snapshot fairly quickly anyway if you introduce a server with a fresh data directory.
",slackpad,myusuf3
866,2016-10-10 21:48:07,"@slackpad well I am not convinced that's how it works, I recently had to replace a server and introduced it to the cluster and now its raft.db is just as big as the others, it was a new server with clean data directory. 

What is exactly the process you are describing? Also is there a way to know when I snapshot was completed other than grepping logs and waiting?

Do you mean to say new servers added won't have this bloat? If so how do you explain new server I recently added to the cluster. 

Lastly, by data directory, you mean parent folder containing raft.db and snapshot directories?
",myusuf3,slackpad
866,2016-10-10 22:03:03,"@myusuf3 ok then that means there's a problem in one of two places. Either snapshots are not happening correctly or that logs aren't getting truncated correctly after a snapshot. When a new server joins, it will indicate to the leader what index it knows about (for a new server this will effectively be zero), so usually the leader will send the last snapshot followed the the log entries that occurred after the snapshot. If there was something that caused the raft.db to bloat, I would not expect it to be carried over to the new server.

In your case it's not clear what happened and it seems like whatever went into the Raft log that caused the bloat got replicated to the new server. Deleting the parent folder with raft.db and snapshots is the right way to remove the data, that's what I meant by new server. Right now the logs are the only way to see the snapshots happen (0.7.1 will have an API to force a snapshot). Do you see any of those in your leader logs? Do you have any logs from when you joined the new server (logs from the leader and the new server)?
",slackpad,myusuf3
866,2016-10-10 22:07:53,"@slackpad hmm. logs incoming.
",myusuf3,slackpad
866,2016-10-10 22:23:25,"@slackpad anything specific we are looking for here? there are quite a few logs!
",myusuf3,slackpad
866,2016-10-10 22:29:38,"@slackpad also getting this on the leader since the 6th 


",myusuf3,slackpad
866,2016-10-11 00:11:55,"@slackpad possibly our health checks are comprehensive, so removing box from cluster one by one deleting data directory `consul/data` and adding them back to the cluster should reclaim disk usage? Wouldn't we see behaviour like we just saw for the newly added node? 
",myusuf3,slackpad
866,2016-10-11 14:18:58,"@slackpad on leader? quite often
",myusuf3,slackpad
866,2016-10-11 14:19:41,"> @slackpad possibly our health checks are comprehensive, so removing box from cluster one by one deleting data directory consul/data and adding them back to the cluster should reclaim disk usage? Wouldn't we see behaviour like we just saw for the newly added node?

More interested about this though ^^
",myusuf3,slackpad
866,2016-10-11 14:55:03,"@myusuf3 yes if you have something rapidly committing ~1 MB entries to the Raft log that could use up space pretty quickly, even for a fresh set of servers. Something like this query will locate your top health checks by output size:


",slackpad,myusuf3
866,2016-10-11 15:45:21,"@slackpad well those machines have been running for over a year and I would image that this isn't issue atm, but totally possible but I would imagine I would have seen this issue earlier. Regardless how do I fix this issue without taking out production since it seems like cluster seems to be replicating the large raft.db to new machines
",myusuf3,slackpad
866,2016-10-11 16:07:58,"@myusuf3 you'd have to locate the source and adjust that health check to not produce a large output because it seems like some process is repeatedly creating new, large log entries. I think a health check should be the only thing capable of making such a large log entry in Consul prior to 0.7.
",slackpad,myusuf3
866,2016-11-13 23:26:12,"@slackpad cool! so we upgraded to Consul 0.7 and have removed consul 0.5.\* from our system completely. As you mentioned adding new machines to the cluster and having it have a clean `raft.db` wasn't true in consul 0.5.\* but it is true for Consul 0.7. When we would previously add machine it would copy the entire `raft.db` or what looks to be the entire thing to the new box. 

Anyways that was an observation ^^

The issue I am seeing now is that `raft.db` for the old boxes that was at 70% disk usage isn't going down and I would like to clear that up since it's dangerously close to full. 

Is it safe to remove the node from cluster `rm -rf /data/` and restart consul add it back to the cluster? Then repeat for all the remaining servers to reset disk usage or not?
",myusuf3,slackpad
866,2016-12-09 00:04:07,"@Nomon so doing this rotating per machine till they came back up, but didn't have bloat and that worked. 

I will give it a shot, but recently added a new box and it matched the machines in bloat as well. ",myusuf3,Nomon
862,2015-04-18 00:06:00,"@ryanuber I'm not sure I understand, this looks like it will pass through the CNAME but won't actually resolve it.
",armon,ryanuber
862,2015-04-18 00:23:29,"@armon so maybe we were thinking two different things. If a recursor is provided in Consul's configuration, the recursor handles resolving the CNAME as it should. However, when Consul crafts the DNS reply, it currently returns only the first CNAME, and the resulting A or AAAA record, so the response ends up looking something like this:



Notice that the above CNAME chain is broken because we are missing the intermediate CNAME's. It was my understanding that this is what was breaking the clients. After patching, we get the full chain:



Were you thinking that Consul would act as its own DNS recursor if none was configured?

One other thing I was going to ask about was the limit on # of records. I am guessing that it was to make DNS responses smaller if many A records are returned, but in these cases this might be limiting, which is why I bumped it slightly to 5. Any thoughts on that?
",ryanuber,armon
862,2015-05-04 22:19:13,"@ryanuber I see. Makes sense!
",armon,ryanuber
862,2015-09-11 18:45:12,"@bradmurray Do you have a `recursor` configured for Consul?
",armon,bradmurray
861,2015-04-13 19:45:35,"@fraenkel I've left some feedback, I think a more minimal change is possible and avoids additional nesting.
",armon,fraenkel
861,2015-04-14 02:33:32,"@artushin I couldn't quite figure out what you changed but I do now use the lockSession instead.
@armon I went with your approach but had to play some variable declaration games so no new variables were introduced.
",fraenkel,artushin
861,2015-04-14 02:33:32,"@artushin I couldn't quite figure out what you changed but I do now use the lockSession instead.
@armon I went with your approach but had to play some variable declaration games so no new variables were introduced.
",fraenkel,armon
861,2015-04-14 03:10:04,"@artushin I would expect ErrLockHeld to be returned if it's already held. What is the issue? I may just not be understanding. Maybe a diff only gist would help clarify?
",armon,artushin
861,2015-04-14 03:50:32,"@artushin I understand what you are saying now. I would suggest a separate PR which will also need a new test case since you are adding new behavior that I don't believe is currently covered.
",fraenkel,artushin
859,2015-04-12 20:29:25,"@salehe we will still need to be able to pass check status during check registration, because we have service checks as well as node checks (not attached to any particular service). We should support passing the status in for both. This also keeps things simple. We would otherwise need to create a new field for storing the default status of the service, and persist that with the registration to be able to use it as checks were added later on.
",ryanuber,salehe
859,2015-04-13 19:47:41,"@Heuriskein We should not allow ""unknown"" as it is being deprecated. It is already mostly on the way out, but the constants are left for backwards compatibility.
",armon,Heuriskein
859,2015-04-13 21:14:15,"Removed unknown.

On Mon, Apr 13, 2015 at 12:47 PM, Armon Dadgar notifications@github.com
wrote:

> @Heuriskein https://github.com/Heuriskein We should not allow ""unknown""
> as it is being deprecated. It is already mostly on the way out, but the
> constants are left for backwards compatibility.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/859#issuecomment-92475777.
",Heuriskein,Heuriskein
859,2015-05-11 23:43:19,"@Heuriskein Thanks! Sorry about the delay!
",armon,Heuriskein
857,2015-04-11 02:33:44,"@ryanbreen not all of them, actually. We still use an in-memory only LMDB for Consul's state store, so for example, the FAQ entry about virtual memory size should be left intact until we completely remove it in 0.6. Anything specifically about the Raft log + LMDB can be updated though.
",ryanuber,ryanbreen
855,2015-04-10 17:01:45,"@fraenkel Good call, that should be an easy enough check! Tagging as bug
",armon,fraenkel
854,2015-04-10 17:24:55,"This is a problem for people compiling with `CGO_ENABLED=0` and using Consul for DNS in Go 1.4+.

I've [created a gist](https://gist.github.com/cjhubert/d4f4e547129abd20891b) to show the exact code we're running in the output below.

In Go 1.3.3, the above code outputs the following. Note that the 401 response is correct, I just wanted to show that the DNS resolves.



In Go 1.4.2, with the same exact code this is output:



Note the error: `cannot unmarshal DNS message`. According to tcpdumps, the response we're getting back from Consul DNS is ~700 bytes. After [the change](https://github.com/golang/go/blob/master/src/net/dnsclient_unix.go#L42) to `readDNSResponse()` that @fedyakin linked, the max response must be under 512 bytes.

The same DNS response when using `8.8.8.8` is only ~200 bytes, since it's using [message compression](https://www.ietf.org/rfc/rfc1035.txt).

We're using `CGO_ENABLED=0` since we run in `FROM scratch` docker containers.

For now, we've found a workaround. It involves setting the Consul config to not recurse (before, it was set to `8.8.8.8`.



And then, when running the docker container, setting the first DNS as Consul (which is advertised on the `docker0` interface, and setting a fallback of `8.8.8.8`.



Edit: For anyone who is using the workaround, note that's only good if you don't actually need Consul to recurse through DNS. I would look at #971 if you do need it to recurse (though, while using #971, Consul seems to panic from #1023)
",cjhubert,fedyakin
854,2015-06-04 18:59:33,"@armon Just FYI, we (Docker) just changed the registry dns name to a CNAME which means this bug (or netgo but, see my linked issue) is breaking everyone using docker and consul with recursor right now.
",discordianfish,armon
854,2016-06-20 10:43:31,"@thebenwaters it's a horrible one, but you can run your container in host network mode I think.
",hermansc,thebenwaters
854,2016-06-20 10:49:54,"@hermansc I don't think this makes any difference. But there might be unrelated udp issues with Docker:
- https://github.com/docker/docker/issues/11998
- https://github.com/docker/docker/issues/8795
- https://github.com/docker/docker/issues/7540
",discordianfish,hermansc
854,2016-08-05 16:53:16,"@slackpad Hi.  Is there a resolution for this one in the works?
",tmichaud314,slackpad
854,2016-08-17 22:38:38,"@slackpad Are these fixes in the master branch?
",tkambler,slackpad
854,2016-08-17 22:44:43,"@tkambler yes they are in master - please let me know if you still see any issues.

DNS compression is [opt-out](https://www.consul.io/docs/agent/options.html#disable_compression) so you shouldn't need to do anything special to enable it with a later build. Earlier today we announced a release candidate build of 0.7 that's not ready for production yet, but has these fixes if you'd like to test using that - https://groups.google.com/d/msg/consul-tool/7KDuvdwNpi0/LSY5LiPnCwAJ.
",slackpad,tkambler
852,2015-04-10 05:15:52,"This is definitely something we plan on pinning down in a v2 API. We are planning this internally, but it's not on our roadmap at this point for near-term work. @fraenkel is right on the money on this one.

I'm going to close this because we can't change the v1 API response format at this point. Thanks for the report, and watch for a v2 API in the future.
",ryanuber,fraenkel
852,2015-04-10 18:09:40,"@fraenkel You're correct, the response isn't technically malformed. I should have said that the response content-type was incorrect and that it should have been `application/json` for consistency.

@ryanuber Fair enough. I'll keep an eye out for when the v2 API is released for this bug fix.
",mtougeron,ryanuber
852,2015-04-10 18:09:40,"@fraenkel You're correct, the response isn't technically malformed. I should have said that the response content-type was incorrect and that it should have been `application/json` for consistency.

@ryanuber Fair enough. I'll keep an eye out for when the v2 API is released for this bug fix.
",mtougeron,fraenkel
851,2015-04-17 18:15:16,"I think it may make sense to support a `?persist` flag to flag the persistence off on a per-service registration. Thoughts @jefferai @ryanuber?
",armon,jefferai
851,2015-04-17 18:15:16,"I think it may make sense to support a `?persist` flag to flag the persistence off on a per-service registration. Thoughts @jefferai @ryanuber?
",armon,ryanuber
851,2015-04-17 20:34:11,"Tagged as an enhancement, thanks @jefferai!
",ryanuber,jefferai
849,2015-04-08 22:09:55,"@abronan You are right that the client has no way of handling failover on its own. Normally we rely on Consul's DNS server for this. If you are able to resolve the .consul zone, then you could just point your api client at consul.service.consul, which should always return a healthy consul server node.

Hope that helps!
",ryanuber,abronan
849,2015-04-08 22:13:32,"Thanks for the quick answer @ryanuber! That's all I wanted to know ;-)
",abronan,ryanuber
843,2015-04-27 20:28:14,"@ryanbreen @dpurrington this is definitely in the crosshair for 0.5.1 (the next release of Consul), which should be on its way out in the coming weeks. The release won't go out the door without this.
",ryanuber,ryanbreen
843,2015-04-27 20:28:14,"@ryanbreen @dpurrington this is definitely in the crosshair for 0.5.1 (the next release of Consul), which should be on its way out in the coming weeks. The release won't go out the door without this.
",ryanuber,dpurrington
841,2015-04-06 17:36:45,"@armon This happened for quite some time (several minutes at least) after all nodes were up and running, so it wasn't just, as expected, during the initial bootstrapping. Once I started the cluster one-by-one, things worked as expected.
",discordianfish,armon
840,2016-09-21 18:09:38,"@slackpad May I ask how txn solves this? You can only do PUTs in a txn, so how do I combine a PUT (to unlock) and DELETE?
",fraenkel,slackpad
840,2016-09-21 18:17:06,"@fraenkel with the /v1/txn endpoint you PUT a JSON structure with a list of operations to perform - you would PUT a structure like this:



These are done atomically, so if the unlock succeeds it will delete the key as part of the same request.
",slackpad,fraenkel
840,2016-09-21 18:18:13,"@slackpad The docs say PUT is only supported which is why I asked. Ah, so that meant you PUT /v1/txn but any verb is supported.
",fraenkel,slackpad
838,2015-04-02 16:39:30,"@discordianfish this is a symptom of #457. There is a bit more to it since the node IP addresses are persisted on other members of the cluster as well, but we are very aware of this. Let's track this in #457. Thanks for reporting!
",ryanuber,discordianfish
836,2015-04-10 16:13:02,"@armon thanks that worked
",sge-babrams,armon
835,2015-04-02 16:42:20,"Thanks @ryanuber!
",grantr,ryanuber
834,2015-06-02 22:27:14,"Hey @apoydence,

Since this change is actually in the KV code, I'm not sure it would fix the 301 on the HTTP endpoint side.
I'm also not sure about the utility, since a client can follow the redirects and still succeed in doing the PUT. Let me know if I'm missing something here.
",ryanuber,apoydence
834,2015-06-05 02:17:39,"@ryanuber If the key name ends with a '/' then it messes up the URL that's built.
",apoydence,ryanuber
834,2015-06-05 22:23:55,"@apoydence ah this is a client modification. I read it as a server change for some reason. Thanks!
",ryanuber,apoydence
832,2015-05-07 00:02:33,"@treed Sorry about the delay. I agree. I guess for the SRV lookups we should use a special FQDN that is
distinct from the node lookup to avoid the ambiguity. The issue as you said is that the IP address depends on the lookup context (node -> agent IP, service -> service IP).

I'll mark this as a thinking bug.
",armon,treed
831,2015-04-28 21:44:32,"@ryanbreen I don't think you are missing anything. If the port is configured, the HTTPS server should start, and the HTTPS address field is just there to allow changing what it binds to.
",ryanuber,ryanbreen
831,2015-05-05 21:45:30,"Closing, this seems to be done. Thanks @ryanbreen 
",armon,ryanbreen
829,2015-03-30 22:18:32,"Hey @apoydence, currently you can do this in two ways:
1. Use `consul watch` and invoke a script based on its output
2. [Configure a watch in consul](https://consul.io/docs/agent/watches.html) with a script handler to invoke the API.

There is no in-built way to automatically query the internal API, but using watch handlers you should be able to do just about whatever you want to in a few lines of code.
",ryanuber,apoydence
829,2015-03-30 22:21:43,"Hey @ryanuber, I might have missed it, but I didn't see anywhere in the linked document to do this any other way besides the first way (script based).
",apoydence,ryanuber
829,2015-03-30 22:25:32,"@apoydence you are correct that you would still need a script. You can use the command-line `consul watch` to create a watch as an external process, or you can configure Consul with internal watches, which fire the handler script that you configure. This helps reduce the number of moving parts.
",ryanuber,apoydence
829,2015-03-31 14:52:31,"@ryanuber Are there any plans to expand the functionality of watches? Meaning, in the future will we be able to do it programmatically?
",apoydence,ryanuber
829,2015-04-01 00:38:12,"@apoydence I'm not sure what you mean. Watches are just a convenient abstraction around doing blocking queries programatically. Those are the underlying API that enables watchers. See the ""Blocking Queries"": https://consul.io/docs/agent/http.html
",armon,apoydence
829,2015-04-01 01:32:28,"@armon Ah, I didn't notice that the service endpoint had noted to have blocking queries.  I will look into those. Thanks!
",apoydence,armon
829,2017-01-30 23:08:02,@apoydence I've a question around the usage of watches. I'm new to Consul and started looking at the documentation to use it for our use cases. I see the maximum time a blocking query can wait is 10 mins. Is there a reason for this upper cap? We were planning to use watches for job completion notifications where the job could take more than 10 mins. Are blocking queries the right ones to use or Consul offers any other functionality? ,cthumuluru,apoydence
829,2017-01-31 04:47:23,@cthumuluru 10 minutes is a long time and many proxies have limits for an inactive connections (e.g. 1 minute on an AWS elb) and therefore your code should assume timeouts (simply reconnect when they do). I believe watches are a powerful tool sound relevant for your solution.,apoydence,cthumuluru
828,2015-04-06 21:23:46,"@apoydence The sample format you used is for config files, but it looks like you guys figured out the correct API format. Closing!
",armon,apoydence
827,2015-03-30 22:20:49,"Mmm, good point @highlyunavailable.  If the tests pass, I'll compact the code and update the PR.
",mfischer-zd,highlyunavailable
827,2015-04-01 01:24:59,"Thanks, @mfischer-zd. We do already have some handling for SIGTERM [here](https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L694-L758). The behavior of SIGTERM is configurable. If what you're after is a graceful leave, you can set the `leave_on_terminate` config option, which should cause Consul to invoke the same code path as SIGINT.
",ryanuber,mfischer-zd
827,2015-04-01 15:53:56,"@ryanuber, this patch corrects behavior of `consul lock` and other tools - it's not related to the behavior of Consul in agent mode.  See #797 for further discussion.
",mfischer-zd,ryanuber
827,2015-04-01 16:58:52,"@mfischer-zd ah that makes sense then, merging this in. The test failures are definitely unrelated to this change. I'll address those separately.
",ryanuber,mfischer-zd
822,2015-03-27 21:55:17,"Hey @MrMMorris, is the config identical on all of the servers? The logs you pasted above appear to be from a different node than the configuration. It would be helpful to have the DEBUG-level logs from one of the nodes where you see the error, and its configuration as well.
",ryanuber,MrMMorris
822,2015-03-27 22:07:17,"@ryanuber I can definitely provide those. Someone in IRC suggested I use this flag:

`consul members --rpc-addr=10.0.1.5:8400`

and that worked on the servers that were experiencing the error. Is there something I can add to the config so it Just Works without the flag?

10.0.1.5:

logs:



config:


",MrMMorris,ryanuber
822,2017-02-09 12:47:22,"@MrMMorris 
how did you solve?",shakisha,MrMMorris
822,2017-03-23 22:29:55,"Sorry @shakisha your email got buried and I didn't respond.

It was a while ago, but from taking a look at my current configs, the difference seems to be I have now explicitly set the `bind_addr` to the internal IPV4 address of the server (for example, 10.0.0.5).

Hopefully this helps you! (and someone else having a bad day and being incapable of communicating like an adult :love_letter:) ",MrMMorris,shakisha
820,2015-11-25 02:33:04,"This should now be a non-issue, as we've completely replaced the LMDB-backed state store with an in-memory index so we never need to touch the disk. @fraenkel I know this ticket is old but are you still seeing this? Trying with the newest Consul RC might give you significantly better results.
",ryanuber,fraenkel
820,2015-11-25 02:35:47,"@ryanuber Nope. I will close it.
",fraenkel,ryanuber
819,2015-03-26 22:20:32,"@fraenkel this sounds like it could be a startup race. The error message `Missing node registration` indicates that the node is not yet registered in the catalog. Are you attempting to create a session immediately after starting Consul, in a script or similar? If so, you might need to allow Consul some time to initialize and sync the node registration to the catalog.
",ryanuber,fraenkel
818,2015-05-06 19:53:41,"Hey @alpduhuez,

Sorry for the delay. I'm not sure exactly what's going on here. Deleting the data directories _could_ help us at least understand if this could be some corruption issue, however it's a fairly destructive action and should only be done if the cluster state and data are unimportant. Were you able to get this sorted out? There are some further improvements to Consul and Raft in the master branch, which should be released soon as 0.5.1, so it might also be worthwhile to give that a try if you can.
",ryanuber,alpduhuez
818,2015-05-14 19:34:03,"@ryanuber thank you for looking.  Deleting the data is in fact what I did do to get back to square one.  I eventually found that the state was being caused by chef runs.  Every time the nodes converged, the consul recipe scheduled a restart.  Over time, all 3 servers convergence would eventually line up and cause a down state.  If did the manual recovery steps, it would come back.

Far as the health checks.  It was also a chef recipe bug that would hork up the service check, sometimes.  

I've fixed our recipes now so they only install consul and don't modify and the bugs as well.  Since I've done that, the cluster has been happy.
",alpduhuez,ryanuber
817,2015-03-26 17:00:24,"@armon Yup, Prometheus is about ""pull"" as well, so it's a bit the odd one out in `go-metrics`. But if you want to keep it to a JSON format, then you'll need custom code, yeah. The question would then be whether it'd also be possible to expose it as Prometheus metrics on some other endpoint (or via content-type negotiation on the same endpoint).
",juliusv,armon
817,2016-04-26 01:26:24,"@armon Did you think about this any more? It came up here again and I would like to solve that somehow. You said that in the rpc layer you access the metrics already but it seems like the metrics there are difference and the only way (I know of) to get metrics state out of go-metrics is via the prometheus sink or a new sink. So I'm happy to implemented that, but it's a bit unclear to me how it's suppose to work.
Right now the simplest option seems to use the Prometheus sink. If that works for you, I can submit a new PR for that. It still has the problem with only support for flat metrics but everything else would lead to redundant metric code or require heavy refactoring of go-metrics.
",discordianfish,armon
817,2016-04-27 00:39:11,"@armon Here is a new branch: https://github.com/hashicorp/consul/compare/master...discordianfish:fish/add-prometheus-sink
I've decided against using the existing api listener because people usually bind that to 127.0.0.1 where the metric listener needs to be reachable from other hosts.
This also depends on https://github.com/armon/go-metrics/pull/30 or consul might crash if service tags are used.

Even though it already helps me a lot to debug our ongoing consul issues and I'm not very happy with the resulting metrics for two reasons:

a) They are not named very well. Even if you don't want to adopt the prometheus format, maybe you are up to adhere to some prometheus best pratices that are IMO universal: https://prometheus.io/docs/practices/naming/

b) They are flat. I'll submit another PR to go-metrics to make the resulting metrics a bit 'better', but ultimately if the interface of go-metrics only supports flat metrics we won't be able to solve this properly. What are you thoughts about that? Have you considered refactoring the metrics to support multidimensional ones? The Datadog support also looks a bit hackish in that regard: https://github.com/armon/go-metrics/blob/master/datadog/dogstatsd.go#L60 
",discordianfish,armon
816,2015-05-04 22:40:23,"@pepov Sorry about the epic delay! Not sure how this slipped through. This looks great, merging!
",armon,pepov
815,2015-03-25 18:05:23,"This is an interesting idea. I think if we were to support setting custom DNS records, we would want to have a first-class API for doing CRUD operations on them. I agree with @armon, there are going to be numerous edge cases we should think about.
",ryanuber,armon
811,2015-03-24 17:23:33,"This is expected behavior. The script/interval check is run locally on the agent, so if that node goes away, the result will not be updated, which was indeed a design decision. This is where the `serfHealth` check smooths things over for you by quickly detecting the node failure and updating the catalog. As pointed out by @grobie, you will want to use the `/v1/health` endpoint to query for services in a passing state. The equivalent API call in your use case would have been `curl consul:8500/v1/health/service/infra-haproxy-stats?passing`.
",ryanuber,grobie
811,2015-03-24 23:52:36,"@discordianfish definitely not - the DNS interface should only return healthy results. Please do let us know if you see otherwise.
",ryanuber,discordianfish
810,2015-03-25 17:45:23,"thx @armon, you can close ticket.

out of topic:
You have mentioned that

> The problem is that many (most) Consul deployments actually do depend on the A records.

Might be, that we are doing something wrong here, thats why ask for more details :), so sorry for being so picky. Can you just tell me how **only** A record is being used for Consul deployments? I thought that **only** SRV is needed since it contains a important couple of real IP and PORT?
",sielaq,armon
810,2015-03-25 17:50:09,"@sielaq Most deployments depend on well-known ports, so the port is hardcoded and the A record is used for IP discovery. Hope that helps!
",armon,sielaq
809,2015-03-24 17:43:11,"@imcom Currently there is no way to have Consul send the changes only. I believe there is an open ticket for this however. For now, you do need to store that index and de-duplicate within the watcher if necessary.
",armon,imcom
808,2015-03-23 17:13:45,"@tcolgate This can be done currently by setting the `Session` in `SemaphoreOptions`
",armon,tcolgate
808,2015-03-23 20:05:39,"From what I could tell, that is a string name that would be looked up in
the current DC
On Mar 23, 2015 5:13 PM, ""Armon Dadgar"" notifications@github.com wrote:

> @tcolgate https://github.com/tcolgate This can be done currently by
> setting the Session in SemaphoreOptions
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/808#issuecomment-85101384.
",tcolgate,tcolgate
808,2015-03-23 20:16:08,"@tcolgate It is the actual Session ID value, not it's name. The Semaphore doesn't allow directly setting of the Datacenter, but you can create a client associated with any datacenter, and then use the Semaphore.
",armon,tcolgate
808,2015-03-24 18:23:17,"I'd missed the dc setting on the client and was using read write opts! No
probs. Thanks. Will close the ticket
On 23 Mar 2015 20:16, ""Armon Dadgar"" notifications@github.com wrote:

> @tcolgate https://github.com/tcolgate It is the actual Session ID
> value, not it's name. The Semaphore doesn't allow directly setting of the
> Datacenter, but you can create a client associated with any datacenter, and
> then use the Semaphore.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/808#issuecomment-85174822.
",tcolgate,tcolgate
807,2015-05-05 21:24:25,"@primal-github I think this was actually caused by an unrelated issue in the connection pooling between servers. If an RPC returned an error, the connection would not be reused. In this case, an invalid domain would always cause and error, so each query would start a new internal connection. This looks to be resolved in master!
",armon,primal-github
807,2015-05-29 17:52:05,"@frankfarmer In this case they were both co-occurring.  As @armon mentioned this was likely caused by the lack of connection reuse, which may have in turn triggered excessive file descriptors being used.  We addressed the cause (fixed our dns lookups) so we haven't had the urge to replicate it again. 
",primal-github,armon
807,2015-05-29 17:52:05,"@frankfarmer In this case they were both co-occurring.  As @armon mentioned this was likely caused by the lack of connection reuse, which may have in turn triggered excessive file descriptors being used.  We addressed the cause (fixed our dns lookups) so we haven't had the urge to replicate it again. 
",primal-github,frankfarmer
805,2015-03-20 15:06:34,"@ryanbreen Like this?
",discordianfish,ryanbreen
803,2015-03-24 21:23:16,"@ryanuber Any feedback about the previous comment?
",Amit-PivotalLabs,ryanuber
803,2015-03-24 22:38:58,"@Amit-PivotalLabs sorry about the delay, I've been gone for a few days. The agent configuration should be automatically copied into the server config at start time, so there shouldn't be any disconnect there.

I think it's probably fine to remove the validation from the agent, since the server does the same exact check during the next RPC call, and returns the same error. Invalid requests shouldn't be repeated, so I think this is sane.

Really it seems like this should be checked in one place (the session create code path). I'm not entirely sure why it is re-checked in the state store, and what the implications of removing that would be if servers are configured with different values. @armon any ideas on this?
",ryanuber,Amit-PivotalLabs
803,2015-03-25 17:33:43,"@ryanuber @Amit-PivotalLabs Primarily the check was done in a few places for defense in depth. I think it's probably fine to leave just a single check for min/max values in the session create path on the server. The state store checks can probably be reduces to a very basic sanity check instead of bounds check.
",armon,Amit-PivotalLabs
803,2015-03-25 17:33:43,"@ryanuber @Amit-PivotalLabs Primarily the check was done in a few places for defense in depth. I think it's probably fine to leave just a single check for min/max values in the session create path on the server. The state store checks can probably be reduces to a very basic sanity check instead of bounds check.
",armon,ryanuber
802,2015-03-19 23:02:28,"@sethvargo this seems reasonable to me - perhaps an additional field in the health responses with an aggregate status would do the trick so existing clients continue to work normally. Nice example :+1:
",ryanuber,sethvargo
802,2016-09-15 14:30:08,"Could we dump this in a milestone for scheduling @slackpad. Seems high-value with little effort ðŸ˜„ 
",sethvargo,slackpad
798,2015-03-24 17:48:36,"@rockymtnlinux So I think this is a few different issues being conflated together. Issue one is that the agent's local service representation is distinct from the global catalog. You can register a service via `/v1/agent/service/register` but that may be blocked from the global catalog. We are planning on adding a pre-flight check so that the local agent registration will fail too, but from the perspective of the cluster, that service has not been registered.

The second issue is that you cannot currently do per-registeration token overrides. (See #734). Instead, only the agent ACL is used. So in this example the `client_token` is being completely ignored. That will be addressed shortly.

Lastly, with 0.5 the ACL system only protects registration of services, not discovery. That is a roadmap item for 0.6, so it is expected that you can read all of the services currently.

I hope that helps clarify!
",armon,rockymtnlinux
798,2015-08-20 18:04:28,"@tillig You can instead of setting a `acl_token` for the entire agent now set the token for a per-service registration. This allows the service to be registered without causing the anonymous HTTP requests to pickup the token.
",armon,tillig
798,2015-08-20 19:04:38,"@armon Is there some doc or an example showing how to specify a per-service `acl_token`? Do I just add an `acl_token` parameter to a [service definition](https://consul.io/docs/agent/services.html) when defining it in configuration?
",tillig,armon
796,2015-03-18 21:28:50,"@Amit-PivotalLabs I'd be open to a PR that allowed min/max values to be configurable. I'd avoid adding a CLI flag, since it's a very advanced tuning parameter that most people should not touch. 
",armon,Amit-PivotalLabs
796,2015-03-19 01:13:56,"Okay, so config file settings only?

On Wednesday, March 18, 2015, Armon Dadgar notifications@github.com wrote:

> @Amit-PivotalLabs https://github.com/Amit-PivotalLabs I'd be open to a
> PR that allowed min/max values to be configurable. I'd avoid adding a CLI
> flag, since it's a very advanced tuning parameter that most people should
> not touch.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/796#issuecomment-83186434.
",Amit-PivotalLabs,Amit-PivotalLabs
796,2015-03-19 02:00:41,"@Amit-PivotalLabs Yep!
",armon,Amit-PivotalLabs
795,2015-03-23 14:08:41,"@armon Sorry for the delayed response. Yes, multiple server nodes are available in the case I described - I created a cluster of three server nodes, each one a separate Docker container; consul1 is the leader in the scenario, the other two start as followers but one is promoted to leader when ""docker pause"" is applied to consul1. Other than pausing the leader, it's a normal three-node server cluster, implemented as containers.

If the issue is an arbitrarily long or indefinite TCP timeout, wouldn't this problem also occur if a network partition occurred in a real-world environment? Specifically:
1. consul1 loses connection to the cluster
2. consul_client1 tries to register a service before it learns that consul1 is down
3. consul_client1 waits, possibly indefinitely, for consul1 to respond
4. consul_client1 blocks on all HTTP API calls until it's restarted or the network partition is resolved

Let me know if you need any more information about the test case.
",ghicks-rmn,armon
795,2016-01-14 17:17:36,"Hello, I am doing the same tests that @ghicks-rmn and ran into the same issues.

Any updates ?
What kind of information should we provide to help ?

#### Consul agent -client logs



#### Loop of service registration



### Notes
- ~ 1min30s after leader election, the Client agent ""de-spool"" the services
- The client calling the Consul Agent HTTP endpoint does not get any ""proper"" answer during registration tries
",xakraz,ghicks-rmn
795,2016-01-15 01:24:22,"Hi @xakraz which version of Consul are you using? Consul 0.6.0 added some fixes that allow it to detect failed TCP connections more quickly and attempt reconnection.
",slackpad,xakraz
795,2016-01-15 08:59:21,"@slackpad : I am running Consul 0.5.2 currently, but I will test with the latest Consul 0.6.2 today and keep you posted. Thx for the lead !
",xakraz,slackpad
795,2016-01-20 17:53:58,"Hi @slackpad ,

I finally managed to test consul 0.5.2 vs the latest 0.6.3 and you are right, it has been fixed (at least in the latest version).

So I guess I will have to update all my servers know :p

### Consul 0.5.2



### Consul 0.6.3


",xakraz,slackpad
795,2016-02-09 12:37:46,"@slackpad Have you some other feedbacks about the issue ?

From my point of view the update to Consul 0.6.3 solve it.
",xakraz,slackpad
795,2016-02-09 19:24:15,"Hi @xakraz thanks for the follow up report - I think we can close this. There were several changes in 0.6.0 around TCP connection handling, and specifically to fix the dead connection detection so we should be good.
",slackpad,xakraz
793,2015-03-18 17:05:35,"@sielaq Thanks for opening this. Tagged as an enhancement!
",ryanuber,sielaq
792,2015-03-17 20:08:11,"@mfischer-zd At that point, it means the attacker also has access to the keys of the certificate authority as well. Access to just the client side public/private keys are not enough to forge a new key signed by the CA.
",armon,mfischer-zd
792,2015-03-17 20:17:44,"@mfischer-zd The same certificate authority would be used that exists now. The `ca_file` configuration currently allows you to specify the CA used to validate the certs. https://consul.io/docs/agent/options.html#ca_file

So the only real change is that outgoing requests to servers would validate the hostname against a specific pattern.
",armon,mfischer-zd
792,2015-03-18 20:47:08,"+1 on the severity of this, and the reluctance in adopting consul for a security-conscious environment.

@armon, A question to clarify on the CA/TLS proposal, would it be possible to validate the server/client certs independently, or is this an illusion of security?

I also like the idea of having separate shared secrets for server-to-server vs agent/server communication (servers would have both keys, agents would not have the key used for server to server configuration). Does this make sense to consider?
",ketzacoatl,armon
792,2015-03-18 21:19:31,"+1 and thanks @armon for raising the issue and all the discussion.
",fazy,armon
792,2015-03-18 21:22:22,"@ketzacoatl I'm not sure quite what you mean by the server vs client cert validation. Both must be signed by a trusted CA (or multiple different CAs). The difference is that server certificates would contain additional data to distinguish them.

I'm not sure where this additional shared secret would come into play? Do you mean in the gossip protocol layer?
",armon,ketzacoatl
792,2015-03-18 21:43:53,"@armon. On my certs question, I think you answered it with _(or multiple different CAs)_.

On the shared secret, the thought is for there to be separate secrets used for servers who pass around updates to the directory, and agents which just read the directory.
",ketzacoatl,armon
792,2015-03-18 22:51:36,"@ketzacoatl I'm not sure the shared secret adds any more security here, but just additional complexity for the user.
",armon,ketzacoatl
792,2015-03-19 00:42:09,"@armon, If it is optional (servers could have same secret as agents, or a unique secret), the user is not inhibited. If an agent is compromised, they need to get the server secret (along with generate a cert with the right CA) before they can impersonate a consul server. What do you see that is not reasonable? 
",ketzacoatl,armon
791,2015-03-17 23:06:20,"@pforman That is a bit out of context. I think that would require something along the lines of at-rest encryption.
",armon,pforman
791,2015-04-12 18:31:36,"Tokens should no longer appear in the monitor or logs after ee56598.

@tummychow I'm not sure if it makes sense to do that in the API package. The client made the request, so it must already know about the token. We do plan on enhancing and unifying the response formats in a v2 api in the future, but we haven't started on that project yet.
",ryanuber,tummychow
790,2015-03-17 00:06:09,"Hey @consultantRR, this behavior should be supported. I just ran your exact example against a local cluster, and I can't reproduce the issue. It might be useful to have some debug-level logs to get a better idea of what's going on. Can you provide the debug logs?
",ryanuber,consultantRR
789,2015-03-16 19:59:15,"Hey @telmich, thanks for opening an issue. This is a dupe of #725, so let's track the issue there. Thanks!
",ryanuber,telmich
786,2015-03-15 00:29:21,"@allgeek The general idea was to wrap a disruptive operation to the local node or one of its services in `consul maint` to minimize the impact to clients. We could probably do something similar to support this use case though, marking as an enhancement!
",ryanuber,allgeek
780,2015-09-23 09:48:21,"@armon are there plans to implement this in the foreseeable future, or would you accept a pull request for this? In the latter case: can you give me an indication of how hard it is to implement this in Consul?

@iconara did you find a workaround for the missing `-try`/`-timeout` flags in your setup? If so, can you share that?
",marceldegraaf,armon
780,2015-09-23 09:48:21,"@armon are there plans to implement this in the foreseeable future, or would you accept a pull request for this? In the latter case: can you give me an indication of how hard it is to implement this in Consul?

@iconara did you find a workaround for the missing `-try`/`-timeout` flags in your setup? If so, can you share that?
",marceldegraaf,iconara
780,2015-09-23 10:05:58,"@marceldegraaf I haven't got any good workaround for this, no. I have one application that does something like it through the HTTP interface, but it would be so much better to use `consul lock -try`. I'd be very greatful if this was implemented.
",iconara,marceldegraaf
780,2015-09-28 08:47:14,"Thanks @slackpad. If you're open to a PR for this, and can point me to how that would work in the Consul code base, I'd be glad to submit one.
",marceldegraaf,slackpad
780,2015-12-09 11:03:12,"@armon @slackpad any updates on getting this functionality into Consul?
",marceldegraaf,armon
780,2015-12-09 11:03:12,"@armon @slackpad any updates on getting this functionality into Consul?
",marceldegraaf,slackpad
779,2015-03-13 17:19:52,"Hey @darron, thanks for the report. This is sounding like it might be a keep-alive issue. Is the server you are talking to configured with a keep-alive timeout of < 30s? The default Go HTTP client uses a 30s keep-alive. We probably need to adjust this on the Consul side, but I just want to nail the issue down further before going down that road. Also, if you could provide the check configuration in its original JSON form, and the curl command you used, that would be helpful.

Tagging as a bug, Thanks!
",ryanuber,darron
779,2015-03-13 17:51:43,"@ryanuber We should just disable keep-alive, it seems sane for doing localhost checks to just re-dial.
",armon,ryanuber
779,2015-03-13 17:53:08,"@armon +1
",ryanbreen,armon
779,2015-03-13 19:04:21,"It's a really standard nginx container - I'm just away from my laptop and
will get full config when I get back.
On Fri, Mar 13, 2015 at 11:53 AM Ryan Breen notifications@github.com
wrote:

> @armon https://github.com/armon +1
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/779#issuecomment-79187084.
",darron,armon
779,2015-03-13 19:56:46,"FYI - @ryanuber - this is the config:

https://github.com/octohost/nginx/blob/master/nginx.conf - 15 second keepalive timeout.

Was setting this JSON:

`{""ID"": ""interactions-49155"",""Name"": ""interactions"",""Port"": 49155,""Tags"": [""http""],""check"": {""http"": ""http://10.132.82.182:49155"",""interval"": ""15s""}}`

With this command - $2 is the JSON that's passed:

`curl -s -X PUT -d ""$2"" ""localhost:8500/v1/agent/service/register?token=anonymous""`

It goes from here: https://github.com/octohost/octohost/blob/master/bin/octo#L421

To here: 

https://github.com/octohost/octohost-cookbook/blob/master/files/default/consulkv#L39-L41

I have all sorts of containers though - so likely what @armon and @ryanbreen +1'd would be the best - it would be a bit of a futile process to make sure everything had a long enough keepalive.

Thanks for taking a look at this!
",darron,armon
779,2015-03-13 19:56:46,"FYI - @ryanuber - this is the config:

https://github.com/octohost/nginx/blob/master/nginx.conf - 15 second keepalive timeout.

Was setting this JSON:

`{""ID"": ""interactions-49155"",""Name"": ""interactions"",""Port"": 49155,""Tags"": [""http""],""check"": {""http"": ""http://10.132.82.182:49155"",""interval"": ""15s""}}`

With this command - $2 is the JSON that's passed:

`curl -s -X PUT -d ""$2"" ""localhost:8500/v1/agent/service/register?token=anonymous""`

It goes from here: https://github.com/octohost/octohost/blob/master/bin/octo#L421

To here: 

https://github.com/octohost/octohost-cookbook/blob/master/files/default/consulkv#L39-L41

I have all sorts of containers though - so likely what @armon and @ryanbreen +1'd would be the best - it would be a bit of a futile process to make sure everything had a long enough keepalive.

Thanks for taking a look at this!
",darron,ryanbreen
779,2015-03-13 19:56:46,"FYI - @ryanuber - this is the config:

https://github.com/octohost/nginx/blob/master/nginx.conf - 15 second keepalive timeout.

Was setting this JSON:

`{""ID"": ""interactions-49155"",""Name"": ""interactions"",""Port"": 49155,""Tags"": [""http""],""check"": {""http"": ""http://10.132.82.182:49155"",""interval"": ""15s""}}`

With this command - $2 is the JSON that's passed:

`curl -s -X PUT -d ""$2"" ""localhost:8500/v1/agent/service/register?token=anonymous""`

It goes from here: https://github.com/octohost/octohost/blob/master/bin/octo#L421

To here: 

https://github.com/octohost/octohost-cookbook/blob/master/files/default/consulkv#L39-L41

I have all sorts of containers though - so likely what @armon and @ryanbreen +1'd would be the best - it would be a bit of a futile process to make sure everything had a long enough keepalive.

Thanks for taking a look at this!
",darron,ryanuber
779,2015-03-15 20:36:06,"Hey @darron - I just pushed 952ec28, which should disable HTTP keep-alive's. If you have a minute, give master a test and see if the issue persists. I'll leave this open for now until we confirm the fix. Thanks!
",ryanuber,darron
778,2015-03-12 21:07:17,"Hey @fujin, if you prefix the socket path with `unix://` that should work. Basically the client keys off of this prefix to replace the default HTTP client with a custom one which speaks over UNIX sockets.

Can you give that a try and let us know if it works? It should be the same for consul/api too. Thanks!
",ryanuber,fujin
769,2016-03-02 04:14:44,"Hi @tonglil,

Is this check inside of a config file? This fix is only to purge health checks which were submitted from the REST API, and whose services no longer exist when Consul is restarted. If the check is defined in a configuration file, you have to remove the check or the config file which contains it.

Hope that helps.
",ryanuber,tonglil
769,2016-03-03 02:09:49,"Ah gotcha, thanks for the clarification @ryanuber.

Do you know what the reasoning is for making it fatal for config files?
",tonglil,ryanuber
768,2015-03-06 23:30:06,"@vtolstov I highly recommend reading this page first:
https://consul.io/intro/vs/zookeeper.html

With respect to your questions:
- Bootstrapping Consul is very simple, and the address of all nodes do not need to be known. The gossip protocol is used to automatically manage that.
- You cannot use 100 nodes as a server. Technically you can try, but the system will suffer and not perform as you expect. There should be 3 or 5 servers, potentially 7, and the rest are clients.
- There is no official C API, but you can use libcurl easily enough, as it's just a REST HTTP/JSON API.
- The `/v1/status/leader` endpoint can be used to find the leader.
- Nodes are automatically added/removed using the gossip protocol

If you are trying to do client-side leader elect (e.g. elect a leader in your own application, not Consul), then take a look here:
- https://consul.io/docs/guides/leader-election.html
- https://consul.io/docs/commands/lock.html

Hope that helps!
",armon,vtolstov
768,2015-03-06 23:54:17,"@vtolstov Unfortunately Consul does not support hot-standby servers. Nodes must be active servers or clients. This is something we are interested in looking into eventually, but no short term plans.
",armon,vtolstov
768,2015-03-07 14:41:49,"@armon So if you have 3-5 active servers and 100 clients, if one of the active servers kicks the bucket, a client won't step up to take the place of an active server?
",iamthemuffinman,armon
768,2015-03-07 14:43:40,"That is correct.  Consul agents are either servers or clients.  There's not
currently a facility for a client to become a server automatically.

On Sat, Mar 7, 2015 at 9:41 AM, Robert Deusser notifications@github.com
wrote:

> @armon https://github.com/armon So if you have 3-5 active servers and
> 100 clients, if one of the active servers kicks the bucket, a client won't
> step up to take the place of an active server?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/768#issuecomment-77691807.
",ryanbreen,armon
768,2015-03-07 15:03:51,"@ryanbreen Is there a branch to add this feature?
",iamthemuffinman,ryanbreen
768,2015-03-07 15:13:45,"I don't believe so.  It may be something the team is considering, but to my
knowledge it's not an immediate roadmap item.

On Sat, Mar 7, 2015 at 10:03 AM, Robert Deusser notifications@github.com
wrote:

> @ryanbreen https://github.com/ryanbreen Is there a branch to add this
> feature?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/768#issuecomment-77692756.
",ryanbreen,ryanbreen
768,2015-03-09 20:57:59,"I think @ryanbreen perfect answered this. There is no plans to support that feature in the short term, so you must dedicate server nodes in advance. I'm going to close this as I think the question is answered.
",armon,ryanbreen
767,2016-01-17 23:46:51,"@armon love your product, but your getting started for consul sucks.
",RongxinZhang,armon
767,2016-01-22 22:18:53,"Hi @RongxinZhang - sorry that you didn't find that guide helpful. Is there anything specific that didn't work well for you?
",slackpad,RongxinZhang
767,2016-07-29 02:54:54,"@RongxinZhang, why troll man?  If you got something to criticize at least be helpful.

Anyways, I'd like to answer the question raised about the guide.  I've found that all the information I need is in there.  Sometimes its hard to find.  A prime example is IP addresses and ports, which is partly why I ended up here.  It would be nice to have a concise document talking about all the networking pieces.  It took me a bit of trial and error to figure out how exactly I needed to setup my AWS security groups and VPCs so that everything could communicate properly.  And, my fingers are still crossed I got it right.

I think you guys have documented everything, its just there is, I believe, lack of high-level documentation in some places which pull it all together.  You've got all the vertical documents ""this is how this specific feature works"" and seem to be missing the horizontal documents ""this is how you get this workflow running, which uses all these features"".

Oh, one other documentation point that I've hit and haven't overcome yet.  The documentation on how to setup ACLs is very lacking.  The documentation about how ACLs changed from one version to the next is great, but there is no guide to set them up in the first place.  All I have are samples of the contents of ACL files.  But... where do I put them, etc?  Maybe I missed a document somewhere.  If so, maybe there needs to be more cross-referencing within the documents.

Hope that helps!

As @RongxinZhang said, love you product!
",bluefeet,RongxinZhang
766,2015-03-06 20:07:43,"@stevendborrelli The way forward on this is via the ACL system. With 0.5 it was extended to support service registration, to restrict who can register services. With 0.6 it will be extended to discovery as well. So you could create a ""dev"" ACL policy that only allows registering and discovering a subset of instances, etc. Hope that helps!
",armon,stevendborrelli
766,2016-01-12 14:23:35,"@ryanuber how do prepared query improve this? Can you elaborate please?
",raphink,ryanuber
766,2016-01-12 14:24:34,"@armon so you're saying instead of namespace, make it so that consumers can only see some nodes? What if I want to configure an haproxy for multiple services that share the same name with a different namespace?
",raphink,armon
766,2016-01-15 06:18:00,"@raphink Basically the ACL system can be used to provide users with a partial view of the system. Instead of seeing all the services, you can restrict what is visible. Its not the same as a namespace, but can be used to segregate teams and services.
",armon,raphink
766,2016-01-18 07:51:13,"@armon I get the idea, but it doesn't allow to have multiple services with the same name on a given proxy.
",raphink,armon
762,2015-03-06 20:22:33,"@aminjam It is currently being used just to tag the versions at the time of the release. You can always move that file into the root as the `Godep` file, and then use the tool to reset and vendor the dependencies.
",armon,aminjam
761,2015-03-05 17:48:18,"Hey @remmelt, this definitely seems a bit odd. Thanks for letting us know, marking as a bug.
",ryanuber,remmelt
758,2015-03-05 22:57:36,"@highlyunavailable Please go for it: your NSSM setup is cooler than our WinSW config. :smile:
",ryanbreen,highlyunavailable
758,2015-09-23 20:59:49,"@armon Just want to let you know that we are working to build a MSI package with NSSM and consul.exe running as an automatic build at AppVeyor. I'm sure I can get this open sourced very soon.
",StefanScherer,armon
758,2015-11-05 17:02:21,"Not quite as nice as @highlyunavailable but we've got a similar Deploy.ps1 script for our Octopus Deploy rollout:



We use a separate deployment step to set the environment var `GOMAXPROCS` as until I saw this issue, I was unaware we can set it on NSSM on a per service level...
",megakid,highlyunavailable
758,2016-01-14 19:37:07,"@carlpett @StefanScherer I would be interested in seeing both these packages. I'm in the process of configuring consul agent on a Windows server. 
",vLifeOfBrian,StefanScherer
758,2016-01-14 19:37:07,"@carlpett @StefanScherer I would be interested in seeing both these packages. I'm in the process of configuring consul agent on a Windows server. 
",vLifeOfBrian,carlpett
758,2016-01-20 09:22:50,"@vLifeOfBrian: I will do some minor cleanup to get rid of some specifics, then get a PR up later today.
",carlpett,vLifeOfBrian
758,2016-01-20 20:12:11,"@vLifeOfBrian @carlpett I was allowed to open source parts of our MSI build process. I've put it into an extra repo that can build the MSI package and deploy it as GitHub release as an example. All done at AppVeyor CI. Have a look at https://github.com/StefanScherer/consul-agent, an AppVeyor build badge is also there to see what happens in CI.
",StefanScherer,vLifeOfBrian
758,2016-01-20 20:12:11,"@vLifeOfBrian @carlpett I was allowed to open source parts of our MSI build process. I've put it into an extra repo that can build the MSI package and deploy it as GitHub release as an example. All done at AppVeyor CI. Have a look at https://github.com/StefanScherer/consul-agent, an AppVeyor build badge is also there to see what happens in CI.
",StefanScherer,carlpett
758,2016-01-22 16:31:59,"Took some extra time due to work-related stuff, but here's our take: https://github.com/hashicorp/consul/pull/1640
There is no ui and such polish that @StefanScherer has in his version, though (we exclusively use this in automated scenarios, so it never came up). I'll try to do a more detailed comparison during the weekend to see if there are any other nice features that I can ~~steal~~ be inspired by.
",carlpett,StefanScherer
758,2016-01-22 16:48:55,"@carlpett Thanks for sharing! Looks pretty good.

Our setup with the `package.json` where we read many values from it comes from building MSI packages for Node.js microservices. We stripped that down to put Consul in a very similar MSI.

I also have removed the code signing steps we have to sign both the `consul.exe` as well as the final MSI file. This might be interesting for an official MSI build to suppress the ""unknown publisher"" Windows warnings.

A missing step are some tests with the MSI. I plan to add some at work and share them as well in the public repo soon.
",StefanScherer,carlpett
758,2016-02-10 16:29:39,"@carlpett - this is a great setup!
Thank you for sharing!

In my team we need a custom consul.json with a specific local bind_addr in place of the loopback advertise_addr.
Do you think it is better to fork off your repo or to use it as a submodule in our repo?

Thanks,
Vassil
",vassilvk,carlpett
758,2016-02-10 18:49:51,"@vassilvk - Thanks! The service is installed with the [`-config-dir`](https://www.consul.io/docs/agent/options.html#_config_dir) parameter pointing to the `consul.d` directory below the install directory. You should just be able to drop an additional configuration file there and have it working without modifying the installer.
",carlpett,vassilvk
758,2016-02-11 13:59:26,"Thanks, @carlpett.
And @StefanScherer, thank you for open sourcing your WiX setup - this is really solid stuff!
",vassilvk,StefanScherer
758,2016-02-11 13:59:26,"Thanks, @carlpett.
And @StefanScherer, thank you for open sourcing your WiX setup - this is really solid stuff!
",vassilvk,carlpett
757,2015-03-04 23:18:22,"Hey @cablehead, yeah that sounds reasonable to me, marking as an enhancement. Thanks!
",ryanuber,cablehead
754,2015-03-05 01:57:17,"@lindane Unfortunately the `acl_default_policy` cannot be updated via a reload, it requires a restart of the servers to take affect. My guess is that the updated policy had not taken place.

With respect to the initial test of value ""deny"", based on your configuration here, it seems that is the correct behavior. The agent is configured with `acl_token` of ""anonymous"" and the default behavior is being set to ""deny"", so registration _should_ be blocked unless I'm missing something.
",armon,lindane
754,2015-03-06 05:42:15,"@lindane Currently there is no way to change the default policy without a restart. You will have to reload the servers in order for this to take effect.

Regarding the policy for the mysql service, you might want to make sure that the policy text is correct. It looks like there is a trailing slash '/' character in the service name, which might explain why you are being denied.
",ryanuber,lindane
754,2015-03-06 20:27:06,"@lindane It sounds like you are hitting this same issue: https://github.com/hashicorp/consul/issues/734
Currently, the `acl_token` of the agent is used to register the service, so if that ACL does not have the proper permissions the registration is denied. The token passed in via the `/v1/agent/service/register` API is being ignored which is a bug.
",armon,lindane
751,2015-03-04 00:12:37,"@ryanuber Some minor comments but looks great!
",armon,ryanuber
751,2015-03-04 00:18:43,"@ryanbreen I see what you mean, yeah we do switch between ""the value is opaque to Consul and it does't care"" and ""the value is opaque to the client, and don't attach semantics to it"". I guess that is unclear which direction the opaqueness exists. I'm not sure if there is anything we can do except clarify more.
",armon,ryanbreen
750,2015-03-04 00:21:20,"@pepov It has to do with the semantics of leave. With a leave you are basically telling Consul ""please announce to the cluster your intention to leave, and do not re-join this cluster again unless explicitly told to."". As part of that, the node leaves the raft replication group and broadcasts a gossip message with its intent to leave. When we leave the raft group, the peers are purposely set to `null` to avoid bothering the existing cluster on restart. Does that make sense?
",armon,pepov
750,2015-03-04 05:11:13,"@armon I understand you, but confused because I thought I'm explicit by setting the start_join in the config. Why the gossip layer is allowed to join together and only the raft peerset is handled differently in this case? Is there a config flag I should use to avoid this, or simply avoid leaving for server nodes? 
",pepov,armon
750,2015-03-05 01:49:27,"@pepov The gossip layer is simpler since joins are idempotent and there is no issues of data safety. The raft layer is much more sensitive, and hence a little more challenging to work with. Typically, you avoid this by never having servers leave. It's rather strange operationally to have servers come and go.
",armon,pepov
750,2015-06-17 21:52:08,"@awheeler If you shutdown the servers gracefully they will leave the cluster and not re-join when you restart. You'll need to `join` each new server as it comes up with the new version of Consul (or follow the process discussed in #993 by fixing up the `peers.json` file if you accidentally have all 3 nodes leave simultaneously).
",slackpad,awheeler
750,2015-07-22 19:36:17,"@theonewolf The experience around this can definitely be improved as Consul was designed for continuous operation. It really dislikes being stopped so the notion of a graceful shutdown of an entire cluster really wasn't planned for. There is handling of a disaster total failure (power loss), but not as something people intend to do. That said, you can just `kill -9` everything and it will survive.
",armon,theonewolf
750,2015-07-22 19:45:40,"I can confirm kill -9 works well for now. I have exercised to kill and recover server or agent under failure scenario (e.g. dc power cut, server crash)

> On 22 Jul 2015, at 20:36, Armon Dadgar notifications@github.com wrote:
> 
> @theonewolf The experience around this can definitely be improved as Consul was designed for continuous operation. It really dislikes being stopped so the notion of a graceful shutdown of an entire cluster really wasn't planned for. There is handling of a disaster total failure (power loss), but not as something people intend to do. That said, you can just kill -9 everything and it will survive.
> 
> â€”
> Reply to this email directly or view it on GitHub.
",activars,theonewolf
750,2015-07-23 00:45:31,"@armon I see.  I think my/others confusion comes in because of incomplete documentation.

I didn't realize ctrl-c took a node out of the cluster in a deep sense.  But the design makes sense to me.

My confusion came in when I see things like ""Graceful shutdown""----> which I took to imply a possibility for a ""Graceful startup"" and rejoining of the cluster even if all nodes were brought down.

So for upgrades and resets we should be sending a different signal to the Consul process?

I think this signal, or all of the signals Consul expects and the outcomes of those signals should be very well documented somewhere.

Maybe a table listing the signals and Consul states post-signal?
",theonewolf,armon
750,2015-07-23 00:54:32,"@theonewolf Partially, I think this was a mistake UX wise. I think that the ""deep remove"" should not have been the default behavior, but we are here now. Its a damned if you do, damned if you don't situation.

The problem with the signals table is that the behavior is configurable. It responds to 3 signals:
- SIGHUP - Reload, always. Only some things can be reloaded.
- SIGINT - Graceful leave by default, can be configured to be non-graceful.
- SIGTERM - Non-graceful leave. Can be configured to be graceful.
",armon,theonewolf
750,2015-09-11 02:03:33,"Yes, and it's covered in #993 -- you manually populate the peers.json file.  See @slackpad 's example there.
I've used it several times since I read that and it makes the whole situation a non-event.
",awheeler,slackpad
750,2016-03-09 22:19:16,"Hi @Dmitry1987 that definitely should not be the case. Can you share a gist with your configuration and some log messages from when this happens?
",slackpad,Dmitry1987
750,2016-03-10 13:02:52,"Hi @slackpad , i think i figured this out, by adding some parameters that say ""do not gracefully leave in any case, hard/soft kill"" , don't remember exactly, but problematic configuration BEFORE i found that solution was: 

{

  ""acl_datacenter"": ""dc-main"",
  ""acl_default_policy"": ""deny"",
  ""advertise_addr"": ""22.22.22.22"",
  ""advertise_addr_wan"": ""11.11.11.11"",
  ""bootstrap_expect"": 3,
  ""ca_file"": ""/zzzzz"",
  ""cert_file"": ""/zzzzzz"",
  ""data_dir"": ""/var/consul"",
  ""datacenter"": ""dc-new"",
  ""disable_remote_exec"": true,
  ""domain"": ""my.domain.consul"",
  ""enable_syslog"": true,
  ""encrypt"": ""zzzzzzzzzz"",
  ""key_file"": ""/zzzzzz"",
  ""log_level"": ""INFO"",
  ""server"": true,
  ""start_join"": [
    ""x.compute.amazonaws.com"",
    ""y.compute.amazonaws.com"",
    ""z.compute.amazonaws.com""
  ],
  ""start_join_wan"": [
    ""zzz.compute.amazonaws.com"",
    ""yyz.compute.amazonaws.com""
  ],
  ""syslog_facility"": ""LOCAL5"",
  ""ui"": false,
  ""verify_incoming"": true,
  ""verify_outgoing"": true
}
",Dmitry1987,slackpad
749,2015-03-04 00:24:06,"@ryanbreen Looks great!
",armon,ryanbreen
747,2015-03-03 02:48:10,"@ryanbreen Thanks!
",armon,ryanbreen
747,2015-03-04 00:24:11,"@ryanbreen Thanks!
",armon,ryanbreen
743,2015-03-02 03:06:23,"@highlyunavailable If you want to whip up a PR, I'll be happy to review it.  Otherwise, I can take a crack at adding coverage of negative caching to dns-cache.html tomorrow.
",ryanbreen,highlyunavailable
743,2015-03-02 07:33:42,"Wow, it helps if I actually make the pull request to the root repo. Anyway, @ryanbreen I've made some docs on it.
",highlyunavailable,ryanbreen
742,2015-03-23 21:09:10,"@armon +1 on sharing some details on the known issue. We can start throwing ideas once we have a basic understanding of what's going on :)
",rotatingJazz,armon
742,2015-05-11 18:24:03,"@ashish235 It's hard to say what could be the issue with so little context, but typically there is a UDP routing issue at play. Make sure you get bi-directional routing of UDP packets. If you do rapid restarts of docker containers with fixed IPs, there is a known ARP cache issue in docker as well.
",armon,ashish235
742,2015-05-12 04:47:05,"Hi @armon, thanks for the reply. I don't think I 'm restarting containers rapidly. Also I had tried  ""conntrack -F"" for clearing the ARP cache. 

Can you provide me some pointers on where to dig the issue? 

I 've stopped the consul container on the Host where my application + consul agent was running and after that it seems the discovery is stable. 

Was it because of some NAT issue? that two containers (consul, consul agent) can't run on the same host ? My consul had all the port exposed and mapped while my consul agent only had the application port exposed and mapped. 

Kind of in middle of some confusion with the utility of consul server and consul agent. 
",ashish235,armon
742,2015-05-18 22:49:19,"@ashish235 You would need to look at the logs to get a better idea of where to look. Especially if you crank up the verbosity to debug, they will shed more insight.

@marc- Not currently, but we likely need something like that to handle bad nodes.
",armon,marc-
742,2015-05-18 22:49:19,"@ashish235 You would need to look at the logs to get a better idea of where to look. Especially if you crank up the verbosity to debug, they will shed more insight.

@marc- Not currently, but we likely need something like that to handle bad nodes.
",armon,ashish235
742,2015-05-29 20:24:46,"@armon Sounds like a good idea! :+1: Do you think this can hit in 0.6? This issue is a roadblock for using it in production (at least, for me, I'd love to hear how others deal with it).
",rotatingJazz,armon
742,2015-05-29 20:42:38,"Talked to @armon a bit today and we are going to try adding a TCP fallback for pinging peers, with a warning in the log if this actually confirms the existence of the peer. This should help the misconfigured client discover the correct state of the world and not introduce bad information into the cluster via the anti-entropy mechanism (which also uses TCP), while still being obvious to operators that there's a networking problem.
",slackpad,armon
742,2015-06-04 04:28:38,"The TCP ping change is in and should help with flapping in bad UDP connectivity scenarios, providing a clear log message when this occurs. This should make it into the next release of Consul.

@ashish235 please re-open this or create a new issue if your investigation leads you to think this wouldn't help what you were seeing.

@marc this should help prevent these nodes from getting marked bad in the first place since there's an alternate TCP ping mechanism, so I think we should be covered.
",slackpad,ashish235
740,2015-03-04 00:29:45,"@blalor So I am a bit confused, I think this is already possible right?
",armon,blalor
740,2015-03-31 06:11:06,"I was looking into this and the issue is the way ServiceDefinition is defined. 





ServiceDefinition takes a slice of CheckTypes rather than full blown HealthDefinitions so you don't get fields like ID and Name. You could add ID and/or Name to CheckType and I think that would solve this but then you might as well just have a slice of HealthDefinitions inside of ServiceDefinition. The way I am currently avoiding this problem is just defining a Service in one file and then in a separate file defining a list of checks that are all associated with that one service which makes config management easy. It's not as elegant as what @blalor suggested but it works. 
",cruatta,blalor
740,2015-07-13 18:59:48,"@aconrad the endpoint `/v1/health/checks/<service>` does currently exist. Does it not function how you would expect?

I looked at this a while back and found exactly the same as @cruatta did - the changes actually go pretty deep to support passing in the CheckID, which is unfortunate. I would probably just use a file with separate definitions like some have hinted at above, all in a single file for each service, like this:



This is going to be a somewhat low-priority enhancement since we have a reasonable work-around, but we definitely want to get it fixed for the embedded definitions.
",ryanuber,cruatta
740,2015-07-13 18:59:48,"@aconrad the endpoint `/v1/health/checks/<service>` does currently exist. Does it not function how you would expect?

I looked at this a while back and found exactly the same as @cruatta did - the changes actually go pretty deep to support passing in the CheckID, which is unfortunate. I would probably just use a file with separate definitions like some have hinted at above, all in a single file for each service, like this:



This is going to be a somewhat low-priority enhancement since we have a reasonable work-around, but we definitely want to get it fixed for the embedded definitions.
",ryanuber,aconrad
740,2015-07-13 20:28:19,"@ryanuber the endpoint works (and I'm using it) but I have no way to know which check item in the list of checks is the one I care about since I can't identify them by name -- so as I explained, I try to detect the check I care about by parsing its output.
",aconrad,ryanuber
740,2015-07-14 17:05:14,"@aconrad using a configuration like the sample above, you should be able to pass in the check ID to your liking. Then you can refer to the health check much more easily from your own app my just checking the ID field in responses. Does that make sense, or am I missing something?
",ryanuber,aconrad
740,2015-07-14 18:38:59,"@ryanuber ah got it. The person that manages our cluster applied the work-around, works great. Thanks!
",aconrad,ryanuber
740,2016-07-11 23:28:15,"@n2taylor can you paste your service + check config? This should work perfectly with the example config above. You can verify by saving the example config as `config.json` and running:


",ryanuber,n2taylor
739,2015-02-26 01:02:39,"Hi @amitmawkin,

The port the UI runs on is currently always the same as the HTTP API.  You can change this by specifying the `ports` key in consul's configuration, like so:



You can read more about the configurable ports in the [agent configuration documentation](https://consul.io/docs/agent/options.html).

If you need to run the UI on a different port than the HTTP API, you will need to serve the UI files from a different web server, such as Apache or nginx.
",ryanuber,amitmawkin
737,2015-02-26 00:01:50,"@justinrosenthal This is super interesting work! I'd never thought about this. What are the motivations for this out of curiosity?

An alternative approach to the fixed slice is to change the map from map[string]bool to map[string]int and have each holder just map to their slot number. This way, we can still efficiently find ourself, but finding a free slot is still a linear scan, so no worse than the slice. Additionally, we don't need to represent the unheld slots explicitly.

I also like the idea of a `Watch` method. Maybe something similar for the `Lock` also makes sense, so that you can watch who currently holds the lock.

I think we need to iterate a bit more on this PR, for one we need to address the compatibility question. I think we have to retain backwards compatibility with the other Semaphore, otherwise a ""consul lock"" with 0.5 would break when used with agents running a future version.
",armon,justinrosenthal
737,2015-02-26 00:48:12,"@armon Thanks for the comments.

As for motivation... I've had to solve this once before, but I'm working on a new project that has a fixed size cluster that I'm addressing into hash-ring style.  The simplest example is probably a cluster of cache machines where each key lives on node `hash(key) % numNodes`.  With caches in particular, allowing numNodes to change is really dangerous because it allows for keys to migrate from one node to another.  You can easily end up with a single key being present on multiple nodes with _different_ values when nodes fail, etc.  So, it's more reasonable to just fix numNodes and have empty standbys ready to jump in when nodes fail, etc., but the important part is that a given key always maps to the same virtual node.

Protip: Probably use Redis Cluster if you're facing this issue for caching, they handled key migration during cluster resizing :smile: Alas, I'm working on something that has a similar problem but isn't a cache.

Anyway, back to the Semaphore.  `map[string]int` would certainly work, I can make a pass at implementing it that way if you'd like.  We could also take it a step further and maintain a list of available slots along side the holders map, which would let us avoid the empty slot search.  It's a little more bookkeeping, but since everything is synchronized it shouldn't be hard to get it right.

I'll think a bit more about compatibility.  It would be a shame to have to introduce `SlottedSemaphore` and deprecate `Semaphore`.
",justinrosenthal,armon
737,2015-02-26 02:39:09,"@justinrosenthal Interesting. Have you considered a consistent hashing technique to avoid the problem of `numNodes` changing? This is something we for caching as well as other systems. It might obviate the need to do this PR at all.

I do think that the compatibility story is critical, so that would be good. Let's try the `map[string]int`, and punt the free list optimization. I'm not sure for any sane value of N that it will matter.
",armon,justinrosenthal
734,2015-02-24 17:55:28,"Hi @lud4ik,
Consul 0.5 introduces service ACL's. There is an additional upgrade step you need to perform if the default policy is `deny`. Please see the [upgrade instructions for 0.5](https://consul.io/docs/upgrade-specific.html). If you still have problems just let us know!
",ryanuber,lud4ik
733,2015-02-24 19:29:19,"@amiorin The problem is that `lgi01` changed IPs too quickly. Basically the cluster reached a stable state where `lgi01` was at ""172.16.0.108"". Suddenly a node at ""172.16.0.177"" starts advertising that it is `lgi01`. Consul still believes that the original node is alive since the failure detector takes about ~7-10 seconds to notice the failure. Thinking that both nodes are alive, conflict resolution kicks in and ejects the node with the minority vote to maintain cluster stability. Eventually the cluster realizes that `lgi01` has left/failed, and so restarting the node is successful.

There are a few options here:
- Gracefully leave `lgi01` before starting the new agent
- Do not re-use names (dynamically generate)
- Sleep for 10 seconds before starting the agent.

Hope that helps!
",armon,amiorin
732,2015-03-26 12:15:06,"@armon it seems like this PR fixes a build problem [1] which I encounter while packaging 0.5.0 for Gentoo Linux.

Do you think it possible to release a 0.5.1 version with at least this fix in a near future ? I'll remain stuck on 0.4.1 otherwise for now.

Thank you.

[1] https://travis-ci.org/hashicorp/consul/builds/51879912
",ultrabug,armon
732,2015-03-26 16:55:04,"@ultrabug If you build everything against master it should compile! You will have an issue if you are using the Consul 0.5.0 code base with the master of Serf.
",armon,ultrabug
732,2015-03-26 17:24:00,"@armon yes I know mate, that's exactly what I was saying. But this thus defeats the packaging of 0.5.0 hence my request for a new tag please.
",ultrabug,armon
732,2015-03-26 17:53:37,"@ultrabug Ah. We are hoping to cut that release in a few weeks.
",armon,ultrabug
732,2015-03-27 08:40:28,"@armon fair enough, good thing I was late in packaging it ;) thanks mate
",ultrabug,armon
731,2015-02-23 19:02:41,"@lyrixx I understand. We are actively migrating away from LMDB because of issues like these. The next major release will not use LMDB for data storage.
",armon,lyrixx
731,2015-02-24 09:25:30,"@armon I'm happy to hear that ;) What are you going to use?
",lyrixx,armon
731,2015-02-24 15:01:04,"@ryanbreen Thanks ;)
",lyrixx,ryanbreen
731,2015-03-04 00:16:02,"@hyc This is the first time I've seen this particular issue.
",armon,hyc
731,2015-03-04 11:15:21,"@armon I guess I was looking for the more general - how many LMDB-specific issues have you encountered. But now I see you were on 0.9.11 for a long time. Your issue #509 sounds like our ITS#7815 that was fixed in 0.9.12. Still, we would have investigated if you had let us know you were having problems.
",hyc,armon
731,2015-03-04 18:59:35,"@hyc Honestly LMDB has been mostly very trouble free and great for us. The main difficulties are it forces us to use cgo and cross-compilation becomes much more challenging. There have been very few bugs, and the performance is still higher than boltdb, even including the penalty LMDB pays due to the cgo boundary.

The switch is being done for a few reasons:
- The assumption of data size being larger than memory is mostly a non-issue for Consul
- The main catalog is not persisted to disk anyways (we use the LMDB flags to avoid flushing)
- Using LMDB causes us to serialize/deserialize and the pressure on the GC is too high

On the negative side, we have benchmarked boltdb and know it to be slower (10-15%) but this only affects the write performance which is already high enough. Real-world Consul deploys just don't do 4K+ writes/sec.
",armon,hyc
729,2015-02-23 18:44:53,"@rosmo You want to make use of the /v1/agent/ endpoints instead of the /v1/catalog endpoints directly. What is happening is that the catalog endpoint registers with the servers, but the agent is unaware of the service. When it runs anti-entropy (roughly every minute), it notices the discrepancy and deletes the service.
",armon,rosmo
729,2015-02-24 06:46:13,"That solved the problem, thanks @armon. 
",rosmo,armon
728,2015-02-23 15:26:22,"Hi @oba11 

I am sorry you are having issues. I believe you need to specify the full resource group path. ""live"" is not a valid resource group - it should be of the form ""<username>/infrastructure"". For example: `sethvargo/production`.

You will also need to have an active and confirmed account on Atlas with permission to connect to the infrastructure you specify.
",sethvargo,oba11
728,2015-02-23 16:19:03,"Hello @sethvargo 

Thanks so much, I got it working now.
I tried random/live or random/prod before but didnt know the syntax was `atlas_userid`/`cluster_name`

Thanks so much and really cool stuff
",oba11,sethvargo
725,2015-02-23 18:42:05,"@cetex Consul does not bind or advertise to a public IP by default for security reasons. You can always provide the `-bind` or `-client` CLI flags to override it's behavior and force it to bind to a public address. As you've noted, it's impossible for us to understand the context of the network and security completely, but avoiding public addresses is a sane default in most cases.

As to multiple -client and -bind addresses, this is complicated significantly by the design of the gossip system, as it does not easily allow us to broadcast our availability on multiple addresses.
",armon,cetex
725,2015-03-03 02:38:20,"@cetex Thank you for testing all of the combinations, there are definitely some bugs which you've helped to find with selecting the bind address in the various sub-systems.

In terms of defaults, Consul will only bind to a private IPv4 address by default. The reason for this is that almost no deployments of Consul should be on the public internet, and many environments still aren't great for IPv6.

For users that want to bind to a public address they must do so explicitly so that it is clear to them that the node will be on the public internet and that extra security measures should be taken. IPv6 is also not done automatically due to the number of environments where it does not work properly.

I think this is a sane tradeoff. In the majority of cases, we can automatically bind to the private IPv4 address. In any other case, an explicit bind value can be provided to override the behavior.

Eventually, it would be nice to support interface binding as well, but it is not a high priority ticket.
",armon,cetex
725,2015-03-16 20:08:05,"@armon I just want to mention a use case that may not be entirely clear here: We at ungleich are running an infrastructure for customers that consists solely of machines with public ip addresses and safe firewall settings - they are all managed by configuration management (cdist in our case).

At the moment we have to include the individual public ip address in the configuration, which kind of reverses the purpose of consul (which is able to discover things, but before discovering, we need to manually discover the node's ip address).

In short: we do have a use case in which we want consul to bind and announce on any address. I would expect consul to do so by issuing -bind=0.0.0.0, however that results in the infamous error message also seen in #789.

If your point of view is that this is insecure by default, then I suggest to add a flag to consul like -allow-insecure-bind or -allow-non-private-bind, but still allow to bind _without_ specifying the public ip address.
",telmich,armon
725,2015-03-17 17:42:28,"@telmich So in this case, is it not possible to just query the IP address of the device via ipconfig and provide that to Consul via `-bind`? The issue with ""0.0.0.0"" is that it's not actually a routable address, we cannot gossip that to our peers. So when you give that address to Consul, it looks for a private IPv4 address by default, and that is the address it uses to announce to peers.

This is why the `-announce` and `-bind` flags are there as an escape hatch. They allow you as an operator to intervene where it's either ambiguous or unsafe by default. What Consul cannot currently do is advertise multiple IP addresses for the same node. This would require a great many changes to how the catalog and gossip systems work to support.

I hope that helps!
",armon,telmich
725,2015-03-19 04:43:25,"@armon I understand the problem in regard to consul now - I wasn't aware that the IP is not taken from the IP packet itself, but is contained as data.

I will try to find a way around it by writing cdist types that query for the address of ethX.

I wonder, would it be a smaller change to consul to support something like -bind-interface to select the ip to be used? Almost all of our machines are running on opennebula and thus the interface is eth0 in most cases, so being able to use -bind-interface eth0 would at least make the situation easier for the moment.

I would however appreciate support for ""no configuration required"" in case of having only official ip addresses mid term - either way (multiple ip support, using the source ip in the ip packet, ...)
",telmich,armon
725,2015-03-19 07:47:34,"@cetex I agree in the regard that using rfc1918 ip addresses for security is flawed by design.

I would personally favor fix no. 1, as it feels very strange in 2015 to rely on rfc1918 ip addresses (may have ""felt"" more sensible in ~1996).

I would also suggest another solution that could make life very easy for developers of consul as of users:
1. Remove check for private ip address
2. Check if list of available ip addresses minus 127.0.0.1 equals 1
   2.1. if yes: bind to it and announce that ip address
   2.2. if no: error out, because it is ambiguous, which IP to announce

That would fix probably 99% of the cases and if you are having multiple IP addresses on a host, you might be doing something ""special"" and require adjusting.
",telmich,cetex
725,2015-03-19 08:17:30,"@telmich I agree. that would be a very sane design since it removes any possibility that consul may select the wrong address to announce ""automagically""

I'm also a bit torn between keeping the ip filter or not, removing it completely would be the most sane thing to do, but keeping it around (changing the default filter to ""::"" so it's not filtering by default) and then making it configurable with an option like ""-limit-announce-ip"" which would override the default of ""::"" would simplify deployment in our case.

For example:
We want consul to listen on \* and we have one or a few known ranges of ip's we want to use for announcement in consul. this ip range is guaranteed to give 1 unique ip per host.

-bind=:: -limit-announce-ip=a.a.a.a/b -limit-announce-ip=c.c.c.c/d would make this work for us.
-limit-announce-ip would make consul only pick ip's for announcing from the specified range and we could configure it quite static in our deployments. Allowing this to be specified multiple times would be neccesary.

But i guess i'd prefer software that doesn't care about what ip's are used at all so my ""vote"" is for complete removal of the feature.
",cetex,telmich
725,2015-05-14 04:16:25,"@johnjelinek that seems odd, specifying an explicit bind address should bypass the code that performs the private IP check. Is there anything special about the environment? What release of Consul are you using?
",ryanuber,johnjelinek
725,2015-05-14 13:25:16,"Using 0.5.1 on Windows Server 2012 R2.



â€”
Sent from Mailbox

On Wed, May 13, 2015 at 11:16 PM, Ryan Uber notifications@github.com
wrote:

> ## @johnjelinek that seems odd, specifying an explicit bind address should bypass the code that performs the private IP check. Is there anything special about the environment? What release of Consul are you using?
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/725#issuecomment-101904637
",johnjelinek,johnjelinek
725,2015-06-17 19:08:11,"@duritong Not quite, you are able to use Consul but you just have to specify the bind address, Consul will not automatically infer it. So you must provide a single configuration option, certainly not an undue burden.
",armon,duritong
725,2015-06-17 19:28:14,"And you also need to create a loopback interface. The burden exists, but it's not significant.

â€”
Sent from Mailbox

On Wed, Jun 17, 2015 at 2:08 PM, Armon Dadgar notifications@github.com
wrote:

> ## @duritong Not quite, you are able to use Consul but you just have to specify the bind address, Consul will not automatically infer it. So you must provide a single configuration option, certainly not an undue burden.
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/725#issuecomment-112916242
",johnjelinek,duritong
725,2015-06-25 20:10:57,"@duritong: That hasn't been my experience. `-bind` without a private interface does not bind to public ipv4. I testing in Windows. Maybe this is not the case in a newer build.
",johnjelinek,duritong
725,2015-06-25 20:33:25,"@johnjelinek Have you tried clearing out your data-dir before running `consul agent -data-dir .\consul -bind 104.167.111.185`? I had some problems where if you start Consul on 1 IP, then try to start it again with a different IP, it keeps trying to use the old IP. I was able to start consul on Azure (which had a 100.x.x.x IP, which up until recently was not considered a private IP) by setting the bind option, but I did it in a config file, not in the command line. I personally try to do everything in the json file and just pass in -config-file ""C:\whatever\consul\conf"" (which reads all jsons in that directory, so it's easy to generate a json file with just 1 config option in it if you need to pre-gen something at runtime).
",highlyunavailable,johnjelinek
725,2015-08-07 16:48:32,"@staticglobal I think there must be some misunderstanding. The problem we face is that if you start Consul without telling it to bind to anything, it needs to pick an IP to use. By default, we will scan for a private IP and bind to that if available. Otherwise, we return an error. Again, this is only in the case where an operator has given no configuration indicating what we should bind to.

An operator can freely use the `bind` and `client` configurations to use any IP they so choose. The IP selection logic is not a security mechanism. The only assumption we have made is that in the absence of _any_ user input, it is probably not a good idea to bind to a public IP, just in case they accidentally run a production cluster with no security enabled on the public internet. 

A perfect example of this is a university campus, where at my school every IP was publicly routable. I'd really rather not discover my research lab's Consul cluster was attacked because I accidentally used a public IP.
",armon,staticglobal
725,2015-08-07 19:29:20,"@armon I do agree with @staticglobal in the sense that consul should not make any difference regarding rfc1918 ips and any other IP. If there is only one IP, it should use it. If there are multiple IPs, it cannot know what to advertise and should fail with ""Multiple IPs detected - please specify the IP to announce"". Even better solution would be to select a preferred interface and if that also has multiple IPs, consul can fail again.

However, distinguishing rfc1918 and public IPs makes the life harder for everyone - I never understood your design decision in this regard.
",telmich,armon
725,2015-08-07 19:29:20,"@armon I do agree with @staticglobal in the sense that consul should not make any difference regarding rfc1918 ips and any other IP. If there is only one IP, it should use it. If there are multiple IPs, it cannot know what to advertise and should fail with ""Multiple IPs detected - please specify the IP to announce"". Even better solution would be to select a preferred interface and if that also has multiple IPs, consul can fail again.

However, distinguishing rfc1918 and public IPs makes the life harder for everyone - I never understood your design decision in this regard.
",telmich,staticglobal
725,2015-09-11 15:49:51,"""By default, we will scan for a private IP and bind to that if available. Otherwise, we return an error. ""

So why not instead bind to whatever IP is found, rather than returning an error? Combine that with the suggestions made by @telmich  and perhaps both ""sides"" can have their cake an eat it to. After all, if a host only has a single IP it is pretty obvious the operator is wanting Consul to bind to it, and pretty obvious it is expected to.

Saying ""we won't bind to a non-rfc1918 address _even if there are none found_ is telling the user you're smarter than they are. Making them jump through hoops to do what daemons are expected to do should have a very high bar, and I don't see that bar as being met here.
",therealbill,telmich
725,2016-02-24 16:41:06,"@telmich - +1 for selecting default interface. Current setup makes it different to run consul automatically on virtual hosts - each one will have different IP, so one has to write a shell script, guess the IP, append to configuration... If we could select an interface - it all gets a whole load easier. I'd tell consul ""advertise on interface eth0"" and that's it.
",TiS,telmich
725,2016-03-06 12:36:37,"+1 for @TiS  suggestion. You can't spawn cloud machines automatically, with docker installation without this feature. One have to write a shell script to bypass.
",OferE,TiS
725,2016-03-08 14:52:38,"@therealbill The downside with choosing the ""first address"" is that in the case of a docker network overlay, the first ip will likely be the wrong one. It would be better if it would bind to all ip's on a given interface, if you don't want it to bind to all of them then the ip should be specified. Perhaps something like:

`--bind eth0` to bind to all ip's on a given interface

`--bind eth0;10.0.0.0/16` bind to any ip on a given interface that matches the given cidr.

`--bind eth0;10.0.0.5` bind to a specific ip on a given interface

`--bind 10.0.0.5` bind to a specific ip regardless of interface

`--bind 10.0.0.0/16` bind to a given ip that matches a cidr regardless of interface
",withinboredom,therealbill
725,2016-03-08 20:14:24,"@withinboredom I'd be ok with that.
",therealbill,withinboredom
725,2016-03-08 23:20:07,"@beornf, individual addresses can end with `.0`, it is not a certain indication of a subnet mask. @withinboredom's proposal is better.
",orivej,beornf
725,2016-03-08 23:20:07,"@beornf, individual addresses can end with `.0`, it is not a certain indication of a subnet mask. @withinboredom's proposal is better.
",orivej,withinboredom
725,2016-09-09 10:32:00,"@jyoti-264  , your port is already in use. Try to provide another port.
",Globik,jyoti-264
725,2016-12-02 17:55:37,"@sean- that looks awesome - will give it a try next week!
",telmich,sean-
725,2017-03-06 20:32:31,"@Yuav you have to restart Consul, but if you use `-bind={{GetPrivateIP}}` and restart the process when it changes IPs you'll be g2g now that https://github.com/hashicorp/consul/pull/2786 has been merged.",sean-,Yuav
724,2015-02-23 18:32:25,"@ryanuber Can you make sure the docs get updated for this?
",armon,ryanuber
724,2015-02-23 18:45:35,"@armon done in 84f04ff and 2c3995b
",ryanuber,armon
724,2015-02-23 18:46:07,"@ryanuber :+1: 
",armon,ryanuber
721,2015-02-20 19:41:23,"@blalor shared some debug logs with me, which included this raft log:



Looking at the raft code, it's obvious why this log causes this problem. Need to look into how we get into this state to begin with. Perhaps a graceful leave on a single-node cluster is how we get here(?).
",ryanuber,blalor
721,2015-02-23 17:24:55,"@blalor I haven't been able to get a repro case on this. I tried starting up a 0.4.1 single-server cluster with 1 client and then upgrading it to 0.5, but things worked normally, so the upgrade by itself doesn't seem to be the problem. Are there any steps you've been able to reproduce this with?
",ryanuber,blalor
721,2015-02-23 18:31:43,"@blalor The simplest fix is to just blow away the data dir. There was a regression in 0.4.1 that changes how single node clusters worked, which is why the 0.4.0 -> 0.4.1 and the 0.4.1 -> 0.5.0 transitions have been problematic.
",armon,blalor
721,2015-02-23 18:50:44,"@blalor What may be possible is to actually start another server (no bootstrap), then edit the peers file to have both of the servers.
",armon,blalor
721,2015-02-23 19:11:09,"@blalor You cannot have a cluster with partial encryption, it's sort of all-or-nothing.
",armon,blalor
720,2015-02-20 21:42:47,"@armon @ryanuber this is something that has come up in almost all of our projects at least once. I think we could build something into middleman-hashicorp in the frontmatter or some type of common annotation that we use.
",sethvargo,armon
720,2015-02-20 21:42:47,"@armon @ryanuber this is something that has come up in almost all of our projects at least once. I think we could build something into middleman-hashicorp in the frontmatter or some type of common annotation that we use.
",sethvargo,ryanuber
720,2015-02-20 22:50:12,"Yea, I think @sethvargo has a good point in that we can just build this into middleman-hashicorp. 

Design wise, a subtle `> v0.5` underneath the doc title or w/e would be a good approach and not clutter things too much IMO.
",pearkes,sethvargo
720,2015-02-20 22:51:03,"But yea, I also agree with @ryanuber that if we do it inline full width across the text it could get tiresome/distracting. Need something a little quieter.
",pearkes,ryanuber
719,2015-02-20 03:14:16,"@blalor so this is tricky. The problem you are facing is that any given node will _only_ send messages using the primary encryption key. We don't encrypt replies based on the the key used from the requestor. Since your 2nd node never knew about the new key, it was unable to decrypt the response sent to it from the original node, and therefore could not join. Normally a key rotation should happen when all nodes are available to receive the new key, and not during a deploy. I'll think more about how we can make this nicer.
",ryanuber,blalor
719,2015-03-04 02:29:56,"@blalor makes sense, I'll see if we can do something more intelligent for the initial keyring persistence. For the time being, you could work around it by removing the data directory if the initial start-join fails.
",ryanuber,blalor
718,2015-02-20 02:44:47,"@blalor ah, re-reading the message now it does sound a little ambiguous (**what** is it ignoring?). I'll clarify.
",ryanuber,blalor
718,2015-02-20 02:53:19,"@blalor the message should now read:



Thanks for the report!
",ryanuber,blalor
717,2015-07-07 02:12:53,"@armon any thoughts on this? I'd really love to get our ACL definitions in source control!
",colinrymer,armon
717,2015-07-07 16:14:16,"@colinrymer It's now possible with some of the changes in Consul 0.5.2, but wasn't previously. It's on our roadmap, but no definitive timeline yet. It should be pretty easy to whip up a script using our API currently to scan files in a dir and hit the API.
",armon,colinrymer
714,2015-02-19 22:46:03,"@highlyunavailable this is exactly what i needed, thanks a lot!
",hoffoo,highlyunavailable
711,2015-02-19 00:53:38,"@ryanuber I think we can actually re-write most of the API to use the shared query() / write() methods. It just started to get too far out of scope for this PR.
",armon,ryanuber
711,2015-02-19 00:54:55,"@armon makes sense to me. Have to draw that boundary somewhere.
",ryanuber,armon
709,2015-04-18 00:00:16,"@nathanisaac-s We haven't actually attempted to generate a zone transfer, so I'm not sure. It's not a recommended pattern. Better to use DNS delegation or forwarding.
",armon,nathanisaac-s
709,2015-10-13 16:57:04,"@alexinthesky Use the datetime as the serial number? If you use `{{timestamp ""unix""}}` then it'll return the unix time in seconds. Otherwise, check out the ""timestamp"" directive in the consul-template readme and it has alternative ways to format the time.
",highlyunavailable,alexinthesky
709,2015-10-13 17:13:35,"@blalor if you can get that data, that would be a better serial, yes. I didn't see anything that let you access the consul index for consul-template.
",highlyunavailable,blalor
709,2015-10-13 19:11:49,"@highlyunavailable using the UNIX timestamp does generate a legal zonefile that will meet the DNS requirements for a higher serial number, but it's not strictly speaking a `+=1` increment which seems to be the original intent... In any case the unix timestamp has been my goto solution for the same issue as well so I'm not alone.

Would storing the DNS zone into a consul KV pair be one possibility?
",nathanisaac-s,highlyunavailable
709,2015-10-14 07:42:43,"@awheeler this fails if you have dots in the service names..... I ended up using the ID field, like that 

{{range services}}{{range service .Name ""any""}}
{{.ID}} 60 A  {{.Address}}{{end}}{{end}}

but maybe there is a more elegant solution to introduce dots (I have no choice but to do this ) ?
",alexinthesky,awheeler
708,2015-02-20 19:30:48,"Thanks, @zoli! Since we support multiple recursors, it would be nice if the `-recursor` flag was repeatable. You can see an example of how to do this with the `-config-file` argument.
",ryanuber,zoli
707,2015-02-17 20:20:10,"@ryanbreen the call to `UpdateCheck` will only update the in-memory status of the check and its output, not the check definition itself. So this should give the desired functionality.
",ryanuber,ryanbreen
706,2015-04-11 17:41:46,"@nickwales we originally had checks register as healthy. The problem with that approach is that the service may appear healthy before its first health check has run, and then immediately fail. To err on the side of caution we flipped this so that API consumers with watches on services don't see a given service until it is confirmed healthy.

I think the best thing to do is keep the current defaults, but allow specifying an alternate initial state.
",ryanuber,nickwales
704,2015-02-17 19:32:42,"@seropian It's hard to tell without the logs from all the machines what is happening. There is clearly some issue preventing the leader election, but this is too limited of information to tell.
",armon,seropian
703,2015-02-21 12:28:58,"I guess this is the same issue as https://github.com/hashicorp/consul/issues/725

By default, consul won't bind to any ip that isn't in the ranges:
10.0.0.0/8
172.16.0.0/12
192.168.0.0/16
The source is here https://github.com/hashicorp/consul/blob/master/consul/util.go

A VPC can be setup with any ip range, so if the vpc that @dgarstang has is using anything else than these ip's consul will refuse to start.
",cetex,dgarstang
703,2015-02-23 18:43:02,"@dgarstang Can you confirm if that is the case? @cetex is correct, Consul will not bind to a non-private address by default, but that behavior can be overridden with `-bind`.
",armon,dgarstang
703,2015-02-23 18:43:02,"@dgarstang Can you confirm if that is the case? @cetex is correct, Consul will not bind to a non-private address by default, but that behavior can be overridden with `-bind`.
",armon,cetex
697,2015-02-17 19:33:16,"@tayzlor Yes, there is another open ticket to support adding metadata to services which could then be used downstream by registrator.
",armon,tayzlor
697,2015-03-11 21:16:39,"@armon Can you post that other ticket's ID?  I am interested in following that effort, and seeing if I can contribute to it.
",pccowboy,armon
697,2015-03-12 21:21:34,"@pccowboy It's not a specific issue I guess, but a collection:
- https://github.com/hashicorp/consul/issues/367
- https://github.com/hashicorp/consul/issues/154
- https://github.com/hashicorp/consul/issues/1107

Basically, it's to support K/V tags on Nodes / Checks / Services. My guess is this will require a v2 API that allows us to rethink things a bit.
",armon,pccowboy
695,2015-02-13 01:03:06,"@ryanbreen So the code for it is here:
https://github.com/hashicorp/consul/blob/master/command/agent/session_endpoint.go#L105

But @sethvargo recently showed me that Golang time.ParseDuration does not allow a value without a suffix, so this may be a non-issue.
",armon,ryanbreen
693,2015-02-13 06:02:55,"1.I register a service in consul agent:



And, I exam the result use `http://192.168.2.71:8500/v1/health/service/innosql`



2.I create a session like this:



result is:



and use session/info api: `http://192.168.2.71:8500/v1/session/info/fa9599ae-f4e4-8015-6325-cc9e1c83581e` 



3.I reload the consul agent.



4.Use session/info api: `http://192.168.2.71:8500/v1/session/info/fa9599ae-f4e4-8015-6325-cc9e1c83581e`  again.
return _null_

Is that normal? Thank you for your answer!@armon
",ahjdzx,armon
693,2015-02-17 19:45:03,"@ahjdzx Thanks for the detailed report! I see the issue, it is not expected behavior. Tagged as bug. Thanks!
",armon,ahjdzx
688,2015-02-17 19:34:11,"@balexx @dpkirchner There was a regression that caused a lot of connections to be maintained, which is now fixed in master for the 0.5 release. Sorry about that!
",armon,balexx
688,2015-02-17 19:34:11,"@balexx @dpkirchner There was a regression that caused a lot of connections to be maintained, which is now fixed in master for the 0.5 release. Sorry about that!
",armon,dpkirchner
688,2015-02-17 21:56:47,"We just had the same issue. Great that it's fixed! @armon could you please link to the commit or PR that fixes it?
",tgwizard,armon
688,2015-02-18 00:16:04,"@tgwizard Here it is: https://github.com/hashicorp/consul/commit/d92e5d37e3b83dc05c6504861041bd8c294fb844

It was actually a revert of the commit that caused the regression.
",armon,tgwizard
688,2015-04-17 23:52:37,"@cglewis Can you provide more information? This should be a fixed issue as far as we know
",armon,cglewis
688,2015-04-20 15:51:07,"@armon I'm running on Ubuntu 14.04.1 with consul 0.5.0 and seeing the same error message as at the top of this issue.  what other information would be helpful to you?  for now I just increased the allowed open file count and rebooted the box.
",cglewis,armon
688,2015-04-20 17:34:39,"To make sure I understand this - The standing issue is that Consul floods the logs when file handles are exhausted, not that Consul itself is leaking resources, correct? It sounds like @armon has fixed @dpkirchner's resource leaking problem, but if any program exhausts file handles Consul fills the disk with logs.

@cglewis are you just redirecting consul's log output to a file? If you use a syslog server, most often times there is a coalescer built in (like rsyslog's [message reduction](http://www.rsyslog.com/doc/rsconf1_repeatedmsgreduction.html)).
",ryanuber,armon
688,2015-04-20 17:34:39,"To make sure I understand this - The standing issue is that Consul floods the logs when file handles are exhausted, not that Consul itself is leaking resources, correct? It sounds like @armon has fixed @dpkirchner's resource leaking problem, but if any program exhausts file handles Consul fills the disk with logs.

@cglewis are you just redirecting consul's log output to a file? If you use a syslog server, most often times there is a coalescer built in (like rsyslog's [message reduction](http://www.rsyslog.com/doc/rsconf1_repeatedmsgreduction.html)).
",ryanuber,cglewis
688,2015-04-20 17:34:39,"To make sure I understand this - The standing issue is that Consul floods the logs when file handles are exhausted, not that Consul itself is leaking resources, correct? It sounds like @armon has fixed @dpkirchner's resource leaking problem, but if any program exhausts file handles Consul fills the disk with logs.

@cglewis are you just redirecting consul's log output to a file? If you use a syslog server, most often times there is a coalescer built in (like rsyslog's [message reduction](http://www.rsyslog.com/doc/rsconf1_repeatedmsgreduction.html)).
",ryanuber,dpkirchner
688,2015-04-20 17:40:53,"@ryanuber so I only have two things running on that machine, and the former has been running fine for months without file handle issues, but only after adding consul agent to it has it started to have this issue.  I don't care as much about the logs filling up, as that can easily be filtered, I was more concerned that Consul seems to be the culprit for the resource leak, though I can't verify that specifically, as I haven't isolated it yet.
",cglewis,ryanuber
688,2015-04-23 01:42:19,"@cglewis How large is your cluster? There are a number of fixes in master now for causing excessive socket usage on large clusters. 0.5.1 should improve that situation. There is definitely an issue of excessive logging as well if we exhaust file handles, but the answer there is to just crank ulimit way up for now.
",armon,cglewis
688,2015-11-17 00:53:43,"@ChrisMcKenzie are you still experiencing this? The issue of aggressive logging when file handles are exhausted still exists, and it's a difficult-to-detect situation from inside of the application. The solution for now is to set high limits for ulimit, or using a syslog server to leverage its log throttling abilities, such as rsyslog. The latest release should contain the fixes mentioned above by @armon so this should be less of a problem now.
",ryanuber,armon
688,2015-11-17 00:53:43,"@ChrisMcKenzie are you still experiencing this? The issue of aggressive logging when file handles are exhausted still exists, and it's a difficult-to-detect situation from inside of the application. The solution for now is to set high limits for ulimit, or using a syslog server to leverage its log throttling abilities, such as rsyslog. The latest release should contain the fixes mentioned above by @armon so this should be less of a problem now.
",ryanuber,ChrisMcKenzie
688,2015-12-15 16:13:27,"Hi @samprakos the mixed Consul versions should be fine. Can you run `lsof -p <consul agent pid>` on one of these boxes that's out of descriptors so we can see what type of things are using up the file descriptors?
",slackpad,samprakos
688,2015-12-17 01:35:53,"@samprakos didn't realize this was already open but this is probably a good fix - https://github.com/hashicorp/consul/pull/1499. I'll do a little more digging and probably merge this tonight - this would let your existing code work as-is.
",slackpad,samprakos
688,2015-12-17 20:03:21,"@samprakos even better this is being fixed in the upstream library in https://github.com/hashicorp/go-cleanhttp/pull/2 - once that's done you should be able to just update go-cleanhttp and be good to go with no changes to your code.
",slackpad,samprakos
680,2015-02-08 19:56:51,"Hey @lalyos, thanks! We will probably want to check if there is a pre-release flag set, so in the case of a final release number we don't end up with `x.x.x-` (empty pre-release field).
",ryanuber,lalyos
680,2015-02-09 07:23:52,"Ohhhh @ryanuber you are just destroying my single character PR ;) 
fixed that.
",lalyos,ryanuber
680,2015-02-09 08:08:49,"LGTM, thanks @lalyos!
",ryanuber,lalyos
679,2015-02-08 19:16:54,"@blalor unfortunately that's not always possible.  For example, I'd register the service from the Mesos executor process, this process could get OOM killed (since it runs inside a control group) and then I'd be unable to clean up the service definition.

What we're doing now is using etcd to add a key for the service with a TTL, and constantly refresh the TTL.  If the TTL expires the key is deleted.  There's no other process that needs to run to clean up stale etcd keys, which really makes operations much more simple.

It'd be interesting if something like this is possible, or if we need to write cron jobs that can somehow reconcile stale service definitions with services that should actually exist?  The latter seems really lame.
",ajf,blalor
679,2015-02-17 19:37:51,"@ajf Sounds like what may work is to have a TTL based check, but to specify new behavior such that if it fails the entire service should be de-registered. Does that seem reasonable?
",armon,ajf
679,2015-02-28 16:37:23,"@armon exactly right.
",ajf,armon
679,2015-07-08 23:49:58,"is it still planned @armon by any chance ?
",scalp42,armon
679,2015-07-10 00:20:09,"@scalp42 Yes, it is still planned
",armon,scalp42
679,2015-08-01 19:31:27,"@ajf and @armon We can really use this as well. 

Perhaps a new boolean attribute called deregisterService. By default value for deregisterService is false for backward compatibility. If deregisterService is true and after TTL is breached the service is deregistered from the catalog. 
Json example.
{
  ""check"": {
    ""id"": ""web-app"",
    ""name"": ""Web App Status"",
    ""notes"": ""Web app does a curl internally every 10 seconds"",
    ""ttl"": ""30s"",
    ""deregisterService"":true
  }
}
",brycechesternewman,armon
679,2015-08-01 19:31:27,"@ajf and @armon We can really use this as well. 

Perhaps a new boolean attribute called deregisterService. By default value for deregisterService is false for backward compatibility. If deregisterService is true and after TTL is breached the service is deregistered from the catalog. 
Json example.
{
  ""check"": {
    ""id"": ""web-app"",
    ""name"": ""Web App Status"",
    ""notes"": ""Web app does a curl internally every 10 seconds"",
    ""ttl"": ""30s"",
    ""deregisterService"":true
  }
}
",brycechesternewman,ajf
679,2015-08-04 01:01:47,"Agreed @brycechesternewman -- should be defined at the check and/or the service. The latter would allow for built in checks for agent availability to be leveraged by default. 
",kriss9,brycechesternewman
679,2015-08-06 20:12:27,"Not sure if this is what you're already thinking this @armon. If service/register supported the `acquire` parameter, the service could be deleted when it's session ttl expires, the way ephemeral keys currently work.
",cablehead,armon
677,2015-02-08 20:10:12,"Hi @jhmartin, this is likely consul receiving the HUP before the signal handler is registered. We might be able to move the handler registration earlier in the process, but that only improves our chances of catching the signal (not guaranteed). 

This is easily reproducible with the following command:



Adding a sleep before `kill` demonstrates the handler catching the signal if given a chance to register. I'll see if moving it earlier in the startup helps at all.
",ryanuber,jhmartin
677,2015-02-08 20:32:11,"@jhmartin I just experimented with this a bit, and I don't think we'll be able to do much better. You can see my example program [here](https://gist.github.com/ryanuber/368a7b8b63e76d967759). You might want to keep a very short sleep on the end of the command, or in your init script to guard against this.
",ryanuber,jhmartin
677,2015-07-13 03:17:47,"@ryanuber Could the startup order be reworked to prevent consul info from being successful until after initialization is complete?
",jhmartin,ryanuber
669,2015-02-04 18:44:04,"@nicholascapo yep! Currently we don't have any special branches, we just tag master as we go for each release.
",ryanuber,nicholascapo
669,2015-02-04 18:47:18,"Excellent, thanks!

On Wed, Feb 4, 2015, 12:44 Ryan Uber notifications@github.com wrote:

> @nicholascapo https://github.com/nicholascapo yep! Currently we don't
> have any special branches, we just tag master as we go for each release.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/669#issuecomment-72912915.
",nicholascapo,nicholascapo
668,2015-02-04 18:55:53,"@nicholascapo I think the main thing is just making sure that there are no races, so if we did end up keeping HealthUnknown or some other status, we would need to modify any place where we apply health filters (probably `dns.go` and `health_endpoint.go`). I don't recall if there was any other reason we stopped using HealthUnknown aside from the race conditions it caused initially. @armon thoughts?
",ryanuber,armon
668,2015-02-04 18:55:53,"@nicholascapo I think the main thing is just making sure that there are no races, so if we did end up keeping HealthUnknown or some other status, we would need to modify any place where we apply health filters (probably `dns.go` and `health_endpoint.go`). I don't recall if there was any other reason we stopped using HealthUnknown aside from the race conditions it caused initially. @armon thoughts?
",ryanuber,nicholascapo
668,2015-02-05 18:56:33,"@armon @ryanuber Can't we deprecate unknown health and just provide initial status while registering a check? Or with less granularity, while registering a service? It seems that initial status depends on the semantics of the service.
What consul 0.5 currently do with zero checks for a service?
",salehe,armon
668,2015-02-05 18:56:33,"@armon @ryanuber Can't we deprecate unknown health and just provide initial status while registering a check? Or with less granularity, while registering a service? It seems that initial status depends on the semantics of the service.
What consul 0.5 currently do with zero checks for a service?
",salehe,ryanuber
663,2015-01-31 18:36:18,"@ryanbreen this looks great! Just one comment about a small mistake, but otherwise this looks merge-ready.
",ryanuber,ryanbreen
661,2015-01-30 18:39:27,"@sigil66 Take a look at the event APIs: https://consul.io/docs/agent/http.html#event. Those are mapping down to Serf user events under the hood. Other types of events (Join/Fail/Leave) map to state in the catalog which can be queried.
",armon,sigil66
660,2015-01-30 07:34:47,"@gkze the build failing isn't from your changes, so no worries on that front.

This is great! You might want to take a peek at the master branch since there are a number of new commands and arguments going in to the 0.5 release.
",ryanuber,gkze
660,2015-01-30 08:12:28,"@ryanuber thanks for the heads up! Added
",gkze,ryanuber
654,2015-02-04 18:35:35,"@arnaudbriche Thanks! Could you also add the appropriate doc updates? If you don't have time, I'll eventually swing back around to this
",armon,arnaudbriche
654,2015-02-06 07:03:36,"@arnaudbriche I'm going to merge this in and make the documentation changes. I'll link you to the commit after. Thanks for taking care of this!
",ryanuber,arnaudbriche
654,2015-02-06 07:36:58,"@arnaudbriche you can find the adjustments I made [here](https://github.com/hashicorp/consul/compare/45097f9f3d...5c2a764cbe). I had to adjust a few of the tests as well, but nothing major. Thanks!
",ryanuber,arnaudbriche
653,2015-01-29 10:56:38,"@ryanbreen I like this. Nice work.
",ceh,ryanbreen
652,2015-01-28 22:40:14,"Looks like a bug in Consul. I'll take a look at this shortly. Thanks @ryanbreen !
",ryanuber,ryanbreen
650,2015-02-03 11:29:38,"@sielaq ""Why do You need consul in every container on one same DOCKER_HOST ?"" -> multi-tenancy is one reason.
",rotatingJazz,sielaq
650,2015-02-03 17:33:57,"@sielaq I suppose you assume everyone runs docker hosts on elastic cloud and not on dedis. On dedis the illogical thing is to under-use your hardware, not the opposite because of software limitations. 

Besides, having multiple consul instances will be trivially possible once https://github.com/hashicorp/consul/issues/550 lands.
",rotatingJazz,sielaq
647,2015-01-27 17:50:07,"Hi @byllc,

Sounds like this is related to the new cluster mixing guard we are introducing in 0.5. Is the client in a different datacenter than the server? Consul could be guarding against mixing multiple datacenters into a single gossip pool.
",ryanuber,byllc
647,2015-01-27 18:06:00,"@ryanuber  Thanks, that seems to have been the problem, the server had a different datacenter name specified than the config for the agent. 
",byllc,ryanuber
646,2015-01-26 22:14:17,"Hey @darron, this actually seems correct. If the node has gone offline, it is likely not running the checks any more, and definitely not submitting them to the catalog. Since the check is a script + interval type, the only thing that ends up marking the check as failed is when a bad return code is observed when the agent runs the script, and the result submitted to the catalog. I can see how this could be a little confusing when looking at the UI. 

As a side note, the node in the output you've provided actually **should** be excluded from any queries for the `bunk` service with passing filters enabled. Reason being is that `serfHealth` is failing, and is attached directly to the node. If any node-level health checks go into a failed state, then all services from the node should be excluded from the typical DNS or API `/v1/health/service/bunk?passing` interfaces.
",ryanuber,darron
645,2015-01-26 18:15:40,"@hoffoo probably not with the Makefile, since we ensure from there that all of the deps are available. You might be able to build using plain old `go build` in the consul directory, but YMMV.
",ryanuber,hoffoo
644,2015-01-28 05:49:10,"@foostan this LGTM! I merged before I read your question about adding tests, so I added them in 58eba95. Thanks for the fix!
",ryanuber,foostan
640,2015-01-24 21:18:09,"Hey @foostan, thanks for the PR! We have definitely noticed the various inconsistencies we have in Consul's API around allowed methods, response codes, etc.

By doing `GET /v1/agent/service/deregister/`, I don't see the behavior you mention where all services become deregistered. Only if a service ID is specified does it actually deregister anything.

Although it seems silly to use GET to deregister a service, we accept that method currently, and we don't state anywhere in our HTTP docs which methods are allowed/disallowed for deregistering services. We want to avoid breaking existing clients as much as possible.

For these reasons, we've started to tally up things we want to address in a `/v2` API set. We'll post a public GitHub issue once we have our initial set of goals laid out, and we likely won't start working through these until at least post-0.5 release.

I'm going to close this for now, but I've taken an item down to address this globally in all of Consul's API methods for `/v2`.
",ryanuber,foostan
640,2015-01-24 21:18:43,"@foostan if I missed anything or misunderstood you, let me know and we can re-open this. Thanks!
",ryanuber,foostan
639,2015-01-24 21:22:56,"@ceh I agree that this would be really nice to have. I think we also want artifact generation for various platforms while using cgo to make our releases less manual, its just not something we've been able to invest in yet.
",ryanuber,ceh
637,2015-01-25 04:32:49,"@ryanuber 

Moved the implementation into util_GOOS.go and made the function take an integer pid instead of a `os.Process` to make it more useful.

Kept `syscall.Signal` in the Windows function signature to keep 'em identical, plus, Go might add support for interrupts on Windows in the future.

Please take another look.
",ceh,ryanuber
633,2015-01-23 23:14:46,"@hoffoo are the servers running different versions of Consul? It sounds from the logs like the leader is newer than the follower(s) being replicated to, and is attempting to replicate the `TombstoneRequestType`, which was recently introduced in Consul 0.5.0rc1. If that is the case, upgrading the other servers in the cluster might be the only way to get the followers to accept the data again, unless I am missing something. @armon what do you think?
",ryanuber,armon
633,2015-01-23 23:14:46,"@hoffoo are the servers running different versions of Consul? It sounds from the logs like the leader is newer than the follower(s) being replicated to, and is attempting to replicate the `TombstoneRequestType`, which was recently introduced in Consul 0.5.0rc1. If that is the case, upgrading the other servers in the cluster might be the only way to get the followers to accept the data again, unless I am missing something. @armon what do you think?
",ryanuber,hoffoo
633,2015-01-24 09:31:46,"@armon @ryanuber doesn't this break consul's compatibility promise? 
",wuub,armon
633,2015-01-24 09:31:46,"@armon @ryanuber doesn't this break consul's compatibility promise? 
",wuub,ryanuber
633,2015-01-24 21:40:14,"@wuub the protocol compatibility is not affected by this. The issue of not being able to apply new items from the Raft log on older versions of Consul should only come up if a partial upgrade of the server pool is performed (say, 1/3 of them), and normal operations are resumed while this inconsistency exists. There should not be problems during the upgrade process, but generally running multiple versions of Consul servers together in a cluster during normal operation is not ideal.

Since this particular case involves older server nodes being unable to apply certain operations replicated to them from newer servers, we will likely need to publish a note about upgrading from pre-0.5 releases.

@armon any other thoughts on this?
",ryanuber,armon
633,2015-01-24 21:40:14,"@wuub the protocol compatibility is not affected by this. The issue of not being able to apply new items from the Raft log on older versions of Consul should only come up if a partial upgrade of the server pool is performed (say, 1/3 of them), and normal operations are resumed while this inconsistency exists. There should not be problems during the upgrade process, but generally running multiple versions of Consul servers together in a cluster during normal operation is not ideal.

Since this particular case involves older server nodes being unable to apply certain operations replicated to them from newer servers, we will likely need to publish a note about upgrading from pre-0.5 releases.

@armon any other thoughts on this?
",ryanuber,wuub
633,2015-01-25 22:01:54,"I've clarified the backwards compatibility in f53bd94. 
@wuub the short answer is kind of. The servers cannot be mixed with 0.5, but the clients can. The clients are largely where this promise matters, as it's very hard to coordinate the upgrade of thousands of nodes. We try very hard with the servers as well, but it can be extremely challenging to be forward and backward compatible in all cases. With 0.5 there is a 15 minute time window before you will have any issues, which is reasonable enough to handle a 3-5 node rolling upgrade.
",armon,wuub
633,2015-01-27 01:54:08,"@wuub Let me try to clarify:

1) The 15 minutes comes from the servers periodically issuing a new `TombstoneRequest`. This is an internal detail, but it basically allows Consul to cleanup some keys in the background after a configurable TTL. The default value of the TombstoneTTL (not configurable currently) is 15 minutes: https://github.com/hashicorp/consul/blob/master/consul/config.go#L242.

Basically, 15 minutes after a 0.5.0 leader is elected, it will issue that command to followers. Older versions will append to their Raft log, but then panic when they attempt to apply it. This is by design, since we don't know if its safe to ignore a command (future compatibility), we log a message and then hard panic. This is to avoid potential state corruption given that the command is not understood.

2) As above, it will hard panic / stop processing. Stale reads will not affect this since the server will just crash.

3) Correct! The issue stems from trying to process the `TombstoneRequest` internally.

4) Yep! This command is purely internal to the cluster, and does not get issued between clusters.
4a) I highly doubt it. That would be a logistical nightmare that we would work very hard to avoid.
",armon,wuub
633,2015-01-27 09:20:17,"thank you @armon , everything is clear now
",wuub,armon
630,2015-01-23 17:52:37,"@petemounce this is already in master! 0.5rc1 was just tagged yesterday and includes this feature. Thanks!
",ryanuber,petemounce
630,2015-01-26 17:39:09,"Brilliant :-)

## 

Sent from my phone. Please excuse typos and brevity, but never text speak.
On 23 Jan 2015 17:52, ""Ryan Uber"" notifications@github.com wrote:

> @petemounce https://github.com/petemounce this is already in master!
> 0.5rc1 was just tagged yesterday and includes this feature. Thanks!
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/630#issuecomment-71233793.
",petemounce,petemounce
629,2015-01-23 06:17:32,"@darron was this working before? I do not see where a config_dir was supported in the code. Previously consul would have silently ignored this, but in 0.5.0 we are adding a more strict config checker which catches unknown config keys.
",ryanuber,darron
629,2015-01-23 06:20:44,"@darron related: #71 
",ryanuber,darron
628,2015-01-22 21:13:52,"@ryanuber quite the opposite actually

Right now, if we (someone who has commit to hashicorp/consul) push a branch (like f-new-feature) to hashicorp/consul, a Travis build is triggered. Next, when we open a PR for said branch, **another** build is triggered. As such, for each commit we push beyond the original PR, **two** builds will happen - one because we pushed to a branch that is in the repo and two because we pushed a commit to an open PR.
",sethvargo,ryanuber
628,2015-01-28 12:37:20,"@sethvargo OS X is in beta and can be enabled according to http://docs.travis-ci.com/user/multi-os/

Updates #639.
",ceh,sethvargo
628,2015-01-28 16:23:25,"@ceh ^
",sethvargo,ceh
619,2015-01-20 20:15:35,"@armon This looks great! Only minor nit-picks added. Otherwise this LGTM. Glad to see a SIGTERM attempt before SIGKILL in here, too!
",ryanuber,armon
619,2015-01-20 20:42:46,"@armon added one more question about `RenewPeriodic()`.
",ryanuber,armon
619,2015-01-21 23:59:28,"@sean- the `-n` value actually is encoded in the key used for the semaphore! This allows additional clients trying to use the semaphore with a conflicting `-n` value to detect this and exit immediately. The code that does the check was actually part of a different PR [here](https://github.com/hashicorp/consul/blob/master/api/semaphore.go#L208), which extended the API client with a bunch of helper methods, including both the lock and the semaphore. This PR wraps those extra methods nicely into the base consul CLI. Agreed though, we could probably add a note that using `-n` with a conflicting value will result in an error.
",ryanuber,sean-
619,2015-01-22 01:35:38,"@sean- Clarified the documentation in d478f78. You will get an error if -n conflicts. 
",armon,sean-
617,2015-01-18 01:42:20,"@blalor i think we are definitely interested in having auto generated docs. This was just a fairly easy split of the existing docs that makes them much easier to navigate and easily fits into the existing consul website.
",ryanuber,blalor
616,2015-01-18 02:26:05,"Thanks, @ceh! Are two `-f`'s required in the `go get` command?
",ryanuber,ceh
612,2015-01-20 15:04:10,"@ryanuber @armon  I wish you guys had included me in the discussions before unilaterally changing this around. Both of these are bad changes. I would appreciate if you reverted these and included me in the discussion.
",jefferai,ryanuber
612,2015-01-20 16:18:02,"Hey @jefferai 

I am sorry if you feel like we went behind your back. That was certainly no one's intention. We discussed the changes at length as a team and we decided that many of the behaviors introduced were not in parallel with the [Principle of Least Surprise](http://en.wikipedia.org/wiki/Principle_of_least_astonishment) or other tools in the industry. Please allow me to elaborate further.
- When listening on a socket in nginx, nginx will create the socket as the same user:group the nginx processes is running as. If you need particular permissions for the socket, you must run nginx as a different user (or more commonly a different group) so that other services can read/write to the socket. We decided to take a similar approach with Consul. Furthermore, the standard description of a unix socket is `unix:/path/to/socket`. We did not feel comfortable coalescing the unix socket descriptor with the permissions on the socket file itself.
- We did not think it was the appropriate UX to automatically delete the socket. If the socket was persisted on disk, that means Consul was unable to shut down cleanly (something bad happened), and a human being should make a decision of whether it is safe to remove the socket file and restart Consul or if more intervention is needed. Other tools (like postgres and nginx) both follow this paradigm.

If there are specific issues I did not cover in my response, please let me know comment on the appropriate lines in the diff of this PR and we can definitely revisit the decision(s).
",sethvargo,jefferai
612,2015-01-20 16:54:50,"Hi @sethvargo @ryanuber @armon 

First off, I want to point out that this is an example of being a _terrible_ upstream. The syntax was proposed on the mailing list. Nobody, including Consul team members, objected. Ryan asked about it on the previous pull request, then after I explained my rationale, he thanked me for it and expressed no reservation.

You guys could have had a further discussion with me on the previous PR. You could have expressed concern and asked for community input on the mailing list. You could have poked me in email or on IRC. You could even have gotten me to make needed changes prior to you merging them so that my time wasn't wasted coding them in and writing tests for them only for you guys to waste your time reverting them less than 24 hours later.

That sucks.

So let's go over the problems with these changes.

1) nginx is not the only game in town. Many other services -- for instance, dovecot, clamav, _and_ your own later example of postgres -- allow you to specify the (usually) user and (definitely) group and mode you want to use, to make it easier and -- crucially -- more secure for other services to interoperate. That way you don't need to have the primary group you are running consul under be the group that everyone else uses to communicate with it. Removing that capability reduces both flexibility and security.

2) You can't simply get around this by making a directory and creating the socket in that directory and having it inherit permissions. I don't know what man page you're looking at, but `man 7 unix` on my Ubuntu 14.04 system says nothing of the sort. And I just verified that using netcat -- permissions of the parent directory have nothing to do with anything, so the workaround you guys suggest isn't actually a workaround. Proof:



3) Rather than removing the user/group/mode altogether, you could have simply expanded the configuration language, as Ryan and I discussed in the previous PR. As I said there, nobody expressed any issue with the configuration language since the original RFC, and if people didn't like the coalesced syntax the right thing to do would be to modify configuration to support sockets properly. You guys picked the nuclear (and time-wasting) option instead.

4) Leaving aside the point of what a user would do with a dead socket if Consul died in an unclean fashion, I don't know where you got your intel about removing sockets and postgres, but it's wrong. If postgres dies and you restart it, something in postgres wipes the socket and recreates it. I don't know what does it, but I _can_ tell you that it's not Ubuntu's init script. It's one of the pg tools, or it's the daemon itself. I just tested this -- on unclean shutdown the socket remains, and upon restarting the socket is removed and recreated, which I can tell because the inode changes:



Here's another example, using everyone's favorite netcat:



As a contrast, let's see the workflow with nginx:



I don't know where you guys got your intel, but it's wrong. You care about principle of least surprise...so do I. The least surprise solution is not to leave a dead socket lying around that the user can't do anything with anyways and then fail to start because of it. That will just leave users pissed off when a simple restart of consul fails to work. The least surprise solution is to do what everyone else is doing, and remove the socket and then re-create it.
",jefferai,ryanuber
612,2015-01-20 16:54:50,"Hi @sethvargo @ryanuber @armon 

First off, I want to point out that this is an example of being a _terrible_ upstream. The syntax was proposed on the mailing list. Nobody, including Consul team members, objected. Ryan asked about it on the previous pull request, then after I explained my rationale, he thanked me for it and expressed no reservation.

You guys could have had a further discussion with me on the previous PR. You could have expressed concern and asked for community input on the mailing list. You could have poked me in email or on IRC. You could even have gotten me to make needed changes prior to you merging them so that my time wasn't wasted coding them in and writing tests for them only for you guys to waste your time reverting them less than 24 hours later.

That sucks.

So let's go over the problems with these changes.

1) nginx is not the only game in town. Many other services -- for instance, dovecot, clamav, _and_ your own later example of postgres -- allow you to specify the (usually) user and (definitely) group and mode you want to use, to make it easier and -- crucially -- more secure for other services to interoperate. That way you don't need to have the primary group you are running consul under be the group that everyone else uses to communicate with it. Removing that capability reduces both flexibility and security.

2) You can't simply get around this by making a directory and creating the socket in that directory and having it inherit permissions. I don't know what man page you're looking at, but `man 7 unix` on my Ubuntu 14.04 system says nothing of the sort. And I just verified that using netcat -- permissions of the parent directory have nothing to do with anything, so the workaround you guys suggest isn't actually a workaround. Proof:



3) Rather than removing the user/group/mode altogether, you could have simply expanded the configuration language, as Ryan and I discussed in the previous PR. As I said there, nobody expressed any issue with the configuration language since the original RFC, and if people didn't like the coalesced syntax the right thing to do would be to modify configuration to support sockets properly. You guys picked the nuclear (and time-wasting) option instead.

4) Leaving aside the point of what a user would do with a dead socket if Consul died in an unclean fashion, I don't know where you got your intel about removing sockets and postgres, but it's wrong. If postgres dies and you restart it, something in postgres wipes the socket and recreates it. I don't know what does it, but I _can_ tell you that it's not Ubuntu's init script. It's one of the pg tools, or it's the daemon itself. I just tested this -- on unclean shutdown the socket remains, and upon restarting the socket is removed and recreated, which I can tell because the inode changes:



Here's another example, using everyone's favorite netcat:



As a contrast, let's see the workflow with nginx:



I don't know where you guys got your intel, but it's wrong. You care about principle of least surprise...so do I. The least surprise solution is not to leave a dead socket lying around that the user can't do anything with anyways and then fail to start because of it. That will just leave users pissed off when a simple restart of consul fails to work. The least surprise solution is to do what everyone else is doing, and remove the socket and then re-create it.
",jefferai,sethvargo
612,2015-01-20 17:42:05,"@jefferai @ryanuber @sethvargo Okay, so how about the following:
- Consul should perform a delete + re-create on the socket if it already exists. This allows it to recover from a crash by simply restarting. I don't see any reason to not just delete the socket, since this way we can re-bind to it.
- I think if we split the UNIX domain socket configuration into multiple configuration variables it will be much clearer. Namely, we should still use the ""unix:path"" syntax to switch from a TCP to domain socket listener, but new configurations for `unix_socket_user`, `unix_socket_group` and `unix_socket_perm` should be added to explicitly specify the other variables. We can sanely default those of to that of the running agent, and the permissions to match the parent folder.

Thoughts?
",armon,jefferai
612,2015-01-20 17:42:05,"@jefferai @ryanuber @sethvargo Okay, so how about the following:
- Consul should perform a delete + re-create on the socket if it already exists. This allows it to recover from a crash by simply restarting. I don't see any reason to not just delete the socket, since this way we can re-bind to it.
- I think if we split the UNIX domain socket configuration into multiple configuration variables it will be much clearer. Namely, we should still use the ""unix:path"" syntax to switch from a TCP to domain socket listener, but new configurations for `unix_socket_user`, `unix_socket_group` and `unix_socket_perm` should be added to explicitly specify the other variables. We can sanely default those of to that of the running agent, and the permissions to match the parent folder.

Thoughts?
",armon,ryanuber
612,2015-01-20 17:42:05,"@jefferai @ryanuber @sethvargo Okay, so how about the following:
- Consul should perform a delete + re-create on the socket if it already exists. This allows it to recover from a crash by simply restarting. I don't see any reason to not just delete the socket, since this way we can re-bind to it.
- I think if we split the UNIX domain socket configuration into multiple configuration variables it will be much clearer. Namely, we should still use the ""unix:path"" syntax to switch from a TCP to domain socket listener, but new configurations for `unix_socket_user`, `unix_socket_group` and `unix_socket_perm` should be added to explicitly specify the other variables. We can sanely default those of to that of the running agent, and the permissions to match the parent folder.

Thoughts?
",armon,sethvargo
612,2015-01-20 17:46:32,"@armon That's fine -- as I said in the other pull request, changing configuration is the ideal option. I can see arguments as to why you'd want to be able to specify user/group individually for each socket (since RPC and HTTP have different APIs, and AFAIK not all things can be done on each). Maybe that's too advanced, but this might be the best time to implement something along those lines.

Unfortunately, the ""best"" solution that I can think of would require deprecating or changing `-addresses` to have sub-objects instead of sub-strings. Otherwise it'd be to add a separate option along the lines of `-unix-addresses` but then you have to have a war between which one takes precedence when both are set.
",jefferai,armon
612,2015-01-20 17:49:49,"@jefferai Is this a use case you guys have currently? (Having distinct permissions per-socket). If it isn't then I'd prefer to keep is simple and just have a single set of `unix_*` configuration. If it is a use case, then I think we can have sub-objects within a different block. e.g.


",armon,jefferai
612,2015-01-20 17:54:17,"@armon It's not a current use-case, no, although I can't speak for everyone here. But, I was simply figuring that if that might be useful to anyone down the road, easier to change things before people use them than after. :-)
",jefferai,armon
612,2015-01-20 17:56:35,"@armon @sethvargo  @ryanuber BTW, since nginx is a common example for you guys, nginx uses `unix:/path`, but most other utilities that I've seen -- including actual languages -- prefer the full URL syntax with `unix:///path`. Just FYI. I'm a big fan of nginx, but not of all of their decisions...
",jefferai,armon
612,2015-01-20 17:56:35,"@armon @sethvargo  @ryanuber BTW, since nginx is a common example for you guys, nginx uses `unix:/path`, but most other utilities that I've seen -- including actual languages -- prefer the full URL syntax with `unix:///path`. Just FYI. I'm a big fan of nginx, but not of all of their decisions...
",jefferai,ryanuber
612,2015-01-20 17:56:35,"@armon @sethvargo  @ryanuber BTW, since nginx is a common example for you guys, nginx uses `unix:/path`, but most other utilities that I've seen -- including actual languages -- prefer the full URL syntax with `unix:///path`. Just FYI. I'm a big fan of nginx, but not of all of their decisions...
",jefferai,sethvargo
612,2015-01-20 18:08:49,"@armon I'm guessing you meant ""rpc"" and ""http""; there's no reason for DNS to be over Unix sockets. (Or rather, not for the same reasons that drove this implementation.)

But yes, that looks great.
",jefferai,armon
610,2015-01-17 00:46:31,"@dave-tucker LGTM! Thanks!
",ryanuber,dave-tucker
608,2015-01-18 02:17:18,"@imkira good catch! We can see in go's `http.Client` `Do()` method, which is what's getting called under the hood, that it either returns `nil, err`, or `resp, nil`, so IMO it is probably safe to assume we would never do anything with the response body if err is not nil. I agree though that it wouldn't hurt to just check if the response struct is nil, and if not, at least close the Body to prevent leaking handles. Maybe this belongs in `requireOK`, which will also ensure that future uses of that method get the same protection.
",ryanuber,imkira
608,2015-01-19 02:55:38,"Thank you @ryanuber .
I also agree that, like http.Client.Do, closing all resources on error (in this case resp.Body) is the right approach.
I am sending a new commit to attempt to fix this issue.
Please let me know if it looks good.
",imkira,ryanuber
607,2015-01-20 22:42:09,"@petemounce We don't have this information ""easily"" available. It would require doing an internal query and aggregation every interval to generate this. It may be simpler to write a small service that consumes the API to forward that information to statsd.
",armon,petemounce
607,2015-01-22 17:59:10,"@petemounce You may be able to do it more easily with a blocking query against `/v1/health/state/any` endpoint. That way you can aggregate all the healthy/warning/critical instances in a single API call.
",armon,petemounce
607,2015-01-23 18:01:54,"@petemounce yes, a ""blocking query"" in Consul refers to making a specific HTTP request that will wait until some change is made. You can read more about how to perform a blocking query [here](https://consul.io/docs/agent/http.html) under the ""Blocking Queries"" section (right up near the top).
",ryanuber,petemounce
607,2015-01-23 18:09:06,"@petemounce Here is an example.

First, make a query to the health endpoint and note the `X-Consul-Index` header:



Make the same query, passing in the index and an (optional) time to wait.



The above query will ""block"" until the status of a health check changes, at which point a response very similar to the one above is received with the new list of services and a new `X-Consul-Index`, which you could use for further blocking queries.

Hope that helps!
",ryanuber,petemounce
606,2015-01-15 20:45:07,"@sethvargo I do think in this context that PUT is the correct verb, because the resource we are updating is the maintenance state of the given service or node, and not the service as a whole. If we do use PATCH at some point, I'd suggest we do that in a v2 API, since the current set of methods all use PUT in v1.
",ryanuber,sethvargo
606,2015-01-20 22:22:13,"Looks really good. Minor feedback, could we also add the API client updates for this too? One thing worth discussing is a potential CLI command to easily toggle the node/services. It seems like it would be useful.

@sethvargo @mitchellh thoughts?
",armon,sethvargo
606,2015-01-20 22:42:23,"@armon CLI tool seems useful. Is that something you envision in consul itself or a plugin of sorts?

I'm thinking it should be a separate project. If I'm using a monitoring service, I probably just want a CLI with some auth flags as opposed to all of Consul.
",sethvargo,armon
606,2015-01-21 19:12:05,"@armon added the API endpoints and modified the endpoint. You can see the diff [here](https://github.com/hashicorp/consul/compare/d89af51eb6...e088240c95).
",ryanuber,armon
605,2015-01-22 17:57:44,"@petemounce You can do `force-leave` idempotent, so not an issue. As long as the ASG group brings up a node that joins the existing cluster, it should get added in automatically. Both scale-up and scale-down should be fine as long as quorum is not lost!
",armon,petemounce
605,2015-01-23 17:57:55,"@petemounce the consensus protocol is covered in detail [here](https://consul.io/docs/internals/consensus.html), but I think the most relevant part to your question is the following:

> Quorum - A quorum is a majority of members from a peer set, or (n/2)+1. For example, if there are 5 members in the peer set, we would need 3 nodes to form a quorum. If a quorum of nodes is unavailable for any reason, then the cluster becomes unavailable, and no new logs can be committed.

If there are 3 servers, the quorum size is 2, so you should still remain operational while the lost node is fixed or replaced. You might also be interested in reading the [outage guide](https://consul.io/docs/guides/outage.html) for more details on how to recover if quorum is lost.
",ryanuber,petemounce
605,2015-01-25 07:05:17,"@petemounce  What we're looking at for this is to allow the consul autoscaling group to be able to query the AWS API to list instance info.  When a new host in the autoscaling group comes up it gets the other instances in the consul server cluster from that API and automatically joins.

We don't currently force leave the old server, assuming that it will safely disappear after the timeout (I think the default is 72 hours) but perhaps that is misguided.

We're still in the process of testing it out, but so far it seems promising.
",phobologic,petemounce
605,2015-09-23 17:21:54,"@phobologic @ryanuber When you use ASG to maintain the desired number of servers, do the new servers increase the quorum? Let's say you start with 5 servers, so the quorum is 3. If two servers are lost and two new ones are brought back up by ASG, does the number of known servers (at least for the first 72 hours) become 7 and the quorum becomes (7/2)+1? If the quorum is not static, and you go trough two more iterations within 72 hours the quorum will be (11/2)+1=6, but the number of servers will be 5 so it will be in an unhealthy state. In other words, I would like to know if new server nodes joining would increase the quorum.
",calvn,ryanuber
605,2015-09-23 17:21:54,"@phobologic @ryanuber When you use ASG to maintain the desired number of servers, do the new servers increase the quorum? Let's say you start with 5 servers, so the quorum is 3. If two servers are lost and two new ones are brought back up by ASG, does the number of known servers (at least for the first 72 hours) become 7 and the quorum becomes (7/2)+1? If the quorum is not static, and you go trough two more iterations within 72 hours the quorum will be (11/2)+1=6, but the number of servers will be 5 so it will be in an unhealthy state. In other words, I would like to know if new server nodes joining would increase the quorum.
",calvn,phobologic
605,2015-09-23 18:01:18,"@highlyunavailable Thanks for the prompt reply! So there is a chance that ASG (if no `leave` or `force-leave` is issued) will cause an outage in the case where it spins up servers to the point that the quorum is above the desired/max amount set on ASG. I guess I will do something similar to what @petemounce mentioned and use SQS + AutoScaling SNS to signal a `force-leave` on the old instances.

Edit: Is there a way to query the quorum? `consul info` does not seem to provide that information.
",calvn,petemounce
605,2015-09-23 18:01:18,"@highlyunavailable Thanks for the prompt reply! So there is a chance that ASG (if no `leave` or `force-leave` is issued) will cause an outage in the case where it spins up servers to the point that the quorum is above the desired/max amount set on ASG. I guess I will do something similar to what @petemounce mentioned and use SQS + AutoScaling SNS to signal a `force-leave` on the old instances.

Edit: Is there a way to query the quorum? `consul info` does not seem to provide that information.
",calvn,highlyunavailable
603,2016-01-14 15:52:59,"@tesseract2048 not sure if you are using consul-template but there's a recent feature that can help in the meantime if you have a lot of duplication (such as rendering many instances of the same template) - https://github.com/hashicorp/consul-template#de-duplication-mode
",slackpad,tesseract2048
603,2016-01-15 12:14:06,"Thanks a lot, @slackpad . This would certainly reduce the number of requests necessary when using `consul-template`. But unfortunately we do not currently have it deployed in production yet. 
IMHO it is not so straight forward to get notified about changes via filesystem (`inotify` would definitely do it though), since we intend to watch changes of services instead of configurations.

In this case, if we go the straight way, primary concern would be that if every worker process must send individual watch requests via HTTP to local agent, there will sure be lots of them (several thousands or more on some node), and I doubt whether that could work in real world with heavy traffic.
However, if we can somehow merge watch requests, there will only be few connections established at the same time.
",tesseract2048,slackpad
603,2016-01-22 17:43:46,"@tesseract2048 the agent will multiplex those requests to the servers over a single TCP connection, so it's not as bad as it may seem, but thousands of watches are definitely still expensive in other ways.
",slackpad,tesseract2048
602,2015-04-16 07:25:25,"@florentvaldelievre unfortunately this barely missed the 0.5.0 release. There will be a 0.5.1 release in the next couple of weeks which will include this fix.
",ryanuber,florentvaldelievre
599,2015-05-11 20:50:58,"@petemounce Could you share exactly what you did to make it work? I am also having the same problem.
",saulshanabrook,petemounce
599,2015-05-11 21:56:52,"@saulshanabrook I used the configuration file to set the http interface to listen on the NIC instead of the default loopback address.



Here's the consul agent upstart task from my cloudformation:


",petemounce,saulshanabrook
599,2015-05-11 22:04:16,"@petemounce thank you!

Would `$BIND` be `10.10.10.257` as well in this case?

With it set up like that I still get this:



But works with `localhost`



This is my config:


",saulshanabrook,petemounce
599,2015-05-11 22:29:45,"Yes, think so. My pleasure :-)

## 

Sent from my phone. Please excuse typos and brevity, but never text speak.
On 11 May 2015 23:04, ""Saul Shanabrook"" notifications@github.com wrote:

> @petemounce https://github.com/petemounce thank you! Would $BIND be
> ""10.10.10.257"" as well in this case?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/599#issuecomment-101061655.
",petemounce,petemounce
598,2015-01-22 01:16:10,"@philcryer Setting all to -server shouldn't be an issue with only 4. However, it still looks like a networking issue. Looks like UDP packets aren't being routed back properly.
",armon,philcryer
598,2015-01-27 01:56:23,"@petemounce Based on this log:



It looks like the TCP connection (to port 8301) is being closed (EOF) while we are still expecting data.
With tcpdump you should be able to watch the TCP traffic to/from port 8301 to see if you are getting any data at all, or if potentially the connection is being RST immediately etc.

I wish I could be of more use, but since I've never seen this, it's incredibly hard to triage the any number of network / configuration issues that could be at play.
",armon,petemounce
598,2015-03-03 20:08:47,"I had this same issue, having just set up two Consul instances for the first time. Both are running on EC2 instances in the same VPC, but because they are in different availability zones, they're in different subnets.

Without opening up any networking (except SSH), the Consul instances couldn't see each other. So far, so expected.

Then I created a security group like this for each instance (I'm using CloudFormation here):



Now I could join the two servers together... but I had the same issue as @philcryer above: ""Suspect ip-xxx has failed"" etc.

So in the Network ACL, I added these rules:



Notes:
- Change RuleNumber depending on your list
- Change `{ ""Ref"" : ""VpcMainCidr"" }` to whatever range of IP addresses you need
- You definitely need both the inbound and outbound rules - I've tested with Serf but not tried DNS yet

The reason why it's needed is because AWS has two security layers - instance security groups and network ACLs. They both work a bit differently. See the [Security in Your VPC](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Security.html). The network ACL applies to traffic between different subnets (e.g. for availability zones), not just in and out of the VPC.

As to why I could join the Consul instances together in the first place without even touching my Network ACL. It turns out I already had all the high TCP ports open both ways. As the Network ACL is stateless (no connection tracking), I think these are already needed:



In any case, I got them from the [CloudFormation example templates](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/sample-templates-services-us-west-2.html) (see the first VPC one near the bottom for example).

I hope that helps!
",fazy,philcryer
598,2015-07-01 00:38:01,"@petemounce it looks like there are Serf pings and normal Serf TCP connections in the sample you posted - was the node you were gathering on experiencing the `[ERR] memberlist: failed to receive: EOF` problems at the time?

Also, not sure if this is a test cluster or a production setup, but you probably don't want to publicly post the pcap for anything production, it could have real node names and event data in there since it has the contents of the messages moving through the network and not just the headers.
",slackpad,petemounce
598,2015-07-06 23:07:05,"@slackpad thanks. Test cluster. Yes, the node I captured on was experiencing the issue at the time.
",petemounce,slackpad
598,2015-07-13 14:45:10,"@petemounce Nice spot on the agent/self I missed that one!
",antonosmond,petemounce
596,2015-01-11 05:31:07,"Hi @pikeas, 0.5 is only a short way out! We plan to have a release within the month, barring any major issues. The master branch should be pretty stable at this point, but there are a few additional features in the coming weeks which should be getting merged in. Consul 0.5 is going to be a fairly large release, and will bring lots of new functionality, so bear with us while we make sure the release is ready. Hang in there!
",ryanuber,pikeas
596,2015-01-11 05:40:40,"@pikeas it's a safe bet that the CHANGELOG will get some lovin' pretty shortly. We typically bulk-update it as part of release preparation for Consul. No firm details on timeframe though.
",ryanuber,pikeas
595,2015-01-12 21:23:38,"Looks good! @ebroder could you add a test for this behavior?
",armon,ebroder
594,2015-01-10 18:12:35,"@armon I left 1 comment, but otherwise everything LGTM! Super awesome.
",ryanuber,armon
593,2015-01-10 21:28:13,"Thanks @nicholascapo!
",ryanuber,nicholascapo
592,2015-01-12 20:02:38,"I think is a good idea. @blalor it's possible this was rejected early on, but I've had a change of heart on it. 
Some feedback I have:
- Any 2XX status code should be treated as OK
- Let's use 429 ""Too Many Requests"" for WARN
- Anything else is critical. 
- Tests for the new functionality would be great :)
- Super pedantic, some log statements are missing the appropriate ""agent: "" prefix.
",armon,blalor
592,2015-01-12 20:58:33,"I agree with @armon on using a 429 for warnings. It also agree with @sean- that writing the response into the output field would be helpful, and it's probably not too complicated to implement. Looking good!
",ryanuber,armon
592,2015-01-12 20:58:33,"I agree with @armon on using a 429 for warnings. It also agree with @sean- that writing the response into the output field would be helpful, and it's probably not too complicated to implement. Looking good!
",ryanuber,sean-
591,2015-01-12 21:40:56,"@armon Hm, yeah I think that is the case. We could modify the code path to continue passing the single `.Check` field through to preserve compatibility, but there would still be this weird gap if a client restarted using the newer `.Checks` field instead. I think advising in the upgrade documentation is probably the most reasonable thing to do. Should we do this in the release notes when 0.5 is cut?
",ryanuber,armon
591,2015-01-14 19:23:03,"I've made a few adjustments in here after some experimentation. What we have now should be compatible with older versions of Consul by using `Check` instead of `Checks` when there is only a single check for a service (which would be the case on older Consuls).

We also solve the issues @armon mentioned earlier by batching service sync operations with check syncs where appropriate. Basically, if a check is to be synced, and is associated with a service, we attach the service to the `RegisterRequest` if it is out of sync or doesn't exist. This requires scoping the `RegisterRequest` to a single service and its associated checks, which is handled in `syncChecks()`.

One final change is that we batch all checks which are not associated with any service together to reduce the number of RPC requests required to perform anti-entropy.
",ryanuber,armon
591,2015-01-15 07:12:16,"@armon I ended up reverting `syncChecks` back to its original `syncCheck`, and instead modifying `syncService` so that it searches for any out-of-sync checks and piggybacks them along with it. Reduced complexity quite a lot. I think this is ready for a once-over.
",ryanuber,armon
588,2015-01-09 21:54:21,"Thanks, @tiwilliam. I'll take a look at that.
Another note to self: This one has come up on occasion:


",ryanuber,tiwilliam
588,2015-01-22 00:56:45,"@armon I think so. I looked into Terraform to see what we were doing for tests and updating deps, and we aren't taking the same approach there. I t seems fair to get test errors if you try running the tests with outdated deps.
",ryanuber,armon
587,2015-01-12 20:13:25,"@jefferai The tests passing as often as master is a good sign. I do still think we need some general testing around some of the functions that are going in here though. For example, `populateUnixSocket` and `adjustUnixSocketPermissions` seem like fairly generic functions which we could have some unit testing for individually. We could use the runtime to figure out if we are running on Linux/UNIX, and skip if we are not with `t.SkipNow()`.
",ryanuber,jefferai
587,2015-01-13 14:10:19,"@ryanuber Sure. I haven't had time to get to new tests yet, just fixing the one regression I had against old tests and running over and over to determine what's likely to be a problem and what's just test brokenness. New tests are next.
",jefferai,ryanuber
587,2015-01-13 18:26:45,"@jefferai sounds good, just let us know when you think its ready and we'll take another look!
",ryanuber,jefferai
587,2015-01-13 20:15:19,"@ryanuber @armon in agent.go, in Create, a configuration is passed in; this configuration is then ignored by the agent.setupServer and agent.setupClient calls, which means my adjustments to the config to have it listen on Unix sockets have no effect (on either the server or client).

I'd like to change setupServer and setupClient to honor config.Addresses if set to something other than the defaults. This feels slightly intrusive, but I don't see any other way. Comments?
",jefferai,armon
587,2015-01-13 20:15:19,"@ryanuber @armon in agent.go, in Create, a configuration is passed in; this configuration is then ignored by the agent.setupServer and agent.setupClient calls, which means my adjustments to the config to have it listen on Unix sockets have no effect (on either the server or client).

I'd like to change setupServer and setupClient to honor config.Addresses if set to something other than the defaults. This feels slightly intrusive, but I don't see any other way. Comments?
",jefferai,ryanuber
587,2015-01-13 22:36:50,"@jefferai Not sure why they would be impacted? Since the HTTP listener is in the agent level and not at the Consul level.
",armon,jefferai
587,2015-01-14 19:54:47,"@armon @ryanuber I believe this is now ready for review. Also, let me know if you'd like me to squash these into either one or two (code in one, tests in the other) commits, or leave as-is.
",jefferai,armon
587,2015-01-14 19:54:47,"@armon @ryanuber I believe this is now ready for review. Also, let me know if you'd like me to squash these into either one or two (code in one, tests in the other) commits, or leave as-is.
",jefferai,ryanuber
587,2015-01-14 22:24:37,"@jefferai I'll take a look at this in just a bit, thanks!
",ryanuber,jefferai
587,2015-01-15 00:29:20,"@jefferai I went through and added some comments about various things. Overall looking really good!

I am wondering about the format of the UNIX socket URI since it includes `;[user];[group];[mode]` at the end. I might be missing something here. Is this a typical UNIX socket path, or are we inventing some syntax here? Maybe you could elaborate on why we are taking that path here.
",ryanuber,jefferai
587,2015-01-15 14:38:11,"@ryanuber OK, I've gone through the issues above.

A typical UNIX socket path is unix:///path/to/socket/file. The user/group/mode are necessary parts of the specification though. The reason it's in that form is compatibility with the current configuration, which is a string. Most other applications have the owner/group/mode as separate configuration items.

The only way to do it the ""normal"" way would be to change the configuration file format, or at a minimum add several more values for each of the rpc and http addresses, either in a sub-object or as extra optional keys.

When I proposed this on the mailing list (https://groups.google.com/forum/#!topic/consul-tool/9m4iKt6PTgE) I got no indication from either armon or other users that this method was unsatisfactory, and it retains compatibility. I'm fine with a change to the configuration syntax instead, but that would require a separate discussion with more parties involved, I think.
",jefferai,ryanuber
587,2015-01-15 23:37:28,"@jefferai I've read through the comments, thanks for elaborating on the implementation. I'm going to merge this in and update a few minor stylistic things, but I think the functionality is there. I'll link you to the changeset afterwards. Thanks for doing this! :+1:
",ryanuber,jefferai
587,2015-01-16 22:38:39,"@jefferai I pushed #612 as a follow-on to this PR. See the description there for details on what changed and why. Again, thanks for tackling this, we appreciate it!
",ryanuber,jefferai
585,2015-01-08 18:29:32,"@JensRantil The current master, and Consul 0.5 will support ACLs on service registration as well!
",armon,JensRantil
583,2015-11-25 17:41:11,"@cskksc  @ryanuber thanks!
",marcellodesales,ryanuber
583,2015-11-25 17:41:11,"@cskksc  @ryanuber thanks!
",marcellodesales,cskksc
581,2015-01-07 18:48:33,"@ryanuber any idea why the tests are failing?
",sethvargo,ryanuber
581,2015-01-07 19:14:56,"@sethvargo normally we see failures on Travis due to some timing issues, but these look a little scarier. I'll look back and make sure nothing on our end is causing this.
",ryanuber,sethvargo
581,2015-01-07 19:16:55,"@ryanuber okay. I'm just wondering if there's a recursive dep or something weird (like we already had a package named ""api"" from somewhere else)
",sethvargo,ryanuber
579,2015-02-27 23:32:45,"@oliora Good idea! Tagging for enhancement.
",armon,oliora
575,2015-01-05 22:07:42,"Hey Thordur,

Feel free to PR the comment changes and doc updates! I still do think shuffle should be done with
the full list just to prevent clients which access only index 0 from causing issues.

Best Regards,
Armon Dadgar

From:Â Thordur Bjornsson notifications@github.com
Reply:Â hashicorp/consul reply@reply.github.com>
Date:Â January 5, 2015 at 12:45:04 PM
To:Â hashicorp/consul consul@noreply.github.com>
Cc:Â Armon Dadgar armon.dadgar@gmail.com>
Subject:Â  Re: [consul] DNSConfig EnableTruncate to true by default. (#575)  

@armon, thanks for the clarification, but I have a small objection if you'll allow me:

The current EnableTruncate behaviour breaks RFC conformity (RFC2181, Section 5.1) but I can see why breaking it might be beneficial given your 99.9% argument.

Documenting this better might be very beneficial, and I'll see if I can cook something up.

Any objections to the other two commits ?
I'll resubmit a PR for those, apologies for mixing commits in this PR.

â€”
Reply to this email directly or view it on GitHub.
",armon,armon
573,2015-01-05 19:18:56,"Ah, tricky! @armon makes sense, will adjust this.
",ryanuber,armon
573,2015-01-08 03:11:56,"@kdlan This should now be fixed in master! Let us know if you have further issues. Thanks for reporting this.
",ryanuber,kdlan
571,2015-01-06 18:43:39,"@darron oh are you saying that the watchers compound over time? e.g. a new set of 50 watchers is added on each reload?
",armon,darron
571,2015-07-13 16:01:41,"@jsok event watches are a bit of a snowflake, as they are powered by the gossip layer. `LTime` should be safe to use in the way you describe for event watches since it is a monotonic value, but it will not apply to other watch types and will not be part of the payload returned for those watches.
",ryanuber,jsok
571,2015-07-29 22:20:59,"@ryanuber what is `Ltime`?
",joelmoss,ryanuber
571,2015-08-10 14:46:53,"@armon Do you still plan to add the flag to the watches (to turn off fire-on-create)? If so, any plans when this is going to be available?
",BjRo,armon
571,2015-08-11 17:20:22,"@BjRo We are tracking it here, but no concrete plans. Lots of more pressing things.
",armon,BjRo
571,2016-05-25 17:16:35,"@ssenaria can you expand on how you use Sifter?
",davidneudorfer,ssenaria
569,2015-01-05 20:02:13,"@petemounce I think what you suggest should work! DNSMasq is useful to avoid running Consul as root to bind to port 53. I'm not sure if Windows lets you specify a custom port, if not you may need to run with elevated privileges to bind to that port. Using a non-Consul node as a backup DNS also makes sense, should be fine!

Sorry I can't be of more use, I haven't worked with Windows in a while and am not quite sure what the best way would be.
",armon,petemounce
567,2015-01-01 21:40:34,"@ryanuber That stale example is testing that you can set either ?stale or ?consistent, but not both.
",thorduri,ryanuber
567,2015-01-01 22:33:46,"@thorduri I just pushed a basic test for pretty-printed responses in e9615c5. If you rebase against master and add one more test (or expand the `TestPrettyPrint` test), we can then merge this in. We want to test that both forms (`?pretty=1` and `?pretty`) work as intended so we don't break any clients.
",ryanuber,thorduri
567,2015-01-02 08:19:28,"@ryanuber Done. Hopefully the test refactor is OK.
",thorduri,ryanuber
565,2015-01-06 18:38:07,"There are many customers running in EC2 classic, so it's not an EC2 issue. My guess is that the security groups / iptables are causing some type of havoc. This is a really high error rate, and as @ryanuber said, at very low levels of the system. 

I'd check dmesg and maybe a little bit of tcpdump to see what is happening. My guess is network configuration issues.
",armon,ryanuber
565,2015-01-14 18:35:56,"@lyrixx What kinds of disk are you using? Is it possible that you are experiencing some extremely slow or contested IO?
",armon,lyrixx
565,2015-01-27 18:35:19,"@eolamey Given the frequency, I think this is just a known head-of-line blocking issue with disk in Consul before 0.5. Please give 0.5 a try and see if this happens.
",armon,eolamey
565,2015-01-27 19:49:08,"@armon thank you very much for your answer. I was planning on testing 0.5, but I was hoping skipping rc1 and going directly to the final release :) Do you know when that would be?
",eolamey,armon
565,2015-01-27 19:52:56,"@armon also, what value would you recommend for GOMAXPROCS? Does it depend on the number of concurrent requests, or the number of cores available?
",eolamey,armon
565,2015-01-28 20:52:35,"@eolamey Typically just the number of cores, but at a minimum 2.
",armon,eolamey
564,2015-01-05 19:59:40,"@chrismiller Do you have a minimal repro case you could provide? That would be very helpful
",armon,chrismiller
564,2015-01-14 00:07:24,"I think I know why this is happening.
1. When a new service is registered, it registers with the agent and is later synced to Consul.
2. Currently, the agent syncs service definitions first, independently of health checks. Since there are no health checks registered at this point, it makes sense that the service appears healthy.
3. Consul then iterates over all of the health checks, and registers them in critical state. All health checks are registered initially with Critical status to avoid placing unhealthy nodes into the pool. This explains why the service would not show up when using `?passing`.
4. Health checks eventually are run, and once they are passing, that status is again synced to Consul from the agent, and the service enters a healthy state. This explains how the service magically came back.

I am working in a branch on service registration, and I think this issue will also be resolved once we get it merged in. I'll try to get some test cases against this kind of thing as well.

Thanks @chrismiller!
",ryanuber,chrismiller
564,2015-01-30 07:27:48,"@chrismiller this should actually be fixed in the master branch, from #591! There were a number of tickets that were related to this, I just forgot to update this one. This should be fixed in consul 0.5.1, including 0.5.1rc1.

Thanks again for the detailed report and repro cases!
",ryanuber,chrismiller
562,2015-01-02 19:58:25,"@armon that's great; looking forward to it landing!
",petemounce,armon
562,2015-01-09 23:16:33,"@petemounce there is a PR open for this on #591, and an existing issue on #230. Closing this out to track in those issues, thanks!
",ryanuber,petemounce
562,2015-01-10 00:47:20,"Brilliant!

## 

Sent from my phone. Please excuse typos and brevity, but never text speak.
On 10 Jan 2015 00:16, ""Ryan Uber"" notifications@github.com wrote:

> @petemounce https://github.com/petemounce there is a PR open for this
> on #591 https://github.com/hashicorp/consul/pull/591, and an existing
> issue on #230 https://github.com/hashicorp/consul/issues/230. Closing
> this out to track in those issues, thanks!
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/562#issuecomment-69417195.
",petemounce,petemounce
561,2014-12-30 02:37:53,"I agree with @blalor on this one. I think we could disambiguate the current responses by returning an empty list with a 200-range response while listing an empty keyspace, since the keyspace does exist and just happens to be empty, which is different than it just not existing to begin with.

The thing is though, there could be (and likely are) clients depending on the current functionality, so any changes like this would need to go into a `/v2` api.
",ryanuber,blalor
560,2015-01-02 16:33:16,"@telmich Did all the servers join the WAN gossip ring? It looks like only consul01 joined. The WAN join is done separately from the normal cluster join.
",armon,telmich
560,2015-01-02 21:58:45,"@armon I have just joined -wan one server of the ungleich-init7 dc from hetzner-rz16.

I assumed (seems incorrectly) that all servers are informed about the other datacenter via gossip in the local datacenter?

If it is necessary to join -wan to every other server in the datacenter, I would have to repeat the step for every server in the other datacenter every time the node reboots?

I.e. having 3 servers in ungleich-init7, 3 servers in hetzner-rz16 and 3 servers in our upcoming dc, every server would have to join 6 other servers?

I think what makes me mostly puzzled is that I assumed that the information (view) of the cluster should be eventually consistent -  did I assume wrong here?
",telmich,armon
560,2015-01-03 02:37:03,"@telmich currently consul utilizes two separate gossip pools; a LAN gossip ring and a WAN gossip ring. Each server node must join at least one other server node in the WAN gossip ring in order to see the remote datacenters. It is not necessary to join every node in the WAN pool.

Also, you should not need to perform the join manually on each reboot. The peer set should be persisted and re-joined on subsequent start-ups.

Hope this helps!
",ryanuber,telmich
557,2015-01-02 16:42:43,"@armon Is the only behavior we can do in this case to panic? Is there a way we can gracefully fail out somehow. And, in either case, perhaps we just make it configurable as an ""advanced case"". 
",mitchellh,armon
557,2015-01-03 03:00:54,"@telmich from my understanding, we have to use a timeout because a routine we call from the LMDB C code gets ""stuck"" on occasion, and rather than blocking forever (essentially causing an undetectable/unrecoverable condition), we set a conservative upper limit on execution time and bail if we aren't done by the deadline.

@armon is that correct? Do we have an open issue upstream yet by chance?
",ryanuber,armon
557,2015-01-03 03:00:54,"@telmich from my understanding, we have to use a timeout because a routine we call from the LMDB C code gets ""stuck"" on occasion, and rather than blocking forever (essentially causing an undetectable/unrecoverable condition), we set a conservative upper limit on execution time and bail if we aren't done by the deadline.

@armon is that correct? Do we have an open issue upstream yet by chance?
",ryanuber,telmich
557,2015-01-05 19:20:24,"@telmich One possibility is you could build from master and modify this constant:
https://github.com/hashicorp/consul/blob/master/consul/mdb_table.go#L31
If you set that to a huge value (10 minutes) it should work around this.

The issue is that LMDB is stuck blocking on IO and we have to way to get it to un-stick. It's not a deadlock per se, rather just arbitrarily slow IO. Restarting Consul or LMDB won't help since it will still need to interact with the disk and just block again.
",armon,telmich
557,2015-04-06 19:42:11,"@ryanuber will this be fixed with BoltDB backend?
",c4milo,ryanuber
555,2015-01-02 16:35:41,"@blalor Thanks for tackling this! The Apiary docs do look really good. I bet we can get pretty close to that by improving the docs generation we have now, instead of needing to link in an external service.

@sethvargo Thoughts? Any extensions to middleman we can use to make it more like Apiary and make the API doc experience nicer?
",armon,blalor
555,2015-01-02 20:16:44,"@armon I would like to move to standardized, versioned documentation for all our projects, but it's not something I have had time to research much.
",sethvargo,armon
555,2015-01-11 04:59:43,"@blalor Awesome :+1: :beers: 
",rotatingJazz,blalor
553,2015-02-03 13:58:27,"@armon I made a separate issue as it is confusing to discuss this here. #667
",derekelkins,armon
551,2014-12-31 07:05:47,"Hey @ceh thanks for the solid work as always. I also realized these changes would violate the api compatibility for the v1 endpoints and paused there to figure out the right way to go about it. We might need to go the v2 route to avoid breaking any clients.
",ryanuber,ceh
550,2015-01-05 20:04:46,"@ryanuber I have a config file for the container stuff:



Consul is properly starting with it.

@armon I understand. I will look into how to advertise the RPC port. Maybe you have some pointers for me what needs to be considered. 

Is there anything I can provide to help identify the bug regarding the self-doubts of the node?
",i0rek,armon
550,2015-01-05 20:04:46,"@ryanuber I have a config file for the container stuff:



Consul is properly starting with it.

@armon I understand. I will look into how to advertise the RPC port. Maybe you have some pointers for me what needs to be considered. 

Is there anything I can provide to help identify the bug regarding the self-doubts of the node?
",i0rek,ryanuber
550,2015-01-05 20:36:57,"@armon Thank you so much for looking into this! :beer: Happy new Year! :beers: 
",rotatingJazz,armon
550,2015-01-05 22:35:25,"@i0rek Take a look at consul/server.go setupSerf(). Basically the ""port"" value we gossip out is the RPC port, which currently is setup to the real port. I guess there could be a new AdvertisePorts configuration that would allow a different port value to be gossiped out which would be set there.
",armon,i0rek
550,2015-01-05 22:38:43,"@i0rek with respect to the self-suspect, a dump of ""consul members"" and ""consul members -detailed"" would be useful. Looking through the memberlist code, not sure how this is possible.
",armon,i0rek
550,2015-01-05 22:44:23,"@armon this is what I see when I start consul in the container: 



and after a minute or so:


",i0rek,armon
550,2015-01-06 10:54:45,"@ryanuber you were right and I was wrong. I got the configuration option wrong. Consul doesn't start anymore now that I am using the right one.


",i0rek,ryanuber
550,2015-01-06 18:08:26,"@i0rek I pushed #576 yesterday which should help us avoid this confusion in the future. As for `advertise_addr`, I don't think we can just accept the port number on the end of the address in `ip:port` format, since we use it to set up two separate gossip agents and the RPC advertise address. I think as @armon said the way to go would be to have some new config option, maybe like:


",ryanuber,armon
550,2015-01-06 18:08:26,"@i0rek I pushed #576 yesterday which should help us avoid this confusion in the future. As for `advertise_addr`, I don't think we can just accept the port number on the end of the address in `ip:port` format, since we use it to set up two separate gossip agents and the RPC advertise address. I think as @armon said the way to go would be to have some new config option, maybe like:


",ryanuber,i0rek
550,2015-01-06 18:38:55,"@ryanuber I've tried that, it only works when all the nodes have the same ports, which defeats the purpose. We need to be able to advertise the port along with the address.
",rotatingJazz,ryanuber
550,2015-01-06 19:10:28,"@ryanuber thanks for #576!
Re `ports`: thats not enough as @rotatingJazz said. 
Re `advertise_addrs`: I will give it a shot and let you know once I have something to look at.
",i0rek,ryanuber
550,2015-01-06 19:10:28,"@ryanuber thanks for #576!
Re `ports`: thats not enough as @rotatingJazz said. 
Re `advertise_addrs`: I will give it a shot and let you know once I have something to look at.
",i0rek,rotatingJazz
548,2015-11-25 01:58:01,"@sethvargo have you seen this since you reported it? I haven't noticed it thus far and not sure how to reproduce it.
",ryanuber,sethvargo
546,2014-12-18 02:59:11,"@ryanbreen there is also a function in util, `randomStagger()`, that should help with this. Check it out [here](https://github.com/hashicorp/consul/blob/ce4aa7beb5dc9434e19a93e04902520a7114386f/command/agent/util.go#L36). It can probably plug right into the interval.

Otherwise I think this is a good idea!
",ryanuber,ryanbreen
546,2014-12-18 03:08:28,"Agreed with @ryanuber! Also some tests for this would be good :)
",armon,ryanuber
546,2014-12-18 03:30:59,"@ryanbreen Probably enough to ensure the check is run within a timely manner (e.g. <= Interval).
",armon,ryanbreen
546,2014-12-18 06:48:16,"@ryanbreen I left a few comments, but looking good!
",ryanuber,ryanbreen
546,2014-12-18 14:02:22,"Great feedback, thanks @ryanuber!  Let me know if this doesn't address those points adequately.
",ryanbreen,ryanuber
546,2014-12-18 20:46:50,"@ryanbreen LGTM, Thanks for doing this!
",ryanuber,ryanbreen
544,2014-12-17 06:07:45,"@owaaa The nodes should automatically reap out after 72hours (not yet configurable, but soon). Otherwise, the best route is to issue a graceful leave before destroying the nodes (consul leave), so that they can be reaped immediately. They are kept around for that long since without a graceful leave, Consul cannot distinguish between a temporary failure, agent crash, network partition, etc.
",armon,owaaa
544,2015-05-07 00:13:40,"@c4milo Were the nodes dead when you did a ""force-leave""? Do they show up in ""consul members"" at all?
",armon,c4milo
544,2015-05-07 01:14:35,"@c4milo Hmm force-leave should push them into the ""left"" state. Nodes are not reaped until they are in failed for 72h or in the left state. Did ""force-leave"" not cause them to go to ""left""?
",armon,c4milo
544,2015-05-12 17:40:00,"@armon I just ran into this again, here is a video: https://asciinema.org/a/bd1apr97vc45f4syahet3dxig. Should I open a separate issue for this?
",c4milo,armon
544,2015-05-12 18:14:35,"@c4milo Everything looks fine in that video, the nodes are in the left state. ""force-leave"" just moves a node from the ""failed"" -> ""left"" state. They are not removed from the members list for 24 or 72h.
",armon,c4milo
544,2015-05-12 18:49:08,"I see. I'm going to need more sleep. Thanks @armon. 
",c4milo,armon
544,2016-08-15 15:44:02,"@slackpad For me, the problem that this causes is that /v1/catalog/service/service endpoint, still shows services from failed nodes, for me it makes more sense, once it's failed, the services get removed.
",lucaswxp,slackpad
544,2016-08-15 15:47:06,"@lucaswxp usually clients use the https://www.consul.io/docs/agent/http/health.html#health_service endpoint to find healthy instances (there's a `?passing` parameter that will filter to only healthy ones).
",slackpad,lucaswxp
543,2015-02-11 13:18:32,"Hi @armon 

It seems this pr is not deployed yet.

Could you deploy it ?

And BTW, I(t) may be stupid, but IMHO a link to https://github.com/hashicorp/consul/tree/master/api for the Go part could be useful ;)
",lyrixx,armon
542,2014-12-16 11:25:06,"@ryanuber tests are added.
",lalyos,ryanuber
542,2014-12-17 00:36:42,"@lalyos great tests! Thanks for filling those in. Merging on in.
",ryanuber,lalyos
541,2015-01-02 20:42:09,"@sethvargo Hey! How often do you update consul.io? This change is still not present :sweat_smile:
",carlanton,sethvargo
541,2015-01-02 21:35:59,"@carlanton it is live now
",sethvargo,carlanton
541,2015-01-04 12:59:35,"Thanks!

On Friday, January 2, 2015, Seth Vargo notifications@github.com wrote:

> @carlanton https://github.com/carlanton it is live now
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/pull/541#issuecomment-68564607.

## 

Mvh
Anton

Sent from my iPhone
",carlanton,carlanton
541,2015-01-04 17:23:13,"@carlanton actually had to roll this back because we have docs on not-yet-released-features. It will go out with Consul 0.5
",sethvargo,carlanton
539,2014-12-14 18:36:48,"Hey @Scorpiion it looks like we have [special cases for building BSD packages](https://github.com/hashicorp/consul/blob/0953efd5a0044756857860ca76c45f6690c5a423/scripts/build.sh#L30-L32) in the build script, but it doesn't look like we are uploading them to [the Bintray repo](http://dl.bintray.com/mitchellh/consul). I'll let @armon chime in, because I suspect there is a history/reason why we don't.
",sethvargo,Scorpiion
539,2014-12-16 05:26:32,"That's great @i0rek :+1: 

I have some other things that are more time sensitive to work on now, but I'll get back later to this issue to update on success or problems found.
",Scorpiion,i0rek
538,2014-12-14 21:14:11,"@amiorin there is another related discussion going on around supporting a domain socket for the HTTP interface in #421. Let's continue the discussion there.
",ryanuber,amiorin
534,2014-12-13 12:42:09,"@armon I understand what you are saying. I don't think our case is pathological if you think of load balancers like HAProxy where few servers generate high load. But consul-template is probably a better way to archive our goal in that case.
",i0rek,armon
533,2014-12-15 12:17:12,"@armon - I believe the problem is not the ""."" but simply because the DC name in this case with uppercase is registered unormalized while DNS resolution being generally case insensitive is enforced at https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L311 . This is a problem as well as it looks to me as the HTTP API is case sensitive. Maybe you could consider enforcing semantics and canonicalization outside the different interfaces to ensure consistency.
",alouche,armon
533,2014-12-15 21:52:09,"@alouche They should both be case insensitive since the internal indexes normalize for that. I do agree that datacenter name is not currently normalized which could cause issues. Probably need to down-case it everywhere, but it will be backwards incompatible change in some cases.
",armon,alouche
532,2015-02-02 21:23:23,"@jhmartin The interim solution is to disable exec support until the ACL framework covers it
",armon,jhmartin
532,2015-05-27 07:08:35,"@armon I would also like to see a feature, where we can decide which commands are whitelisted, e.g. block `rm -rf /`. The proposed interim step by @jhmartin sounds reasonable good to me. That way we can decide, if the command gets really executed or is being blocked by the node. A similar way would be to add a configuration option to the agent, which describes which command should be used to execute the command given by the exec request, e.g. `{ ""exec_engine"" : ""/usr/local/bin/secure_bash"" }` and maybe the exec carries only the parameters to this command.
",kaelumania,jhmartin
532,2015-05-27 07:08:35,"@armon I would also like to see a feature, where we can decide which commands are whitelisted, e.g. block `rm -rf /`. The proposed interim step by @jhmartin sounds reasonable good to me. That way we can decide, if the command gets really executed or is being blocked by the node. A similar way would be to add a configuration option to the agent, which describes which command should be used to execute the command given by the exec request, e.g. `{ ""exec_engine"" : ""/usr/local/bin/secure_bash"" }` and maybe the exec carries only the parameters to this command.
",kaelumania,armon
530,2015-01-29 19:16:30,"@ronpanto a fix is now in the master branch! See #655 for details.
",ryanuber,ronpanto
530,2015-01-29 19:28:42,"@ronpanto within the next few weeks (sorry I don't have a solid date)
",ryanuber,ronpanto
526,2015-02-23 18:55:29,"@dellis23 I'm not sure what your situation is, but there are two different mechanisms for outage recovery. You can either:
- Clear the peers file, and use the -bootstrap flag to re-establish the cluster. Not the recommended option.
- Edit the peers file to reflect the list of all servers. Restart the servers. This is recommended.

Touching the peers file does not do anything, nor does killing the processes once the outage is already happening. Hope that helps!
",armon,dellis23
526,2015-02-23 18:58:23,"Thanks @armon.  I think the other component to this was that the serf local snapshot had marked the servers as having left.  This was due to me misreading ""gracefully leaving"" as being something that you would want to do when shutting down a server.  I assumed this was the preferred way -- that the server would come back up just as gracefully when restarted.
",dellis23,armon
526,2015-02-23 18:59:51,"@dellis23 It is a bit confusing I agree. Graceful leave means ""I intend to leave this cluster, and when I do, do not mark it as a failure."" This means all services / node is deregistered instead of being marked as failed. For servers, they are removed from the raft peer set to avoid a quorum loss.
",armon,dellis23
526,2015-04-17 23:56:32,"@thedjEJ That will cause complete data loss, and is not really recommended
",armon,thedjEJ
526,2015-04-20 05:18:38,"@armon With my testing, whenever the peers.json file is empty (shows a value of ""null"" in the file), deleting the folder, then starting up each server again seems to bring the servers back to state of quorum. I have not seen other files other than the peers.json file in the rafts folder though. 

Is it also not advisable to only delete the peers.json file when it is null, as it seems that the servers discover each other correctly once this is done. I am on consul 0.5.0
",thedjEJ,armon
526,2015-04-23 01:44:24,"@thedjEJ The `raft/` folder should contain all persisted data. There should be some other files in there namely snapshots and the mdb databases. Deleting everything probably allows clustering to work because `-bootstrap-expect` will only operate on a fresh cluster (no data). It is unsafe for it to act under other situations, because it could cause data loss. In this case, nuking the directory will also cause full data loss (since that is where the data is stored).
",armon,thedjEJ
526,2015-04-24 09:52:13,"Thanks @armon . I think I understand this better now and nuking the directory is DEFINITELY not a good idea. Not leaving gracefully is the issue though and I will look into not letting the servers do this, especially when they might once again join the cluster.
",thedjEJ,armon
516,2014-12-05 08:48:26,"@mtchavez thanks for this PR. I made a note above about `globalRPC`. Could you try wrapping the test in a `WaitForResult`? That would be a more reliable fix if this is in fact a timing issue.
",ryanuber,mtchavez
516,2014-12-05 18:04:50,"@mtchavez You have the right idea - I should have explained a little better. Since many of Consul's tests are sensitive to timing, we actually have a method built for exactly this purpose called `WaitForResult`. You can see an example of its usage [here](https://github.com/hashicorp/consul/blob/master/consul/server_test.go#L201).

Basically what this does is the exact same thing you pasted above, just on a shorter interval. We just brute force checking a result, and give up if the condition still isn't met after some time.

Does that make sense?
",ryanuber,mtchavez
511,2014-12-04 08:40:31,"@catsby good catch, thanks!
",ryanuber,catsby
510,2014-12-09 08:10:31,"@drauschenbach my fix was merged so your issue should be solved.
",i0rek,drauschenbach
509,2014-12-03 19:12:22,"@lyrixx thanks for the report. Just looking over the MDB source I'm not exactly sure how this happens.

[This comment](https://github.com/armon/gomdb/blob/master/mdb.c#L6465) suggests that this should not happen, so perhaps this could be an upstream bug. Again, not sure though.

@armon thoughts?
",ryanuber,lyrixx
509,2014-12-03 19:15:21,"@lyrixx any additional information about the cluster you can volunteer would also be useful here.
- Which version of Consul are you running? `consul -v`
- Any other known problems on the host which had the error?
",ryanuber,lyrixx
507,2014-12-01 22:55:18,"@janitha This is implemented in master. It was added just in the last few days, so that might be why you missed it. There are no special flags required to get the persistence, it is automatic. This will be part of the next release, which is looking like 0.5, and likely coming around January some time.
",ryanuber,janitha
505,2014-11-30 18:29:05,"Hey @angelosarto, this is actually expected behavior, but maybe lacks the best documentation. See the `check_update_interval`: https://www.consul.io/docs/agent/options.html#check_update_interval.

Basically, if the status of the check does not change, then any updates to notes or outputs are deferred for up to `check_update_interval`. This is to reduce the write volume. (e.g. a check that may run every 10s, instead updates every 5m, so a 30x reduction in writes).
",armon,angelosarto
504,2014-12-01 02:31:36,"This is actually because `Check` is specified with a capital `C`. Technically we document this configuration in all lower-case in the [service definition docs](https://consul.io/docs/agent/services.html). Mapstructure does accept the capitalized form, though.

81d4e5c fixes this by searching service definitions for any check occurances regardless of case and fixes them up. Might be better to eventually only allow the expected configuration (i.e., all lower-case).

@armon this shouldn't affect persisted services, since marshaling a `time.Duration` just writes it out as a number instead of a string.
",ryanuber,armon
504,2014-12-01 02:33:17,"Thanks for reporting this, @angelosarto! Give master a try and let us know if you still have trouble.
",ryanuber,angelosarto
496,2014-11-24 18:45:32,"@deadjoe With force leave you use the name of the node not the IP. Also nodes that are in the alive state cannot be forced to leave. The command is used to transition from the ""failed"" to the ""left"" state.
",armon,deadjoe
496,2014-11-24 18:49:43,"Got it! Thanks a lot.

Armon Dadgar notifications@github.comäºŽ2014å¹´11æœˆ25æ—¥æ˜ŸæœŸäºŒå†™é“ï¼š

> @deadjoe https://github.com/deadjoe With force leave you use the name
> of the node not the IP. Also nodes that are in the alive state cannot be
> forced to leave. The command is used to transition from the ""failed"" to the
> ""left"" state.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/496#issuecomment-64242341.

## 

Sent from Gmail Mobile
",deadjoe,deadjoe
493,2014-11-24 09:36:17,"@igormoochnick the endpoint to get information about a single node would be singular, like:



We can probably improve the endpoint conventions in a later version. For the time being though, see [the docs](https://consul.io/docs/agent/http.html) for all of the API endpoints.
",ryanuber,igormoochnick
490,2014-11-21 18:43:40,"@andrewwatson Sure! Want to open a PR?
",armon,andrewwatson
490,2014-11-23 03:24:04,"@hh you gave ld the -s flag, which [omits the symbol table](https://golang.org/cmd/ld/) (strip)
",shoenig,hh
490,2014-12-01 22:59:30,"This seems mostly related to `go build` and not Consul itself, so I'm closing this for now. If there is some reason that Consul specifically does not support static builds, feel free to re-open.

@andrewwatson open up that PR if you get something working!
",ryanuber,andrewwatson
485,2014-11-20 16:24:46,"Hi @lyrixx 

Thank you for the bug report. Those links are actually designed to be ""linked"" to, which is consistent among all our products. I definitely see your point about the link being misleading, so I'll work on getting something into [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp).
",sethvargo,lyrixx
479,2014-11-21 18:13:46,"@hoffoo this is fixed in master and will be in the next release!
",ryanuber,hoffoo
479,2014-11-21 18:33:11,"very cool, thanks @ryanuber !
",hoffoo,ryanuber
478,2014-11-17 23:08:04,"@amalaviy This is looking good. I've left a few minor comments above. Other than that, if we can get some tests and comment all the methods in here, we will be in good shape!
",ryanuber,amalaviy
476,2014-11-20 19:58:36,"Thanks @armon.  It'll be some days before I can get us upgraded to 0.4.1 but I will most def. report back.
",ctro,armon
476,2015-03-23 17:37:30,"Same issue as @francois here, playing around with Consul (0.5.0 now) in a Vagrant environment. 

@armon I had a look at the outage guide, but the problem is that the content of the peers.json file on all three nodes is the string ""null"". Removing the file didn't seem to make a difference, nor did restarting the server agents with or without -bootstrap-expect - they simply won't elect a leader without wiping my data directory.
",AirbornePorcine,armon
476,2015-03-23 17:37:30,"Same issue as @francois here, playing around with Consul (0.5.0 now) in a Vagrant environment. 

@armon I had a look at the outage guide, but the problem is that the content of the peers.json file on all three nodes is the string ""null"". Removing the file didn't seem to make a difference, nor did restarting the server agents with or without -bootstrap-expect - they simply won't elect a leader without wiping my data directory.
",AirbornePorcine,francois
476,2015-03-23 17:51:38,"@AirbornePorcine If the peers file is blank, this means you had the nodes do a graceful leave. This is expected behavior. If the nodes leave, you don't want them to disrupt the existing cluster unless they rejoin. You would have to use the `-bootstrap` flag as you discovered at that point.

The `-bootstrap-expect` flag only operates if the cluster is fresh (e.g. no data in the Raft log) otherwise it is potentially unsafe.
",armon,AirbornePorcine
476,2015-03-23 17:52:47,"Great, thanks @armon !
",AirbornePorcine,armon
476,2015-04-13 20:44:44,"@ctro never responded back with his experience unfortunately, but we're running a very similar immutable setup and have run into the same situation with 0.5.0. Is there a suggested process to follow here? I do not fully understand why the cluster goes into outage mode when during the upgrade process we balloon out from cluster size of 3 to 6 nodes (1 leader, 5 peers). Shouldn't we never lose quorum if we have six nodes and then shutdown the older nodes thus returning us to a size of three? Should I force-leave the old nodes instead?
",plombardi89,ctro
476,2015-04-18 00:16:25,"@plombardi89 It depends on how you are removing the older nodes. If they do not leave gracefully, then they are still part of the raft replication group. This means only 3 of 6 members are reachable and quorum is lost. If they leave gracefully or you remove one, then force leave, remove another, etc, then it will be okay as well.

As it stands you are dividing the cluster in half, and it is no longer able to safely commit new transactions.
",armon,plombardi89
476,2015-04-28 17:14:35,"@plombardi89 
Well, that took me forever :)
I just upgraded our consul boxes to 0.5.0.  Bringing up 3 new 0.5.0 nodes to join the old cluster worked.
Simply `consul leave`ing on each of the ""old"" nodes successfully transferred leadership to one of the ""new"" nodes.  Yipee :)

@armon, at this point I'll leave closing this issue up to you...
",ctro,plombardi89
476,2015-04-28 17:14:35,"@plombardi89 
Well, that took me forever :)
I just upgraded our consul boxes to 0.5.0.  Bringing up 3 new 0.5.0 nodes to join the old cluster worked.
Simply `consul leave`ing on each of the ""old"" nodes successfully transferred leadership to one of the ""new"" nodes.  Yipee :)

@armon, at this point I'll leave closing this issue up to you...
",ctro,armon
475,2014-11-23 08:37:12,"@armon 

> Would it be possible to support IPv6? Not sure what is involved for that.

Actually it involved me reading RFC about ipv6 as i never used it before. But the hardest part was to find an environment to test ipv6. Kudos to **digital ocean**.

To refactor the PR to support ipv6 actually took replacing 5 lines with 2 ;) ( see [commit](https://github.com/sequenceiq/consul/commit/d583bc2ccb5375ff4cb53681f82508d718fd3fd8) )

The digital ocean test setup/result are documented in this [gist](https://gist.github.com/lalyos/1fff88c2511abd4716d5)
",lalyos,armon
475,2014-11-23 08:43:49,"I made the FQDN resolution to include the datacenter name. But it might be useful to be it configurable.
Maybe under the `dns_config` object something like `reverse_lookup=fqdn/nodc` with fqdn as default.

@armon  does it makes sense?

But it should go into a new PR once this got merged.
",lalyos,armon
475,2015-09-02 15:10:20,"@armon - what do you think of @lalyos' suggestion to make this configurable? This feature is currently making it hard for us to use Consul DNS, because we use our internal DNS for stuff still. Specifically, we run a service, and it currently registers itself with a home-grown service discovery system. As part of that, it takes the IP address of the host VM, does a reverse lookup, and uses that domain name to register itself.

When I enabled Consul as the default DNS resolver, the service started registering itself like ""deals.domain.net.node.flex.consul"". This is correct as this feature is defined (nodename matches, ""flex"" is the datacenter name, etc), but this address is not addressable by services that don't yet have Consul running. Since we need to roll out Consul in stages, we need some way to have the reverse lookup configurable so that on specific nodes it just uses the recursor DNS servers to do the reverse lookup. 
",robreinhold,armon
475,2015-09-02 15:10:20,"@armon - what do you think of @lalyos' suggestion to make this configurable? This feature is currently making it hard for us to use Consul DNS, because we use our internal DNS for stuff still. Specifically, we run a service, and it currently registers itself with a home-grown service discovery system. As part of that, it takes the IP address of the host VM, does a reverse lookup, and uses that domain name to register itself.

When I enabled Consul as the default DNS resolver, the service started registering itself like ""deals.domain.net.node.flex.consul"". This is correct as this feature is defined (nodename matches, ""flex"" is the datacenter name, etc), but this address is not addressable by services that don't yet have Consul running. Since we need to roll out Consul in stages, we need some way to have the reverse lookup configurable so that on specific nodes it just uses the recursor DNS servers to do the reverse lookup. 
",robreinhold,lalyos
475,2015-09-02 18:35:09,"@robreinhold It's probably easier to just generate the redundant entries in the home grown system so that the reverse lookup works. If we need to start adding hacks into Consul to support homegrown semantics, the project will suffer overall. It's easier to have those hacks live within the organizations that need them rather than affect the project with a much broader impact.
",armon,robreinhold
475,2015-09-02 20:59:32,"Thanks for the reply, @armon. I think I may have cluttered up my point talking about our internal service discovery.

Maybe a better way to say it is that, when doing a reverse lookup on an IP that happens to have a Consul agent running on it, we were not expecting to get back a Consul address, we were expecting to get back the DNS address that our upstream recursors would return. 

What I'm proposing is a config value like:
reverse_resolve=recurse/consul (or something better, I'm no good at naming)

The way it works right now, Consul is basically clobbering a reverse lookup of the local IP on VMs/servers that have Consul agents setup as the DNS resolver. This was not what I expected, and it breaks name resolution for anybody consuming the Consul name (node.dc.consul) that doesn't yet have Consul configured as their resolver. So this would work great on a distributed system that's not using DNS names yet, or where IPs are used exclusively, but would be very difficult for us to adopt.

I'm willing to do the dev work and get you a pull request, I was just wondering how it would be received. Any chance this config option would be looked at and potentially merged?
",robreinhold,armon
475,2015-09-18 23:33:01,"I am having a similar problem as @robreinhold but for me its happening with Mesos instances on AWS. I need the reverse lookup for the master and slave instances to go to the AWS internal FQDN not Consul. I suspect this would be a problem for any of the servers that figure out their hostname via their IP address (personally I think this is bad, but so many services in the Hadoop ecosystem do this)

Is there a way to disable the reverse lookup with a config?
",rberger,robreinhold
473,2016-01-10 09:33:42,"@blalor I'm inferring from your original post that you run consul in docker with --net=host.

I think there is a workaround if you use --net=bridge:
- you can bind consul -client=0.0.0.0 to all interfaces (inside the net-container-space)
- map 8400/8500/8600 to your bridge0 (172.42.17.1) on the host
- map 8300-8302 to your private-network ip on the host
",tgeens,blalor
473,2016-05-19 22:54:09,"I ran across this one today using addresses->http so I can access the Web UI on server1.



Local `consul rtt` fails because:



Switching http to 0.0.0.0 actually fixed this by binding to all network interfaces, so now I can use 127.0.0.1 and 10.xx.xx.xx to connect to HTTP. This is slightly different than client_addr above, and is different than some users requests where they would like to bind to explicitly 2 IPs, but maybe not _all_ IPs.

This might be worth calling out in the documentation for the [addresses](https://www.consul.io/docs/agent/options.html#addresses) section because in the [bind](https://www.consul.io/docs/agent/options.html#_bind) section, the use of 0.0.0.0 is different:



Suggest adding to the `addresses` section, the use of 0.0.0.0 to bind to all network interfaces. It might even solve @saulshanabrook's issue.
",techwolf359,saulshanabrook
473,2016-05-20 01:46:02,"@techwolf359 

Believe the behavior of the `0.0.0.0` wildcard in golang's net package is to [bind to the first available interface, not all available interfaces](https://github.com/golang/go/issues/9334).  So, I think the docs are correct.

> By default, this is ""0.0.0.0"", meaning Consul will use the first available private IPv4 address.
",steve-jansen,techwolf359
470,2014-11-13 18:48:12,"@sfitts you are correct, the configuration is cumulative of all configuration files seen. The problem with just overriding the array values each time is that it would make spreading the configuration across multiple configuration files impossible. In the case of `start_join` this might make sense, but for other config options like service or check definitions, we definitely want to build those up using all of the available definitions. I'll look into the inconsistent `start_join` result you mentioned.

The better approach here might be to use the `-bootstrap-expect=N` and `-retry-join` arguments together, so that you can form a cluster of servers, and automatically bootstrap after the N servers had successfully joined eachother.
",ryanuber,sfitts
470,2014-11-13 19:23:29,"@ryanuber that all makes sense.  You may want to clarify that in the documentation since it says that latter values ""override"" earlier ones (which could be interpreted as one array replacing the other).

Thanks for the suggestion that appears to work better.  One question -- are those settings which can be provided whether or not we are actually initializing the cluster vs. re-starting from existing state? Ideally I'd like one configuration I can spin up regardless of condition.

Another question -- if I use `bootstrap-expect=N` must I have exactly N peers or is that a lower bound?  I'd like the freedom to spin up additional peers if needed so I don't want to have the exact number encoded in configuration.
",sfitts,ryanuber
470,2014-11-13 19:58:46,"@sfitts Using `bootstrap-expect` should only bootstrap once, so you should be safe there. Bootstrap expect mode does not hard-set the number of server peers required, only the number required for the initial bootstrap. That means it's entirely possible to bootstrap-expect with 3 nodes, then later add 2 more if you needed more redundancy for servers.

I'll update the documentation to be a bit more specific on the config merging strategy. Thanks!
",ryanuber,sfitts
468,2014-11-13 01:56:14,"@webcoyote I just pushed 8a1969cc8cf4585438630e051e6fcc24fc7e908f, which should fix this. Do you think you could give it a try with a build from master?
",armon,webcoyote
468,2014-11-20 19:04:45,"@webcoyote Have you had a chance to try again on the master build? 
",armon,webcoyote
468,2014-11-21 18:54:47,"@webcoyote Can you confirm the new versions were never running at once? Working with the LMDB developer, I think the issue is upstream. Apparently concurrent processes can break this.
",armon,webcoyote
468,2014-11-21 19:17:37,"@hyc We've been pinned to 0.9.11 for quite some time (May 30th). Not sure why this would be happening now that we touched that setting.

Does this mean upgrading to LMDB 1.0 will also break all existing installs?
",armon,hyc
468,2014-11-21 19:30:52,"@armon - should not have happened, but changing compile environment might have affected it.

LMDB 1.0 will break 0.9 compatibility, yes. The on-disk data layout will change. It has not (intentionally) changed so far.
",hyc,armon
468,2014-11-21 19:34:47,"@hyc Is there a compatibility promise with the 1.0 release? How do you guys handle the upgrade process for OpenLDAP?
",armon,hyc
468,2014-11-21 19:50:09,"@webcoyote Do you think you could provide @hyc with copies of the raft/ data directory after running it with each version? That may be of use in determine what changed
",armon,webcoyote
468,2014-11-21 19:50:09,"@webcoyote Do you think you could provide @hyc with copies of the raft/ data directory after running it with each version? That may be of use in determine what changed
",armon,hyc
468,2014-11-21 20:10:37,"@hyc I don't see any docs for those two here: http://symas.com/mdb/doc/group__mdb.html. Also seems the docs are for 0.9.14 not 1.0. Where is the best place to look?
",armon,hyc
468,2014-11-21 20:14:28,"> Do you think you could provide @hyc with copies of the raft/ data directory after running it with each version? That may be of use in determine what changed.

Yes. Since he doesn't have a public email address I'll mail it to you, @armon.
",webcoyote,armon
468,2014-11-21 20:14:28,"> Do you think you could provide @hyc with copies of the raft/ data directory after running it with each version? That may be of use in determine what changed.

Yes. Since he doesn't have a public email address I'll mail it to you, @armon.
",webcoyote,hyc
468,2014-11-21 23:22:55,"@webcoyote It looks like you must have built on a 64bit platform. Our official Windows builds are 32bit, so it looks like the mis-match there was causing the issue. (Thanks to @hyc for diagnosing).

Looks like we can close this one down!
",armon,webcoyote
468,2014-11-21 23:22:55,"@webcoyote It looks like you must have built on a 64bit platform. Our official Windows builds are 32bit, so it looks like the mis-match there was causing the issue. (Thanks to @hyc for diagnosing).

Looks like we can close this one down!
",armon,hyc
466,2014-11-24 18:00:11,"@deadjoe Yep! Typically the catalog endpoints are too low-level
",armon,deadjoe
463,2014-11-21 08:33:23,"@topiaruss Are you talking about the message ID and the timestamp in the output? I think the gist is to show that we expect the same response. Please re-open this if there is something I am missing.
",ryanuber,topiaruss
460,2014-11-10 18:42:32,"Hey @gebrits, I actually emailed Igor about many of the factual inaccuracies in his blog post. It's been over 6 months now, so I'm willing to post the email publicly: https://gist.github.com/armon/a8f90ab7f50159ac3cc2

In terms of the Synapse side, there are 2 potential answers. In many cases, there is no need for a Synapse component, as discovery is done via DNS or the HTTP API and there is no other moving pieces. If you need to use an HAProxy or similar for reverse proxy, then recommend using consul-template (https://hashicorp.com/blog/introducing-consul-template.html) which is a super-set of Synapse.
",armon,gebrits
460,2014-11-10 22:26:29,"@armon: In the case of needing to do discovery using DNS, this means that my own app/code needs to be instrumented to talk to Consul specifically instead of just 'some http endpoint' no? 

The beauty of the HAProxy option to me, is that it just works in dev where the actual services are available at localhost at the specified port, whereas in prod you just switch those out for a HaProxy, no code changes needed, and no leak-in of (to me) devops stuff like Consul. Consul-Template seems to be exactly what I'm looking for in this regard, thanks.

BTW: appreciate the email, that clarifies things a lot. I especially got the notion that consul is pretty heavy in operation, while that doesn't seem to be the case. Of course the proof is in the pudding, so I'll have a crack at it tomorrow. 

Lastly, I intend my entire stack to run on CoreOs, which with Etcd seems to partially overlap functionality with Consul. Although that may be the case, I'm pretty sure they don't have to bite eachother. Do you have any experience in this regard?
",gebrits,armon
459,2016-09-21 17:02:56,"I'm going to close this down per @armon's comment above - this would be hard to do properly without introducing a lot of complexity in Consul itself.
",slackpad,armon
457,2015-01-20 22:40:57,"@petemounce This will not affect your case. This is only when the server nodes themselves change IPs but not their node name. The clients can change IPs all day :)
",armon,petemounce
457,2015-02-24 00:16:55,"@blalor Can you provide the DEBUG level logs from the machine and maybe one other machine? This looks slightly different than the issue of this ticket. The ticket is that the Raft peers cannot handle an IP update of a server, while this looks like a different issue (Join/Fail) not converging.
",armon,blalor
457,2015-02-24 19:56:06,"@blalor It looks like consul-001 is unable to ping (directly or indirectly) consul-000:



This could mean there is some network issue preventing UDP packets between them, which is causing the flapping. Could you investigate possible network issues?
",armon,blalor
457,2015-12-01 16:21:01,"I'm determined to introduce ip change support in Consul.

I've hacked the code to allow that and it seems to work. I'd like to agree with you on the design of the final solution so that, possibly, my pull request could be integrated with mainline Consul.
@armon Please let me know your comments and concerns.

The requirements:
- allow ""old-style"" behavior - identification of nodes by their IP address
- allow identification of nodes by some unique (cluster-wide) identifier;
- it is not required to provide online IP change support (i.e. you need to at least restart agent to use new IP)

OK, so here's the idea:
- use node name as a ""node address"" (consistency with serf, web API etc.)
- keep this node address in RaftLayer and in serverParts
- use serf-based node address resolver in RaftLayer::Dial and ConnPool::getNewConn to resolve node address to proper IP when creating a new connection

Please note that no reverse resolution (IP->node address) is required.

Correctness:
Obviously, there is a question whether such approach is correct.

Assumptions:
- Raft algorithm doesn't require reliable network (i.e. network delays,
  partitions, packet loss, duplication, re-ordering is allowed)
- after code inspection I believe hashicorp's Raft implementation doesn't require reliable network either
- consul doesn't identify message sender by remote address (which is by nature IP); instead the sender node identification is passed in messages (if needed); in general, the messages are valid or not regardless of who sends them - it is their content that matters
- nodes are identified (in Raft, for RPC) by their address, but there is no requirement that this is a TCP address. Thus, it can be arbitrary node address without affecting Raft/consistency.

Observations:
- If there is a property that IP address is not re-used the approach is correct, because effectively IP change is seen as a transient network problem.
- if IP address is re-used after some reasonably long time, the scenario is reduced to transient network problem as well.

This is good enough for me, because that covers real-world scenarios I need to handle.

However, I believe than even in case of rapid IP addresses changes the approach stays correct. The new case to consider is when messages reach different destination then intended because serf data is not up-to-date. Still, because it is message content that matters, and not the sender, all invalid requests will be dropped (even now there must be a support for handling stray or delayed messages). There is a risk that some valid requests are dropped, but this affects only efficiency, but not correctness.

Obviously, this is hardly a _proof_ of correctness. I do not intend to perform formal verification though. Is it good enough for you?

I've looked over web API and I think this change doesn't affect it. I hope I haven't broken anything.
",jakubzytka,armon
457,2015-12-02 09:51:50,"fwiw, my workaround worked okayish - until a node hard crashes and you need to replace it.
@jakubzytka's design sounds reasonable to me, but I'm wondering what happens if you end up with two nodes using the same node name.
",discordianfish,jakubzytka
457,2016-02-01 12:48:06,"@deltaroe You can workaround your issue by scripting the startup, and not relying on a manual procedure. Just check and persist the IP when starting consul and then on every restart re-check that IP. If it changed - remove old data and start the node with a new name. Or, alternatively, use node names that contain the IP. You'll never have the same node name for different IPs and you will be able to remove stray peers with force-leave.
The problem (for me) is that both these approaches require quorum of nodes to be alive, and my solution works when there is no quorum.
",jakubzytka,deltaroe
457,2016-04-05 02:03:32,"I don't suppose someone from Hashicorp could give @jakubzytka some feedback on the proposed design?  This problem has just bitten us _badly_, and although I'm implementing workarounds, it'd be nice if this problem was solved in consul.
",mpalmer,jakubzytka
457,2016-04-05 02:12:19,"@mpalmer sorry you got bit by this.

We are currently working on some improvements for Raft's management of config changes but we want to be super careful we do this in the best way. We are currently leaning towards adding a cluster-wide GUID that comes from the memberlist layer and is used to track identity regardless of IP and node name, so we are working through the implications of that.
",slackpad,mpalmer
457,2016-04-05 06:12:59,"@mpalmer If you badly need some solution you can try my patched consul. It handles changing IP address of a node as long as node name stays the same.
The code is available at https://github.com/jakubzytka/consul/tree/ipChangeSupport
The branch is based on consul v0.6 if I remember correctly, but I guess it should apply cleanly over the newest version.
We've been using it in ""staging"" for a few months without issues.
",jakubzytka,mpalmer
454,2014-11-21 21:27:52,"Very interesting @armon! Thanks for the explanation.
",i0rek,armon
454,2014-11-23 11:27:33,"@armon What about being able to specify the expected quorum size ? It is up to the user to use a correct value, like it is for `bootstrap_expect`
",adrienbrault,armon
454,2014-11-24 19:01:01,"@adrienbrault Not currently. There are issues around changing the quorum size then once it is specified. The current approach I think makes the very reasonable trade off of being a zero-touch bootstrap, and zero-touch scale up and down as long as quorum isn't lost. With a sensible amount of redundancy, it should be incredibly unlikely that an operator needs to intervene.
",armon,adrienbrault
454,2015-05-12 02:21:50,"@mohitarora Is that not covered here?  http://www.consul.io/docs/guides/outage.html
",ryanbreen,mohitarora
454,2015-05-12 02:36:27,"@ryanbreen That didn't help. Here is what i did
- Started first node in bootstrap mode ( this node will self-elect as leader, creating a basis for forming the cluster.)
-  Started second and third node in non bootstrap mode which i call a normal server
- I wanted each server on equal footing so I did shutdown the bootstrapped consul instance and then re-enter the cluster as a normal server.

Everything looks good at this point.

I forced the cluster to lose quorum by restarting 2 of the 3 nodes at same time. Nodes came back online but leader was not selected on its own.

I want to know what should be my next step here.

Should i again start node 1 in bootstrap mode and re-execute the steps mentioned above?
",mohitarora,ryanbreen
454,2015-05-12 04:13:03,"Thanks @ryanbreen .

-bootstrap-expect is better than -bootstrap, I will start using that but both these are used when cluster is initialized.

I still need the steps for recovery once quorum is lost. In my case no leader was selected once all nodes came back to life after quorum loss.
",mohitarora,ryanbreen
454,2015-05-12 23:11:39,"I also had a similar question to @mohitarora. If we do lose quorum, and there is no leader, what do we do?
",saulshanabrook,mohitarora
454,2015-05-12 23:41:57,"@saulshanabrook Then you're in an outage scenario (since you've lost quorum) and need to decide which server is authoritative, then follow the [outage recovery guide](http://www.consul.io/docs/guides/outage.html).

One thing I've also found: If your leaders actually leave the cluster when shutdown cleanly (rather than `kill -9` style killed), which is the default behavior, then they can't rejoin after a restart due to having notified the cluster they are leaving. @mohitarora try setting [leave-on-terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate) to false in your server config and then repeating your test of starting 3 servers then stopping 2 and bringing them back up.
",highlyunavailable,mohitarora
454,2015-05-12 23:41:57,"@saulshanabrook Then you're in an outage scenario (since you've lost quorum) and need to decide which server is authoritative, then follow the [outage recovery guide](http://www.consul.io/docs/guides/outage.html).

One thing I've also found: If your leaders actually leave the cluster when shutdown cleanly (rather than `kill -9` style killed), which is the default behavior, then they can't rejoin after a restart due to having notified the cluster they are leaving. @mohitarora try setting [leave-on-terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate) to false in your server config and then repeating your test of starting 3 servers then stopping 2 and bringing them back up.
",highlyunavailable,saulshanabrook
454,2015-05-13 00:11:59,"@highlyunavailable What if all three go down at once? How do I restart then?
",saulshanabrook,highlyunavailable
454,2015-07-28 21:52:26,"Hey @armon

I think there may actually be a bug here though, no?  In order to fix the issue I have to:
1.  Stop consul on all 3 server nodes.
2.  Rewrite /var/lib/consul/raft/peers.json with the correct contents.
3.  Start consul on all 3 server nodes.

The issue with peers.json is the actual contents seem to be written as ""null"".  (Aka the string ""null"").
",jwestboston,armon
454,2015-07-28 22:09:36,"@jwestboston From the perspective of Consul, all three servers have left that cluster. They should not rejoin any gossip peers or take part in any future replication. If they had not left the cluster, they would still have those peers and would rejoin the cluster on start.

Because all the servers or a majority of them have done this, it is an outage that now requires manual intervention. Does this make sense?
",armon,jwestboston
454,2015-07-29 22:40:34,"@armon Ahh .. yes .. that does make sense! :-) Thanks for the clarification.  The peers.json file is a list of folks actually, expected to be in the cluster at the current time.  Stopping consul == gracefully exiting the cluster == removal from that list across the cluster.

So really, indeed, things are operating as designed.  And all we need (maybe? perhaps?) is an easier experience for cold restarting an existing Consul cluster.
",jwestboston,armon
454,2016-02-09 04:17:26,"@tkyang99 do you have `skip_leave_on_interrupt` set to true? You'll want that for server configurations because you'll otherwise leave them from the cluster as you ctrl-c them, which will cause an outage.
",slackpad,tkyang99
454,2016-02-25 09:52:46,"@armon 
I'm having a cluster of 3 nodes on an environment, which is subject to be stopped and restarted in an automated manner.
Since I had trouble with getting the consul cluster up and running again I was looking for the reason why no leader could be elected. 

Regarding your post this seems to be an expected  behaviour. Thanks for your clarification at this point!

Is there any way to prepare the consul cluster for such restarts - like shutting down 2 of 3 instances before stopping the instances?
Beside of telling the nodes that they should not leave gracefully - since the master would have been selected manually in a complicated way (stopping the running service, forcing bootstrapping on this node, starting the service, stopping the service, removing enforced bootstrap, starting the service again)

Is there a feature planned to be implemented in future releases?

Cheers,
Âµatthias
",mwiora,armon
454,2016-03-10 06:18:26,"Hi @mwiora it should be possible to kill -9 the servers, or stop them if the leave_on_terminate settings are set correctly and they will renegotiate leadership when they come back since none of the servers have left the quorum. We are working on some issues related to this, however - https://github.com/hashicorp/consul/issues/1534.
",slackpad,mwiora
454,2016-09-12 22:06:54,"I was having an issue with a 3 node cluster so I figured I'd restart them to see if that addressed the issue. 
""What could go wrong? They'll just re-elect a new leader.""
I cannot get a new leader elected.

 First I created a /data/raft/peers.json file populated as described in this guide:
https://www.consul.io/docs/guides/outage.html

 I tried @angelosanramon suggestion which got me slightly further but not far enough.
`==> WARNING: Bootstrap mode enabled! Do not enable unless necessary
==> Starting Consul agent...
==> Starting Consul agent RPC...
==> Consul agent running!
         Node name: 'consul0.lx.pri'
        Datacenter: 'dc1'
            Server: true (bootstrap: true)
       Client Addr: 0.0.0.0 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
      Cluster Addr: 10.5.100.223 (LAN: 8301, WAN: 8302)
    Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
             Atlas: <disabled>

==> Log data will now stream in as it occurs:



At this point I am actually going to tear down my entire Consul cluster and start from scratch. This is definitely an issue.
",ljsommer,angelosanramon
454,2016-09-12 22:14:53,"Hi @ljsommer  sorry about that.

`2016/09/12 21:20:49 [INFO] raft: Removed ourself, transitioning to follower`

It looks like you have the leave entry in your Raft log, which is un-doing your peers.json change. This should be fixed in master as the peers.json contents are applied last, any chance you can try this with the [0.7.0-rc2 build](https://groups.google.com/d/msg/consul-tool/Eo5rjStEyds/e9LNjpX0DwAJ)?
",slackpad,ljsommer
454,2016-09-12 22:18:17,"@slackpad 

I have the good fortune to be able to actually rebuild from scratch without losing any critical data, and yes I'll definitely be using the latest version of Consul to do it. When I get fully rebuilt I will be simulating this same scenario and documenting the results. I'll make sure and update this thread when I do with a step by step guide.
",ljsommer,slackpad
452,2014-11-05 18:14:30,"@iconara Sounds like you guys theory is correct based on the data. Looks like they mistakenly left the ports open and the attempts to heal a failed node managed to merge the clusters. Besides network rules, and encryption we also have an open ticket to avoid merging clusters if the dc's don't match which should add another layer of protection.
",armon,iconara
449,2014-11-07 05:09:40,"@carlanton this should be fixed now in master. Thanks for reporting it!
",ryanuber,carlanton
446,2014-10-31 23:05:00,"Excellent, makes sense, thanks for taking the time to answer my questions @armon!
",c4milo,armon
445,2014-11-18 21:15:18,"@ollio we just redirect stdout to a file. It is easy in upstart and in any other thing too.
",i0rek,ollio
445,2015-02-21 04:16:58,"As @i0rek mentioned, normally to get file-based logging, you redirect stdout to a file. You can also achieve this by forwarding messages to a syslog server, allowing it to do what it is good at and redirect your logs wherever you want them to go. I'm going to close this, because I don't see us adding this as a core consul feature. Thanks!
",ryanuber,i0rek
443,2014-10-30 20:40:32,"@lra This might just be a bug with how our UI works. The UI is trying to determine if the ACLs are enabled, but since the UI is on the client without `acl_datacenter` it's detection is failing. In this case ACL's are enabled and enforced by the server, but the UI is just mis-reporting as disabled due to how it does it's simple check.

In terms of the ""Access Denied"" message, that is expected. Since you must use a management token to manipulate ACLs, you will need to provide the `acl_master_token` to the UI in the preferences.
",armon,lra
440,2014-10-30 16:37:11,"@lra gossip encryption status should now show up if you build against the latest Serf. I'll leave this open so we can look at doing ACL's as well.
",ryanuber,lra
440,2015-05-18 22:44:19,"@lra There is no way to tell from `consul info`, but you can check the `ACLDatacenter` in /v1/agent/self
",armon,lra
438,2014-10-27 14:59:46,"@richardboydii looking into it
",sethvargo,richardboydii
438,2014-10-27 15:22:04,"@richardboydii it's back up. Thank you for pointing it out :smile: 
",sethvargo,richardboydii
436,2014-10-27 02:26:25,"@sethvargo LGTM, merge away!
",ryanuber,sethvargo
435,2014-10-27 04:28:01,"@sethvargo I had no idea that Google honored these tags, but after looking it up this LGTM!
",ryanuber,sethvargo
434,2014-12-11 18:53:30,"+1, on linux its also easily reproducable like @stephure mentioned. Set bootstrap_expect: 1 and restart.
",osiloke,stephure
434,2014-12-11 19:32:57,"@armon I was seeing it even with fresh data directories iirc. On the initial start it's fine, but after restarting (and preserving the data directory created by 0.4.1), I saw this behavior.
",vito,armon
431,2014-10-24 07:56:06,"@xla This is looking great! I think you've pretty much got it. We aren't breaking backward compatibility, and the implementation is very simple and to the point. It's outside of the scope of this ticket, but it's looking like we need an analogous `checks`-type option to match.

My only recommendation is to add the new `services` config option to `website/source/docs/agent/options.html.markdown`, but I'd be happy to do that after a merge if you prefer.
",ryanuber,xla
431,2014-10-24 19:01:44,"@ryanuber Going to refactor the test and happy to incorporate the documentation changes as well.

Adding another PR for `checks` after sounds like a go way forward.
",xla,ryanuber
431,2014-10-26 18:50:44,"@xla I'm going to merge this in and make the adjustments so we can all start profiting from this. Thanks again, great work!
",ryanuber,xla
431,2014-10-27 18:14:57,"@ryanuber You beat me to it. Thanks for the quick responses on this one.
",xla,ryanuber
427,2014-10-27 18:31:04,"@blalor blah. Sorry - I just saw this. Soooooooooo (prepare), we use a custom middleman extension called [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp). He is open source, but highly customized to our MM installations.

One of the magical things he does is, given a list with a code element in the first:



This automatically gets converted to a named link (so we can link to a specific config item in the documentation).

I **think** that is screwing up your links. Our middleman installation also auto-generates named-header-links (TOC data), so you shouldn't need to manually create them.

This is most likely a bug in middleman-hashicorp, but looking at what you're trying to do, I think it also opens room for new magic.

What we really want to do is have a TOC at the top - I think middleman-hashicorp could be extended to auto-generate that table and links from the H\* tags.
",sethvargo,blalor
427,2014-10-27 18:47:56,"@blalor:



And then browse to `http://localhost:4567`. Note: you need to have a Ruby environment installed and setup as well. 
",sethvargo,blalor
423,2016-02-03 10:22:22,"@armon Has there been any progress on this?
",maticmeznar,armon
423,2016-02-13 01:42:34,"Hi @maticmeznar unfortunately we haven't been able to work this into an upcoming release yet. We will update this once we get some time to work on it.
",slackpad,maticmeznar
421,2015-01-20 16:22:46,"@ryanuber this is done now, correct?
",sethvargo,ryanuber
421,2015-02-20 17:06:16,"@blalor not currently, no. We basically just support setting the address of the HTTP server to `unix://x/y/z` to listen on a domain socket rather than TCP. Could you elaborate on your use case a bit?
",ryanuber,blalor
417,2014-10-21 22:23:16,"@sethvargo The ""HashiCorp Tools"" and ""Community Tools"" headers look... jank. Do we have better styling for those? 
",mitchellh,sethvargo
417,2014-10-21 22:23:31,"@sethvargo I looked around and I guess not. :|
",mitchellh,sethvargo
417,2014-10-21 22:23:46,"@mitchellh yea - that's the standard `<h2>` styling :frowning: 
",sethvargo,mitchellh
416,2014-10-21 20:34:06,"@armon we just kicked off the deploy, but sure :smile: 
",sethvargo,armon
416,2014-10-21 20:34:30,"@armon do you think it would make sense to aggregate all these ""tools"" into their own download page (instead of a separate one for each)?
",sethvargo,armon
416,2014-10-21 20:38:11,"@sethvargo Yeah I think a tool page would be nice. I think we should have a HashiCorp tools page and a community tools page, since there are others we should link to (confd, crypt, consulate, diplomat, some other things)
",armon,sethvargo
415,2014-10-21 15:38:34,"Hi @gmeroz that does not appear to be valid JSON...
",sethvargo,gmeroz
415,2014-10-21 18:41:15,"@gmeroz You need to register the service+check first (using the /v1/agent/service/register) endpoint, then you can use the /v1/agent/check/pass for the periodic heartbeating
",armon,gmeroz
415,2014-10-22 22:44:08,"@gmeroz That JSON looks write for /v1/agent/check/register, but not for /v1/agent/service/register. I think you want to create the service with the associated check, and then use /v1/agent/check/pass with that check.
",armon,gmeroz
415,2014-10-30 16:36:12,"@gmeroz I'm going to close this but feel free to re-open if you have more questions!
",ryanuber,gmeroz
414,2016-11-22 19:35:29,@armon has consul auditing been put on the roadmap? We have a requirement for this and looking into options.,fromonesrc,armon
410,2015-05-11 18:21:27,"@ctheune Please send a PR! Happy to review and merge
",armon,ctheune
408,2014-10-17 21:33:09,"@deviant-logic are there any specific API's that seem to have incomplete documentation coverage? The examples in the documentation should reflect the precise JSON keys the Consul API produces for all API's.
",ryanuber,deviant-logic
408,2014-10-17 22:17:55,"@deviant-logic makes sense, I think this case-insensitive behavior actually comes as a ""feature"" from golang's built-in `encoding/json` package. It will prefer an exact match, but failing that will tolerate a case-insensitive match. I agree we should update the documentation to be more explicit about the JSON config format. Thanks for reporting this!
",ryanuber,deviant-logic
407,2014-10-17 22:19:10,"@fidian agreed! Thanks for opening this.
",ryanuber,fidian
406,2014-10-17 18:58:29,"@fidian I was just talking with @armon about this. The main issue is that just straight replacing the value of configuration variables doesn't necessarily mean they will immediately take effect. This is because at agent start, various goroutines, port binding, and other setup takes place, which we would have to replace on config reloads to effectively change the configuration. It might eliminate the point of the config reload in the first place, which is to reload configuration without disrupting the agent.

The things that can be safely reloaded on the fly include:
- Log level
- Services
- Checks
- Watch Plans

For now, we don't have any plans to try supporting a live reload of the entire consul agent, since the disruptiveness becomes close to the same as just restarting.
",ryanuber,fidian
399,2014-11-25 03:48:16,"Hey @josephholsten, the linked page seems relatively inactive, not having any posts since early October. GitHub is much more visible to us in our daily routine, and responses would likely be a lot faster by opening up a GitHub issue. Between GitHub/Google Groups for async help, and IRC for real-time, I think we have this pretty well covered.

I'm going to close this for now, but if the community on SO fires up again, feel free to let us know! Thanks!
",ryanuber,josephholsten
393,2014-10-12 02:15:27,"I might be somewhat confused here. I think the behavior that @claco is asking for is already available with `-bootstrap-expect`. Once all the servers are online, the leader election is done automatically without having to select a single bootstrap node manually.

@claco Maybe you are referring to the behavior prior to 0.4? We've since changed how bootstrapping is done to simplify.

New method: http://www.consul.io/docs/guides/bootstrapping.html
Old method: http://www.consul.io/docs/guides/manual-bootstrap.html

@ryanuber I think we have a separate ticket open for mDNS. mDNS can be used to remove the ""consul join"" interaction, but the leader election according to `-bootstrap-expect` would be unchanged.
",armon,ryanuber
393,2014-10-12 02:15:27,"I might be somewhat confused here. I think the behavior that @claco is asking for is already available with `-bootstrap-expect`. Once all the servers are online, the leader election is done automatically without having to select a single bootstrap node manually.

@claco Maybe you are referring to the behavior prior to 0.4? We've since changed how bootstrapping is done to simplify.

New method: http://www.consul.io/docs/guides/bootstrapping.html
Old method: http://www.consul.io/docs/guides/manual-bootstrap.html

@ryanuber I think we have a separate ticket open for mDNS. mDNS can be used to remove the ""consul join"" interaction, but the leader election according to `-bootstrap-expect` would be unchanged.
",armon,claco
393,2014-10-25 14:05:38,"@mainframe If that works, cool, and I owe you a beer. :-)
",claco,mainframe
392,2014-10-16 20:44:01,"@kiryam Are you talking about the same use case as @erfane, where `consul exec` is run on very short intervals (< 3 seconds) for an extended period of time? Please clarify, and if you can provide any traces or logs from the machines when this happens that would be helpful!
",ryanuber,kiryam
382,2014-10-06 18:43:47,"@mikn Thanks for doing this. I think that we want to take the time to figure out how we can do OS-specific packages in a more general way (using fpm, omnibus, etc), instead of having to maintain the packaging specific code. For that reason, I'm going to close this request for now until we can do this more generally across all our projects.
",armon,mikn
372,2014-09-30 01:41:30,"@armon Thanks for the reply. You are right. The parameter for start cluster is not correct.



should be replaced with



After that it works fine.
",tiw,armon
371,2014-11-28 17:46:30,"The problem is, I don't know how to reproduce this state. Once it has happend on an ec2 cloud.

I tried to reproduce by `consul leave` or `force-leave` a node, but this way the node is listed by `consul members`. The same happens with 0.4.0 and 0.4.1.

If I kill a node, its still listed as _failed_. Somhow we should reach a state whenn `consul members` doesn't lists a node. @armon how long a node stays in _failed_ state? Does it gets removed after a specific time?

@wallnerryan can you reproduce this error?
",lalyos,armon
371,2014-11-28 17:46:30,"The problem is, I don't know how to reproduce this state. Once it has happend on an ec2 cloud.

I tried to reproduce by `consul leave` or `force-leave` a node, but this way the node is listed by `consul members`. The same happens with 0.4.0 and 0.4.1.

If I kill a node, its still listed as _failed_. Somhow we should reach a state whenn `consul members` doesn't lists a node. @armon how long a node stays in _failed_ state? Does it gets removed after a specific time?

@wallnerryan can you reproduce this error?
",lalyos,wallnerryan
371,2016-09-20 23:19:53,"Hi @mapa3m it probably didn't leave cleanly. Updated the [""Failure of a Server in a Multi-Server Cluster""](https://www.consul.io/docs/guides/outage.html) section of the outage guide with some info on what to do in this case, and Consul 0.7 added some tools to remove a Raft peer manually.
",slackpad,mapa3m
371,2016-09-21 01:48:24,"@slackpad yep, that was it. Thanks!
",mapa3m,slackpad
369,2015-05-31 05:01:03,"@memelet if the members have left, they should not show up in the UI. If they are killed abruptly, they should enter a ""failed"" state. In this state, Consul cannot determine if the node is expected to come back or not, so the member will not be reaped out for 72 hours. If you do not expect the nodes to return to the cluster, you can issue a leave event from the command line of any other member using the [force-leave command](https://consul.io/docs/commands/force-leave.html), or the [force-leave api](https://consul.io/docs/agent/http/agent.html#agent_force_leave).
",ryanuber,memelet
368,2014-09-26 03:54:35,"@mfischer-zd the answer actually does look authoritative for the zone, considering the `aa` in the response flags. Dig's `AUTHORITY` field is actually a simple counter for the number of entries in the authority section, and not a true/false type indicator. This isn't clear in the documentation but is easy to spot in dig's source code.

My understanding of stub-zone vs. forwarders is limited, but to me it sounds like the forwarder is actually the more correct configuration in this case since the authoritative servers are known and relatively static.
",ryanuber,mfischer-zd
368,2015-02-09 16:58:45,"@mfischer-zd were you able to configure unbound for consul? If so, could you share your forwarding configuration, can't get it to work myself. Thanks in advance.
",wunki,mfischer-zd
368,2015-03-13 21:29:30,"@nicwaller, that was my subsequent finding as well (but had failed to mention it here).  Closing this issue.  Thanks for reminding me!
",mfischer-zd,nicwaller
365,2015-01-14 19:34:35,"@tailhook Please do make a separate issue. It is something that is more likely to be part of a V2 API. For this issue, it's more of just a time-based de-duplication. E.g. Only fire the handler once per second for any of these watches. Useful when a single handler is triggered by multiple different watchers.
",armon,tailhook
363,2014-09-23 21:48:48,"@bataras This is actually expected behavior. We use LMDB for our storage engine, and it relies on doing large mmap()'s internally. Thus our baseline virtual memory usage is about 40GB, plus an additional few GB caused by the Golang runtime.

This is not a concert, since the amount that is resident is not that high. In this case, only 40MB is resident which is reasonable for the server nodes.

Closing, since this is expected.
",armon,bataras
355,2014-09-22 16:34:06,"@drnic The ""nodes"" type watch maps to the ""/v1/catalog/nodes"" endpoint, which does not reflect health information, just a list of the known nodes. Nodes that are in the left/failed state are still in the catalog until they are reaped (~72h).

So you wouldn't expect that view to change, since none of the data in it is. I think there probably should be a /v1/health/nodes endpoint that does include the health data however.

I'm closing the ticket, but let me open a new one for the /v1/health/nodes endpoint!
",armon,drnic
355,2014-09-22 16:47:07,"Thanks @armon !
",drnic,armon
352,2014-09-19 19:29:07,"@imkira This looks like an issue with UDP messages not being properly delivered. This pattern of suspected failure / re-join flapping continuously is exactly what is expected if the client is not handling the UDP messages. Verify that the UDP messages are going through on the UDP port (8301 by default)
",armon,imkira
352,2014-09-24 03:06:54,"@armon thanks for the prompt reply.

The weird part is that, if I were to have any firewall setting problem, it shouldn't go away even if I restart the client consul, right? (By ""restart"" I mean the process itself, not the machine where it runs) But the problem does go away, in fact. I have also noticed that this problem happens not after ""1 day of operation"" like I guessed before, but rather when I put my dev machine to sleep.

Anyway, this is my dev machine and it shouldn't happen (I suppose) in production. I am using docker for running consul1,2,3 (servers) and exposing 8300 8301 8302 8400 8500 8600/udp. Docker is running on top of boot2docker (since I am running it on OSX) and the client agent is running on the host machine itself. I have no firewall settings blocking docker vm (boot2docker) or docker instances to host. Also, host is able to contact docker instances at the exposed ports specified above. It appears I should have 8301/udp listed as you said, but that doesn't seem to be the root of this problem since it runs fine for hours until I put the machine to sleep.

I haven't looked at the implementation part where you are ""handling the UDP messages"", but I am assuming client agents listen to 8301/udp and wait for gossip messages (?) If that is true, might be the case the udp server running on the client agents is getting somewhat ""confused"" after awaking from sleep?
Any other ideas on what may be going wrong?
",imkira,armon
352,2014-11-05 17:00:08,"@outrunthewolf these messages come from way down in the gossip layer (memberlist), indicating a network problem between nodes. If nodes aren't able to successfully send ping/ack messages to one another over UDP, then you will likely see members flapping between dead/alive state.

I would try the suggestions above from @arthurbarr and @dennybaa and see if you can get any mileage out of either solution, or as @armon suggested if you are doing rapid teardown/startup of docker networking, you might want to add a pause in between.

Let us know if you are still having trouble!
",ryanuber,dennybaa
352,2014-11-05 17:00:08,"@outrunthewolf these messages come from way down in the gossip layer (memberlist), indicating a network problem between nodes. If nodes aren't able to successfully send ping/ack messages to one another over UDP, then you will likely see members flapping between dead/alive state.

I would try the suggestions above from @arthurbarr and @dennybaa and see if you can get any mileage out of either solution, or as @armon suggested if you are doing rapid teardown/startup of docker networking, you might want to add a pause in between.

Let us know if you are still having trouble!
",ryanuber,armon
352,2014-11-05 17:00:08,"@outrunthewolf these messages come from way down in the gossip layer (memberlist), indicating a network problem between nodes. If nodes aren't able to successfully send ping/ack messages to one another over UDP, then you will likely see members flapping between dead/alive state.

I would try the suggestions above from @arthurbarr and @dennybaa and see if you can get any mileage out of either solution, or as @armon suggested if you are doing rapid teardown/startup of docker networking, you might want to add a pause in between.

Let us know if you are still having trouble!
",ryanuber,outrunthewolf
352,2014-11-05 17:00:08,"@outrunthewolf these messages come from way down in the gossip layer (memberlist), indicating a network problem between nodes. If nodes aren't able to successfully send ping/ack messages to one another over UDP, then you will likely see members flapping between dead/alive state.

I would try the suggestions above from @arthurbarr and @dennybaa and see if you can get any mileage out of either solution, or as @armon suggested if you are doing rapid teardown/startup of docker networking, you might want to add a pause in between.

Let us know if you are still having trouble!
",ryanuber,arthurbarr
352,2015-03-25 19:15:03,"@brycekahle & @dennybaa Thank you! This needs to be shared far and wide. :)
",cap10morgan,dennybaa
352,2015-03-25 19:15:03,"@brycekahle & @dennybaa Thank you! This needs to be shared far and wide. :)
",cap10morgan,brycekahle
352,2015-04-08 01:16:41,"@jlordiales Yep, I've made it an [automated build](https://registry.hub.docker.com/u/cap10morgan/conntrack/).
",cap10morgan,jlordiales
352,2015-04-08 09:27:16,"@cap10morgan Thanks man! Really appreciate it
",jlordiales,cap10morgan
352,2015-04-09 12:03:59,"@florentvaldelievre You can use my docker conntrack container. See my comment above.
",cap10morgan,florentvaldelievre
352,2015-04-09 12:35:42,"Thanks @cap10morgan .
The issue actually happens when I 'docker restart consul' on a node.
I guess, this is the issue mentioned right at the bottom of this <a href=""https://registry.hub.docker.com/u/progrium/consul/"">page</a>

Quoted from the page

---

**Quickly restarting a node using the same IP issue**

When testing a cluster scenario, you may kill a container and restart it again on the same host and see that it has trouble re-joining the cluster.

There is an issue when you restart a node as a new container with the same published ports that will cause heartbeats to fail and the node will flap. This is an ARP table caching problem. If you wait about 3 minutes before starting again, it should work fine. You can also manually reset the cache.

---

**Questions**
1. Do you know where the issue is tracked ?
2. Does it mean i should never restart my consul container(docker restart consul) but i should: 'stop' , wait 3 min, then 'start'?
3. As a _hacky_ solution, does it means i need to create a custom consul image which will clean ARP table each time we start consul ?

Thanks
",florentvaldelievre,cap10morgan
352,2015-09-06 01:38:13,"@ekristen https://github.com/docker/docker/issues/8795 is tracking the issue. 
",gauravphoenix,ekristen
344,2014-10-15 02:23:35,"@armon I've been exploring this a bit today. I noticed that consul itself is what is registering the ""consul"" service. I've been able to also get the service registered in the agent with a few simple lines. I think we can probably take the registration out of consul itself now and let the anti-entropy handle it. The question now is how we get any guarantee that the anti-entropy has run. Right now, `l.changeMade()` is just called from the `AddService()` method on `localState`, so if that runs immediately after starting the server (likely before any leader is elected), I'm not sure it will work reliably. This definitely creates problems for the tests as well.

Any ideas on how to better approach this?
",ryanuber,armon
343,2014-09-19 13:04:48,"@tiwilliam Nice!
",pearkes,tiwilliam
342,2014-09-15 21:25:46,"@hoffoo There is no way currently, but this seems to be common feedback which we will try to address with a parameter to suppress the initial callback.
",armon,hoffoo
341,2014-10-20 18:36:13,"@plorenz we can track this issue here - I'll give your use case a shot and see if I get the same thing. Thanks!
",ryanuber,plorenz
341,2014-10-20 18:40:04,"Thanks, @ryanuber. I'm using the /v1/health/service REST API since the /v1/catalog/service doesn't expose information about health checks. 
",plorenz,ryanuber
341,2014-10-20 19:23:19,"I've separated this into another issue after @armon's comment - I have reproduced this and will look into it. @plorenz have a look at #413, we will track it there.
",ryanuber,armon
341,2014-10-20 19:23:19,"I've separated this into another issue after @armon's comment - I have reproduced this and will look into it. @plorenz have a look at #413, we will track it there.
",ryanuber,plorenz
339,2014-11-26 02:12:35,"@failattu have you seen this crop up again? If we could get a repro case that would be great!
",ryanuber,failattu
339,2015-01-02 09:26:36,"@ryanuber Sorry not working with Consul anymore so no I haven't
",failattu,ryanuber
336,2014-09-22 16:30:32,"@ryanuber Oh since using the event on the WAN won't rotate the remote LAN's?
",armon,ryanuber
336,2014-09-23 06:59:10,"@armon yeah exactly. Initially I was thinking we would just have new keys gossiped to all of the nodes and a collective response returned, which seems desirable from the operator's perspective. The alternative is to have like a `-datacenter` flag and a `-wan` flag, and require the operator to run the key rotation for each datacenter plus the wan keyring. I was going to give the former a shot first to see how feasible that ends up being. Let me know if there is a better way of doing this that I'm not thinking of.
",ryanuber,armon
336,2014-10-02 07:05:29,"Thanks, @armon! Always appreciate your code reviews. I left a few comments inline above regarding the generalized `globalRPC` method. Let me know if it makes sense, and I'll address the other suggestions tomorrow.
",ryanuber,armon
336,2014-10-09 17:45:09,"@armon I think this is better now! There are just a couple of things I want to run by you.
1. Anyone currently using the `-encrypt` flag, and rebooting their clusters to change keys will have broken workflows after their next upgrade. Starting with the `-encrypt` flag will work as they would expect, but changing the `-encrypt` value and restarting the agent would not have the same effect as before.
2. I noticed that the WAN keyring is the slowest to respond to keyring queries. I can get a fast response from all LAN pools (~10-15ms total on 10-DC local cluster), but the WAN pool, even on a completely local cluster with multiple DC's, can take up to ~400ms on its own. I though this might have something to do with the timing values being different for the WAN pool, but thought I'd run it by you to see what you think.
3. `globalRPC` simply forwards to all nodes, including the local DC. I used `forwardDC` for this since `forward` skips the local DC and also checks if we can tolerate stale reads and does leader forwarding, which doesn't seem applicable to the `globalRPC` method.
",ryanuber,armon
333,2014-10-15 23:53:05,"@chrisDeFouRire could you try this with `log_level` set to `debug` and paste some logs? I copy/pasted your configs and just changed the command for the handler, and I'm not seeing this behavior.

The relevant portion of the log should look something like this:


",ryanuber,chrisDeFouRire
328,2014-09-07 22:40:52,"@bscott Perhaps this questions is a better fit for Stackoverflow (or similar). The issue is likely with network configuration and connectivity in general, or consul configuration (in contrast to issues in consul source code).

If you ask a question on Stackoverflow (SO) we can continue the discussion there. Others may have similar questions, and SO will surface the question to more people.

http://stackoverflow.com/questions/tagged/consul

In your SO question, outline what VPC scenario/structure[1] you have, more details on the issue, ICMP [ping] logs, etc.

[1] http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenarios.html
",sandstrom,bscott
327,2014-10-09 21:15:54,"@awheeler exec can be disabled via config, so I guess only a config to disable script based checks would be necessary.
",armon,awheeler
327,2015-05-27 07:12:21,"@awheeler @alexhudson See my comment in https://github.com/hashicorp/consul/issues/532, there I propose a mechanism that makes `exec` more safe. Further one could add something like a `checks_engine` option to the agents config. Then you would have all the flexibility to handle a secure exec (in your own terms) on your own.
",kaelumania,awheeler
327,2015-05-27 07:12:21,"@awheeler @alexhudson See my comment in https://github.com/hashicorp/consul/issues/532, there I propose a mechanism that makes `exec` more safe. Further one could add something like a `checks_engine` option to the agents config. Then you would have all the flexibility to handle a secure exec (in your own terms) on your own.
",kaelumania,alexhudson
327,2015-06-01 13:11:14,"@armon SSH provides a similar solution, for example see http://binblog.info/2008/10/20/openssh-going-flexible-with-forced-commands/
",kaelumania,armon
321,2014-09-29 05:06:21,"@noazark It's been tagged, but not yet resolved.
",armon,noazark
321,2015-03-25 17:31:15,"@begriffs Should be an easy enough fix, we'll try to make sure its in 0.5.1
",armon,begriffs
320,2014-09-05 02:42:40,"Hi, @armon 

Under etcd, When I watch and wait a directory like this:



And I update the file `/dir/sub/file2`

The ""blocking query"" will just return one kv pair which was changed.



But under consul, when I use `recurse&index=xx`, the query always returns all of the nodes.

Regards.
",yzprofile,armon
320,2014-09-05 17:22:41,"@yzprofile unfortunately, we do not support watching for the changes only, you get the entire data view refreshed each time.
",armon,yzprofile
320,2014-09-06 14:32:05,"@armon Do you plan on supporting this eventually? I've been looking at using Consul as my main cross-cluster synchronization/messaging mechanism(service A updates state, service B discovers change and applies it to its own state), but since the entire tree that I am watching is relatively big, getting it all at once is impractical.
",dalegaard,armon
320,2014-09-07 00:49:29,"@dalegaard We have no plans to support this. If it is something you need, you could potentially build it into the application layer. Sorry!
",armon,dalegaard
319,2014-09-04 23:32:40,"@sgargan Yeah the difficulty is that the information about scripts and intervals is only known by the agents. The central servers have no idea about that. Of course, that means we could still have an appropriate /agent/check-config/ endpoint or similar with that information.
",armon,sgargan
319,2016-06-09 12:56:03,"@sgargan Have you opened a ticket about this feature?
We are using your consul module for ansible and it's unacceptable for some of our use cases to have ""always changed"" status for task that configures checks and services. 
",meshok0,sgargan
314,2014-09-02 17:05:41,"@drnic I think your version of Serf is out of date. Did you try ""go get -u ./...""
",armon,drnic
307,2014-08-29 00:41:50,"@josephholsten That is correct!
",armon,josephholsten
307,2014-08-29 00:55:07,"@josephholsten Thanks! Fixed in master.
",armon,josephholsten
305,2015-02-21 05:10:39,"@blalor good catch. We actually _do_ have the proper anchors and links, but I think this is a regression. I opened hashicorp/middleman-hashicorp#6 for this. Thanks!
",ryanuber,blalor
304,2016-02-02 04:59:17,"Hi @mrwilby you are correct - with the current implementation you can't get the ModifyIndex from your PUT without another GET, so there's the possibility of a race condition there. There's no easy way to predict the index value either (it's not a simple increment), so we really need to update the API to allow for sequential CAS operations.
",slackpad,mrwilby
300,2014-08-25 06:50:35,"Hey @armon thank you for the prompt support!
I got the latest source and ran consul but it doesn't seem to address the bug I am reporting.

Sorry for not putting it together as a test.go file, but here is a gist that reproduces the bug.

https://gist.github.com/imkira/f40e64d00583160c0c9f

As initially reported, I get two bug patterns:
- len(Checks) between calls to health/service differs (0 vs 1, 1 vs 2, ...)
- number of Checks matches but newly registered service status doesn't (unknown vs passing)

Let me know if you can fix this.
Thank you in advance.
",imkira,armon
300,2014-08-25 18:03:00,"@imkira I am unable to reproduce the error with you test code running against master. Can you verify you re-built against master? Also a gist of the error output could be useful.
",armon,imkira
298,2014-08-22 11:57:15,"Great work @armon!
",tiwilliam,armon
294,2014-11-18 19:16:08,"Those aren't legal characters in DNS, @babbottscott 
",mfischer-zd,babbottscott
294,2014-11-19 17:31:41,"@i0rek The problem is a tag could be ""foo.bar"", which is hard to disambiguate from ""foo"" and ""bar"" or just ""foo.bar"".
",armon,i0rek
294,2014-11-19 20:59:13,"@armon it already is a problem, no? service ""foo.bar"" VS service ""bar"" and tag ""foo"".
",i0rek,armon
294,2015-05-04 21:47:57,"@blacked, because that's not how one typically specifies multiple values for a named parameter in HTTP request parameters.  The idiomatic form is `?tag=master&tag=qa`.
",mfischer-zd,blacked
290,2015-03-17 17:38:09,"@tdeckers Typically, you want to treat Consul as a shared platform within a large organization. Teams individual manage and expose their services, but they do it on a shared cluster. Having tons of independent Consul clusters will quickly become a burden to operators, as there is so many more Consul servers to reason about. The goal is to get the ACLs to the point where they are sufficiently advanced enough to enable even the most complex multi-tenant use cases.
",armon,tdeckers
290,2015-08-09 22:45:34,"Hi @nati this is still in work. ACLs are getting much richer for the upcoming 0.6 release. You can see the upcoming documentation here - https://github.com/hashicorp/consul/blob/master/website/source/docs/internals/acl.html.markdown.
",slackpad,nati
290,2015-08-22 10:55:12,"@slackpad that sounds great! I was going to try and hack it by creating a namespace/directory for each tenant and then restricting accordingly. But the benefits of preventing leaking via service registration and DNS have convinced me I should hold off.

If there's some way to help with the development let me know. I'd like to try and do more than add another +1 :smile: 
",glenngillen,slackpad
290,2015-08-31 23:13:36,"@scalp42 I'm not sure I follow. The ACLs should be rich enough for you to provide read-only access to services if so desired. Do you have a specific use case in mind that we wouldn't hit?
",slackpad,scalp42
290,2015-10-29 16:19:15,"So considering that this case has been open for over a year, am I to assume that from a service discovery perspective, that native support for multiple environments will not be happening?  I'm with @dvusboy that I'm not clear how ACL's help with DNS-based discovery.  I guess I could use tags, but I'd have to wrap my head around how we would deal with that given our current environment.  Plus using tags would likely be more prone to errors as not all of our applications are completely 'environment' aware.  

I will likely have to go the multiple consul clusters route to prevent that from happening, which is something I was hoping to avoid.
",ssorathia,dvusboy
290,2016-03-10 07:18:55,"Hi @rkno82 this is still a ways out though it is on our roadmap. There are some architecture implications to think through, but we know that a lot of folks are interested in this capability.
",slackpad,rkno82
287,2015-02-08 00:04:15,"@armon is there any roadmap for this?
",niclashoyer,armon
287,2015-02-08 20:00:22,"@niclashoyer we will likely get this added once the 0.5.0 release is complete. We are trying to lock down on features to get that release out the door since we already slipped the intended release date.
",ryanuber,niclashoyer
284,2014-08-22 21:49:32,"@payoffstan Can you confirm with your test case that this patch works? I don't have a test case to reproduce this.
",armon,payoffstan
284,2014-08-23 00:27:54,"Thanks @miekg and @armon. We don't have a test case per se but I can patch a dev server and see how it holds up. We finally encountered another panic recently but I haven't gotten the scrubbed packet capture from my ops guy yet. I'll email that once I have it so maybe we can construct a test case for the future.
",payoffstan,armon
284,2014-08-23 00:27:54,"Thanks @miekg and @armon. We don't have a test case per se but I can patch a dev server and see how it holds up. We finally encountered another panic recently but I haven't gotten the scrubbed packet capture from my ops guy yet. I'll email that once I have it so maybe we can construct a test case for the future.
",payoffstan,miekg
284,2014-08-23 06:23:21,"[ Quoting notifications@github.com in ""Re: [consul] Consul panic after rep..."" ]

> @payoffstan Can you confirm with your test case that this patch works? I don't have a test case to reproduce this.

Yes, some binary data would help here. I think this check should also be
placed in the other cases.

/Miek

## 

Miek Gieben
",miekg,payoffstan
284,2014-08-28 17:23:17,"@krolaw If you have a reproducible case, or a test input that would be great!
",armon,krolaw
284,2014-08-28 17:24:09,"Even a tcpdump would suffice.
On 28 Aug 2014 18:23, ""Armon Dadgar"" notifications@github.com wrote:

> @krolaw https://github.com/krolaw If you have a reproducible case, or a
> test input that would be great!
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/284#issuecomment-53760205.
",miekg,krolaw
280,2014-08-11 15:10:01,"+1. It's been a long time that I'm thinking of requesting this. Thanks @johnrengelman
",salehe,johnrengelman
274,2014-11-24 19:22:30,"@drauschenbach Are you using the `/v1/catalog` endpoints directly? My guess is that the anti-entropy is coming through and deregistering things which looks like data loss.
",armon,drauschenbach
274,2014-11-24 19:50:40,"@drauschenbach Yep! Otherwise the agent will reconcile the difference and clear the entries.
",armon,drauschenbach
274,2016-01-08 01:26:18,"@kunalvjti did you figure this one out? It looks like there's another server it is connecting to, losing quorum.
",slackpad,kunalvjti
266,2014-08-01 17:53:11,"Yeah as mentioned by @wuub, it is already handled automatically. We will add a flag to tune that ""reap"" interval, so you can change it from 72h as you see fit.
",armon,wuub
263,2014-07-31 17:53:09,"@mtchavez hey! I like that idea and placing. If we have that row there, we can probably move the IP down as well.
",pearkes,mtchavez
262,2015-02-21 04:03:30,"@armon is this partially solved by the new `consul lock -n` semaphore?
",ryanuber,armon
260,2015-01-09 15:44:47,"@armon Awesome, this is much appreciated!
",sandstrom,armon
259,2014-09-18 20:07:02,"@r04r you make me realize it must not be so easy to integrate docker with consul... isolation means apps running inside docker can't expect localhost:8500 to work (and forwarding only works inside->outside). 

I know some work is being done to let containers talk to each other, which means running consul in a (single) docker container might be a solution...
",chrisDeFouRire,r04r
259,2014-09-21 01:48:01,"@chrisDeFouRire So far I've not been having any issues for my use case except for the lack of checks. I've got consul running on the host providing DNS to all of the containers, and each container that is launched gets added to consul under its hostname by a daemon running on the host watching the docker event log. Generally there's only a single application running on each container, and the applications query consul primarily through DNS (to discover other containers). I'm also using the K/V value store, which can always be reached through its own DNS name resolving to the internal IP of the host machine.
",r04r,chrisDeFouRire
259,2016-04-01 11:30:49,"@jmcarbo in consul-externalservice, ""All checks are defined and run from the consul node attached to the running consul-externalservice instance"". How does that compare to registering the external service with its health check to that node?
",raboof,jmcarbo
259,2016-05-27 02:28:43,"I think @raboof  point is right. If the consul-externalservice node goes down all the external services go down too.
I understand the reasoning for not adding scripted health check for external services, but a TTL would solve most of this problems cleanly. I could register an external service with a TTL and then it is my responsibility to do the checking and update consul with the result.
If my service/application goes down, it will be marked as unhealthy after it misses its TTL.
",mterron,raboof
258,2014-07-23 18:40:41,"@armon this was brought to my attention last night by a co-worker of mine. I agree that service checks should be marked as _critical_ if the serfHealth check becomes critical. If it is not, then I believe it will become a common pattern in the application layer to check for both the status of the service check AND the status of the serfHealth check on a node.

@chrisDeFouRire as a side note: we're also using Consul in the online gaming space and it's been great to us, too!
",reset,armon
258,2014-07-23 18:40:41,"@armon this was brought to my attention last night by a co-worker of mine. I agree that service checks should be marked as _critical_ if the serfHealth check becomes critical. If it is not, then I believe it will become a common pattern in the application layer to check for both the status of the service check AND the status of the serfHealth check on a node.

@chrisDeFouRire as a side note: we're also using Consul in the online gaming space and it's been great to us, too!
",reset,chrisDeFouRire
258,2014-07-23 19:05:26,"@armon If that is the case I think you're right and it's probably best leave this up to the application level to determine what a healthy check looks like. Perhaps a healthy check to some applications are not just the service but also the status of serf.
",reset,armon
257,2014-07-23 14:25:04,"@spro Looking good!

Design feedback:
- I think the ""action bar"" should go just under the node name, as the checks can scale out to many and cause the bar to be lost. If it's right under, it's always in the same place
- Inside the action bar, button links may be better...but also could cramp it out. Hard to tell. Maybe something from [Bootstrap button groups](http://getbootstrap.com/components/#btn-groups) would make sense. (you may have noticed we use bootstrap with overrides)
- We should be sure to include a `confirm` dialog, though one day graduating to richer confirmations would be cool. We currently do a confirm on the K/V delete, I think.

Note that the whole node pane is getting pretty dense, and I've never really loved the borders and blocki-ness visually, so if you want to take a step further back and modify what's existing, go for it! Otherwise, I think given some revisions based on the feedback this could be great.
",pearkes,spro
257,2014-07-25 23:47:01,"Thanks for the pointers guys!

@armon What I was thinking for ""service deregister"" was if you had some service that had died/been killed without deregistering, while serfHealth stands strong. Perhaps another has been started on the same node with a new ID so you don't want to deregister the whole node. Is that an alright use case?

@pearkes I haven't found a good place to fit a row of buttons... but what about a standard Bootstrap dropdown placed somewhere in the top? Picture shows two possible places for that. Also featured is an attempt at anti-blockiness and squeezing in some more useful service details (namely service ID and port).

![screen shot 2014-07-25 at 4 44 58 pm](https://cloud.githubusercontent.com/assets/211613/3709438/ee89ca22-1455-11e4-8d69-28617563aa0f.png)
",spro,pearkes
257,2014-07-25 23:47:01,"Thanks for the pointers guys!

@armon What I was thinking for ""service deregister"" was if you had some service that had died/been killed without deregistering, while serfHealth stands strong. Perhaps another has been started on the same node with a new ID so you don't want to deregister the whole node. Is that an alright use case?

@pearkes I haven't found a good place to fit a row of buttons... but what about a standard Bootstrap dropdown placed somewhere in the top? Picture shows two possible places for that. Also featured is an attempt at anti-blockiness and squeezing in some more useful service details (namely service ID and port).

![screen shot 2014-07-25 at 4 44 58 pm](https://cloud.githubusercontent.com/assets/211613/3709438/ee89ca22-1455-11e4-8d69-28617563aa0f.png)
",spro,armon
257,2014-07-27 17:42:42,"@spro The issue is that the client is the source of truth, not the server. If the client still believes the service exists, even if you remove it on the server, the client will re-register the service. Not sure of the best approach now.
",armon,spro
254,2014-07-22 15:05:59,"With the new fix @armon, it looks like cluster bootstrapped normally with 3 nodes no problems)
Btw could you please tell if it's okay already preparing to use consul in production? Because now I get constant flapping of agent states  and it's seems a bit suspicious...?
https://gist.github.com/dennybaa/c09d56723bdf4d42e247
",dennybaa,armon
254,2014-07-22 15:24:51,"Oh, thanks a lot @armon. It's exactly docker! About `-bootstrap-expect` awesome I will mind this.
",dennybaa,armon
252,2016-01-13 22:33:47,"@a86c6f7964 prepared queries can help across datacenters for sure (using pre-configured fallbacks or network coordinates, or both). Within a datacenter, many HTTP endpoints now support the `?near=` argument that lets you find the closest service, but this issue still stands for a more general weighting feature.
",slackpad,a86c6f7964
252,2016-03-27 07:26:46,"While not exactly server priorities, many on this issue have referenced automatic DC failover as a reason for wanting server priorities.  As @slackpad mentioned earlier, with Prepared Queries this is possible, and has been made easier with Prepared Query Templates.  We held a webinar and covered this at around minute 31.

https://www.youtube.com/watch?v=FGbzS6ripXA&feature=youtu.be&t=1690
",sean-,slackpad
250,2014-07-17 17:39:45,"@chrisDeFouRire This is intended behavior. It should probably be better documented, but look at the `check_update_interval` configuration on this page: http://www.consul.io/docs/agent/options.html

Basically, when a check is in a steady state, updates to output may be delayed up to `check_update_interval` time. This is actually a safe guard for exactly this case. If 1000 nodes were updating a check output every 5 seconds, it causes 200 writes/s on the servers. This is an optimization that reduced that to closer to 3 writes/s.
",armon,chrisDeFouRire
250,2014-07-18 07:42:03,"Thanks @armon ! That's exactly what I need to adjust to a lower limit...

Sorry I didn't find it by myself... I guess I was mislead by my `curl`attempt which did hit the agent instead of a server (so the API seemed to answer immediate values, while the GUI lagged by 5m)...
",chrisDeFouRire,armon
246,2014-07-15 17:05:31,"@ryanuber I don't see any potential caveats off the top of my head... I think its actually a bit simpler since Consul requires a data directory, we have a convenient location to put the key ring file.
",armon,ryanuber
246,2014-07-15 21:14:38,"Related is a request to allow symmetric encryption of RPC messages -- I'd love to have rotation for both. I chatted with @armon a bit about this today...I have some ideas for how it could work, and for what caveats you'd want to put in your documentation about security guarantees vs. TLS. If you are using symmetric encryption for RPC messages, rotation is really something that you need.
",jefferai,armon
244,2014-07-29 01:15:20,"@carlivar It could be! Current it is 72 hours to reap any node (client or server). 
",armon,carlivar
240,2014-07-03 19:07:51,"@flupke This flag actually has to do with how the underlying gossip ""advertises"" it's address. Serf uses IP addresses only underneath the hood to avoid DNS interactions, so it must be an address.
",armon,flupke
233,2014-06-30 01:25:29,"@armon Thanks! I think these are the tests I wanted, so I'm now happy with this.

`wrapTLSclient` is mostly copied from http://golang.org/src/pkg/crypto/tls/handshake_client.go#L235 if that makes you feel any better about it.
",nelhage,armon
232,2014-07-17 13:49:58,"@XavM I think the ""overhang"" is enough of a visual cue for someone to try scrolling it. Fixed in master!
",pearkes,XavM
230,2014-06-29 01:52:17,"@abursavich Hmm that is a good point. I think you are right, the agent will deregister them when anti-entropy happens.
",armon,abursavich
228,2014-06-23 18:56:37,"@drnic AFAIK the behavior of linux resolver is to failover to next nameservers defined in /etc/resolv.conf only if the previous one is **timed out**. Once a nameserver responds to the query (either with failure or success), the resolver process is over.
In your case, if consul agent is available, secondary nameservers are always bypassed.
",salehe,drnic
228,2014-06-24 01:28:36,"This is odd indeed, since we didn't change the way DNS works at all between 0.2 and 0.3. The only changes were to optionally allow for TTL values or stale reads. Default behavior is unchanged. I agree with @salehe however, that the secondaries are only used if the first DNS server fails to respond. Relying on that behavior for DNS recursion is not the way to go.
",armon,salehe
226,2014-06-19 22:13:26,"@bryanl To clarify: yes, when you make the query, it is non-TLS to the agent. From the agent to the server, it is all encrypted (if you enable it). Because you're generally querying localhost (local agent), this _shouldnt_ be a problem.

If you want to query Consul from outside (non-localhost), you can always put a SSL terminator in front of it. 

TLS-based HTTP is something we might support in the future for completeness, but for the time being I think there are multiple methods that allow you to achieve the properties you want.
",mitchellh,bryanl
224,2014-07-16 17:57:11,"@tiwilliam Sorry, didn't realize this was waiting for so long! I don't think we want to modify the structs directly, since I think it is weird from a user perspective to put ""Node Foo"" in and get ""node foo"" out. I think it's better to preserve the case, but do insensitive lookups. 

My thinking so far has been to add maybe a `CaseInsensitive` bool to `MDBIndex`, and basically push this into the index level. This way the structs are not modified, only the indexes on top. Thoughts?
",armon,tiwilliam
224,2014-07-23 08:38:48,"Alright, so this is what I've done now:
- Lowercased incoming DNS query
- Added `CaseInsensitive` to `MDBIndex`
- Set Node and ServiceName indices to be case-insensitive
- Made the service tag filter case-insensitive

So my previous two test cases work as expected but I'm not sure how we should treat datacenters. @armon any thoughts?
",tiwilliam,armon
224,2014-07-23 13:42:23,"@tiwilliam Awesome! This is looking great. I think we take the simplest approach with the DC and just lower-case it in the configuration. We may need to add some additional hacks to prevent Consul from being confused if it joins ""Datacenter"" when it is in ""datacenter""
",armon,tiwilliam
208,2014-07-11 09:34:30,"@armon this is very interesting. are there any active work/design going on, or is it only an idea?
",wuub,armon
208,2014-07-11 17:53:29,"@wuub No active work on this yet, but its in the design phase you could say. Definitely something I'm keen to support!
",armon,wuub
208,2014-10-27 17:17:55,"@mfischer-zd As a note, this ticket will only affect DNS and not the KV store
",armon,mfischer-zd
208,2014-10-27 17:19:34,"@armon understood - this would affect how the Consul HTTP server (which would be accessible remotely) would be resolved.
",mfischer-zd,armon
208,2014-10-27 17:22:24,"No, I don't think so. It would affect the answers you got back from the
consul server you send DNS queries to.

On Mon, Oct 27, 2014, 1:19 PM Michael S. Fischer notifications@github.com
wrote:

> @armon https://github.com/armon understood - this would affect how the
> Consul HTTP server (which would be accessible remotely) would be resolved.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/208#issuecomment-60631558.
",andrewwatson,armon
208,2014-10-27 17:25:34,"@andrewwatson in my scenario I have two separate Consul clusters, one configured in the usual way (cluster A), and another that provides a replicated K/V store (cluster B, running on a dedicated set of hosts which does not include the clients).  Cluster A would be used by clients to perform DNS queries to resolve members of Cluster B.  

So really we're saying the same thing.
",mfischer-zd,andrewwatson
208,2015-04-08 15:54:03,"@mfischer-zd then you have to implement and configure some other piece of software to do this, when Consul already knows where things live.
",jefferai,mfischer-zd
208,2015-07-23 13:56:05,"Thanks @armon - what's the release timescale on those?
",StephenTallamy,armon
208,2015-07-23 20:39:54,"@StephenTallamy No hard deadlines. Consul 0.6 likely next month, and 0.7 in Q4.
",armon,StephenTallamy
206,2014-06-12 17:40:38,"@tarrant On thinking about this more, I think a few more pieces are clear:

1) There is increased Serf traffic because we now send the ""build"" tag with the version (e.g. 0.3rc). Since you are doing a rolling upgrade, all the clients are sending new ""alive"" messages to update the tags. This will cause some temporary congestion on a very large cluster like yours, since effective throughput is only about 40-80 updates/sec with Serf. This is not an issue, since Serf is designed to be eventually consistent.

2) The increased activity causes increased logging, and for some reason the syslog write is blocking.

3) Once the process locks up in the write, other nodes detect a failure (since the agent is not responding to ping messages).

So, I think the root issue here is the blocking syslog. The other pieces of this make sense.
",armon,tarrant
201,2014-07-31 20:17:58,"@sprin Yeah that would work fine. Likely the API will be modified to take a token which overrides any default one. So envconsul would probably take a `-token` parameter to pass through to the API.
",armon,sprin
201,2014-08-08 20:51:29,"@brugidou We are targeting KV for this initial version.
",armon,brugidou
197,2014-06-08 20:18:20,"@andrewwatson UI is not tested via Travis no worries. I will let @pearkes review and merge this since he is owning the UI.
",armon,andrewwatson
197,2014-06-11 13:00:37,"@andrewwatson Does the above make sense? Let me know if not and I can implement separately.
",pearkes,andrewwatson
189,2014-06-12 16:59:18,"@tiwilliam Awesome. I'd love to talk more about this while you are working on it. I think that largely we can do this all in the state store by just doing a ToLower on all the indexes and corresponding read values. I think most of the changes can actually be localized to the MDBTable
",armon,tiwilliam
187,2014-06-02 18:19:24,"@jfesler So far, those docs are just a guide since we haven't actually introduced any changes that require an upgrade. For example, in the upcoming 0.3 update, there is a protocol version change, but as you said, the clients can gracefully handle both versions so a site-wide upgrade is actually not necessary. I agree that in a large environment we will need to support a more incremental roll-out, which is something we are keeping in mind!
",armon,jfesler
187,2014-06-11 18:26:55,"@jfesler I've updated the docs on this process. By default we do not expect 2-phase upgrades to be necessary. I've clarified the ""Standard"" vs ""Backwards Incompatible"" upgrade. For now, it's a bridge we don't have to cross.
",armon,jfesler
184,2014-06-02 21:31:25,"Thanks @armon. I would be good to highlight that in the docs.
",c4milo,armon
181,2014-06-02 02:11:06,"@andrewwatson I think we will be rethinking bootstrap for 0.4 entirely. Most likely, instead we will have something like ""-bootstrap-servers 3"" which instead can be set on all servers, waiting until 3 servers are available to do the initial bootstrap. This should make it much simpler since they can come up in any order without a single special node.
",armon,andrewwatson
181,2014-06-02 11:42:50,"@armon Forgive my ignorance, but why is it necessary to specify N at all? Couldn't an election be held in respond to _any_ membership event in the absence of a leader provided a majority?

To elaborateâ€”a single node doesn't accept writes. When another node joins, they elect a leader. If a third node joins, no election is necessary. If the leader is partitioned from the rest of the nodes, the leader steps down and doesn't accept writes (holding the invariant above). The other side of the partition notices the leader has failed/left and those nodes hold an election since they have a quorum (N/2 + 1) based on the previous N = 3. 

Again, I'm no expert but something like this seems to eliminate the need to specify N explicitly. I also haven't thought through all the implications when a (set of) node(s) is ""flapping"". I bring up the idea mainly to spark some interesting dialogue and learn something. 

Cheers...

Edits: change 1 to majority, change majority to quorum
",christianromney,armon
181,2014-06-02 14:26:20,"@christianromney it could be that the algorithm isn't reliable with < 3 nodes.  @armon are you thinking of the  Bully Algorithm http://en.wikipedia.org/wiki/Bully_algorithm?  Seems like you'd have to have tight clock sync to prevent two bullies from electing themselves.
",andrewwatson,armon
181,2014-06-02 14:26:20,"@christianromney it could be that the algorithm isn't reliable with < 3 nodes.  @armon are you thinking of the  Bully Algorithm http://en.wikipedia.org/wiki/Bully_algorithm?  Seems like you'd have to have tight clock sync to prevent two bullies from electing themselves.
",andrewwatson,christianromney
181,2014-06-02 14:40:25,"@andrewwatson I'm re-reading [this](http://www.consul.io/docs/internals/consensus.html) (and the Raft paper) to educate myself further. Paragraph 6 on the Consensus Protocol page gives a good example of this situation when we have only 2 peers. Of course, the 2-peer ""problem"" is just a special case of the general even-numbered peer problem. 

Edit:
I did want to add that what I'm trying to advocate is not a particular algorithm since I obviously lack the requisite expertise to do so, but rather a means of forming a cluster that involves as little ""special case"" intervention as possible. Omitting the specification of N may not be possible (and I would like to understand why) but even @armon's suggested mechanics above are a big improvement over the current bootstrapping dance. The two problems of setup and consensus are orthogonal as even in the current bootstrap process there is a point in time when a 3-peer cluster becomes a 2-peer cluster (when the bootstrapped peer leaves) prior to the former leader re-joining.
",christianromney,armon
181,2014-06-02 14:40:25,"@andrewwatson I'm re-reading [this](http://www.consul.io/docs/internals/consensus.html) (and the Raft paper) to educate myself further. Paragraph 6 on the Consensus Protocol page gives a good example of this situation when we have only 2 peers. Of course, the 2-peer ""problem"" is just a special case of the general even-numbered peer problem. 

Edit:
I did want to add that what I'm trying to advocate is not a particular algorithm since I obviously lack the requisite expertise to do so, but rather a means of forming a cluster that involves as little ""special case"" intervention as possible. Omitting the specification of N may not be possible (and I would like to understand why) but even @armon's suggested mechanics above are a big improvement over the current bootstrapping dance. The two problems of setup and consensus are orthogonal as even in the current bootstrap process there is a point in time when a 3-peer cluster becomes a 2-peer cluster (when the bootstrapped peer leaves) prior to the former leader re-joining.
",christianromney,andrewwatson
181,2014-06-02 21:41:04,"@armon thanks for the explanationâ€”that makes perfect sense. 
",christianromney,armon
180,2014-06-02 02:08:24,"@evanphx thoughts?

I'm torn here, because if you disallow listing these, then you can get decent security through obscurity using sufficiently long random keys. However, from an administrative view point, you want some ability to inspect all the keys.
",armon,evanphx
180,2014-06-02 04:25:44,"In my opinion, no, there should not be an option for a normal user to list these entries. The idea is that they are hidden from enumeration and by using one that is random and long, you can store entries in consul that are undiscoverable by others.

@armon An administrator, though, should have a way to do that. Adding such an ability is tricky because there isn't currently an admin mode. Is a configured token that can be presented by an admin be enough?

This (as well as this evenings BBQ with @mitchellh) has made me realize perhaps we should put energy into a ACL/capabilities system instead, since dealing with all of the side effects of hidden entries may result in more changes that a proper ACL system.

@armon Love to chat about that on Tuesday!
",evanphx,armon
180,2014-06-02 21:36:24,"Just food for thought, I've said this privately before but I think its worth bringing up in public forum:

I think an ACL system begets hidden keys in a more correct way. As @tiwilliam said, and as I know everyone in this thread so far is aware, the hidden dot-prefixed files in Unix was never a point of security. Adding hidden keys would be easy if we had a flag or attributes bitmask internally on keys (UX issues aside). An ACL system would likely require some sort of attribute/flag system for marking permission bits, and it would be interesting there to perhaps discuss hidden keys. But it might turn out that the semantics of an ACL make it such that hidden keys are no longer necessary.

Either way, I think discussing ACLs is the proper discussion.
",mitchellh,tiwilliam
180,2014-06-02 22:31:36,"@tarcieri Can you please elaborate (or provide another link that summerizes the paper) on the Zebra Copy problem?
Why is synchronization a problem? Because it's eventually consistent (I'm just guessing)?
",thedrow,tarcieri
180,2014-06-02 22:35:02,"@thedrow here's a shorter summary of the Zebra Copy problem:

http://wiki.erights.org/mediawiki/index.php/Zebra_Copy

The problem boils down to HP having to synchronize their current database of active employees and roles with Zebra Copy's system. This is a problem because it's a pain: every time HP adds or terminates an employee, or an employee changes roles, they have to update Zebra Copy's database as well.

Instead, HP can create a short-lived capability (or delegate authority through a proxy) allowing an employee to access Zebra Copy's services. Then Zebra Copy doesn't have to care whether or not you're an HP employee, they merely verify you have a valid capability from HP.
",tarcieri,thedrow
180,2014-06-04 00:51:47,"Had a chance to talk with @evanphx today about this, and we've hashed out what we feel to be a solid approach. We are moving design discussion to this doc: https://docs.google.com/document/d/1BbBMpuJMoO19ZoJNigoj68Z-OA6aEFEmVC5oZquwagw/edit?usp=sharing
",armon,evanphx
177,2014-05-29 19:10:59,"@webcoyote The download for 0.2.1 should be fixed now! Thanks for reporting!
",armon,webcoyote
172,2014-12-13 06:18:43,"Closed by @amalaviy via #524 
",armon,amalaviy
169,2014-08-04 16:48:31,"@blalor It should have broken the DNS parser to have a DC like that. Were you using the DNS interface at all? 

We must have mistakenly failed to put it in the change log.
",armon,blalor
166,2014-05-22 05:48:50,"@bscott can you show us what the config looks like? Specifying `ui` as the `ui_dir` seems to work as expected, as well as specifying an absolute path.
",ryanuber,bscott
166,2014-05-22 17:45:56,"@bscott When you hit the index page (http://localhost:8500/) what do you get? Does it say ""Consul Agent"" or do a redirect?

Also unrelated, but you will run into issues if you datacenter has periods in it. It makes the DNS parsing ambiguous. Instead, you might try making the datacenter ""us-west-1"", and if you want, set the `domain` to ""compute.internal"".
",armon,bscott
166,2014-05-22 20:25:22,"@armon The node isn't even listening on port 8500
",bscott,armon
166,2014-05-23 00:33:59,"@armon Yes, the agent is starting and joining the cluster.
",bscott,armon
166,2014-05-29 03:47:36,"@webcoyote Can you verify if this is happening with the latest build? Might be the same issue of running the older Consul build.
",armon,webcoyote
166,2014-05-29 16:14:45,"@armon: The UI >does< work on Windows when I compiled the latest version from source (re: 
https://github.com/hashicorp/consul/issues/177#issuecomment-44442962).
",webcoyote,armon
166,2015-11-23 17:52:58,"@slackpad I mean this:



I also get a 200 and the same response on the body of the client if I do not specify `ui_dir`. However, as soon as I enable it I get a 301 on both the root and `/ui` endpoints. Why does root `/` redirect to `/ui`, is that intended or is that a side-effect on some misconfiguration on my part?
",calvn,slackpad
166,2015-11-23 21:22:33,"@slackpad @hridyeshpant Got it working by adding this to my `config.json`:



As explained in #599 the client binds the HTTP address to localhost by default so within the client you're able to curl the `/ui` endpoint, but you'll just get `connection refused` if you try to resolve it from the outside. 

I'd suggest to update the docs on the Web-UI page so that it explicitly states that the default config only enables the UI within `localhost`.
",calvn,hridyeshpant
166,2015-11-23 21:22:33,"@slackpad @hridyeshpant Got it working by adding this to my `config.json`:



As explained in #599 the client binds the HTTP address to localhost by default so within the client you're able to curl the `/ui` endpoint, but you'll just get `connection refused` if you try to resolve it from the outside. 

I'd suggest to update the docs on the Web-UI page so that it explicitly states that the default config only enables the UI within `localhost`.
",calvn,slackpad
166,2015-12-17 15:16:52,"@hridyeshpant Can you check the port mapping for that container with `docker ps`? Perhaps port 8500 is mapped to some other port on the host. https://ewegithub.sb.karmalab.net/EWE/docker/tree/master/stratus/consul/server is not accessible for me.
",calvn,hridyeshpant
166,2016-07-19 16:22:07,"@gvenka008c that's the correct behavior - Consul is trying to redirect you to /ui/ which is the location of the web UI. If you add a `-L` to your `curl` command it will follow the redirect.
",slackpad,gvenka008c
166,2016-07-19 17:29:35,"@slackpad Thanks. When I try to hit the URL http://xx.xxx.xxx.xx:8500/ui/ from the browser, it says ""Failed to Open Page"". I have opened the ports on the server but still the same problem.


",gvenka008c,slackpad
166,2016-07-19 17:47:39,"@slackpad I started consul with -client argument and that fixed the issues.


",gvenka008c,slackpad
165,2014-06-06 15:40:38,"@tarrant Agreed, I kind of got it in there as a stub for now, still working out tags for the 0.3 release

@andrewwatson Would be great to see a PR if you're able!
",pearkes,andrewwatson
165,2014-06-06 15:40:38,"@tarrant Agreed, I kind of got it in there as a stub for now, still working out tags for the 0.3 release

@andrewwatson Would be great to see a PR if you're able!
",pearkes,tarrant
164,2014-05-22 17:41:08,"@drnic For any of the hosts that are returning that tag value, can you run: `curl localhost:8500/v1/agent/services`?

I've grepped the code and don't see that string anywhere on our side
",armon,drnic
163,2014-10-03 08:49:07,"@rawtaz I didn't get to it. It's on my open source back log. Ping me in a month.
",thedrow,rawtaz
159,2014-05-22 05:09:49,"@jim80net not sure if it is related or not, but #168 fixes a build issue with `command/agent`.
",ryanuber,jim80net
159,2014-05-22 17:46:49,"@jim80net There was a missing file that @ryanuber fixed. Could you try again? I think that the cgo support for SmartOS is limited, which may prevent Consul from compiling.
",armon,jim80net
159,2014-05-22 17:46:49,"@jim80net There was a missing file that @ryanuber fixed. Could you try again? I think that the cgo support for SmartOS is limited, which may prevent Consul from compiling.
",armon,ryanuber
159,2015-11-29 07:20:04,"Hi @cmacrae if you are building the latest master then there's no longer a CGO dependency, but it looks like there's no Solaris support for those terminal functions (see https://github.com/golang/go/issues/13085, which links to several issues). I think at the current time you'd have to do some surgery on those dependencies in order to build on this platform. For the CLI dependency you could probably remove the `IsTerminal` branch of that `if` in ui.go since Consul doesn't use that. For Docker I'm less sure, though you could take out Docker check support from Consul's command/agent/check.go (and unit test) since that's the only place it is used. Sorry this is ugly at the moment, but it looks like things are still being sorted out on the Go side.
",slackpad,cmacrae
159,2015-11-29 12:22:27,"Thanks @slackpad! Managed to get it to build with your tips :+1:  
I'll break this out into an optional step in my Ansible role using a patch from the changes I made to get it to build.  

I'll likely be doing automated builds, and host a zipped archive for the amd64 binary for Solaris (more specifically, illumos/SmartOS) systems on my personal domain: http://cmacr.ae/consul/solaris_amd64.zip
Mostly for my own convenience, but, others can grab it too, if they so wish :)

EDIT: Chucked a quick page together for builds: http://cmacr.ae/consul/
",cmacrae,slackpad
159,2015-12-05 17:14:53,"@cmacrae thanks for this, very helpful.

I would like to get Consul [into pkgsrc](https://pkgsrc.joyent.com/docs/creating/).  Is there anyone here who can help fasttrack the process?
",doublerebel,cmacrae
159,2015-12-06 23:59:48,"That'd be great! @jperkin would be the best person to talk to regarding
this. But I'm not sure how ""ethical"" the patches are that I'm using.

On Sat, 5 Dec 2015 at 17:15, Charles Phillips notifications@github.com
wrote:

> @cmacrae https://github.com/cmacrae thanks for this, very helpful.
> 
> I would like to get Consul into pkgsrc
> https://pkgsrc.joyent.com/docs/creating/, I see hashicorp/vault
> https://github.com/hashicorp/vault is already present
> http://ftp.netbsd.org/pub/pkgsrc/current/pkgsrc/devel/hs-vault/README.html.
> Is there anyone here who can help fasttrack the process?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/159#issuecomment-162224344.
",cmacrae,cmacrae
159,2015-12-07 03:49:49,"I would also be interested by a package for smartos.
By the way @cmacrae I gave a try to your binary and it works seamlessly on 15.3.0.
Thank you for sharing.
",benjamin-bergia,cmacrae
159,2015-12-07 11:24:05,"No problem @benjamin-bergia :)
I could make a pkgsrc port for it, and submit it for review. But, like I say, I'm not sure how reasonable the patches are.
",cmacrae,benjamin-bergia
159,2015-12-10 17:49:54,"@dekobon I doubt it, SmartOS is not an officially supported platform for Consul
",cmacrae,dekobon
159,2015-12-10 18:06:36,"@cmacrae I've spoken to my contact at Joyent, we may be able to get Consul in sooner than later.
",doublerebel,cmacrae
159,2015-12-10 18:13:25,"@doublerebel Awesome news!
",cmacrae,doublerebel
159,2015-12-10 18:36:52,"@cmacrae Who's your contact at Joyent? I'm also with Joyent.
",dekobon,cmacrae
159,2015-12-10 18:37:50,"@doublerebel - sorry the previous comment was for you.
",dekobon,doublerebel
159,2015-12-10 19:12:12,"@dekobon Oh excellent!  Robby Andrews.  Mentioned that some of you were interested in Consul inclusion, so he was right :)
",doublerebel,dekobon
159,2015-12-10 23:32:47,"@doublerebel have you hung out on #consul on IRC yet?
",Chewyrobbo,doublerebel
159,2015-12-10 23:48:58,"@Chewyrobbo no, just #smartos and #joyent.  Just joined #consul now. Thanks!
",doublerebel,Chewyrobbo
159,2015-12-11 09:32:31,"@cmacrae Can you share the patches, any way you're comfortable with? I'm with Joyent and working on pkgsrc.
",mamash,cmacrae
159,2015-12-11 09:34:32,"@mamash Sure :) Just on my way into the office at the moment, I'll share them once I'm in
",cmacrae,mamash
159,2015-12-11 10:44:16,"@mamash So, patches are necessary to both [mitchellh/cli](https://github.com/mitchellh/cli) & [hashicorp/consul](https://github.com/hashicorp/consul).  

Here are the patch files, pretty much just stripping stuff out:  
- [mitchellh_cli_solaris.patch](https://gist.github.com/cmacrae/1343683fd0be35e733dd)
- [hashicorp_consul_solaris.patch](https://gist.github.com/cmacrae/ddcadaf8517b929af84b)
",cmacrae,mamash
159,2015-12-11 10:54:28,"@cmacrae looks like your patch to cli will not ask for input via stdin anymore if `secret=true`. You removed the bit that does read the input without replacing it.
",MerlinDMC,cmacrae
159,2015-12-11 10:57:38,"@MerlinDMC Thanks for pointing this out - these patches were chucked together quickly one evening after work, and I haven't had time to review them properly. Given the fact that this now seems to be moving toward to an official pkgsrc port at Joyent, I trust that those involved will address any issues posed by my hasty patching ;)
",cmacrae,MerlinDMC
159,2015-12-11 16:37:04,"@MerlinDMC thanks for this, I'm able to get hashicorp/vault almost built as well.  Looking now at patching both vault and consul to use [bgentry/speakeasy](https://github.com/bgentry/speakeasy) for cross-platform getpasswd support.
",doublerebel,MerlinDMC
159,2015-12-15 19:48:18,"@mamash that's a great start, thanks for the help.  I'm also working on vault and consul-template, which have similar and related dependencies.  Is there anything we can do about the projects' structure to make the builds simpler?  When compiled, the end result is just one binary that needs one config file.
",doublerebel,mamash
159,2016-01-06 10:14:32,"Awesome! Thanks @slackpad & @jen20 :+1: 
",cmacrae,slackpad
159,2016-01-07 10:55:30,"Excellent, thanks @mamash!
",cmacrae,mamash
155,2014-05-16 07:30:01,"@armon : Imagine we have a same service running on multiple servers, but that we segregate different pool of users to a specific subset of those hosts for whatever reason (performance, multitenancy, etc ...)

We can use service tags to automate reverse proxy's upstream lists, but when we switch one server from one pool to an other, we have to deploy a new service.json file on each host and then SIGHUP consul

It would come in handy to allow this tag update thru HTTP and RPC, but we would then need to persist this change upon the next server restart/failure to make sure it gets back to the desired upstream pool and not to the one that it was first deployed with

EDIT: Of course it should work with node tags as well #154 
",XavM,armon
155,2014-05-16 20:10:48,"@XavM Got it. Makes sense to me.
@hunter Not yet, but it seems like something we need to address.
",armon,hunter
155,2014-05-16 20:10:48,"@XavM Got it. Makes sense to me.
@hunter Not yet, but it seems like something we need to address.
",armon,XavM
155,2015-02-18 06:36:36,"@armon: Thank you so much !!
",XavM,armon
155,2015-02-18 18:44:44,"Yes thanks @armon !
",darron,armon
154,2014-05-16 20:11:16,"@XavM Again, makes sense to me. Thanks!
",armon,XavM
154,2015-02-22 20:38:33,"@dellis23 Consul 0.5 has built-in support for node-level and service-level maintenance modes. When maintenance mode is enabled, the node or service will be automatically excluded in all queries for nodes/services with passing health checks. Check out the [`maint` command](https://consul.io/docs/commands/maint.html) and [http endpoints](https://consul.io/docs/agent/http/agent.html) to get a feel for how it works!
",ryanuber,dellis23
154,2015-02-22 20:45:03,"I agree with @armon, having node-level tags seems reasonably useful. I think this would provide enough functionality to add ""facts"" about nodes by use of tags without needing to support specific fact generation systems like Ohai, facter, etc.
",ryanuber,armon
154,2015-04-16 16:40:39,"Hi @sitano,

> What do you think if it will be implemented by someone else? (or you would like to impl it yourself)

We are always open to implementations from the community! We should agree on the design and functionality first, though, and I don't think we're quite there yet.

> Actually, i think we can consider any node have a tag if its service have a tag.

I think we will run into some odd collision cases by going that route. This would also still require a service to be registered before any tag system would be available, which would promote registering a service just to add tags to the node. While it would work, the UX doesn't quite feel right to me.

> its not very good i have to ask each DataCenter the same query just to obtain any info across the whole world. It will be good to have something like ?dc=*.

We added some plumbing not long ago that would make this type of query possible internally, but honestly from an API perspective I think that the current design works well and lends itself easily to obtaining global information across datacenters. If you have a more specific use case, please open a separate issue and we can discuss it there.

> there is no way to ask for a nodes list in the DC with full info.

I _think_ the API's were designed this way to avoid absolutely massive responses. Consider a case where there are hundreds of nodes in the same datacenter. Returning each node with its full list of services and tags inline will be a very large response, and contain lots of duplicated information. As they are, the API's are composable so that they can help clients build any kind of response they need. 

Since the original issue here is about adding tags support to nodes, please open separate issues if you would like to discuss any of the unrelated stuff above in more detail.
",ryanuber,sitano
154,2015-06-02 06:44:49,"+1 for `Node Tags`

@sitano can you share it?
",ybogdanov,sitano
154,2015-06-02 07:25:15,"@ybogdanov actually i am trying to discuss it with my employer. it turned out quite useful thing for us.
",sitano,ybogdanov
154,2015-06-02 07:37:10,"@sitano as a temporary solution, I'm thinking of something like `tail -f /dev/null` service on every node, to which tags can be assigned. And this will be a stub `node tags` service, by which you can easily query nodes by tags. Will it work, or am I missing something?
",ybogdanov,sitano
154,2015-06-03 06:51:18,"@ybogdanov , it is possible. it was the way i was thinking about one of workarounds for it. but the api which do selects for you is very restricted. my advice - check in advance whether it fits your future usage patterns. we were filtering nodes based on tags / services over 10 datacenters, and it took a lot of time (actually we end up making a lot of http requests to each dc master / per node). So, then i did write my sql cache for consul.
",sitano,ybogdanov
154,2015-07-07 16:12:05,"@ssenaria Likely this would not be until a V2 API which would allow us to change various representations and rethink the APIs a bit. People instead either just create a virtual ""service"" on every node and attach tags to that or create entries in the KV store.
",armon,ssenaria
154,2016-03-11 02:32:17,"Hi @plorenz I don't think we'd implement this using Serf tags. Consul makes use of them internally for some operations, but there are limits to the number of tags, etc. that would make this a tricky feature to use if we exposed Serf tags. I think these tags would be Consul-level and managed between the Consul agent and the catalog.
",slackpad,plorenz
154,2016-10-04 18:05:32,"@yosefy We ended up using Serf but now have a need to use Consul. I can't abandon Serf for Consul and I don't want to have to run both!
",ssenaria,yosefy
154,2017-01-05 07:29:34,"I didn't quite follow the /dev/null approach. Does this refer to registering the service with a dummy check and tag the service to our needs? In this case I am assuming the service names can be the same.

Particularly interested in the behavior, where lets say 

Service A was tagged with Tag1, Tag2 & Tag3 in Node1
Service A was tagged with Tag 2, Tag3, Tag4 in Node 2

Will querying for Service A and Tag 1 yield Node 1, Service A and Tag 2 return Node 1 & 2?

Looking to try this out today but @ybogdanov and @scalp42 if you are aware of the behavior please let me know.
",gamefundas,ybogdanov
154,2017-01-05 07:29:34,"I didn't quite follow the /dev/null approach. Does this refer to registering the service with a dummy check and tag the service to our needs? In this case I am assuming the service names can be the same.

Particularly interested in the behavior, where lets say 

Service A was tagged with Tag1, Tag2 & Tag3 in Node1
Service A was tagged with Tag 2, Tag3, Tag4 in Node 2

Will querying for Service A and Tag 1 yield Node 1, Service A and Tag 2 return Node 1 & 2?

Looking to try this out today but @ybogdanov and @scalp42 if you are aware of the behavior please let me know.
",gamefundas,scalp42
148,2014-06-10 17:44:45,"@davidfeldi Currently it is fixed by providing the `-bind` configuration. Its an issue when not provided
",armon,davidfeldi
148,2014-06-11 10:52:52,"@armon Thanks!
",davidfeldi,armon
141,2014-05-10 02:20:23,"@mbrevoort I've pushed https://github.com/hashicorp/raft/commit/5800ad50556257529865e32d896ee0d55876bf10 which should resolve the deadlock issue here. Also as a safety 686fac0 changes our interaction with Raft to limit how long we wait. This will prevent writes from hanging forever if Raft is ever extremely busy or deadlocked (which would be a bug).
",armon,mbrevoort
137,2014-05-08 20:43:59,"@thedrow Circus has a completely different use case than this. The Serf ""suspect"" messages can be used to detect network partitions, not to check for a process flapping.
",armon,thedrow
136,2014-05-16 20:52:43,"@tiwilliam Awesome work. Thanks so much, it'll be great to have the tests be more reliable.
",armon,tiwilliam
136,2014-05-16 22:03:46,"@tiwilliam Actually, I'm going to merge this in now! We can port the tests in master!
",armon,tiwilliam
134,2014-05-22 17:35:36,"And to perhaps address the original issue, we've been bouncing ideas for long-running processes to avoid the fork/exec cost for thousands of services. Is this what you were thinking @armon?
",mitchellh,armon
131,2015-04-07 18:22:29,"@discordianfish Which numbers are you referring to? We switched to a solution where we wait for the leader until it is elected using polling and then have a timeout for failure. That replaced using estimated sleeps in tests.
",tiwilliam,discordianfish
130,2014-05-20 07:36:10,"@bscott Can we have a look at the PR?
",thedrow,bscott
130,2014-05-20 16:00:46,"@thedrow Sure, actually was working on it this morning, should be there shortly. 
",bscott,thedrow
126,2016-01-15 13:18:22,"@armon -- I know this is closed but I stumbled over this as well. And I think there could be a better solution: **Two** domains could be specified, one for node's one for service's. Default would just prefix a singular domain with `.node` and `.service` as before. 

This would vastly simplify non-greenfield integrations -- especially if a _new_ environment is connected to the _legacy_ (seen that a few times) world and naming for nodes _connected_ needs to follow some archaic internal DNS-guideline.
",LeDominik,armon
126,2016-01-22 17:52:02,"Hi @LeDominik that's an interesting approach - I'll kick this back open so we can give that some thought.
",slackpad,LeDominik
126,2016-03-29 07:50:06,"@matthewvalimaki Wow, that makes it even _more_ complicated. We've solved that quite easily because we have a wildcard SSL certificate for `*.service.datacenter.domain` per datacenter and that's all that _our_ services use per convention. However we'd of course need another set of wildcard-certificates if we want to address the nodes...
",LeDominik,matthewvalimaki
126,2016-03-29 08:03:34,"@LeDominik sorry, do you mean regexp makes it more complicated? Sure it is easy to buy wildcards but not cheap and not practical if tags are used.
",matthewvalimaki,LeDominik
126,2016-03-30 07:55:41,"@matthewvalimaki no, I just wanted to point out that the current pattern is _very_ straightforward, albeit quite rigid. Maybe a configurable regex is the right idea because it truly becomes totally impractical with tags + SSL, we're currently not using them, but they are tempting. 

As our services are only reachable internally (external exposure through reverse proxy / firewalls / api manager) we just generate the certificates internally so no cost associated. But getting a wildcard _per_ service (to support tags) is truly a lot of work.
",LeDominik,matthewvalimaki
126,2016-03-31 14:21:33,"@LeDominik thank you for the clarifications.

>  But getting a wildcard per service (to support tags) is truly a lot of work.

No doubt. You should be able to solve this partially with wildcard SNI.

For Consul developers it might be easier to offer hard-coded option where same FQDN structure is kept but with dashes instead of dots.
",matthewvalimaki,LeDominik
126,2016-04-22 16:10:13,"I vote for a little bit flexible dns discovery description. I don't think it's a good idea to pass on (at least for me) important feature, because someone _can_ misconfigure it.

My use case is to provide DNS for node/host discovery in docker containers itself. Service discovery in a swarm cluster and with overlay network works perfectly fine.

Because I already use Consul, it would be nice to get rid of dnsmasq or like and use just Consul. Sure, there some limitations, but they don't matter much. A and SRV entries are enough for microservices.

I think it would be nice to provide something like regexp (as @matthewvalimaki already says) with parameter `-discovery-service-regexp`, which defaults to something like



for services ([click on green GO button](http://fiddle.re/f69mna), to play with it) and similar for nodes with `-discovery-node-regexp`.

Maybe it should be possible to define an order, if there is an ambiguity, like -discovery-order=""node,service,file:/etc/hosts,dns:8.8.8.8"". Just an example.

Domain should be also optional.

@XavM would be able [just define](http://fiddle.re/y5xgna):



or better:



to get desired results.

It's any chance to get it? Unfortunately, go isn't language in which I can code qualified pull requests...
",Bessonov,matthewvalimaki
126,2016-04-22 16:10:13,"I vote for a little bit flexible dns discovery description. I don't think it's a good idea to pass on (at least for me) important feature, because someone _can_ misconfigure it.

My use case is to provide DNS for node/host discovery in docker containers itself. Service discovery in a swarm cluster and with overlay network works perfectly fine.

Because I already use Consul, it would be nice to get rid of dnsmasq or like and use just Consul. Sure, there some limitations, but they don't matter much. A and SRV entries are enough for microservices.

I think it would be nice to provide something like regexp (as @matthewvalimaki already says) with parameter `-discovery-service-regexp`, which defaults to something like



for services ([click on green GO button](http://fiddle.re/f69mna), to play with it) and similar for nodes with `-discovery-node-regexp`.

Maybe it should be possible to define an order, if there is an ambiguity, like -discovery-order=""node,service,file:/etc/hosts,dns:8.8.8.8"". Just an example.

Domain should be also optional.

@XavM would be able [just define](http://fiddle.re/y5xgna):



or better:



to get desired results.

It's any chance to get it? Unfortunately, go isn't language in which I can code qualified pull requests...
",Bessonov,XavM
126,2016-06-02 19:43:21,"@armon @slackpad 
Before I try to dig into the code, would you like to accept pull requests? May be I have some time in two or three month.

EDIT: my proposal fixes #215. It's not really broken, but it gives @darron ability to work around his problem.
",Bessonov,armon
126,2016-06-02 19:43:21,"@armon @slackpad 
Before I try to dig into the code, would you like to accept pull requests? May be I have some time in two or three month.

EDIT: my proposal fixes #215. It's not really broken, but it gives @darron ability to work around his problem.
",Bessonov,slackpad
126,2016-08-10 23:49:57,"@Bessonov have you taken a look at https://www.consul.io/docs/agent/http/query.html#templates? This might help get you some of what you need already.
",slackpad,Bessonov
126,2016-08-14 20:42:46,"@slackpad I don't used it before, but I can give it a try. Hopefully this year. Thank you!
",Bessonov,slackpad
124,2014-05-05 01:09:07,"@tiwilliam The ""folder"" view is just imposed by the UI. There is no actual folder structure. So if the only key is ""1/2/3/4"" and that key is removed, then those ""folders"" also are removed. Does that make sense?
",armon,tiwilliam
124,2014-05-05 07:57:13,"@armon Thanks for explaining! This should now work as expected and redirect to nearest existing parent on delete or pop back to root if needed.
",tiwilliam,armon
121,2014-06-06 23:04:40,"I think this is an abstraction leakage the client should not worry about. If I'm correct, @blalor you've found a way to not need this. Closing.
",armon,blalor
121,2014-06-07 03:45:42,"Not really, I just ignored the problem for now. The leader election discussed in the now-missing Consul docs look good, however. I'm hoping that's in. 0.3! :-)

## 

Brian Lalor
blalor@bravo5.org

> On Jun 6, 2014, at 7:04 PM, Armon Dadgar notifications@github.com wrote:
> 
> I think this is an abstraction leakage the client should not worry about. If I'm correct, @blalor you've found a way to not need this. Closing.
> 
> â€”
> Reply to this email directly or view it on GitHub.
",blalor,blalor
121,2014-06-07 04:28:46,"@blalor If its in master ,it'll be in 0.3. :)
",mitchellh,blalor
118,2014-05-04 20:22:00,"@deadjoe You need to update the upstream dependencies. There was an API change in the upstream hashicorp/raft repository.
",armon,deadjoe
112,2014-05-03 16:23:58,"We're planning on implementing an event system into Consul in the near, but not short, term. 

@josephholsten It will be turing complete: it will just be shell scripts that are executed that are under contract to finish within a timely manner. If they need to spend a longer time, they should detach off.
",mitchellh,josephholsten
111,2014-05-02 22:30:15,"@bscott Should be fine under nginx assuming the API calls under it are being forwarded. Consul just serves up static files for the UI
",armon,bscott
111,2014-05-02 22:30:56,"@armon Thanks!, I was just reading the code in consul and figured that out. 
",bscott,armon
110,2014-05-04 20:30:14,"@blalor: Not sure i get your question right; What i meant : 

Upon start up, the consul agent queries the DNS (the one you have specified with the new suggested configuration key, or the one set in resolv.conf) for the SRV record ""consul.service.consul"", then, the DNS answers the list of available servers (including ips and associated ports) where you can join an existing consul cluster

The DNS you query could be an existing consul cluster, or your main DNS server (bind, dnsmasq, etc ...) that you have previously setup to forward queries to Consul as appropriate (when zone is ""consul"")

My point was : Consul is designed for service discovery; Why not use consul to discover existing and healthy consul cluster members

PS : of course, the SRV lookup should use the ""domain"" configuration key when specified, and only fall back to the ""consul"" default domain when missing
",XavM,blalor
110,2014-05-04 20:40:08,"@XavM I agree, but I think there is no special integration required. If the node is using Consul for DNS already, then ""consul join consul.service.consul"" should just work!
",armon,XavM
110,2014-05-04 20:57:06,"@armon: Thank you for your answer

I think i must have missed your point (sorry about that)

Regarding the consul join command with a DNS host name, you have to know which host is up, is running consul (and on which port) and is member in the desired cluster, meaning you still have to maintain a hard-coded list of hosts:ports to join on startup

A rejoin using old cached member information could fail due to a stale cache (Depending on how long the node has been down, the topology could have change)

Any way, thank you for this promising solution; I am sure you will make the best choice

---

Edit :
@armon: After I have seen your previous response, I tried to join using ""consul join consul.service.consul"" and it works brilliantly !! (The doc does not mention it)
",XavM,armon
110,2014-05-04 21:37:39,"@blalor This actually does not solve the chicken and egg issue. This solution assumes that the DNS servers exist at a well known address to begin with (otherwise the SRV record would fail with no DNS server). At some point, there must be a well known address, that may be Consul or it may be DNS.

My suggestion is to because this is unescapable, simply run Consul on the DNS server. You need a well known address for at least one of them, this way it is 2 birds with one stone. Doing this allows you do use DNS to join the cluster without making any changes to Consul.

If you have 3 well known DNS addresses, then the DNS lookup for ""consul.service.consul"" will work unless all the DNS nodes are down, which is unlikely. Hope that helps.
",armon,blalor
110,2014-05-04 21:45:07,"@blalor Can you have a cron job on the consul servers that writes their IP to Route53 every few minutes? This way you can just join a well known address that is relatively up to date. It is only the initial join that is an issue, since moving forward we will be adding the re-join support.
",armon,blalor
110,2014-05-04 22:44:41,"@blalor Why do you need the leader node specifically? You only need to do a join with any node, so it doesn't need to be the leader. It is totally fine if `server-a` overwrites the record of `server-b`, since a join to any of them will succeed. 

Trying to ensure only a single write from the cluster leader only seems like an optimization that isn't necessary due to the nature of the gossip and the join. If you just have a cron on the servers, allowing an override, then even when you decommission, one of the remaining live nodes will update the record by overwriting it.
",armon,blalor
110,2014-06-18 17:32:44,"@dennybaa That is embarrassing! Fixed in a05e1ae.
",armon,dennybaa
108,2014-05-02 22:26:31,"@armon Thanks, I'll give it a try now
",bscott,armon
104,2014-05-02 03:23:26,"@blalor This is valid as well, opening an issue.
",mitchellh,blalor
104,2014-05-12 13:25:54,"I think @mitchellh's note about daemonization is also valid about logging. It's up to the service manager to handle log output of a process on it's standard output.
",salehe,mitchellh
104,2016-05-11 07:54:37,"Hi, I was wondering if there is any easy way to know when consul has finished bootstrapping. I explain my case:

I have a systemd service that launches consul at boot. I have other services that dependes of consul, so they should start when consul has finished starting. The problem is that with systemd files, the service is considered active at the moment the command is executed. (this happends when de _Type_ is set to default, but I didn't find any other Type useful to this case). So the next services start when consul hasn't finished bootstraping, resulting on several problems. 

I thought that maybe it was a good idea to modify consul and set somethig like docker has to notify when it has finished bootstraping: [docker-systemd-notify](https://github.com/docker/docker/blob/master/cmd/dockerd/daemon_linux.go), but I guess that this contradicts what @mitchellh said of leaving daemonization to a higher level.

So I thought about wrapping the consul service with something that checks that consul has finished and make the nofity. In this case, my initial idea was to make request to `/v1/status/leader` every second and when the request's reponse was ok, then notify. But I don't know if there's a better way of doing this.

Thanks!
",jorgemarey,mitchellh
104,2016-11-28 21:07:04,"@jorgemarey Where did you end up with your startup issues? I've been debugging a dependency issue for about an hour that sounds like yours. I have a Systemd Unit for consul-template:



It depends on the local Consul agent (managed via SystemD with consul-agent.service). The problem is, as you said, that the consul-template service starts before the Consul agent has finished bootstrapping, so I get a failed request from consul-template, which causes downstream issues for the service that consul-template is configured to restart on template renders.

",jniesen,jorgemarey
104,2016-11-29 19:01:49,"Hi @jniesen! I didn't find a ""nice"" way to do this. The choices that you have (from what I could see) are: made the service that will use consul (in this case) use some kind of retries or make some service that, based on some polling, waits for consul to be ready and then make consul-template wait on that service.",jorgemarey,jniesen
104,2016-11-30 01:52:20,"@jorgemarey thanks for the input. I went with your suggestion.





The consul-template.service now depends on consul-ready.service and things are working nicely.",jniesen,jorgemarey
96,2014-04-30 19:36:05,"@gmr That was also an issue with 0.1. Fix is in master.
",armon,gmr
95,2014-04-30 19:03:24,"@gmr Thanks for the report. This is a 0.1, and is fixed in master. Fix will be in 0.2 going out tomorrow.
",armon,gmr
89,2014-04-30 12:25:16,"Hey @da-z! The value is base64 encoded (see [KV section](http://www.consul.io/docs/agent/http.html#toc_2)) so this is intentional. Thanks!
",pearkes,da-z
86,2014-04-29 05:22:25,"@tarrant Thanks for reporting. It is mostly cosmetic, but this is an issue with Serf. Nothing to worry about since the behavior will be correct, but shouldn't be happening nonetheless. I'll get back to you when I know more.
",armon,tarrant
86,2014-04-29 19:31:12,"@tarrant This should be fixed by https://github.com/hashicorp/memberlist/commit/2595b7e29e0fb25891b9f131151020aa5ac6ba5a. Turns out to be caused by a subtle issue around metadata changes when there is no graceful leave and before the failure detector notices the node has failed. Let me know if you are able to reproduce this issue with the fix.
",armon,tarrant
84,2014-05-04 20:46:45,"@twirrim I agree, which is why default the 0 TTL. Mostly, for performance reasons we need to allow stale DNS reads, and to allow setting a TTL. If we set some TTL, then an upstream system, like dnsmasq / bind can do the caching.
",armon,twirrim
84,2014-05-05 01:44:25,"@twirrim dnsmasq can not cache a record if the original TTL is 0. As @armon mentioned, having the TTL 0 by default but making it configurable makes sense.

This feature is necessary for my applications which already have a local dnsmasq running to reduce read latency.
",ijin,armon
84,2014-05-05 01:44:25,"@twirrim dnsmasq can not cache a record if the original TTL is 0. As @armon mentioned, having the TTL 0 by default but making it configurable makes sense.

This feature is necessary for my applications which already have a local dnsmasq running to reduce read latency.
",ijin,twirrim
83,2014-04-28 18:18:32,"@mmikulicic Haha I can see that may cause some issues... I think probably a 1KB limit is sane. Anything beyond that is probably an abuse of the note. (I mean maybe up to like 2-4K is reasonable). We should just use a circular buffer, and capture the last LIMIT bytes.
",armon,mmikulicic
82,2014-04-28 18:23:21,"@deadjoe There are some weird case-sensitivity issues lurking in the API parser. There have been some PR's to resolve some of them. Can you try with the latest build from master to see if this issue persists?
",armon,deadjoe
82,2014-04-29 00:13:30,"@deadjoe Ah nevermind! I just realize you have an extra layer of nesting. The ""Service"" object should actually be the top level object. That nested format is only used for the config files so that the parser can disambiguate. The API does not use that top level object.
",armon,deadjoe
82,2014-04-29 03:44:43,"Thanks a lot.
2014å¹´4æœˆ29æ—¥ ä¸Šåˆ8:13äºŽ ""Armon Dadgar"" notifications@github.comå†™é“ï¼š

> @deadjoe https://github.com/deadjoe Ah nevermind! I just realize you
> have an extra layer of nesting. The ""Service"" object should actually be the
> top level object. That nested format is only used for the config files so
> that the parser can disambiguate. The API does not use that top level
> object.
> 
> â€”
> Reply to this email directly or view it on GitHubhttps://github.com/hashicorp/consul/issues/82#issuecomment-41629683
> .
",deadjoe,deadjoe
82,2014-04-30 04:41:34,"Thanks a lot. It works now.
 2014å¹´4æœˆ29æ—¥ ä¸Šåˆ8:13äºŽ ""Armon Dadgar"" notifications@github.comå†™é“ï¼š

> @deadjoe https://github.com/deadjoe Ah nevermind! I just realize you
> have an extra layer of nesting. The ""Service"" object should actually be the
> top level object. That nested format is only used for the config files so
> that the parser can disambiguate. The API does not use that top level
> object.
> 
> â€”
> Reply to this email directly or view it on GitHubhttps://github.com/hashicorp/consul/issues/82#issuecomment-41629683
> .
",deadjoe,deadjoe
75,2014-04-24 15:40:21,"I agree with @mitchellh. I think having a Synapse plugin would be great. No need to re-invent the wheel! 
",armon,mitchellh
75,2015-01-10 00:09:40,"We're shopping for nicer solutions to this as well. @mitchellh I just watched your recent dockercon presentation and you mentioned it's on the roadmap for Consul, do you think that's a near-future feature? Cutting out that extra layer for our small team would be awesome!
",tj,mitchellh
75,2015-01-10 01:46:17,"@tj Take a look at (consul-template)[https://github.com/hashicorp/consul-template]. It is now our defacto standard way to do this. You can use it to configure HAProxy / Varnish / nginx / Apache as a reverse proxy as you need.
",armon,tj
74,2014-04-24 04:55:02,"@wolfeidau Glad to hear it is working! Let me know if you find any issues on ARM.
",armon,wolfeidau
74,2014-07-03 02:52:24,"@wolfeidau Do you have an ARM-compiled version somewhere that I could download? I couldn't get it to build on my Raspberry Pi (process gets killed during `go build github.com/miekg/dns`)
",spro,wolfeidau
74,2015-09-01 23:07:33,"You can do the builds of this on a cloud service now like https://www.scaleway.com/.

Fast cheap ARM based VPS on demand.

That is what I am using for builds using the distributions built by @davecheney.
",wolfeidau,davecheney
74,2015-09-01 23:16:27,"With Go 1.5, cross compilation requires no preparation of the local tool
chain, you can build for every architecture from any 1.5 install.

Hope this helps

Dave

On Wed, 2 Sep 2015 09:07 Mark Wolfe notifications@github.com wrote:

> You can do the builds of this on a cloud service now like
> https://www.scaleway.com/.
> 
> Fast cheap ARM based VPS on demand.
> 
> That is what I am using for builds using the distributions built by
> @davecheney https://github.com/davecheney.
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/74#issuecomment-136888148.
",davecheney,davecheney
74,2016-01-16 18:42:11,"@alexellis The whole underlying storage mechanism changed in Consul 0.6.0 (there's no more cgo, it's all memdb and written in Go now AFAIK) - you might want to open a new issue with the exact errors you are getting for further assistance.
",highlyunavailable,alexellis
74,2016-01-16 20:29:18,"@alexellis Have you seen the download page https://www.consul.io/downloads.html with consul 0.6.3 for ARM as well.
For the old version 0.5.2 the Hypriot team once did a drone build on a Scaleway machine https://github.com/hypriot/rpi-consul/blob/drone-0.4.0/.drone.yml, but this seems outdated for 0.6.x
",StefanScherer,alexellis
74,2016-01-16 21:39:49,"@highlyunavailable  @StefanScherer Hi again Stefan, after finding this thread and spending ages trying to build on ARM docker.. the binary comes as welcome news. We really need some official ARM images for things like Consul.

Ref: https://github.com/hashicorp/consul/issues/125 (says no consul binary available on arm)

I'm trying to set up a multi-host docker 1.9.1 ARM cluster with swarm, so the documentation calls for Consul. Anyway this is what I've put together:



agent.config


",alexellis,StefanScherer
74,2016-01-16 21:39:49,"@highlyunavailable  @StefanScherer Hi again Stefan, after finding this thread and spending ages trying to build on ARM docker.. the binary comes as welcome news. We really need some official ARM images for things like Consul.

Ref: https://github.com/hashicorp/consul/issues/125 (says no consul binary available on arm)

I'm trying to set up a multi-host docker 1.9.1 ARM cluster with swarm, so the documentation calls for Consul. Anyway this is what I've put together:



agent.config


",alexellis,highlyunavailable
73,2014-04-24 05:29:19,"@tarrant Nice! I think I know what the issue is now. Basically Raft has an ElectionTimeout and a HeartbeatTimeout value. If we don't hear from the leader in HeartbeatTimeout we start an election. We restart the election every ElectionTimeout until eventually somebody ones. In this case ElectionTimeout is 400ms and HeartbeatTimeout 1s.

Due to the safety properties of Raft, franken8 can never win since it is behind, hence the message about rejecting the vote. But because of these values, if franken8 reaches the HeartbeatTimeout first, it  will run the election first. It will loose, but it will restart the election every 400ms. This pre-empts the other two nodes (which could win) since they will only timeout every 1s.

I think the solution to this is actually to ensure ElectionTimeout >= HeartbeatTimeout. Let me push the appropriate changes now.
",armon,tarrant
73,2014-04-24 05:35:13,"@tarrant I just pushed https://github.com/hashicorp/raft/commit/09d87a3995bc4fdb3a182a3044fc7349e8ca9f40. I am fairly confident this was the root of the issue. This was easier to trigger before since the old node has a HeartbeatTimeout of 300ms, instead of 1s in the latest versions. I think the ElectionTimeout was the lurking issue in there, which should be resolved now. Let me know if you can reproduce it, otherwise we can close the ticket.

Thanks a lot for beating on this!
",armon,tarrant
71,2014-04-22 21:07:27,"I agree with @mitchellh on this one. I think usually its either a config file or config dir, and it's rather confusing to have one link to the other. 
",armon,mitchellh
61,2014-04-24 09:33:51,"@sammcj Not difficult, but might be a nuisance. Essentially what @mitchellh said. 
",lsc,mitchellh
61,2014-04-24 09:33:51,"@sammcj Not difficult, but might be a nuisance. Essentially what @mitchellh said. 
",lsc,sammcj
61,2014-04-30 17:24:59,"@sammcj Yeah I agree with @mitchellh. It's just yet another thing for us to maintain.
",armon,mitchellh
61,2014-04-30 17:24:59,"@sammcj Yeah I agree with @mitchellh. It's just yet another thing for us to maintain.
",armon,sammcj
61,2014-12-10 23:53:10,"thanks, @bcandrea!
",jm3,bcandrea
61,2016-05-05 15:02:21,"@geekq This assumes you have your own build infrastructure, can trigger it on updates to some public URI address and don't want to parametise anything like the version. Or are you really suggesting someone would type those commands out every time one wants to upgrade consul?
",haf,geekq
57,2014-04-18 18:08:11,"@armon I think a GET parameter to `/catalog/service/foo` would be easiest, as was originally suggested, since its just a filter on the same operation.
",mitchellh,armon
57,2014-04-18 18:11:07,"I still think it is odd if a filter parameter on an endpoint changes the format of the result. I think @mbrevoort does not want the various check information to even be returned.
",armon,mbrevoort
57,2014-04-18 18:19:46,"In that case, I agree with @mitchellh. We can do this with a filter flag.
",armon,mitchellh
52,2014-04-21 22:37:31,"@carlosdp This is not a safe thing to do. For example, I regularly run multiple Consul servers on localhost bound to different local IPs for testing. This break that setup. Effectively, restarting with a different bind address is hard to solve in code since we cannot know if there is another Raft server which is a peer on localhost, or if we just have a new config.
",armon,carlosdp
40,2014-04-24 04:55:52,"@drnic @mbrevoort Hmm. I'm on Mavericks and it works without any issues for me. This is really bizarre, since it looks like its an open issue with the Golang toolchain. How did you guys get go? Build from source?
",armon,drnic
40,2014-04-24 04:55:52,"@drnic @mbrevoort Hmm. I'm on Mavericks and it works without any issues for me. This is really bizarre, since it looks like its an open issue with the Golang toolchain. How did you guys get go? Build from source?
",armon,mbrevoort
40,2014-04-24 13:48:23,"I installed with the installer. I'll try to build from source today and see
if I'm able to.

Thanks!

On Wednesday, April 23, 2014, Armon Dadgar notifications@github.com wrote:

> @drnic https://github.com/drnic @mbrevoorthttps://github.com/mbrevoortHmm. I'm on Mavericks and it works without any issues for me. This is
> really bizarre, since it looks like its an open issue with the Golang
> toolchain. How did you guys get go? Build from source?
> 
> â€”
> Reply to this email directly or view it on GitHubhttps://github.com/hashicorp/consul/issues/40#issuecomment-41242614
> .
",mbrevoort,drnic
40,2014-04-24 14:05:06,"@armon @drnic 
I built Go from source and updated my path and problem solved! It must be something with the binary distribution.

Thanks!
",mbrevoort,armon
40,2014-04-24 14:05:06,"@armon @drnic 
I built Go from source and updated my path and problem solved! It must be something with the binary distribution.

Thanks!
",mbrevoort,drnic
40,2014-04-24 14:12:01,"I believe I also have Go from an installer

On Thu, Apr 24, 2014 at 8:05 AM, Mike Brevoort notifications@github.com
wrote:

> @armon @drnic 
> I built Go from source and updated my path and problem solved! It must be something with the binary distribution.
> 
> ## Thanks!
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/40#issuecomment-41283630
",drnic,armon
40,2014-04-24 14:12:01,"I believe I also have Go from an installer

On Thu, Apr 24, 2014 at 8:05 AM, Mike Brevoort notifications@github.com
wrote:

> @armon @drnic 
> I built Go from source and updated my path and problem solved! It must be something with the binary distribution.
> 
> ## Thanks!
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/hashicorp/consul/issues/40#issuecomment-41283630
",drnic,drnic
38,2014-04-30 17:24:29,"@jpfuentes2 I'm going to close this for now. Can you re-open when you are ready for review?
",armon,jpfuentes2
32,2014-04-09 17:21:41,"@andrewwatson I don't think you want to make use of multiple zones, it is much better to let Consul handle that routing internally. Otherwise you need to update bind configs if you change the server addresses. Otherwise I think this is super helpful!
",armon,andrewwatson
32,2014-04-09 18:14:21,"@andrewwatson Nice! Would you mind rebasing so I can merge this in? Thanks!
",armon,andrewwatson
24,2014-04-03 17:42:33,"@ryanuber Agreed. There is a lot of inconsistency between the command line flags. Lots of cleanup needed there. Probably some flags need to be added/removed as well.
",armon,ryanuber
23,2014-04-04 20:11:36,"@mitchellh I was more thinking, once a service had been discovered, a node could then register its use of that service. This could be a one-time operation using a Serf event or query, which could contain the node's name/address/whatever else in the event payload.

This would require the endpoint doing the discovery using Consul to take on responsibility of registering utilization once a suitable service had been found. There would also need to be a reliable way of deregistering if a node died/got reaped.

This could help with transparency on who is talking to who in the cluster, which sounds like part of what @andrewwatson needs in #22, and wouldn't rely on DNS query frequency as @armon pointed out. 

Since automatic service discovery moves the source of truth for network topology into runtime, I could see using this to build a topology graph if the data were exposed over say, the HTTP interface.

Anyways, it might not be the immediate goal of Consul to handle stuff like this, and #22 points back here so its cool if we close this out. Thanks for your comments!
",ryanuber,mitchellh
22,2014-04-03 17:41:15,"@andrewwatson I think this would be simple to add given the existing telemetry infrastructure. What I wonder is if you would get meaningful data however. E.g. in our case, most services do some initial DNS queries, but then have persistent connections to the backend services. So they are not constantly re-doing the DNS queries. I think this will be a pretty common performance optimization that limits the utility of metrics that we can provide
",armon,andrewwatson
13,2014-04-03 17:44:23,"@ryanuber This was kind of a ""thought"" ticket for me. Any integration with Consul would just use it's existing APIs (specifically the various /v1/health/ endpoints). I don't think PagerDuty would be ""blessed"" in any way. Just some generic set of wrappers around the existing HTTP API.
",armon,ryanuber
13,2014-04-21 23:07:57,"@armon there are a couple of ways to integrate with PagerDuty. lots of people integrate with us via PD Connect: https://www.pagerduty.com/docs/integration-api/pagerduty-connect/ if you need help with the integration, feel free to reach out to me at vivian@pagerduty.com
",vivianma,armon
13,2014-08-26 21:50:08,"@davedash has the right idea. An agent that lives along side consul and handles dealing with warning and critical checks/services and then performs an arbitrary action (call pagerduty, send email, write to redis) would be what would meet my needs. You could even make these agents services in consul so they'd be more fault tolerant. I'm thinking about building something simple that would have this functionality but to be a fully fledged nagios replacement, it would need to support some additional features like notification periods per health check, custom actions per health check (think: only email for this check, no pagerduty), and optionally parenting. I have some ideas about how to implement these but it would involve adding additional data to each health check's configuration. 
",cruatta,davedash
13,2014-08-29 19:55:17,"@josephholsten Agreed that the integration itself doesn't belong on Consul proper. What's the watch mechanism though? Thus far I haven't found anything better than periodic polling.
",morgante,josephholsten
13,2014-08-29 20:16:23,"Look at blocking queries in the HTTP API. It's a long poll style thing that returns on timeout or state change.

-----Original Message-----
From: ""Morgante Pell"" notifications@github.com
Sent: â€Ž8/â€Ž29/â€Ž2014 12:55 PM
To: ""hashicorp/consul"" consul@noreply.github.com
Cc: ""highlyunavailable"" highlyunavailable@gmail.com
Subject: Re: [consul] PagerDuty integration (#13)

@josephholsten Agreed that the integration itself doesn't belong on Consul proper. What's the watch mechanism though? Thus far I haven't found anything better than periodic polling.
â€”
Reply to this email directly or view it on GitHub.
",highlyunavailable,josephholsten
13,2014-09-17 22:08:00,"@armon Now that the `consul watch` handler mechanism is present in 0.4.0 should this be closed out? 
",jrnt30,armon
13,2014-09-18 01:37:42,"@jrnt30 I'd like to maybe have some handler that can be used with consul watch to do this. I never intended the PD integration to be in Consul core.
",armon,jrnt30
13,2014-09-18 05:50:28,"I think that's what @jrnt30 was saying - this is exactly the mechanism we need to call a script to send an alert through an alerting system, so this bug is ""closed"" pending minor customization by the user.
",highlyunavailable,jrnt30
11,2014-05-02 04:11:59,"@mitchellh No... the that was a KV client only. It actually doesn't support any of the things we need. We could add basic KV manipulation.
",armon,mitchellh
9,2014-02-23 01:48:08,"@mitchellh This is special. Apparently linux only applies `setuid` to the current thread... https://groups.google.com/forum/?fromgroups=#!topic/golang-nuts/BZWXqv3YSg4

Not sure of a sane way to do this, since the runtime has at least like 9 threads...
",armon,mitchellh
9,2014-03-31 04:20:43,"@andrewwatson Great point. bind can also be used as a recursor instead of consul
",armon,andrewwatson
2825,2017-03-23 22:25:52,Hi @charles-dyfis-net thanks for opening a PR. I don't think this code should be in use any more once @sean- merges his pending change to switch over to https://github.com/hashicorp/go-sockaddr.,slackpad,sean-
2803,2017-03-17 18:31:54,"We have a use case that we're trying to accommodate with prepared queries, but can't quite get to work. We're trying to setup puppet SRV records, https://docs.puppet.com/guides/scaling_multiple_masters.html#option-4-dns-srv-records. 

We can get a prepared query setup that almost does what we're looking for, but not quite. The catch is that we have multiple ""well connected"" datacenters in a region and want to return all of the puppetservers across those sites, not just the ones in the current DC. This would be analogous AZs within an AWS region.

The Failover functionality is almost what we want, but not quite. We want it to return things from a list of datacenters always, not just as a failover.

It seems slightly related to https://github.com/hashicorp/consul/issues/671, and https://github.com/hashicorp/consul/issues/252 would likely be useful as well, but isn't 100% required. 

Anyway, I'm happy to open an issue in the repo to discuss, but I wanted to reach out and check to make sure that I'm not overlooking something or failing to find a previous issue about this.

Moving to an issue from the [mailing list](https://groups.google.com/d/msg/consul-tool/UZqGRpqeBtQ/uHW5b8MMBgAJ).

/cc @slackpad ",ross,slackpad
2795,2017-03-10 21:58:17,Consul is trying to resolve that internal address and getting into a loop. We should guard against that in Consul and I'll /cc @sean- on here for thoughts on the right way forward from the Vault side.,slackpad,sean-
2791,2017-03-09 08:58:08,"This was discussed before in issue #410, and with @mfischer-zd here: https://groups.google.com/forum/#!topic/consul-tool/Axow65BtSuY

If we change the behaviour to be ""watch only keys with new UpdateIndex"", then it is possible by just filtering in the endpoint code.

Reading through the code, here

https://github.com/hashicorp/consul/blob/master/consul/kvs_endpoint.go#L151

and here

https://github.com/hashicorp/consul/blob/master/consul/kvs_endpoint.go#L191

we see that in both cases, the result is filtered by applying the ACL.  What if we simply add options and code here to filter out entries or keys that have an old ModifyIndex.  That way, we effectively get values that have been updated.

This should be a relatively simple code change.

A more efficient way would be to also pass this option into the state functions so that only the updated entries are returned, but that is just an optimisation.

My use case is to let a client hold an in-memory replica of a set of KVs, allowing a local scan/query through the values.  This would be possible by first listing all entries with a prefix, and then subsequently doing a blocking pathprefix get with a `?index=N&updates_only` option.



",krestenkrab,mfischer-zd
2790,2017-03-08 17:43:46,"ðŸš§ WIP. Don't merge until final approval from @pearkes

HashiCorp is adding a high-level element to provide navigation and visibility to OSS project sites. We like to call it Mega Nav :zap:. Mega Nav is pulled in from [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp) and is positioned above the local nav in the site. It looks like this: 

### Desktop Inactive
<img width=""1430"" alt=""screen shot 2017-03-08 at 9 29 53 am"" src=""https://cloud.githubusercontent.com/assets/416727/23715979/6b303488-03e3-11e7-81d2-d043b4f11667.png"">

### Desktop Active
<img width=""1423"" alt=""screen shot 2017-03-08 at 9 30 04 am"" src=""https://cloud.githubusercontent.com/assets/416727/23715989/72f0ecda-03e3-11e7-8894-5019ac436af9.png"">

### Mobile Inactive
<img width=""402"" alt=""screen shot 2017-03-08 at 9 30 40 am"" src=""https://cloud.githubusercontent.com/assets/416727/23716013/846abb8a-03e3-11e7-87ee-ee23cdbff89a.png"">

### Mobile Active
<img width=""400"" alt=""screen shot 2017-03-08 at 9 30 49 am"" src=""https://cloud.githubusercontent.com/assets/416727/23716033/92b6a9ba-03e3-11e7-801e-7b94598fbb8d.png"">

cc @hashicorp/design ",jasoncostello,pearkes
2790,2017-03-08 17:43:46,"ðŸš§ WIP. Don't merge until final approval from @pearkes

HashiCorp is adding a high-level element to provide navigation and visibility to OSS project sites. We like to call it Mega Nav :zap:. Mega Nav is pulled in from [middleman-hashicorp](https://github.com/hashicorp/middleman-hashicorp) and is positioned above the local nav in the site. It looks like this: 

### Desktop Inactive
<img width=""1430"" alt=""screen shot 2017-03-08 at 9 29 53 am"" src=""https://cloud.githubusercontent.com/assets/416727/23715979/6b303488-03e3-11e7-81d2-d043b4f11667.png"">

### Desktop Active
<img width=""1423"" alt=""screen shot 2017-03-08 at 9 30 04 am"" src=""https://cloud.githubusercontent.com/assets/416727/23715989/72f0ecda-03e3-11e7-8894-5019ac436af9.png"">

### Mobile Inactive
<img width=""402"" alt=""screen shot 2017-03-08 at 9 30 40 am"" src=""https://cloud.githubusercontent.com/assets/416727/23716013/846abb8a-03e3-11e7-87ee-ee23cdbff89a.png"">

### Mobile Active
<img width=""400"" alt=""screen shot 2017-03-08 at 9 30 49 am"" src=""https://cloud.githubusercontent.com/assets/416727/23716033/92b6a9ba-03e3-11e7-801e-7b94598fbb8d.png"">

cc @hashicorp/design ",jasoncostello,hashicorp
2783,2017-03-10 07:03:41,"@wuub @armon @slackpad 
Please help in resolving this issue.",p1nkrock,armon
2783,2017-03-10 07:03:41,"@wuub @armon @slackpad 
Please help in resolving this issue.",p1nkrock,wuub
2783,2017-03-10 07:03:41,"@wuub @armon @slackpad 
Please help in resolving this issue.",p1nkrock,slackpad
2783,2017-03-13 10:26:51,"It is recommended to have 3 or 5 servers for high availability but it is not mandatory. Hence the above quoted issue should not occur even in single server case. 

Here, we had to do multiple reloads because of watch registration from various applications. We write watch jsons to a consul config directory and trigger reload as there is no Consul Endpoint where watches can be registered thru HTTP calls. Its either thru config file or consul watch command.

We have a workaround now where we queue these watch registrations for a certain interval and then trigger reload. Cons for this workaround is the delay for processes to know the state of other processes.

@slackpad @armon",p1nkrock,armon
2783,2017-03-13 10:26:51,"It is recommended to have 3 or 5 servers for high availability but it is not mandatory. Hence the above quoted issue should not occur even in single server case. 

Here, we had to do multiple reloads because of watch registration from various applications. We write watch jsons to a consul config directory and trigger reload as there is no Consul Endpoint where watches can be registered thru HTTP calls. Its either thru config file or consul watch command.

We have a workaround now where we queue these watch registrations for a certain interval and then trigger reload. Cons for this workaround is the delay for processes to know the state of other processes.

@slackpad @armon",p1nkrock,slackpad
2766,2017-03-16 04:35:45,Hey @armon - Do know something about this?,vrenjith,armon
2764,2017-02-22 00:54:07,":wave:

This PR is part of a larger effort by HashiCorp to implement more consistent typography across the OSS sites. The changes are: 

- Headings are set in Klavika font (remove Museo)
- Paragraphs are set in Open Sans
- Updated logo
- Subtle tweaks to the docs typography for legibility

It looks like this: 

**On Desktop**

![screencapture-localhost-4567-1487721788315](https://cloud.githubusercontent.com/assets/416727/23191917/3da26ae8-f855-11e6-9d7d-f14e0a59f633.png)

**On Mobile**

![screencapture-localhost-4567-1487724110206](https://cloud.githubusercontent.com/assets/416727/23191933/5889e3f4-f855-11e6-8345-926d05935b34.png)

**Docs**

![screencapture-localhost-4567-docs-upgrading-html-1487724653941](https://cloud.githubusercontent.com/assets/416727/23192048/ff046ca4-f855-11e6-99b2-d145237966df.png)

cc/ @captainill @sethvargo 
",jasoncostello,captainill
2764,2017-02-22 00:54:07,":wave:

This PR is part of a larger effort by HashiCorp to implement more consistent typography across the OSS sites. The changes are: 

- Headings are set in Klavika font (remove Museo)
- Paragraphs are set in Open Sans
- Updated logo
- Subtle tweaks to the docs typography for legibility

It looks like this: 

**On Desktop**

![screencapture-localhost-4567-1487721788315](https://cloud.githubusercontent.com/assets/416727/23191917/3da26ae8-f855-11e6-9d7d-f14e0a59f633.png)

**On Mobile**

![screencapture-localhost-4567-1487724110206](https://cloud.githubusercontent.com/assets/416727/23191933/5889e3f4-f855-11e6-8345-926d05935b34.png)

**Docs**

![screencapture-localhost-4567-docs-upgrading-html-1487724653941](https://cloud.githubusercontent.com/assets/416727/23192048/ff046ca4-f855-11e6-99b2-d145237966df.png)

cc/ @captainill @sethvargo 
",jasoncostello,sethvargo
2724,2017-02-09 15:52:06,"Hi @cityofships thanks for the report - we will figure this out (it was new code for 0.7.3).

/cc @dadgar ",slackpad,dadgar
2712,2017-02-06 14:42:46,"I'd expect that there'd be other users than ourselves that use the Key/Value store to store JSON nested keys so I thought I'd pass up a PR for review. The implementation itself is pretty lightweight; see if `JSON.parse` throws an error, if not then valid. The `isValid` function can be changed to suit. 

This has been implemented through the use of a flag to enable/disable the functionality with a watcher on the value to set the success/error class on the textarea itself:

**Default**

<img width=""767"" alt=""screen shot 2017-02-06 at 14 30 55"" src=""https://cloud.githubusercontent.com/assets/3958636/22651138/e340e66a-ec79-11e6-9987-600059a4b548.png"">

**Enabled (error)**

<img width=""764"" alt=""screen shot 2017-02-06 at 14 31 01"" src=""https://cloud.githubusercontent.com/assets/3958636/22651163/fa9a7402-ec79-11e6-8c0c-f64845716fcc.png"">

**Enabled (success)**

<img width=""778"" alt=""screen shot 2017-02-06 at 14 31 18"" src=""https://cloud.githubusercontent.com/assets/3958636/22651174/053924c6-ec7a-11e6-8b26-1bbd6f61f5fa.png"">

No hard validation added to form to prevent the request - intentional as this didn't feel like expected behaviour and I didn't want to force the users into any specific workflow.

In all honesty, I won't be heartbroken if this doesn't make it in, we can run our own UI after all although I do think its a net gain overall. cc: @nathanhebe",jackturnbull,nathanhebe
2710,2017-02-03 05:06:01,"@sean- 
   This is the PR with just the the unit test for what I am trying to do with the TXT RR in Consul. If we agree on a solution it would solve #2709.

",sodre,sean-
2709,2017-02-03 02:32:15,"@sean- 

As discussed, It would be useful for Consul to serve TXT records at multiple levels in the domain hierarchy. One use-case in mind is a Kerberized cluster configured purely through DNS. This requires that the DNS server respond to `TXT _kerberos.[.data center]<.domain>` with the configured realm name.

One thought is to store this information is in the key-value store, perhaps in a format such as...
key: `/service/dns/req=TXT/<FQDN>` value: `TXTDATA`.",sodre,sean-
2688,2017-01-27 21:04:01,"Adds Google Tag Manager to the website per Hashicorp's request in (~redacted~).

@captainill",ryon,captainill
2678,2017-01-26 05:16:13,"Individual commits contain more detail.

/cc @slackpad ",sethvargo,slackpad
2664,2017-01-19 09:37:06,"Hi all, 

thanks for the amazing job you're all doing with Consul!
However, I could not find any mention of which cipher suites are supported by Consul when implementing TLS. @macb [mentioned](https://github.com/hashicorp/consul/issues/1349) Consul relies on Golang (now updated to the latest 1.7 version) which supports TLS back to TLS 1.0 included.

1. Could you please tell me which cipher suites are supported?

I found AES-GCM 128, using PKCS7 padding and AES-GCM 128, no padding mentioned at [security.go](https://github.com/hashicorp/consul/blob/6f0a3b9bf5c7fd0673213d451bbc9e66f7a9cad9/vendor/github.com/hashicorp/memberlist/security.go). Could you kindly confirm please that those are the ciphers specified by Consul for the TLS configuration that Golang needs to be fed with?

2. Also, usually a cipher suite for TLS is comprised of key-exchange algorithm, bulk cipher algorithm and MAC (Hash) algorithm, e.g. TLS_RSA_WITH_3DES_EDE_CBC_SHA. Since in the mention of ""AES-GCM 128"" AES is for key exchange and GCM is the bulk cipher alg, which hash algorithm are you using?

3. Finally, it would be great to have the possibility to customise the cipher suites used and the minimum supported version of TLS.


Thanks a lot in advance.",iammyr,macb
2657,2017-03-17 08:30:15,"Hello @slackpad,

would you have any feedback regarding this PR?
We've been using this on top of 0.7.3 for a month without any issue",kamaradclimber,slackpad
2656,2017-01-17 13:04:35,"""raft_multiplier"" should be nested into ""performance"". 

Seems like it was accidentally changed in https://github.com/hashicorp/consul/pull/2320
cc @slackpad ",legal90,slackpad
2640,2017-01-09 03:53:11,"Not ready to merge, but continuing the discussion on #2300

I created an agent namespace. When you query agent.consul, the behavior is simply to retrieve the NodeName from config and query that name. This returns effectively the bind address, however I think if a user has overridden this with `advertise_addr` config it will return that. I'm not sure @slackpad if this is what you intended or if this interface needs to be more intelligent. @ryansch or @far-blue is this meeting your need or did I misunderstand the use case?",moofish32,far-blue
2640,2017-01-09 03:53:11,"Not ready to merge, but continuing the discussion on #2300

I created an agent namespace. When you query agent.consul, the behavior is simply to retrieve the NodeName from config and query that name. This returns effectively the bind address, however I think if a user has overridden this with `advertise_addr` config it will return that. I'm not sure @slackpad if this is what you intended or if this interface needs to be more intelligent. @ryansch or @far-blue is this meeting your need or did I misunderstand the use case?",moofish32,ryansch
2640,2017-01-09 03:53:11,"Not ready to merge, but continuing the discussion on #2300

I created an agent namespace. When you query agent.consul, the behavior is simply to retrieve the NodeName from config and query that name. This returns effectively the bind address, however I think if a user has overridden this with `advertise_addr` config it will return that. I'm not sure @slackpad if this is what you intended or if this interface needs to be more intelligent. @ryansch or @far-blue is this meeting your need or did I misunderstand the use case?",moofish32,slackpad
2634,2017-01-06 10:18:58,"@magiconair you seeing this, i assume it is a issue with fabio, i tried to use several urlprefixes. ",raben2,magiconair
2630,2017-01-23 21:45:33,"@slackpad Since dev mode is not supposed to write to disk at all, should the `keyring -install` command even be supported in dev mode?",mckennajones,slackpad
2626,2017-02-08 03:20:40,Hi @celseyking I don't think this is enough information to figure out what's happening. Can you share some details about your Consul and some logs from when this happens? There's no inherent limit for checks.,slackpad,celseyking
2612,2016-12-22 11:13:19,"Following up on [a conversation](https://github.com/solarkennedy/puppet-consul/issues/282#issuecomment-268246692) I had with @armon, it may be worth setting the example here as well, not to send SIGINT to server-mode agents, because they might unintentionally change the Raft consensus pool.

From the commit message:

> Since Consul 0.7, client-mode agents are shutting down gracefully by
> default, so no need to send them a SIGINT specially. The default for
> server-mode agents is still not to leave gracefully on SIGTERM, but it
> was left this way for a reason. To override this, it is better to set
> the leave_on_terminate option, rather than changing the KillSignal.",amiryal,armon
2582,2016-12-09 10:47:55,"@mckennajones, looks like your pull request #2577 failed for the same reason.",ybubnov,mckennajones
2580,2016-12-07 22:02:15,/cc @slackpad ,sethvargo,slackpad
2579,2016-12-07 19:33:47,"This updates the main Consul page to use the KV CLI instead of curl as requested by @armon. I'm working on updates to the other pages that will show both `curl` and `consul kv` as options, but Armon thinks this looks better and easier on the home page.",sethvargo,armon
2572,2016-12-06 19:12:29,Thanks for the tips @sethvargo!,brianshumate,sethvargo
2567,2016-12-02 18:14:57,"If there's an issue with Circonus (in our case we hit a usage limit) we weren't able to start the Consul agent at all:



Since we are depending on an external service, we should probably be robust to outages there. A few different mitigations might be possible:

1. Print a warning and periodically retry, adding the sink when Circonus is available.
2. Print a warning and skip creating the sink.
3. Register a health check for metics that we can set to a failed state if we have issues with an external metrics provider.

This probably isn't limited to Circonus so we should apply whatever we do to all of them.

/cc @phinze @sean- ",slackpad,phinze
2567,2016-12-02 18:14:57,"If there's an issue with Circonus (in our case we hit a usage limit) we weren't able to start the Consul agent at all:



Since we are depending on an external service, we should probably be robust to outages there. A few different mitigations might be possible:

1. Print a warning and periodically retry, adding the sink when Circonus is available.
2. Print a warning and skip creating the sink.
3. Register a health check for metics that we can set to a failed state if we have issues with an external metrics provider.

This probably isn't limited to Circonus so we should apply whatever we do to all of them.

/cc @phinze @sean- ",slackpad,sean-
2557,2016-12-01 15:27:58,"The testutil server uses an atomic incrementer to generate unique port
numbers. This works great until tests are run in parallel, _across
packages_. Because each package starts at the same ""offset"" idx, they
collide.

One way to overcome this is to run each packages' test in isolation, but
that makes the test suite much longer as it does not maximize
parallelization. Alternatively, instead of having ""predictable"" ports,
we can let the OS choose a random open port automatically.

This still has a (albeit smaller) race condition in that the OS could
return an open port twice, before the server has a chance to actually
start and occupy said port. In practice, I have not been able to hit
this race condition, so it either doesn't happen or it happens far less
frequently that the existing implementation.

I'm not sure how I feel about the panic, but this is just test code, so
I'm including to say it's okay?

/cc @slackpad ",sethvargo,slackpad
2549,2016-12-21 16:39:26,"This feature has been discussed in https://github.com/prometheus/prometheus/pull/2028.
@slackpad, what do you thing about it ?",Thib17,slackpad
2549,2016-12-26 09:50:16,"We would be interested by this feature as well @slackpad.
Could you provide some inputs onto the likelihood of it to be merged ? 

",erebe,slackpad
2547,2016-11-30 02:17:38,"I forgot to actually update the types ðŸ˜¦ 

/cc @slackpad ",sethvargo,slackpad
2547,2016-11-30 04:08:21,"Aye! LGTM

> On Nov 29, 2016, at 6:17 PM, Seth Vargo <notifications@github.com> wrote:
> 
> I forgot to actually update the types ðŸ˜¦
> 
> /cc @slackpad
> 
> You can view, comment on, or merge this pull request online at:
> 
>   https://github.com/hashicorp/consul/pull/2547
> 
> Commit Summary
> 
> Return the correct type
> File Changes
> 
> M api/health.go (14)
> Patch Links:
> 
> https://github.com/hashicorp/consul/pull/2547.patch
> https://github.com/hashicorp/consul/pull/2547.diff
> â€”
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 
",slackpad,slackpad
2529,2016-11-28 20:37:50,@babbottscott Thoughts on this @slackpad ? It wouldn't be hard to implement but I'm not sure if this is the intended behavior for this case. ,mckennajones,slackpad
2525,2016-11-21 23:13:08,"- Remove reference to Glyphicon Halflings @fontface
- Remove unused Glphyicon related classes",brianshumate,fontface
2525,2016-11-22 00:55:28,@pearkes might be able to give a little guidance on how we update this,slackpad,pearkes
2516,2016-12-29 02:53:30,"@kyhavlov @slackpad I realize this is merged, but this seemed the best place to comment about an issue before possibly opening a new bug/item. 

The TestAgent_Reload in the tests for this feature break on a machine with 2 private IP's. It took me a while to figure out how to get the output from the MockUi, (this drove me NUTS btw) but once I did it led me to the understanding that while nexConfig is called to get a config, it's never actually used to create the instance of the server used in the test. It builds a DefaultConfig on a Run(), but in that default, the bind is 0.0.0.0. If that's the bind, the agent fails to start because of the multi-private-ip issue. 

Not sure how/if this needs to be fixed. I've worked around it by simply adding a -bind to the args list for the Command. It seems odd I haven't hit this for any other tests, so I'm not sure what this test is doing that's different from the rest. I haven't dug into it deeply yet.",rhyas,slackpad
2485,2016-11-18 16:07:35,"They're apparently included under a [special provision](http://getbootstrap.com/components/) with Bootstrap:

> Glyphicons Halflings are normally not available for free, but their creator has made them available for Bootstrap free of cost. As a thank you, we only ask that you include a link back to Glyphicons whenever possible.

They are referenced in our minified Bootstrap CSS in `ui/static/bootstrap.min.css`, but it does not appear that we actually use them:



We could remove the `@font-face` entries from the static minified `bootstrap.min.css` for an instant resolution of this issue, but to avoid this going forward, we'd have to [customize Bootstrap](http://getbootstrap.com/customize/) further and deselect the Glyphicons component.
",brianshumate,font-face
2474,2016-11-18 07:30:24,"thanks for the feedback @simplechris 
",kamaradclimber,simplechris
2474,2017-03-17 08:28:55,@slackpad @simplechris any feedback on that PR. What can I do to make it progress?,kamaradclimber,simplechris
2448,2016-10-29 19:01:46,"This has been working really well on Nomad and hashicorp.com, so I am ready to port it out to Consul as a beta. This moves the local development to a Docker container, which is the same container that we use to publish the website in production. The result is much faster and more consistent deploys.

/cc @slackpad 
",sethvargo,slackpad
2434,2016-10-25 18:16:13,"@slackpad 
",kyhavlov,slackpad
2418,2016-10-14 22:40:30,"Consul's recurse will now return messages even if the `dns.Exchange` call returns a truncated error.

This PR is in reference to #2384

-Christian Ang and @evanfarrar
",christianang,evanfarrar
2418,2016-10-25 17:45:14,"hey @slackpad we rebased with master and travis is passing now, let us know if there is anything you'd like us to change!
",zankich,slackpad
2417,2016-10-25 23:37:49,"@slackpad -- seems like it's merge week, just bumping the PR
",moofish32,slackpad
2412,2016-10-13 22:06:42,"ðŸ”´  Early POC ðŸ”´ 

This is a fairly large, but localized refactor to attempt to centralize our CLI parsing options and output. It adds a `Meta` struct that is aware of common information and includes functions for generating an HTTP/RPC client and the associated CLI flags. It also has logic on how to pretty-print flags, wrap to a specified line length, and more.
### TODO
- [ ] RPC Client
- [ ] Don't print out help output on flag failure (the failure is way at the top and the help output often scrolls beyond)

/cc @slackpad for early review.
",sethvargo,slackpad
2412,2017-02-08 02:20:21,"@kyhavlov the todo ""Don't print out help output on flag failure (the failure is way at the top and the help output often scrolls beyond)"" is worth keeping track of - that's actually pretty bad rn because the error is always at the top of a bunch of stuff.",slackpad,kyhavlov
2395,2016-10-07 00:29:26,"### hashicorp/consul now has a Chat Room on Gitter

@slackpad has just created a chat room. You can visit it here: [https://gitter.im/hashicorp-consul/Lobby](https://gitter.im/hashicorp-consul/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&content=body_link).

This pull-request adds this badge to your README.md:

[![Gitter](https://badges.gitter.im/hashicorp-consul/Lobby.svg)](https://gitter.im/hashicorp-consul/Lobby?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=body_badge)

If my aim is a little off, please [let me know](https://github.com/gitterHQ/readme-badger/issues).

Happy chatting.

PS: [Click here](https://gitter.im/settings/badger/opt-out) if you would prefer not to receive automatic pull-requests from Gitter in future.
",gitter-badger,slackpad
2384,2016-10-03 16:26:21,"Currently it looks like dns recurse truncation does not work correctly. When a recursor returns a dns response with the truncation flag set consul returns a SERVFAIL instead of returning the truncated dns response. This means the clients won't get the truncated responses, nor will it attempt to retry the request over TCP.

It looks like miekg/dns returns an ErrTruncate for https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L850, which turns out to be an error case with a valid message (https://github.com/miekg/dns/blob/master/client.go#L229-L234). We should actually be returning this message if ErrTruncate occurs.

We tested this with consul 0.7.

We can open a PR to fix this if this sounds like acceptable behavior for consul.

-Christian and @kkallday
",christianang,kkallday
2384,2016-10-12 17:28:24,"Hey @slackpad we'll go ahead and submit a PR for this, and are open to discuss in this issue or on the forthcoming PR.
",Amit-PivotalLabs,slackpad
2380,2016-10-01 22:35:50,"- adding cli config and config file support for specifying the serf wan and lan bind addresses 
- updating documentation for serf wan and lan options 
  Fixes #2007

@slackpad - I am not sure about the non-loopback IP test. I couldn't think of a better way to do this. I need to verify I didn't break any tests, but it should behave the same as the current defaults.
",moofish32,slackpad
2380,2016-10-03 20:17:51,"@slackpad -- from what I see running this locally the failing tests are not differing from the list on master. They are not always the same errors as I think you know.
",moofish32,slackpad
2380,2016-10-25 23:38:11,"@slackpad  - one more bump during the merge party
",moofish32,slackpad
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,armon
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,pearkes
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,ryanuber
2374,2017-01-13 13:07:59,"@muradm did you solved this problem? I've noticed the same issue in my environment. Besides it, there are some other problem: when you restart the host for some reason, the docker daemon doesn't send sig term to the consul-server docker task, therefore, it not properly leave the cluster. After the host is up, a new task is created with a different VIP address. 

As soon as I have persistent storage for /consul/data, the node can't join to the cluster and the old node persists in failed status in the cluster.

IMHO, hashicorp team must change the way consul adds/removes it nodes for properly work in docker swarm mode (1.12.x / 1.13.x).

@slackpad @armon @ryanuber @sean- @pearkes 
",galindro,sean-
2360,2016-09-26 15:17:07,"This implements the `kv` subcommand CLI for reading, writing, and deleting keys. This pass does not support the transaction-based keys yet, but that could be implemented in a later pass. The framework is in place for adding new commands and formats pretty easily.



/cc @slackpad @ryanuber @armon 
",sethvargo,armon
2360,2016-09-26 15:17:07,"This implements the `kv` subcommand CLI for reading, writing, and deleting keys. This pass does not support the transaction-based keys yet, but that could be implemented in a later pass. The framework is in place for adding new commands and formats pretty easily.



/cc @slackpad @ryanuber @armon 
",sethvargo,slackpad
2360,2016-09-26 15:17:07,"This implements the `kv` subcommand CLI for reading, writing, and deleting keys. This pass does not support the transaction-based keys yet, but that could be implemented in a later pass. The framework is in place for adding new commands and formats pretty easily.



/cc @slackpad @ryanuber @armon 
",sethvargo,ryanuber
2353,2016-09-22 19:56:04,"@ryanuber that's an interesting idea, but we range over `serviceStatus`/`checkStatus` maps in order to do the failed lookup in the primary maps, so I think we need some piece of state to say that it needs to be deleted.
",slackpad,ryanuber
2352,2016-09-21 16:20:52,"/cc @slackpad 
",sethvargo,slackpad
2343,2016-09-16 23:15:27,"Hey @slackpad, thanks for meeting with some of us from the Pivotal Cloud Foundry team, here's some of the points we talked about.
- [ ] Make a server leave as a first class thing.
- [ ] Does leave give the right feedback? Seems like it returns before leave has happened.
- [ ] Server name change issue: https://github.com/hashicorp/consul/issues/2172.
- [x] Migrate all gossip key stuff off RPC client so we don't have to use the RPC client at all to orchestrate how we start the consul binary.
- [x] Have an HTTP API endpoint for `leave` command, instead of only RPC interface.
- [ ] Will stale Serf info add a failed server back in (do we check the health)?
- [ ] Gossip keys install should say who failed and why (at least the IP).
- [ ] ""Stats for Raft -> consul operator healthy server replication OK CLI + API"" -- so that we can simplify Consul orchestration, knowing that a server is synced rather than polling stats endpoint and comparing numbers.
- [ ] ""Bootstrap CLI + API -> are you in a cluster and are you synced"" -- so that we can programmatically put a server into bootstrap mode instead of rewriting config and having to restart server.
- [ ] If keys have been rotated new agents don't have the old key history - where are the keys stored?  What files would they need to keep on a restart?
- [ ] Client rapidly turning into a server gets ignored by other clients as a non-server.
- [ ] Do we need a special case operator command to help with leaves (like maybe take a list of server IPs to RPC to)?
- [ ] Manual mode would need TLS configs and stuff, i.e. being able to cURL a Consul server with keys and certs, or even the `consul` CLI supporting commands to remote servers and supporting flags for TLS things -- needs to support just giving it an IP and maybe ignoring domain name verification (chicken-egg problem).

Some of the items above are maybe a bit roughly worded, we can work on refining them.

Also, please let us know how we can help on these via PRs.

Thanks!
",Amit-PivotalLabs,slackpad
2343,2016-10-12 17:09:52,"Hey @slackpad any update on any of these issues, or ideas on how we can help?
",Amit-PivotalLabs,slackpad
2321,2016-09-02 05:12:28,"Hi @Pivotal-Pierre-Delagrave thanks for the PR! Looks great and I merged this under #2322 with just a couple tweaks.
",slackpad,Pivotal-Pierre-Delagrave
2309,2016-08-27 04:35:50,"Hi all,

Several of our users have experienced issues with the hard-coded 2s DNS timeout in how Consul serves DNS.  Some of this has to do with how we operate Consul, some has to do with Consul itself.  For plenty of context, you can take a look at [this thread](https://lists.cloudfoundry.org/archives/list/cf-dev@lists.cloudfoundry.org/thread/SYZBMTB6PKIPHWB2ZOE5FNOAJKUL7KVA/).

Would you folks be interested in a PR along [these lines](https://github.com/Pivotal-Pierre-Delagrave/consul/commit/c8c4b9d344ce94317d8554c85da7dc12f32e8cb2)?  If so, how would this fit into Consul's release cadence, i.e. what's the time scale to go from PR to patch release?

Thanks,
Amit

/cc @Pivotal-Pierre-Delagrave @zankich @keymon
",Amit-PivotalLabs,zankich
2309,2016-08-27 04:35:50,"Hi all,

Several of our users have experienced issues with the hard-coded 2s DNS timeout in how Consul serves DNS.  Some of this has to do with how we operate Consul, some has to do with Consul itself.  For plenty of context, you can take a look at [this thread](https://lists.cloudfoundry.org/archives/list/cf-dev@lists.cloudfoundry.org/thread/SYZBMTB6PKIPHWB2ZOE5FNOAJKUL7KVA/).

Would you folks be interested in a PR along [these lines](https://github.com/Pivotal-Pierre-Delagrave/consul/commit/c8c4b9d344ce94317d8554c85da7dc12f32e8cb2)?  If so, how would this fit into Consul's release cadence, i.e. what's the time scale to go from PR to patch release?

Thanks,
Amit

/cc @Pivotal-Pierre-Delagrave @zankich @keymon
",Amit-PivotalLabs,keymon
2309,2016-08-27 04:35:50,"Hi all,

Several of our users have experienced issues with the hard-coded 2s DNS timeout in how Consul serves DNS.  Some of this has to do with how we operate Consul, some has to do with Consul itself.  For plenty of context, you can take a look at [this thread](https://lists.cloudfoundry.org/archives/list/cf-dev@lists.cloudfoundry.org/thread/SYZBMTB6PKIPHWB2ZOE5FNOAJKUL7KVA/).

Would you folks be interested in a PR along [these lines](https://github.com/Pivotal-Pierre-Delagrave/consul/commit/c8c4b9d344ce94317d8554c85da7dc12f32e8cb2)?  If so, how would this fit into Consul's release cadence, i.e. what's the time scale to go from PR to patch release?

Thanks,
Amit

/cc @Pivotal-Pierre-Delagrave @zankich @keymon
",Amit-PivotalLabs,Pivotal-Pierre-Delagrave
2297,2016-08-23 21:59:51,"@slackpad who can assist us please? We keep this setup up and running and need some advice to extract more relevant data from it. 
Thanks
",rom-stratoscale,slackpad
2292,2016-09-12 16:04:12,"LAN and WAN gossip use the same protocol SWIM (https://www.cs.cornell.edu/~asdas/research/dsn02-swim.pdf), implemented in memberlist package with the Serf (with vector clocks blah-blah) on top of it. 

Read docs.

https://www.consul.io/docs/internals/gossip.html
http://sitano.github.io/2015/10/06/abt-consul-outage/

About connecting cross-dc with lan level serf - you can, but there are certain constraints in the protocol in the deterministic failure detector (timeout based thing) and that may result on the state convergence. 

@armon wrote somewhere about thats not recommended and everything. Search if you want. Or just do some tests.

p.s. Actually we do that in one of our clusters cross 3 dcs.
",sitano,armon
2291,2016-08-18 23:37:32,"Currently points to http://localhost:4567/docs/guides/outage.html - should be https://www.consul.io/docs/guides/outage.html

Introduced by https://github.com/hashicorp/consul/commit/ee5740847ce80f6493e670953de0bdb0a9ec67e0

cc @slackpad :)
",CpuID,slackpad
2285,2016-11-18 00:18:47,"@sean- can you plz. look at this one wrt. to go-sockaddr?
",slackpad,sean-
2276,2016-08-23 04:30:41,"@sroskelley we'll need to keep an eye on when this drops, as it'll alleviate some of the problems we went over today :)

Great work all! 
",dwelch2344,sroskelley
2262,2016-08-24 02:08:18,"@slackpad PTAL
",WIZARD-CXY,slackpad
2262,2016-09-09 02:07:22,"@slackpad PTAL thx
",WIZARD-CXY,slackpad
2248,2016-11-10 01:41:12,"@slackpad Is this still happening? If yes, can I fix this?
",lucasalcantara,slackpad
2229,2016-08-02 07:45:12,"Ping @slackpad @ryanuber @armon 
",sethvargo,armon
2229,2016-08-02 07:45:12,"Ping @slackpad @ryanuber @armon 
",sethvargo,slackpad
2229,2016-08-02 07:45:12,"Ping @slackpad @ryanuber @armon 
",sethvargo,ryanuber
2227,2016-10-26 16:37:41,"@slackpad @joshuaspence I can tackle this. What should the format be for adding the timezone? 

Currently a timestamp in the log looks like this:
2016/10/26 09:28:13 [INFO]

Should the timezone simply follow the time?
2016/10/26 09:28:13 PST [INFO] for example
",mckennajones,slackpad
2215,2016-08-18 22:07:47,"@slackpad any comments on this??
",abhinavdahiya,slackpad
2203,2016-07-25 15:04:12,"Hey @slackpad, I added a very reproducible test and very simple soak test for this here:
https://github.com/FrankHassanabad/consul-e2e-tests-crashes

I uploaded my logs for when it occurs.

Also, I cloned consul, and from the v0.6.4 tag, I did _only_ an upgrade of boltdb.  Then when I reran the soak test again (overnight), it looked like the resize locking error did not show up again.

You don't need to restart windows or any other funny business.  Just soak test for a while and the error shows up eventually.
",FrankHassanabad,slackpad
2203,2016-07-26 16:52:38,"Yea, as a matter of fact @Tzinov15 is setting up a gatling stress test here right now:
https://github.com/Tzinov15/GatlingConsul

Using Gatling he was able to stress test and reduce the time to failure from hours to minutes.  Pretty cool stuff.

As soon as that's up, we will make a windows build of consul from master and give it a whirl.     
",FrankHassanabad,Tzinov15
2203,2016-07-27 15:09:57,"Hey @slackpad, I code reviewed what you checked in and then did a build of `master` on `windows 2000 R2` using `TDM-GCC` tool chain, and ran gatling against it with the boltdb upgrade.  `raft.db` was able to expand beyond `65 MB` to `256 MB` without any issues.

Test run was from @Tzinov15 here:
[SlamKeyValue](https://github.com/Tzinov15/GatlingConsul/wiki/Running-Gatling)

Here are the metrics from SlamKeyValue if you're curious (everything is ms and OK means REST response 200, KO means non REST 200 was returned, and a `-` means no KO):



The other 2 stress tests look to be passing as well.

Only artifact from upgrading boltdb I noticed was that `raft.db.lock` is a new file which shows up when boltdb opens the memory map.  Once it releases the memory map, the `raft.db.lock` file goes away.
",FrankHassanabad,Tzinov15
2200,2016-07-20 22:22:46,"Hi @mjcdiggity it sounds like you probably checked this, but are there any firewalls or network ACLs that could be at play here?
",slackpad,mjcdiggity
2200,2016-07-23 21:30:37,"@mjcdiggity for normal operation you'd want TCP and UDP on 8301, but that doesn't look like it's the issue looking at the logs. The servers not talking might be normal depending on the size of your cluster because agents will randomly choose another node to probe.

If the network looks good, the other thing we've seen cause issues is CPU starvation, especially on low end AWS instances. These often start shedding packets when things get busy.
",slackpad,mjcdiggity
2200,2016-10-31 22:31:10,"@mjcdiggity, did you ever find out what the problem was?

We are experiencing the same thing with a lot of our nodes. Here is an extract from the logs:



It does not seem to be consistent. If it was a firewall issue I would expect each node having problems to have the same problems consistently. None of these nodes is under much load.
",SunSparc,mjcdiggity
2175,2016-07-10 17:34:48,"cc: @slackpad @sean- 
",armon,slackpad
2175,2016-07-10 17:34:48,"cc: @slackpad @sean- 
",armon,sean-
2174,2016-07-10 12:31:25,"### All my nodes are servers
### `consul version`

Consul v0.6.4
Consul Protocol: 3 (Understands back to: 1)
### `consul info` for both Client and Server


### Operating system and Environment details

CentOS Linux release 7.0.1406 (Core)
### Description of the Issue (and unexpected/desired result)

Hi
I'm trying to change the tags of a service ""from outside"" (i.e. through the catalog) using the EnableTagOverride feature.
I've read the good explanation of @slackpad  about how EnableTagOverride works during service sync.
https://github.com/hashicorp/consul/issues/1572#issuecomment-170155251
However, it seems that if, after I change the tag on the catalog, a **check-sync** happens before a service-sync, then the check-sync copies the agent's tags into the catalog - like the behavior of a service **without** EnableTagOverride. 

Thanks in advance,
Motty
### Reproduction steps
1. Register a service using the agent (PUT v1/agent/service/register) with enableTagOverride=True and Tags=[""orig""], and with a health check (Here I use TTL, but I saw it also with a script check)
2. Change the tags using the catalog (PUT v1/catalog/register) with    {""Node"":..., ""Address"":..., ""Service"": {""Id"":..., ""Tags"": [""new""] }}
3. From time to time, read the service's tags both on the agent and the catalog (GET v1/agent/services, GET v1/catalog/service/<name>).  You will see ""new"" in the catalog but ""orig"" on the agent.
4. Change the health check status (v1/agent/check/warn) to induce syncing the check.

**Actual result**:  The tag ""orig"" on the agent remains, and is also copied to the catalog.
**Expected result**:  The tag ""new"" should remain in the catalog, and be copied to the agent.
**Note**: If you skip step 4 (or don't do it fast enough), a periodic service-sync occurs, and it yields the expected result.
### Log Fragments or Link to gist

I used `-log-level=TRACE` but then cut out the boring parts..
https://gist.github.com/motty-stratoscale/521c57bca424169ebf38b3917f9e37df
",motty-stratoscale,slackpad
2172,2016-07-07 18:30:36,"cc @amit-pivotallabs @kkallday
",zankich,kkallday
2172,2016-07-07 18:30:36,"cc @amit-pivotallabs @kkallday
",zankich,amit-pivotallabs
2170,2016-07-06 23:00:08,"This requires a bit of discussion and shouldn't be merged as-is without a conversation first.  Should servers attempt to drain their connections first or only the clients?  This patch does both atm.

CC @slackpad 
",sean-,slackpad
2160,2016-07-02 23:06:21,"/cc @slackpad
",ryanuber,slackpad
2156,2016-07-01 21:31:27,"/cc @slackpad 
",ryanuber,slackpad
2150,2016-06-29 12:09:34,"This isn't a bug, but an extension of a conversation that happened on a vault issue https://github.com/hashicorp/vault/issues/1273.

@jefferai recommended I make my suggestion here.

I created a logical backup utility https://github.com/BSick7/envoy that will dump the consul k/v store into a filesystem and archive into a tar.gz file. This github repo includes automated releases to ""GitHub Releases"".
",BSick7,jefferai
2144,2016-06-24 21:43:21,"With @dankraw we authored https://github.com/allegro/marathon-consul/ this is fork of https://github.com/CiscoCloud/marathon-consul that is no longer developed (see this comment https://github.com/CiscoCloud/marathon-consul/issues/17#issuecomment-161678453).
",janisz,dankraw
2137,2016-06-21 22:57:58,"Allows the use of the `Near` parameter in a prepared query definition. This parameter works just like the `?near=foo` HTTP API parameter, only it is baked into the query, allowing it to be used from the DNS interface. 

This enables some interesting functionality and opens up additional useful prepared query features when using DNS as the query mechanism.

/cc @slackpad 
",ryanuber,slackpad
2132,2016-06-20 23:19:29,"cc @sean- @slackpad 

A simple change that may make using consul health checks for leader health slightly easier. 
",pshima,slackpad
2132,2016-06-20 23:19:29,"cc @sean- @slackpad 

A simple change that may make using consul health checks for leader health slightly easier. 
",pshima,sean-
2118,2016-06-15 18:45:02,"Likely of interest to @slackpad and @evan2645.

This PR builds on https://github.com/hashicorp/consul/pull/1698. That PR translates a returned IP address to a WAN address when Consul is configured appropriately, but only through the DNS interface.

This PR additionally translates a node's address to the WAN address in the HTTP API. The rationale is:
- the DNS and HTTP APIs should return consistent results
- returning an IP local to DC1 to an HTTP client in DC2 is likely not useful (the client can't do anything with it)

The particular use case that motivated this change is ""using the HTTP API in a NAT'd, multi-DC environment, I want to query for all nodes providing service X, and I want to be able to connect to those nodes using the returned `Address`"".

The changes that this PR makes are:
- adding `TaggedAddresses` to the `ServiceNode` struct (so that the `catalog_endpoint.go`, in particular, has access to them and co do the WAN translation before returning the result)
- setting `TaggedAddresses` in the `ServiceNode` struct in `state_store.go`
- moving `translateAddr` into `agent.go` and modifying the signature slightly so that it can be used from both HTTP and DNS handlers
- translating node addresses in the following HTTP APIs (tests added for all)
  - `/v1/catalog/nodes`
  - `/v1/catalog/node/<node>`
  - `/v1/catalog/service/<service>`
  - `/v1/health/service/<service>`
  - `/v1/query/<query or name>/execute`

Added tests are passing, but it seems some of the existing tests are somewhat flaky and will occasionally fail. AFAICT, the failures don't have anything to do with this PR's additions.

First time Go user, view the code with suspicion :-).
",DWvanGeest,slackpad
2118,2016-06-15 18:45:02,"Likely of interest to @slackpad and @evan2645.

This PR builds on https://github.com/hashicorp/consul/pull/1698. That PR translates a returned IP address to a WAN address when Consul is configured appropriately, but only through the DNS interface.

This PR additionally translates a node's address to the WAN address in the HTTP API. The rationale is:
- the DNS and HTTP APIs should return consistent results
- returning an IP local to DC1 to an HTTP client in DC2 is likely not useful (the client can't do anything with it)

The particular use case that motivated this change is ""using the HTTP API in a NAT'd, multi-DC environment, I want to query for all nodes providing service X, and I want to be able to connect to those nodes using the returned `Address`"".

The changes that this PR makes are:
- adding `TaggedAddresses` to the `ServiceNode` struct (so that the `catalog_endpoint.go`, in particular, has access to them and co do the WAN translation before returning the result)
- setting `TaggedAddresses` in the `ServiceNode` struct in `state_store.go`
- moving `translateAddr` into `agent.go` and modifying the signature slightly so that it can be used from both HTTP and DNS handlers
- translating node addresses in the following HTTP APIs (tests added for all)
  - `/v1/catalog/nodes`
  - `/v1/catalog/node/<node>`
  - `/v1/catalog/service/<service>`
  - `/v1/health/service/<service>`
  - `/v1/query/<query or name>/execute`

Added tests are passing, but it seems some of the existing tests are somewhat flaky and will occasionally fail. AFAICT, the failures don't have anything to do with this PR's additions.

First time Go user, view the code with suspicion :-).
",DWvanGeest,evan2645
2103,2016-06-08 04:23:40,"Is it possible to query WAN addresses via the DNS interface?  I am running `dig @consul.mydomain.com consul.service.consul` and Consul always responds with the LAN addresses of the nodes.
",joshuaspence,consul
2092,2016-06-04 06:51:13,"Seeing this in [Travis CI](https://travis-ci.org/hashicorp/consul/builds/135208382) with the latest SCADA changes:



I'll take a look a bit later this weekend. I thought we deleted the agent-level class so this needs double check of a few things.

[Changes came in here](https://github.com/hashicorp/consul/commit/ebf7ea1d759184c02a5bb5263a7c52d29838ffc3) with [original PR here](https://github.com/hashicorp/consul/pull/2084).

/cc @jefferai 
",slackpad,jefferai
2089,2016-06-03 18:26:27,"In [the Google group](https://groups.google.com/forum/#!msg/consul-tool/09OkySyoSnA/MOsK5plxFQAJ) we discussed a problem with TTL health checks in PaaS-like or ""serverless"" environments where there are only servers and no agents. In these environments, Consul isn't collocated with the application client so there's no good way to assign a client to a particular server. This means Consul is making topology assumptions that work well for â€œmachines,â€ but are in conflict with other uses. We don't have VMs, so we don't need Consul to be aware of the underlying infrastructure and impose assumptions about it, but still want to be able to use Consul for service discovery in the application.

@misterbisson and I suggested that health checks (for TTLs) could be defined at the catalog level rather than the agent level. 

@slackpad responded with the following:

> This definitely would not make sense for any other health check type but I could see TTL checks being useful when used this way. There are two architecture questions we'd need to think through:
> 1. Having Consul servers manage TTL expiration for these checks would be a significant new feature. This is currently managed completely on the agent side and they send edge-triggered updates to the Consul servers when a TTL expires and the state changes, so Consul servers have no concept of what kinds of checks are present, and they don't know anything about check TTLs. We have some precedent for servers handling TTL expirations via sessions, and I have a design sketched out to make managing TTL expirations much more efficient, so it seems like we could work something out here to add potentially lots more TTL-expiring things to be managed by servers.
> 2. Agents currently provide a buffer between the load from refreshing TTLs (which the Consul servers never see) and service state changes (which the Consul servers see but happen much less often). Having many, many processes posting TTL refreshes directly to the servers could put a lot of extra load on them in a way that may not scale well. I don't think all the TTL refreshes should need to go through Raft, but we'd need to do some careful planning to make sure that's true so we don't create a bottleneck.
> 
> We'd want to have a solid plan for #2 before jumping into code - that's probably best worked out via a new Consul Github issue. I'm happy to help figure this out!

I'm happy to help contribute to the design discussion as well as a PR for this work when it comes to it.
",tgross,slackpad
2089,2016-06-03 18:26:27,"In [the Google group](https://groups.google.com/forum/#!msg/consul-tool/09OkySyoSnA/MOsK5plxFQAJ) we discussed a problem with TTL health checks in PaaS-like or ""serverless"" environments where there are only servers and no agents. In these environments, Consul isn't collocated with the application client so there's no good way to assign a client to a particular server. This means Consul is making topology assumptions that work well for â€œmachines,â€ but are in conflict with other uses. We don't have VMs, so we don't need Consul to be aware of the underlying infrastructure and impose assumptions about it, but still want to be able to use Consul for service discovery in the application.

@misterbisson and I suggested that health checks (for TTLs) could be defined at the catalog level rather than the agent level. 

@slackpad responded with the following:

> This definitely would not make sense for any other health check type but I could see TTL checks being useful when used this way. There are two architecture questions we'd need to think through:
> 1. Having Consul servers manage TTL expiration for these checks would be a significant new feature. This is currently managed completely on the agent side and they send edge-triggered updates to the Consul servers when a TTL expires and the state changes, so Consul servers have no concept of what kinds of checks are present, and they don't know anything about check TTLs. We have some precedent for servers handling TTL expirations via sessions, and I have a design sketched out to make managing TTL expirations much more efficient, so it seems like we could work something out here to add potentially lots more TTL-expiring things to be managed by servers.
> 2. Agents currently provide a buffer between the load from refreshing TTLs (which the Consul servers never see) and service state changes (which the Consul servers see but happen much less often). Having many, many processes posting TTL refreshes directly to the servers could put a lot of extra load on them in a way that may not scale well. I don't think all the TTL refreshes should need to go through Raft, but we'd need to do some careful planning to make sure that's true so we don't create a bottleneck.
> 
> We'd want to have a solid plan for #2 before jumping into code - that's probably best worked out via a new Consul Github issue. I'm happy to help figure this out!

I'm happy to help contribute to the design discussion as well as a PR for this work when it comes to it.
",tgross,misterbisson
2089,2016-06-09 11:58:44,"@slackpad I've spent a lot of this week getting to understand SWIM/Serf and how Consul agents gossip updates to the servers, and I think I've come around to this being a bad idea to change in Consul. It's really clear that having agents gossip but not participate in the raft is key to Consul scalability (particularly compared to etcd where all TTLs get sent up to the servers). I'd hate to introduce an architectural change that breaks this core advantage of Consul.

The specific use case we were running into with https://github.com/joyent/containerpilot/issues/162 we're going to solve with https://github.com/joyent/containerpilot/issues/175 and running a Consul agent as a co-process in the container. I may at some point explore the idea of a Consul agent _library_ (probably in C or Rust so it's can be embedded in arbitrary applications), but that's certainly out of scope for my current project or for Consul itself.

I'd be happy to close this issue if you're in agreement with the above @slackpad 
",tgross,slackpad
2080,2016-06-01 05:03:24,"Hi:
       i am doing a test. i run consul in three server



then, i login to each server and call `consul leave`.
after this,  i want to start the cluster again, but the cluster can not elect a leader

login 172.16.13.161



login 172.16.13.162



login 172.16.13.160



error log like below:



server - 172.16.13.160

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n1"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.160"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

server - 172.16.13.161

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n2"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.161"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}
`

server - 172.16.13.162
`
{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n3"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.162"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

after join, i found `null` in the file ${data_dir}/raft/peers.json, 
is it a bug ??? @armon @slackpad 
",zackshen,armon
2080,2016-06-01 05:03:24,"Hi:
       i am doing a test. i run consul in three server



then, i login to each server and call `consul leave`.
after this,  i want to start the cluster again, but the cluster can not elect a leader

login 172.16.13.161



login 172.16.13.162



login 172.16.13.160



error log like below:



server - 172.16.13.160

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n1"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.160"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

server - 172.16.13.161

{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n2"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.161"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}
`

server - 172.16.13.162
`
{
  ""datacenter"": ""dc1"",
  ""data_dir"": ""./data"",
  ""log_level"": ""INFO"",
  ""node_name"": ""n3"",
  ""server"": true,
  ""bind_addr"": ""172.16.13.162"",
  ""bootstrap_expect"": 3,
  ""addresses"": {
      ""http"": ""0.0.0.0""
  },
  ""ui_dir"": ""./ui""
}

after join, i found `null` in the file ${data_dir}/raft/peers.json, 
is it a bug ??? @armon @slackpad 
",zackshen,slackpad
2069,2016-05-25 06:19:42,"When I kill with `pkill -f consul` agent correctly leaves cluster:



And node status change to ""crit"":



With `pkill -f -9 consul`:



And node still have status ""passing"":



@armon Is that a bug, or what I'm doing wrong? Reproduced when agent is running on Centos 7. In Windows I don't see problems when killed agent with `taskkill /T /F /IM consul.exe`
",odiszapc,armon
2066,2016-06-12 07:08:37,"No idea about the snapshot files, but if my memory serves me right the data will still be there. This will sound obvious but if you care about your data, you'll need to test this yourself. My knowledge is based on an experiment I did over a year ago and it might behave differently now. If you do end up testing this, I'd love to know the results. 

@slackpad the page https://www.consul.io/docs/guides/outage.html doesn't address cluster failure recovery, and it's more or less absent from the other pages, too. I'm not sure if that's intentional but I think it would help others if the issue was addressed with more clarity. Nobody anticipates an entire cluster to fail but should that happen, can it be recovered after removing bad servers from each peers.json file? What would be the best approach to take? 
",shilov,slackpad
2057,2016-05-16 20:48:08,"/cc @kfishner
",sethvargo,kfishner
2056,2016-08-10 23:08:14,"Hi @mjcdiggity this looks possibly related - https://github.com/hashicorp/consul/issues/1610. Do you see any errors in your stderr log when starting?
",slackpad,mjcdiggity
2018,2016-05-04 00:45:48,"@slackpad This fixes https://github.com/hashicorp/consul/issues/2017

I verified the issue/fix by getting virtual box setup with Windows 10 and Internet Explorer.
",captainill,slackpad
2015,2016-08-07 22:38:17,"@sorenh I'm not entirely sure why I've had this tab open, but I want to make sure you're not accidentally setting `only_passing=false` in a config file someplace.  If you're still seeing this behavior, could you provide additional detail?

As for the intended behavior, if you look at `dns.go` unhealthy nodes are filtered out:

https://github.com/hashicorp/consul/blob/master/command/agent/dns.go#L553-L554

which is implemented in `Filter()`:

https://github.com/hashicorp/consul/blob/master/consul/structs/structs.go#L435-L436

So if that behavior isn't working as expected, we'd definitely be interested in learning more about what's going on in your situation.

If you `pkill -9 consul`, Serf will begin to fail, and the host should no longer be in the results because it is marked as critical as soon as the leader receives the serf failed member event.

Let us know!
",sean-,sorenh
2006,2016-06-02 23:08:40,"Hey @fusiondog, ah yes I forgot to mention that. I use recursors option actually, when I haven't applied the iptables rule everything was fine, I can resolve other TDL such google.com with this command `dig @localhost -p 8600 google.com`, but after I applied those rules I mentioned above, suddenly I couldn't resolve any host other than consul. Do you know why it's happen?
",akurniawan,localhost
2002,2016-06-22 09:34:40,"@sean- @slackpad 
Any update on this PR?
We hit the similar issue about the DNS retry.
",bingosummer,slackpad
1987,2016-04-26 03:35:12,"Hey @sean- @slackpad, we are looking to use consul in production but constantly hear that it may not be production ready. Will it be possible for you to share some large organizations which are using it in prod for us to touch base with. Would love to hear your opinion on the same too.

For reference we are looking ~ 6k vm running right now and moving to multiple docker containers per host very soon across 3 data centres. 

I'm fairly certain this question has been asked a billion times so I apologize in advance if it's already answered somewhere.  
",yagnik,slackpad
1987,2016-04-26 03:35:12,"Hey @sean- @slackpad, we are looking to use consul in production but constantly hear that it may not be production ready. Will it be possible for you to share some large organizations which are using it in prod for us to touch base with. Would love to hear your opinion on the same too.

For reference we are looking ~ 6k vm running right now and moving to multiple docker containers per host very soon across 3 data centres. 

I'm fairly certain this question has been asked a billion times so I apologize in advance if it's already answered somewhere.  
",yagnik,sean-
1965,2016-06-11 02:35:37,"Hey @fusiondog 

Stumbled upon your work when I was reading the mailing list and this really fits into what I'm experiencing as well.

I'd love to get Consul to output to graphite and have this kind of handler.

Have you been updating any of this work lately?

Perhaps we can discuss this with @armon as well in regards to getting the ball rolling again here? :)
",cdrage,armon
1962,2016-11-22 18:06:39,"@sethvargo is working on normalizing how the CLI commands all parse this stuff, and the RPC interface should be gone by 0.8.",slackpad,sethvargo
1952,2016-04-14 21:40:07,"Massive HTTP responses can cause performance problems when we store them unbounded in the state store. This applies the same 4K buffer we use for script checks to HTTP replies to avoid such overload.

/cc @slackpad
",ryanuber,slackpad
1941,2016-04-13 06:00:44,"I'm actually ok with this as-is since it's much more difficult to look at the agent's tags vs. look in the catalog. Doing the sync down to the agent will be a lot of complexity. @sean- feel free to re-open if you disagree.
",slackpad,sean-
1930,2016-11-18 00:13:10,"Sorry for delay responding to this one, and thanks for the PR @abhinavdahiya. What use case do folks have in mind for configuring this? It's a simple change, but we'd like to avoid extra complexity unless there's a compelling reason to be able to tweak this.
",slackpad,abhinavdahiya
1930,2016-12-09 02:26:02,"Just FYI - I have made a few other enhancements that I think will help this. PR will be in coming shortly. 

TL;DR: Currently consul does not serve back full URL paths in its `Location:` headers when it's doing redirects for the UI, nor does the UI itself append on the correct HTTP origin that accessed it in the first place. These things are necessary to properly support reverse proxies not just on things like port or host but on path as well.

I'll reference back this issue on the PR when I'm ready.

@abhinavdahiya maybe if you could look at it if you'd like and see if we could combine work to have the best of both patches. @slackpad your feedback would be welcome as well.",vancluever,abhinavdahiya
1929,2016-04-07 19:19:57,"Hi Hashicorp,

During our deployment of consul clusters, we validate that the cluster is working and synchronized by comparing the last_log_index to the commit_index, as reported by ConsulRPCClient.Stats(). As indicated by issue https://github.com/hashicorp/consul/issues/1092, it seems like if those numbers match then the node has successfully synchronized with the cluster.

Unfortunately, we are seeing a strange issue where the commit index stays at 0 forever, while the last log index is at 327 (so they never match). We hypothesize that for the commit index to stay at 0 forever, no leader election could ever have occurred since it seems like that alone bumps the commit index by ~10. If this is true, then we are surprised to see that the last log index is higher than the commit index since the node should reject writes in the absence of a leader. What do you think might be going on here?

Right after we see that the last_log_index is 327 and the commit_index is 0, consul writes this error message: [WARN] raft: Failed to get previous log: 575 log not found (last: 229411). This seems to indicate a discrepancy between the response from the stats RPC endpoint and the consul log, if we are correctly interpreting 229411 as the last_log_index. We also don't understand why this node would be trying to fetch log 575 if it already knows about all of the logs up through 229411.



Thanks,
George & @kkelani
",gdean123,kkelani
1929,2016-04-09 07:52:09,"Hi @gdean123 and @kkelani - I'm wondering if somehow you've got a rogue server with `-bootstrap` that's started itself as a leader and is sending bogus AppendEntries calls to cluster members that were part of an earlier quorum with an index way ahead, and where log compaction for 327 happened long ago.

Can you give some more details about your setup, what kind of steps you are performing when this happens, and maybe link some gists with more complete logs from the new server and one of the existing ones?
",slackpad,kkelani
1929,2016-04-11 19:31:08,"Hi @slackpad. Thanks for the response. We have limited logs and info because this is occurring from one of the users of our application however here is the info that we know:
- The setup is a 3-node cluster and started with `-bootstrap-expect`
- The user was performing an application upgrade which triggered a rolling deploy
- The following logs are from a client that was connected to the cluster which contains event logs
- After a certain amount of time, if the client is unable to verify sync (by comparing the commit_index and the last_log_index) with the cluster, the client will kill the consul agent and then retry.

Gist: https://gist.github.com/kkelani/97147077b5f1d26cc477c0cbdaca6873

Thanks
@christianang & @kkelani
",kkallday,christianang
1929,2016-04-11 19:31:08,"Hi @slackpad. Thanks for the response. We have limited logs and info because this is occurring from one of the users of our application however here is the info that we know:
- The setup is a 3-node cluster and started with `-bootstrap-expect`
- The user was performing an application upgrade which triggered a rolling deploy
- The following logs are from a client that was connected to the cluster which contains event logs
- After a certain amount of time, if the client is unable to verify sync (by comparing the commit_index and the last_log_index) with the cluster, the client will kill the consul agent and then retry.

Gist: https://gist.github.com/kkelani/97147077b5f1d26cc477c0cbdaca6873

Thanks
@christianang & @kkelani
",kkallday,kkelani
1904,2016-04-13 05:25:18,"Hi @Lswith thanks for opening an issue. Have you considered putting your forwarder on the other side of statsite? There are quite a few sinks floating around, including InfluxDB - https://github.com/armon/statsite/blob/master/sinks/influxdb.py.
",slackpad,Lswith
1903,2016-04-13 05:21:36,"Hi @cleung2010 thanks for the report. The only similar issue I've seen is https://github.com/hashicorp/consul/issues/1248, which we never got to the bottom of.
",slackpad,cleung2010
1888,2016-04-12 18:57:18,"Hi @markbugejacba this is a bit of a subtle artifact of configuring Consul to allow stale DNS responses. Assuming that you've enabled https://www.consul.io/docs/agent/options.html#allow_stale, there will be a window after the outage occurs (outage being no Consul leader) where Consul servers will still provide DNS results based on their own in-memory store. Once the https://www.consul.io/docs/agent/options.html#max_stale window has been exceeded, it will attempt to retry the RPC requests internally, which will fail because there's no leader, so you will start getting `SERVFAIL` responses.

Does this explanation fit with how you've got things configured? This seems like the right behavior given that stale responses are allowed, and lets the cluster better ride out brief moments without a leader, such as during leader elections. We are also planning on making this more robust with some internal retries under https://github.com/hashicorp/consul/issues/1554.

/cc @sean- 
",slackpad,sean-
1871,2016-04-01 03:04:44,"@slackpad what would you have in mind for WAN semantics to support this use case?  This is something we would be happy to submit a PR for.  Is it a ways away due to complexity, priority, both?

/cc @dieucao @onsi
",Amit-PivotalLabs,onsi
1871,2016-04-01 03:04:44,"@slackpad what would you have in mind for WAN semantics to support this use case?  This is something we would be happy to submit a PR for.  Is it a ways away due to complexity, priority, both?

/cc @dieucao @onsi
",Amit-PivotalLabs,dieucao
1858,2017-02-09 14:07:37,@slackpad @here I got into the same issue. Renamed the datacenter name and restarted the service. But lost access to the cluster. What would be the best steps we can follow to rename the datacenter name without affecting the running cluster? ,gvenka008c,here
1846,2016-03-18 19:47:53,"I see now why you did this, I noticed that Go's testing package includes a `private()` function in the interface to expressly prevent implementing it. The code seems reasonable. @slackpad any thoughts?
",ryanuber,slackpad
1838,2016-10-31 02:03:26,"@slackpad What should the expected behavior be in this case? Should consul error out if the -data-dir points to a consul binary? 
",mckennajones,slackpad
1838,2016-12-15 16:56:16,"Despite what I said in https://github.com/hashicorp/consul/pull/2529#issuecomment-263389938, during some testing with this change merge I realized I think we were auto-creating the directory before, so this might be a regression. @kyhavlov will take a look; pulling into the 0.7.2 release milestone.",slackpad,kyhavlov
1825,2016-03-10 21:17:22,"Got an LGTM from @jefferai - merging.
",slackpad,jefferai
1813,2016-03-09 07:11:16,"Took https://github.com/hashicorp/consul/pull/1734 by @idubinskiy and made a few minor tweaks.
",slackpad,idubinskiy
1810,2016-03-08 23:00:43,"@slackpad this is the display fix.

I also refactored so all style changes are in one file for clarity when announcement bnr is displayed.
",captainill,slackpad
1803,2016-03-09 15:49:23,"@slackpad (or someone with access) please add the ""docs"" label to this pull-request.
",tylert,slackpad
1789,2016-03-03 20:26:55,"@pearkes @KFishner
",captainill,pearkes
1789,2016-03-03 20:26:55,"@pearkes @KFishner
",captainill,KFishner
1779,2016-03-24 15:33:09,"Any update about this @slackpad? What are you thinking about here?
",BrianHicks,slackpad
1776,2016-03-10 07:06:08,"Hi @saswatp we are looking into some structured logging libraries so we can take a look at this along with that effort.

/cc @sean- 
",slackpad,sean-
1764,2016-02-26 09:56:05,"This is ready for review.

/cc @ryanuber and @sean-
",slackpad,ryanuber
1764,2016-02-26 09:56:05,"This is ready for review.

/cc @ryanuber and @sean-
",slackpad,sean-
1762,2016-02-26 04:00:15,"@slackpad This addresses https://github.com/hashicorp/consul/issues/1508
",mshean,slackpad
1757,2016-02-24 23:41:51,"The change in #1667 was a good one, but there is a bigger refactor going on under https://github.com/hashicorp/consul/pull/1743. Since we are likely cutting a 0.6.4 release before this lands, we will roll this back for now in favor of the upcoming change post-0.6.4 release.

/cc @sean- 
",slackpad,sean-
1752,2016-02-24 20:34:40,"Thanks to @kikitux for pointing out that there is an existing raw interface for reading keys that I totally didn't know was there :-)

> If the ""?raw"" query parameter is used with a non-recursive GET, the response is just the raw value of the key, without any encoding.

(from [here](https://www.consul.io/docs/agent/http/kv.html))

So the example would just be:

echo $(curl -s http://demo.consul.io/v1/kv/global/time?raw)

Sorry about that!
",slackpad,kikitux
1747,2017-03-20 22:03:09,"I agree that support for wildcards would be of great benefit to us. We have configuration data stored under different namespaces each ACL'ed off to the team that owns that namespace. Right now that involves explicitly denying every other namespace in every ACL. 40 teams = 1600 ACL rules and adding a rule to all 40 ACLs any time a new team is created :( . Being able to reduce that down to what @intelradoux suggested would be awesome.

@slackpack is there any update on possibly getting this support added?",hasPeterr,slackpack
1734,2016-02-19 20:52:28,"Per discussion with @slackpad on IRC, added another commit to the compression branch which adds an `enable_compress` config option and only tries compression if that one is set.

https://github.com/idubinskiy/consul/commit/fa72770bbddb5ddd4b916ceaa7f2f1b4c246378f
",idubinskiy,slackpad
1715,2016-02-13 02:42:00,"@sean- this is a legit borkage. Let's see if we get that weird error from the CI build for this branch.
",slackpad,sean-
1712,2016-02-12 20:25:22,"Based on work done by @fusiondog in #1583, extend the concept to use an integer instead of a boolean.  This is required to work around RFC3484 Section 6 Rule 9.

Fixes: #1583 && #1481
",sean-,fusiondog
1705,2016-02-17 04:16:45,"Hi @cleung2010 unfortunately, there's currently no zero-downtime way to cutover to TLS. We've had a few other folks run into this so we will take a look into how hard this would be to support.
",slackpad,cleung2010
1698,2016-02-07 21:47:26,"All of the real work here was done by @evan2645 under https://github.com/hashicorp/consul/pull/1547. This takes that PR and does the following:
- Rebased to latest master.
- Added some documentation and extra tests.
- Generalized the WAN address configuration into a first-class `TaggedAddresses` config item. This is populated only with the WAN address for now, but it gives us a good base to expose this as a configurable thing later for additional address tags.
- Changed the name of the `Node` structure member from `Addresses` to `TaggedAddresses`. Having `Addresses` next to `Address` was too subtle (even though it was my original suggestion to name it that, sorry to change it again).
- Made anti-entropy sync take care of setting this in the catalog instead of the Serf layer. This will be better if we add more later, and it keeps the logic out of some places like `leader.go`, and it doesn't add any new Serf tags where space is limited.
",slackpad,evan2645
1698,2016-06-09 17:06:17,"@slackpad thanks for your awesome work on this! We've been trying to use this feature but unfortunately it seems that it's only available through the DNS interface. What I would really like to see is the appropriately translated address available in the `""Address""` field of the node object when querying through the HTTP API.

I've been chatting with @evan2645 about this, and he thinks that the above should be do-able. I'm ready to start on a patch but wanted to check with you to see if there was any reason this isn't feasible, or if there was any reason it's a Bad Idea. Thanks!
",DWvanGeest,evan2645
1680,2016-06-14 19:18:11,"@slackpad discussed this earlier today with you - no need to create a duplicate... :)

Need to determine what the [HealthCheck](https://github.com/hashicorp/consul/blob/master/consul/structs/structs.go#L368-L380) type needs to look like, to augment it to expose the actual checks.

There were thoughts regarding future use of HCL from @sethvargo - and structuring the Go type/s to future proof it.

An initial brainstorm of a response JSON body would be something like:



Not super well thought out and I'm almost certain it will need to be tweaked, but something to start iterating against.

Related types:
- [CheckTCP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L467)
- [CheckHTTP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L341)

Things to consider:
- Expanding the single string key TCP and HTTP in each of the above types respectively to be pieces of a URI, or Hostname and Port separately. For example HTTP would become Scheme, Hostname, Port, URI. TCP would become Hostname and Port.
",CpuID,slackpad
1680,2016-06-14 19:18:11,"@slackpad discussed this earlier today with you - no need to create a duplicate... :)

Need to determine what the [HealthCheck](https://github.com/hashicorp/consul/blob/master/consul/structs/structs.go#L368-L380) type needs to look like, to augment it to expose the actual checks.

There were thoughts regarding future use of HCL from @sethvargo - and structuring the Go type/s to future proof it.

An initial brainstorm of a response JSON body would be something like:



Not super well thought out and I'm almost certain it will need to be tweaked, but something to start iterating against.

Related types:
- [CheckTCP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L467)
- [CheckHTTP](https://github.com/hashicorp/consul/blob/master/command/agent/check.go#L341)

Things to consider:
- Expanding the single string key TCP and HTTP in each of the above types respectively to be pieces of a URI, or Hostname and Port separately. For example HTTP would become Scheme, Hostname, Port, URI. TCP would become Hostname and Port.
",CpuID,sethvargo
1680,2016-11-16 19:51:13,"@slackpad _bump_ :)
",CpuID,slackpad
1679,2016-02-03 00:35:41,"There is this [old thread on googlegroups](https://groups.google.com/forum/#!msg/consul-tool/qewFEqgAoF8/b9hxhmy1v6gJ) asking about why consul warns to set GOMAXPROCS > 1 on startup.  Then there's [a commit](https://github.com/hashicorp/consul/commit/a61d89d0e66c6698d4b166aa457bf020d5c383cc) which removes these warnings due to changes in Golang 1.5.  But what about machines with 1 core?  In this case is it necessary to manually set GOMAXPROCS to something else?  And if so, does it matter what, is `2` ok?

/cc @fraenkel
",Amit-PivotalLabs,fraenkel
1669,2016-02-13 16:04:45,"@sean it's works with node but not for service.
If i try a reverse resolution with a node it works and return the name of the node, but i want reverse resolution for service (get the ip(s) of containers that running the service). Is it possible ?
",JrCs,sean
1661,2016-01-28 23:48:11,"I remember finding this a long time ago but I forgot to register it as a bug. Was talking with @slackpad last week and remembered.

I ran into it when a service that was writing config files failed and wrote a blank file into the folder - Consul then fails to start up - tries to parse and craps out.

Example output here:

https://gist.github.com/darron/7275837c7734041c5a4a

Not sure if it's something y'all can fix - guard against - but if it's possible that would likely be pretty awesome.

Thanks for the great software!
",darron,slackpad
1661,2016-02-17 07:33:11,"Thanks for fixing this @slackpad and @alistanis - appreciate that!
",darron,alistanis
1656,2016-06-15 20:42:45,"@slackpad after taking look at the https://www.consul.io/docs/guides/datacenters.html, particularly this fragment 

> The join command is used with the -wan flag to indicate we are attempting to join a server in the WAN gossip pool. As with LAN gossip, you only need to join a single existing member, and the gossip protocol will be used to exchange information about all known members. For the initial setup, however, each server will only know about itself and must be added to the cluster.

It appears to me that this is in fact a bug and this issue should be relabeled accordingly
",takeda,slackpad
1632,2016-01-20 05:58:40,"This fixes #1626.

The basic problem is that we were returning the underlying `NotifyGroup` object here:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L100-L112

This worked fine the first time through, but when a prefix was notified, this `NotifyGroup` would get deleted:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L140-L143

So in a blocking RPC, once you looped around because the watch was notified, you'd end up calling `Wait()` on a `NotifyGroup` that was no longer part of the watch manager:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/rpc.go#L342

The solution is to never expose the underlying `NotifyGroup` to the blocking RPC code. I created a wrapper object that re-registers the wait channel with whatever `NotifyGorup` is in the tree, or it creates one.

This bug was pretty subtle because you had to have these conditions:
1. Make a blocking query on some key ""A"".
2. Update some key ""B"" whose key is a prefix of ""A"".

This is probably not super common, but this would have been difficult to detect. The query timeout would eventually un-block the first query, but it would report stale results from the first time it looked at the state store.

/cc @armon or @ryanuber 
",slackpad,armon
1632,2016-01-20 05:58:40,"This fixes #1626.

The basic problem is that we were returning the underlying `NotifyGroup` object here:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L100-L112

This worked fine the first time through, but when a prefix was notified, this `NotifyGroup` would get deleted:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/state/watch.go#L140-L143

So in a blocking RPC, once you looped around because the watch was notified, you'd end up calling `Wait()` on a `NotifyGroup` that was no longer part of the watch manager:

https://github.com/hashicorp/consul/blob/v0.6.0/consul/rpc.go#L342

The solution is to never expose the underlying `NotifyGroup` to the blocking RPC code. I created a wrapper object that re-registers the wait channel with whatever `NotifyGorup` is in the tree, or it creates one.

This bug was pretty subtle because you had to have these conditions:
1. Make a blocking query on some key ""A"".
2. Update some key ""B"" whose key is a prefix of ""A"".

This is probably not super common, but this would have been difficult to detect. The query timeout would eventually un-block the first query, but it would report stale results from the first time it looked at the state store.

/cc @armon or @ryanuber 
",slackpad,ryanuber
1630,2016-02-02 02:33:38,"Hi @Millnert,

Normally, Consul only verifies that a certificate is signed by a configured CA, it doesn't look at the hostnames. The config you cited is used by this feature - https://www.consul.io/docs/agent/options.html#verify_server_hostname. If `verify_server_hostname` is turned on, then Consul will also verify the hostname is `server.<datacenter>.<domain>`. This lets you create a special certificate just for servers to keep random clients with valid certificates from acting as a server.

I tagged this as docs because I think we can enhance the documentation about this. Does this make sense?

/cc @sean- 
",slackpad,sean-
1624,2016-02-02 01:38:36,"Hi @panda87 I took a look back through the code and these have been floats since the beginning. I'll tag @armon to see if he can lend any insight into why they were built this way, but I'll go ahead and close this out since it is the intended behavior and didn't change in 0.6.x.
",slackpad,armon
1622,2016-01-18 18:55:05,"Changing api.Client to interface will break all programs using consul/api since `*api.Client` will have to change to `api.Client`. We should probably add newly named interfaces and transition to them while still supporting old API. @armon ?
",avishai-ish-shalom,armon
1592,2016-01-13 05:11:45,"This is the Consul side of https://github.com/hashicorp/consul-template/pull/511. Unit tests look good as a regression - I will do some integrated testing in the morning, similar to what was done in the CT PR.

/cc @sethvargo 
",slackpad,sethvargo
1576,2016-07-01 00:10:36,"Hi again @ryanu, @mitchellh. I following up to see if official Windows support for server is still likely to land in 2016. Our use cases keep piling up :)

Thanks. 
",donaldquixote,ryanu
1576,2016-07-15 14:00:03,"@ryanu, @mitchellh   I have a client which is mostly windows. We are using AWS. We use packer, terraform already. We have under utilized windows servers I can use to start using Consul and Vault. I used chocolatey packages created by you guys to install consul as a service. I see a warning about lack of production support for consul on windows. A guide for consul on windows along with official support will help for sure. 
",rajinders,ryanu
1570,2016-08-09 22:37:43,"@slackpad What can I do to help push this forward? This would really help me with some overlay/underlay networking stuff. There seems to be a merge conflict now, but the patch looks pretty self contained, so I'd imagine it is easy to resolve. I'd be happy to resolve the conflicts and make a new PR. I suspect there is something more keeping this from getting merged.
",ChrisLundquist,slackpad
1567,2016-01-22 22:18:06,"Hi @isaacg we didn't design this feature with this use case in mind, but it seems like it could be possible to use it as part of a solution for this. One problem I can see though is that being able to take the lock doesn't necessarily mean that it's safe to take a server down, so doing this in a safe way would require more logic. For example, if one server out of three died during the upgrade and lost the lock, a second one would be able to get it and restart itself, putting the cluster into an outage condition. You'd still want to confirm things like `last_log_index` on the newly-added server before rolling another one - https://www.consul.io/docs/guides/servers.html.

For your second question, I named the `DefaultMonitorRetryTime` in case we decided to make it configurable later but opted for a 1 second time with just a configurable number of retries to keep the number of config knobs down. The time between retries isn't as important as the total time taken attempting retries so that seemed more important. I suppose if you had tons of nodes trying locks you might want to make that larger to avoid a thundering herd, but that's probably not a super common use case for locks.
",slackpad,isaacg
1566,2016-02-09 23:23:44,"@slackpad - if you have any ideas about a test that could be added to ensure this builds in the project's tests overall, let me know.  I had to update this as the provision script was failing due to an old consul version being removed, and wouldn't want it to break again in the future without warning.
",jzohrab,slackpad
1559,2016-01-02 14:59:16,"Wanted to give @railsguru credit for a fix that I missed previously and was added later by someone else but it ended up duplicating the token variable. This fixes it.
",slackpad,railsguru
1554,2016-02-02 03:14:25,"/cc @sean- 
",slackpad,sean-
1548,2016-01-12 08:21:23,"@ryanbreen Thanks very much!
",kikitux,ryanbreen
1547,2015-12-24 15:57:49,"Often times, it is necessary to discover and communicate with a service in a different datacenter which is behind a NAT. Currently, only Consul servers have the concept of a WAN address. Here, we re-use this knob to enable clients to set their WAN addresses as well, and introduce a new configuration option to instruct Consul to prefer the WAN address (if set) when making cross-DC requests.

@slackpad this feature is a blocker for us. Solves #1386. I have not written much go, so please let me know if anything here is non-idiomatic.
",evan2645,slackpad
1543,2015-12-22 17:48:24,"Adds the static web assets into the Consul binary with an explicit flag required to enable.
Thanks to @rgl for prior art in #1274.
",ryanuber,rgl
1539,2015-12-22 05:53:05,"/cc @ryanuber or @sethvargo for review
",slackpad,ryanuber
1539,2015-12-22 05:53:05,"/cc @ryanuber or @sethvargo for review
",slackpad,sethvargo
1534,2015-12-21 09:24:22,"Following the discussion here: https://groups.google.com/d/topic/consul-tool/SJYfMMcE9xI/discussion

We are powering off all the nodes of a 5-node cluster, and powering them back up (this is an instant powerdown, not a graceful one, so the nodes rejoin the cluster after we restart them). 
After the cluster crash, ""consul members"" seems fine, but in about 1 of every 3 cases, we see that the following HTTP requests are hanging:
http://localhost:8500/v1/agent/services
http://localhost:8500/v1/agent/checks
In comparison, the /v1/agent/self request works fine.

This happens with 0.6.0, but also with older versions (0.5.0).

Per @slackpad 's recommendation, we collected debug info about the go routines. If I run the debug/pprof/goroutine command a few times, while the HTTP request is hanging, I see that over time the number of go routines is growing all the time.

Attached is the latest output. 

TIA.
[goroutines.txt](https://github.com/hashicorp/consul/files/68284/goroutines.txt)
",shimshon-stratoscale,slackpad
1534,2016-02-08 06:22:13,"Thanks @slackpad for the analysis. Indeed in this state we found out we cannot write to the KV store.
I had a correspondence on the outage issue with @armon in the past (see here: https://groups.google.com/forum/#!topic/consul-tool/k1ZnMHVwobA ), in which he said that if we restart each of the consul agents with the same flags they had in their previous run, we should be ok - has that changed?
BTW - we added a post-restart code that upon detecting that writes are stuck, it restarts the consul process. Sometimes it takes multiple restarts, but eventually it works. However, that's just a workaround. Appreciate your input on this.
",shimshon-stratoscale,armon
1517,2015-12-17 06:31:56,"This is a take on #1499 that implements as much pooling as possible, drafting off of @orivej work and suggestions.
",slackpad,orivej
1503,2015-12-28 22:19:34,"@slackpad Yeah, looking at it again, I don't think I need it either. Removed. Also rebased on master.
",nicholascapo,slackpad
1500,2015-12-19 07:11:41,"Hi @ErikEvenson take a look at https://github.com/sethvargo/atlas-demo - that's got an end-to-end demo with Consul that should be helpful (though be careful it is set up to allow open access for demo-ing). There are some ssh examples for key handling in there.

/cc @sethvargo 
",slackpad,sethvargo
1500,2015-12-21 16:07:46,"@slackpad @erikdubbelboer here are some more examples:
- https://github.com/sethvargo/terraform-workshop-atlas
- https://github.com/hashicorp/best-practices
",sethvargo,erikdubbelboer
1493,2015-12-11 15:23:25,"/cc @armon
",sethvargo,armon
1493,2015-12-14 19:43:10,"Thanks @sethvargo (and @tgwizard I fixed that)!
",slackpad,tgwizard
1489,2015-12-10 23:19:03,"cc: @dadgar 
",c4milo,dadgar
1484,2015-12-10 02:22:50,"@tymofii-polekhin yep exactly, that sounds like the exact symptom.
",ryanuber,tymofii-polekhin
1472,2015-12-07 16:09:40,"I have an apprentice who needs a real project to work on to level up his skills. I would like to work with him upgrading this codebase to latest version of Ember and to EmberCLI. 

Do you have any objections to this? Would you be open to merging such a PR?

/cc @pearkes @tiwilliam
",taras,pearkes
1472,2015-12-07 16:09:40,"I have an apprentice who needs a real project to work on to level up his skills. I would like to work with him upgrading this codebase to latest version of Ember and to EmberCLI. 

Do you have any objections to this? Would you be open to merging such a PR?

/cc @pearkes @tiwilliam
",taras,tiwilliam
1467,2015-12-04 04:53:11,"I was testing the final 0.6.0 build of the web UI and realized that the settings icon is broken:

It's missing on Chrome:

![image](https://cloud.githubusercontent.com/assets/673509/11582111/50e999ec-99ff-11e5-9a68-cca10123186e.png)

And it looks super weird on Safari:

![image](https://cloud.githubusercontent.com/assets/673509/11582120/630c3b98-99ff-11e5-95d3-73fd5d20aa48.png)

Here's how it used to look:

https://www.consul.io/assets/images/consul_web_ui-aeb578f2.png

This has been deployed to the demo cluster if you want to take a look here - http://demo.consul.io/ui/. I don't think this is a show stopper for release since it's easy to update the web UI, but it would be nice to fix soon.

/cc @pearkes @meirish 
",slackpad,pearkes
1467,2015-12-04 04:53:11,"I was testing the final 0.6.0 build of the web UI and realized that the settings icon is broken:

It's missing on Chrome:

![image](https://cloud.githubusercontent.com/assets/673509/11582111/50e999ec-99ff-11e5-9a68-cca10123186e.png)

And it looks super weird on Safari:

![image](https://cloud.githubusercontent.com/assets/673509/11582120/630c3b98-99ff-11e5-95d3-73fd5d20aa48.png)

Here's how it used to look:

https://www.consul.io/assets/images/consul_web_ui-aeb578f2.png

This has been deployed to the demo cluster if you want to take a look here - http://demo.consul.io/ui/. I don't think this is a show stopper for release since it's easy to update the web UI, but it would be nice to fix soon.

/cc @pearkes @meirish 
",slackpad,meirish
1463,2015-12-02 17:06:18,"While testing the example snippets in my blog post I realized you can register the same name multiple times.

/cc @ryanuber or @armon 
",slackpad,armon
1463,2015-12-02 17:06:18,"While testing the example snippets in my blog post I realized you can register the same name multiple times.

/cc @ryanuber or @armon 
",slackpad,ryanuber
1452,2015-11-28 01:22:16,"Shrink idle yamux streams in the connection pool to reduce memory overhead. Otherwise, each stream may allocate up to 512KB of buffers, and we may have up to 64 idle streams per remote peer.

/cc: @slackpad 

Depends on https://github.com/hashicorp/yamux/pull/21
",armon,slackpad
1451,2015-11-27 18:25:20,"dig @treverpietsch.com zookeeper.service.consul SRV

; <<>> DiG 9.8.3-P1 <<>> @treverpietsch.com zookeeper.service.consul SRV
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NXDOMAIN, id: 37646
;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0

;; QUESTION SECTION:
;zookeeper.service.consul.  IN  SRV

;; AUTHORITY SECTION:
.           8119    IN  SOA a.root-servers.net. nstld.verisign-grs.com. 2015112701 1800 900 604800 86400

;; Query time: 5 msec
;; SERVER: 67.188.113.121#53(67.188.113.121)
;; WHEN: Fri Nov 27 10:35:03 2015
;; MSG SIZE  rcvd: 117

same command internal/external has different answers

my initial post has the response form a local network
",tpietsch,treverpietsch
1451,2015-11-27 18:42:02,"OK, and you are certain that port 53 on `treverpietsch.com` forwards to the DNS port on a node in your Consul cluster?  I can't think of a reason why the Consul server would give a different answer to dig if the same command is being run, regardless of what network it originated from.  `dig` is just making a DNS query to a service; there's no magic in there based on what network it's coming from.

Can you paste the config from your Consul server?

Also, I noticed that in your example output from dig on an external network, the response is for an `A` record, not a `SRV` record.  I wouldn't expect that to be the case if the command you ran was `dig @treverpietsch.com zookeeper.service.consul SRV`.
",ryanbreen,treverpietsch
1450,2015-11-26 02:02:35,"These warnings no longer make sense for Go 1.5+ since it now defaults to the number of CPUs present. They will fire only on single core machines now and we don't want those people oversubscribing their single-core machines so this is strictly giving bad advice.

/cc @armon 
",slackpad,armon
1445,2015-11-23 18:48:39,"This came up in https://github.com/hashicorp/consul/commit/8738f9780bd30f628508d4e721df0d77ad0bd3b7#commitcomment-14566231. It looks like it's probably https://github.com/golang/go/issues/8998, but I couldn't find a newer version of `wget` for precise64, and I couldn't find a good newer Ubuntu box with VMWare support, so I switched to `curl` which checks the cert successfully.

/cc @catsby 
",slackpad,catsby
1432,2016-05-17 18:30:12,"@slackpad Is there anything that prevents merging this PR?
",t3hk0d3,slackpad
1428,2015-11-19 04:32:12,"I have a Consul cluster with 2.8 million garbage `/vault/core/leader` entries (resulting from a bug in some older versions of Vault - https://github.com/hashicorp/vault/issues/679) that hurts Consul KV and UI performance (operations apparently take too long and timeout because of the number of keys that have to be crawled - https://github.com/hashicorp/consul/issues/1407). 

I had no idea that I had accumulated this huge number of keys until things got slow and started timing out and then @slackpad recognized the symptoms and suggested running `strings state.bin | grep vault/core/leader | wc -l` to count the number of keys.

To prevent this in the future I'd like to set up monitoring (e.g.: Nagios, Zabbix, etc.) that can watch the number of keys. It would be best if the Consul HTTP API had a method that exposed the # of keys.

Looking at https://www.consul.io/docs/agent/http/status.html, I wonder if something like `/v1/status/keys` would make sense. It could look something like this:



or maybe it makes more sense to live under the `/kv` API and then maybe it could support returning the count of keys under a certain prefix?



Cc: @sudarkoff
",msabramo,slackpad
1428,2015-11-19 04:32:12,"I have a Consul cluster with 2.8 million garbage `/vault/core/leader` entries (resulting from a bug in some older versions of Vault - https://github.com/hashicorp/vault/issues/679) that hurts Consul KV and UI performance (operations apparently take too long and timeout because of the number of keys that have to be crawled - https://github.com/hashicorp/consul/issues/1407). 

I had no idea that I had accumulated this huge number of keys until things got slow and started timing out and then @slackpad recognized the symptoms and suggested running `strings state.bin | grep vault/core/leader | wc -l` to count the number of keys.

To prevent this in the future I'd like to set up monitoring (e.g.: Nagios, Zabbix, etc.) that can watch the number of keys. It would be best if the Consul HTTP API had a method that exposed the # of keys.

Looking at https://www.consul.io/docs/agent/http/status.html, I wonder if something like `/v1/status/keys` would make sense. It could look something like this:



or maybe it makes more sense to live under the `/kv` API and then maybe it could support returning the count of keys under a certain prefix?



Cc: @sudarkoff
",msabramo,sudarkoff
1427,2015-11-19 04:05:23,"I have a Consul cluster with 2.8 million garbage `vault/core/leader` entries (resulting from a bug in some older versions of Vault - https://github.com/hashicorp/vault/issues/679) that hurts Consul KV and UI performance (operations apparently take too long and timeout because of the number of keys that have to be crawled - https://github.com/hashicorp/consul/issues/1407). 

After some discussion, the suggestion came up to try doing a DELETE to `/kv?recurse`. 

This unfortunately never completed and seems to still be running or queued and preventing all other operations from succeeding, making Consul unusable (@wwalker noticed this bad behavior as well in hashicorp/consul#1278). 

Ideally there would be something I could to do to get Consul out of this state and back to a usable state, without having to reinitialize the cluster and lose data. 

Cc: @sudarkoff
",msabramo,wwalker
1427,2015-11-19 04:05:23,"I have a Consul cluster with 2.8 million garbage `vault/core/leader` entries (resulting from a bug in some older versions of Vault - https://github.com/hashicorp/vault/issues/679) that hurts Consul KV and UI performance (operations apparently take too long and timeout because of the number of keys that have to be crawled - https://github.com/hashicorp/consul/issues/1407). 

After some discussion, the suggestion came up to try doing a DELETE to `/kv?recurse`. 

This unfortunately never completed and seems to still be running or queued and preventing all other operations from succeeding, making Consul unusable (@wwalker noticed this bad behavior as well in hashicorp/consul#1278). 

Ideally there would be something I could to do to get Consul out of this state and back to a usable state, without having to reinitialize the cluster and lose data. 

Cc: @sudarkoff
",msabramo,sudarkoff
1419,2016-03-05 01:29:07,"@sean- and I were thinking more about this and we can probably eliminate all ACL caching in favor of this if it's full ACL replication. We'd create a new endpoint that supports blocking queries and provides a complete snapshot of ACLs (SHA256 hash of token and policy), or we could make a fancier API that can intelligently send updates after an initial full dump. Any server with the replicated ACLs can hash an incoming token and look up the policy, but won't have any other access to the actual tokens. If we do full replication, we can eliminate the ACL cache code completely, which would massively simplify that code path.

We can still support the old ACL endpoint to fetch a policy for a token, so for upgrades you just need to upgrade your ACL DC to Consul 0.7 before you upgrade any of your other servers.
",slackpad,sean-
1408,2015-11-12 00:09:30,"We're working on some code that interacts with the agent via RPC.  For tests of this client, it is useful to mock out the Agent, but still lean on the AgentRPC.

This change enables us to pass a mock Agent object into the AgentRPC constructor.

cc @rosenhouse
",njbennett,rosenhouse
1408,2016-03-19 00:16:34,"cc: @ryanmoran @zankich you guys are maintaining [Consul Release](https://github.com/cloudfoundry-incubator/consul-release) now, right?
",rosenhouse,zankich
1408,2016-03-19 00:16:34,"cc: @ryanmoran @zankich you guys are maintaining [Consul Release](https://github.com/cloudfoundry-incubator/consul-release) now, right?
",rosenhouse,ryanmoran
1404,2015-11-11 16:34:14,"Along similar lines to https://github.com/hashicorp/vault/issues/765, should Consul also print its version when starting up, to aid in troubleshooting?

Currently it prints info that's very similar to what Vault prints:



I figure it might as well print the version, just like Vault now does, thanks to @jefferai's fine work on https://github.com/hashicorp/vault/issues/765
",msabramo,jefferai
1376,2015-10-30 21:59:38,"We should add a CLI to manipulate bootstrap mode vs. flags or configs. If it manipulates the state of consul's data directory, it should be a one-shot command that can not be in a config file or a command line argument that is accepted by the `consul agent` sub-command.  For example:
1. `consul set encrypt-key=foo`
2. `consul agent`

The encrypt key can't be specified on the agent line.  Same for bootstrap flags.

/cc @sean-
",slackpad,sean-
1375,2015-10-30 21:56:01,"Right now they hopelessly keep trying and spam the logs. They could wait for the event before they try again.

/cc @sean-
",slackpad,sean-
1374,2015-10-30 21:55:03,"While interactively debugging an issue with @sean- a number of improvements were noted:
1. It's hard to tell who a server is replicating TO, add IPs to the logs.
2. It's hard to tell who the current leader is without logging into each and looking at `consul info`, make `consul members` show who the current leader is.
3. Consider adding a `consul peers` type command that shows the Raft details in a clear, parseable format. The peer set version is hard to understand, expose the Raft index.
4. Add better metrics for Raft-related events such as leader elections. Right now we can only look at events which are output by all the nodes, so it's really hard to see the actual number of leadership transitions.
",slackpad,sean-
1374,2016-03-01 21:06:57,"Hi all - this hasn't yet been implemented. I'd hold off on working on this for right now - @sean- is looking at a cluster-level status endpoint that would support this type of info. We should have more details in a bit.
",slackpad,sean-
1374,2016-06-08 01:21:20,"@slackpad or @sean- do either of you have any updates on this issue?
",CpuID,sean-
1370,2015-11-11 04:15:21,"@slakpad please take a look at this
",half-dead,slakpad
1368,2015-10-29 23:05:30,"Hello,

We'd like to write some Go code that rotates the encryption keys used by our Consul cluster.  We don't see a way to do this via the HTTP API or the Go `api` package and we'd like to avoid shelling out to the consul CLI `keyring` command.  We've considered reaching into the [`RPCClient` in the `command` package](https://github.com/hashicorp/consul/blob/master/command/rpc.go) used by the CLI, but are concerned about taking a dependency on something that isn't supported for public consumption.

What is the recommended way to programmatically rotate encryption keys?

Thanks!

cc @zaksoup
",rosenhouse,zaksoup
1365,2015-10-29 20:12:48,"This avoids a redirect by adding a trailing slash... it's the little things in life.

/cc @slackpad 
",sethvargo,slackpad
1359,2015-10-29 02:16:21,"In general, coordinate updates are funneled to the leader who batches them in a local data structure and writes them to the Raft log after a timer fires. This helps cut down on the number of Raft transactions due to coordinates. If there's a leadership transition with unwritten batch items, the follower node will emit this:

`2015/10/29 01:51:27 [ERR] consul.coordinate: Batch update failed: node is not the leader`

As its implemented, the follower will throw these updates away, so it does the right thing and doesn't keep spamming. This is pretty ugly, though. We should flush the batch during leader transitions and only run the updater while we are the leader.

/cc @armon - can you think of any reason this is unsafe as-is?
",slackpad,armon
1354,2015-10-28 01:21:16,"Noticed that index.html expects these to be in a subfolder, and it's easier for development to put them in there, I think, vs. deleting the subfolder.

/cc @sethvargo 
",slackpad,sethvargo
1344,2015-10-26 21:30:56,"/cc @slackpad 
",sethvargo,slackpad
1337,2016-02-05 05:22:00,"@AlexisSellier thank you for the tip, we have been running into this issue as well, 0.6.3 helps a lot, we only received a few flapping a day, compared to before where we received a few flapping every 15 minutes. 
@slackpad I wonder if we can tune these values at the config file level ?
",changwuf31,slackpad
1334,2015-10-26 15:02:37,"Original context here from #1300:

> @TannerFilip reported on https://webcompat.com/issues/1806 a bug about Header which isn't readable on Firefox (and Same on Internet explorer).
> This patch fixes the bug.
> webcompat/web-bugs#1806

So my patch will re-break it on FF and IE, if there's a fix that satisfies those it would be good to get in here.
",slackpad,TannerFilip
1331,2015-10-23 22:30:48,"This should complete network tomography on the Consul side. There was a pretty major rebase after the memdb changes, so the final commit (https://github.com/hashicorp/consul/commit/ecd3a1d1d21d635fd62555b710abbb9bc76d0eff) has the major changes associated with that. That change is worth a quick review, everything else has been reviewed previously.

Here are the biggest changes made during the rebase:
1. While in here I realized that the state store would accept coordinates for nodes that weren't in the catalog. Since deleting coordinates is tied to deleting nodes, and we don't really control if agents send coordinates before they have successfully been registered in the catalog, this seemed like a potential for inconsistency. I made the state store just skip coordinate updates for nodes not in the catalog, which required some changes to unit tests.
2. Got rid of the single coordinate get function since it was only used in unit tests.
3. Beefed up unit tests in some places.
4. Cleaned up the coordinate types in the structs package.

/cc @armon and/or @ryanuber 
",slackpad,armon
1331,2015-10-23 22:30:48,"This should complete network tomography on the Consul side. There was a pretty major rebase after the memdb changes, so the final commit (https://github.com/hashicorp/consul/commit/ecd3a1d1d21d635fd62555b710abbb9bc76d0eff) has the major changes associated with that. That change is worth a quick review, everything else has been reviewed previously.

Here are the biggest changes made during the rebase:
1. While in here I realized that the state store would accept coordinates for nodes that weren't in the catalog. Since deleting coordinates is tied to deleting nodes, and we don't really control if agents send coordinates before they have successfully been registered in the catalog, this seemed like a potential for inconsistency. I made the state store just skip coordinate updates for nodes not in the catalog, which required some changes to unit tests.
2. Got rid of the single coordinate get function since it was only used in unit tests.
3. Beefed up unit tests in some places.
4. Cleaned up the coordinate types in the structs package.

/cc @armon and/or @ryanuber 
",slackpad,ryanuber
1317,2015-10-17 18:25:01,"I am trying to set up Route53 so that instances on the same VPC as the consul cluster can hit .consul endpoints.

For experimental purpose I got one of the three server nodes set up with DNS forwarding set up using BIND (private IP 172.31.56.55) to act as the nameserver as suggested [here](https://www.consul.io/docs/guides/forwarding.html) with the addition of `allow-query { any; }` and `listen-on port 53 { any; };`.

I have a ""consul."" hosted zone with the following SOA, NS, and A (glue) records:
SOA:



NS:



ns1.consul A:



If I specify `@ns1.consul` in the `dig` command it works, but if I leave it out it doesn't. What am I missing/misconfiguring?




",calvn,ns1
1317,2015-11-17 23:39:15,"@cleung2010 It seems to be a general question, not a bug in the consul code. If so, this may be a better fit for [StackOverflow](https://stackoverflow.com/questions/tagged/consul). I'd suggest closing this issue and posting a question on SO.
",sandstrom,cleung2010
1313,2015-10-16 12:08:50,"I have a consul server cluster with 3 nodes and one consul client agent
Consul version: Consul v0.5.2

Th servers agents are configured with the following config snippent

{
""datacenter"": ""dc1"",
  ""acl_datacenter"": ""dc1"",
  ""acl_master_token"": ""8fa14cdd754f91cc6554c9e71929cce7"",
  ""acl_default_policy"": ""deny"",
}

The client Agent is configured like.
{
 ""acl_datacenter"": ""dc1"",
  ""acl_default_policy"": ""deny"",
}

I tried to register a service without any token

curl -i -v -X PUT -d @register_service.json  http://localhost:8500/v1/agent/service/register

the response from the agent is : 200 OK succes

but the client agent logs the below message
2015/10/16 17:30:19 [WARN] agent: Service '8888' registration blocked by ACLs

When I checked in the UI from the server, the service is not registered but the service is registered in the client agent

Executed on client agent: (the serviceA returned)
curl http://localhost:8500/v1/agent/services
{""8888"":{""ID"":""8888"",""Service"":""serviceA"",""Tags"":null,""Address"":""10.10.10.2"",""Port"":8083}}

On server agent: (no services returned)
curl http://localhost:9500/v1/catalog/services
{""consul"":[]}

I am wandering if the service can not be registered in the server catalog, then why the client agent is registering it successfully and returning the 200 OK success response?

Please let me know if I am missing some config setting or is it the intended behavior.  I have a use case if my service cant not be registered successfully then the service should not run.

Thanks,
Manoja
",ManojaMishra,register
1311,2016-02-05 22:46:57,"Hey @slackpad 

Thanks for following up.  Yes, we're still having this issue.  We [guarantee data persistence when scaling up from 3 to 5](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L80-L100) whereas we [only guarantee the cluster is functional after scaling up from 1 to 3](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L28-L46). @ryanmoran and @zankich spoke with @mitchellh and some HashiCorp folks when they visited our office, sounded like this is something we have to live with for now.
",Amit-PivotalLabs,zankich
1311,2016-02-05 22:46:57,"Hey @slackpad 

Thanks for following up.  Yes, we're still having this issue.  We [guarantee data persistence when scaling up from 3 to 5](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L80-L100) whereas we [only guarantee the cluster is functional after scaling up from 1 to 3](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L28-L46). @ryanmoran and @zankich spoke with @mitchellh and some HashiCorp folks when they visited our office, sounded like this is something we have to live with for now.
",Amit-PivotalLabs,mitchellh
1311,2016-02-05 22:46:57,"Hey @slackpad 

Thanks for following up.  Yes, we're still having this issue.  We [guarantee data persistence when scaling up from 3 to 5](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L80-L100) whereas we [only guarantee the cluster is functional after scaling up from 1 to 3](https://github.com/cloudfoundry-incubator/consul-release/blob/309d583df6a0027bff49ce040287840b2a2e086a/src/acceptance-tests/deploy/scale_up_instances_test.go#L28-L46). @ryanmoran and @zankich spoke with @mitchellh and some HashiCorp folks when they visited our office, sounded like this is something we have to live with for now.
",Amit-PivotalLabs,ryanmoran
1306,2015-10-15 18:36:58,"I've been reading through #993 #454 and other posts, and would echo the comment made by @pikeas here:
https://github.com/hashicorp/consul/issues/993#issuecomment-123129781

We have had some failures in our test environments, where we've been able to recover the cluster.
We have some specific constraints, which might be unique to us today, but I think are potentially  common to a number of implementations going forwards:
- We have to run consul in a docker container
- All our containers get dynamically assigned an IP address when they start
- When containers terminate, we cannot ensure the consul agent receives a signal

We've currently got the following design, and would like some feedback on how valid it is, and how we can improve it:
- a server cluster of 3 (planning to extend to 5, or 7)
- bootstrap-expect set to 3 on all servers
- leave_on_terminate is true
- if the whole container fails, we discard the filesystem - data-dir is wiped out
- if we need to create a new server node, we give it a new name and it joins with a new IP
- we restart consul inside the docker container with the same parameters, if just the process exits
- we edit peers.json manually when we cycle in a new container to the server cluster
- we can cope with the complete loss of the consul cluster, but with a significant impact (hours of downtime)

Our main practical concerns are:
- what is the right step to take after a server crashes (or is manually deleted to patch in a new docker image), to keep the rest of the cluster healthy?
- if we ever lose quorum, is there any real alternative to completely deleting the cluster and creating a new one (we've not been very successful in recovering)
",peterbroadhurst,pikeas
1306,2016-06-07 18:46:54,"@slackpad are you able to provide any feedback on this one?
",CpuID,slackpad
1306,2016-06-08 22:26:04,"@sean- @slackpad - how would you feel about augmenting [RemoveFailedNode](https://github.com/hashicorp/consul/blob/master/consul/server.go#L643-L652) to support cleaning up the Raft entry in addition to cleaning up the Serf side, for `force-leave` operations?

I wonder if the correct way to do this is to use the Serf layer to broadcast a Raft removal which is actioned on each node locally?

Or potentially hook into the [lanNodeFailed/wanNodeFailed](https://github.com/hashicorp/consul/blob/master/consul/serf.go#L248-L293) hooks as a Plan B? Not 100% sure if these are called on `RemoveFailedNode` scenarios right now.
",CpuID,slackpad
1306,2016-06-08 22:26:04,"@sean- @slackpad - how would you feel about augmenting [RemoveFailedNode](https://github.com/hashicorp/consul/blob/master/consul/server.go#L643-L652) to support cleaning up the Raft entry in addition to cleaning up the Serf side, for `force-leave` operations?

I wonder if the correct way to do this is to use the Serf layer to broadcast a Raft removal which is actioned on each node locally?

Or potentially hook into the [lanNodeFailed/wanNodeFailed](https://github.com/hashicorp/consul/blob/master/consul/serf.go#L248-L293) hooks as a Plan B? Not 100% sure if these are called on `RemoveFailedNode` scenarios right now.
",CpuID,sean-
1301,2016-11-28 03:53:52,@slackpad may be we do a full dns support to consul?,westsouthnight,slackpad
1300,2015-10-13 20:33:22,"@TannerFilip reported on https://webcompat.com/issues/1806 a bug about `Header` which isn't readable on Firefox (and Same on Internet explorer). 

This patch fixes the bug. 

https://github.com/webcompat/web-bugs/issues/1806
",magsout,TannerFilip
1295,2015-10-13 00:44:58,"It would be great if the [Consul vs Other Software](https://www.consul.io/intro/vs/index.html) section of the website included a comparison of Consul vs [Eureka](https://github.com/Netflix/eureka/wiki).

@armon provided a quick summary in the [google group](https://groups.google.com/d/msg/consul-tool/fsLGavCv-j8/xGH2f6XACgAJ)...

> Could you please file a ticket? We can hopefully get this done in more detail, but in gist:
> 
> Eureka:
> - AP (weak consistency), state is replicated with â€œbest effortâ€
> - Services are registered with one server, which attempts to replicate to other servers
> - Service registrations have a TTL, and clients must heartbeat
> - Reads are routed to any server, can be stale or missing data
> - Scales well due to low coordination, especially when server failures relatively rare
> - Fails if all servers down
> 
> Consul
> - CP (strong consistency), state is replicated using Raft
> - Services registered with any server, but written via Raft to a quorum
> - Registrations have complex health checks, including gossip failure detection instead of heartbeating
> - Reads routed to any server, consistent by default but stale reads can be requested
> - Stale reads scale well, Consistent reads scale to tens of thousands per second
> - Consistency offers locking and cluster coordination
> - Lots more features (health checking, locking, KV, federation, ACLs)
> - Fails if a majority of servers down
> 
> Hope that helps!
> 
> Best Regards,
> Armon Dadgar
",philsttr,armon
1291,2015-10-12 17:05:37,"I'll be pushing up some other changes today but this is worth an initial look /cc @armon @ryanuber.
",slackpad,armon
1291,2015-10-12 17:05:37,"I'll be pushing up some other changes today but this is worth an initial look /cc @armon @ryanuber.
",slackpad,ryanuber
1291,2015-10-20 06:19:39,"@armon and @ryanuber all the outstanding comments have been addressed so please take another look.

I'm going to leave the TODO in `PrefixWatch.Notify()` for now since it's an existing bug and clean that up on another PR if I have time. I think it'll need a periodic sweep kind of cleanup, or else the notify groups will have to be able to tell the parent `PrefixWatch` once they have become empty.
",slackpad,ryanuber
1284,2015-11-03 18:48:51,"Any chance to look at this @slackpad following @nbrownus PR ? Would be greatly appreciated.
",scalp42,slackpad
1278,2016-12-21 03:37:05,"@saifabid I use 0.6.4 and try to delete a folder on KV which contains much more than 10M entries, using the HTTP API `curl -X DELETE http://localhost:8500/v1/kv/locks\?recurse\&token=xxxx`

As my understanding, this is a block operation and must be done on leader, and once I send my delete request, my consul cluster leader looks unresponsive and other peers in cluster start to election, and my entire cluster became unstable, finally it goes to `No cluster leader`. Very frustrating.

The delete operation will return `rpc error: EOF` eventually but the big entry still there and also makes my cluster unavailable.
Is there any other efficient way to delete such big entry?",kongchen,saifabid
1271,2015-10-26 17:16:44,"Gotcha. I apologize, I admit i didn't fully understand the problem on first read. Very interested to understand what is happening here as well.

I'm first thinking maybe all servers except the first have to call `-join <first server>`, but that would be hard to detect, and why wouldn't it just continue where it left off.

Any ideas @armon @slackpad ?
",djenriquez,armon
1271,2015-10-26 17:16:44,"Gotcha. I apologize, I admit i didn't fully understand the problem on first read. Very interested to understand what is happening here as well.

I'm first thinking maybe all servers except the first have to call `-join <first server>`, but that would be hard to detect, and why wouldn't it just continue where it left off.

Any ideas @armon @slackpad ?
",djenriquez,slackpad
1271,2015-11-16 13:49:06,"@engine07 could you please create an issue for your case which is just normal behaviour (quorum for 5 nodes cluster is 3, not 2), and not mix it with my bugreport which relates to something completely different?
",jakubzytka,engine07
1267,2015-10-01 08:49:12,"I have it working myself with similar configuration, only difference is I don't have ""IN"" on the first line, try 

zone ""consul"" {

instead, though I doubt it makes a difference. You also need to enable recursion if not already, (recursion yes;) and disable dnssec options.

Does it work if you resolve the consul servers themselves?
e.g.
dig @localhost -p 8600 consul.service.consul +short
dig @localhost -p 53 consul.service.consul +short
",mumblez,localhost
1267,2015-10-01 15:24:44,"dnssec-enabled no and recursion yes are both set in my named.conf.options file...

I removed the IN from the zone config, and same issue:

dig @localhost -p 8600 consul.service.consul +short
192.168.0.200

dig @localhost -p 53 consul.service.consul +short

Running consul in a terminal I can see the call from bind to consul, but for some reason it is leaving an extra dot on the name service ends up service. after the pass-thru
",rjordan,localhost
1267,2015-10-01 18:38:25,"*_modified_*
dig @localhost -p 53 _server_._domain_.org +short
192.168.0.200
dig @localhost -p 53 -x 192.168.0.200 +short
_server_._domain_.org.

Forward and reverse seem to be fine. 
",rjordan,localhost
1265,2015-09-30 19:18:58,"Per the conversation on the mailing list here: https://groups.google.com/forum/#!searchin/consul-tool/thousands$20of$20services/consul-tool/vPAhS1EhABM/_SPAIXuMFDQJ 

There is a slowdown due to how the gent loops over all services and the catalog returned from the server that completes in O(N^2). After talking with @slackpad at HashiConf we think that we can improve on this  fairly simply with an index on the server result. 
",spheromak,slackpad
1265,2015-10-12 08:42:32," @slackpad did you do anything with this since hashiconf ?
",spheromak,slackpad
1254,2015-10-05 18:58:24,"@slackpad I brought this issue up to you during Hashiconf. Would love to hear your recommendation on this.
",calvn,slackpad
1254,2015-10-05 19:07:03,"Interesting topic. We are currently backing up our dockerized Consul servers using [Convoy](https://github.com/rancher/convoy), but it appears that this will cause issues if we were to restore this data onto a new Consul server on a machine with a different IP address, as @highlyunavailable noted. We followed this as recommened by @armon in this [Google Group topic](https://groups.google.com/forum/#!msg/consul-tool/cbe_W_SClog/u3PhFlDlyaAJ).

We know that [Consulate](https://github.com/gmr/consulate) exists, but we are striving for a service-agnostic back up solution, which is why we settled with Convoy. 

Our main goal was to backup the K/V store. Is there a subdirectory we should be backing up instead of the `/data/` directory in its entirety?
",djenriquez,armon
1251,2015-09-20 18:04:16,"We migrated to this in Vagrant. The reason to do a subtree split is for preserving history. We don't actually care about history since this is just the static site and we force-push to heroku anyway.

This PR copies the website into a staging directory and creates a fresh git repository in there. This severely reduces the amount of time required for a deploy :smile:

/cc @ryanuber @slackpad 
",sethvargo,slackpad
1251,2015-09-20 18:04:16,"We migrated to this in Vagrant. The reason to do a subtree split is for preserving history. We don't actually care about history since this is just the static site and we force-push to heroku anyway.

This PR copies the website into a staging directory and creates a fresh git repository in there. This severely reduces the amount of time required for a deploy :smile:

/cc @ryanuber @slackpad 
",sethvargo,ryanuber
1240,2015-09-14 17:49:34,"When building from master, I was getting errors that `-X main.GitCommit ${GIT_COMMIT}${GIT_DIRTY}` was missing an equal sign and may break in a future version.

/cc @ryanuber @slackpad 
",sethvargo,slackpad
1240,2015-09-14 17:49:34,"When building from master, I was getting errors that `-X main.GitCommit ${GIT_COMMIT}${GIT_DIRTY}` was missing an equal sign and may break in a future version.

/cc @ryanuber @slackpad 
",sethvargo,ryanuber
1238,2015-09-15 18:35:48,"Oh I see, you mean you can exec inside the allowed key space that the clients can write to.

In 0.6 you will be able to deny firing events, but it's pretty easy to forget to configure that and open up this hole. It seems like maybe if you aren't allowed to write to ""_rexec"" then you shouldn't be able to exec on any other prefix (kind of an implied extension of the ACL), plus we'd look at your ACL for the prefix as well. This might be a little subtle to explain, but it would work without a new ACL type. Alternative could be a first class exec ACL.

I'll ping @armon and @ryanuber for their thoughts on the interface for this.
",slackpad,armon
1238,2015-09-15 18:35:48,"Oh I see, you mean you can exec inside the allowed key space that the clients can write to.

In 0.6 you will be able to deny firing events, but it's pretty easy to forget to configure that and open up this hole. It seems like maybe if you aren't allowed to write to ""_rexec"" then you shouldn't be able to exec on any other prefix (kind of an implied extension of the ACL), plus we'd look at your ACL for the prefix as well. This might be a little subtle to explain, but it would work without a new ACL type. Alternative could be a first class exec ACL.

I'll ping @armon and @ryanuber for their thoughts on the interface for this.
",slackpad,ryanuber
1238,2016-02-17 04:28:31,"@split3 for now you should disable writes to ""_rexec"" in the KV store _and_ disable firing events (or at least disable firing the ""_rexec"" event). This will prevent agents from using some other prefix to do remote exec. You can also set https://www.consul.io/docs/agent/options.html#disable_remote_exec to prevent an agent from responding to any remote exec requests.
",slackpad,split3
1235,2015-09-17 09:55:50,"@slackpad 

> Want to take a crack at preventing multiple reloads as well?

I'm pretty sure `handleReload()` is only called from `handleSignals()`, and AFAICT handleSignals is fully synchronous (https://github.com/hashicorp/consul/blob/master/command/agent/command.go#L797) and as such doesn't need a mutex to prevent multiple reloads.  (/cc: @ryanuber ?) 

It seems that all the interference was caused by `handleReload` and `antiEntropy` fighting with each other NOT multiple configuration reloads running simultaneously.  It's just easier to trigger a Pause/Resume conflict with `antiEntropy` if you force consul into contant reload mode by spaming SIGHUP for a while. 
",wuub,ryanuber
1231,2015-09-21 14:50:23,"/cc @sethvargo thoughts?
",ekristen,sethvargo
1230,2015-09-10 21:43:31,"Picked this up when @sfncook rebased and built #1187 - @ryanuber I think we missed a couple spots:


",slackpad,sfncook
1225,2015-09-09 00:32:31,"Hi @slackpad 

I'm running `dig` locally against the node agent (`dig @127.0.0.1 -p 8600`).

I see the TTLs only when `dig` is pointed at our Consul server nodes (`dig @consul.example.com -p 8600`) :



In this case does it mean that the local agent **cannot** get stale data ?

Correct me if I'm wrong but it would make any downstream caching impossible if TTLs are not specified.
",scalp42,consul
1223,2015-09-08 19:21:22,"In the default-deny setup, it seems `consul maint` is not able to make progress even with the correct ACL tokens that have write permissions. Errors also occur on the server side for this.

/cc: @ryanuber @sean-
",armon,ryanuber
1223,2015-09-08 19:21:22,"In the default-deny setup, it seems `consul maint` is not able to make progress even with the correct ACL tokens that have write permissions. Errors also occur on the server side for this.

/cc: @ryanuber @sean-
",armon,sean-
1219,2015-09-12 20:00:58,"Cool, this LGTM.  Only question is whether @armon, @ryanuber, or @slackpad have philosophical objections to ""first public IPv6"" being a supported config when we've only ever offered first available private IP binding for IPv4.

I know there are systemic differences between IPv6 and IPv4 that make public IPs more appropriate in IPv6, but this is enough of a difference that I'm not comfortable merging without one of the project owners weighing in.
",ryanbreen,armon
1219,2015-09-12 20:00:58,"Cool, this LGTM.  Only question is whether @armon, @ryanuber, or @slackpad have philosophical objections to ""first public IPv6"" being a supported config when we've only ever offered first available private IP binding for IPv4.

I know there are systemic differences between IPv6 and IPv4 that make public IPs more appropriate in IPv6, but this is enough of a difference that I'm not comfortable merging without one of the project owners weighing in.
",ryanbreen,slackpad
1219,2015-09-12 20:00:58,"Cool, this LGTM.  Only question is whether @armon, @ryanuber, or @slackpad have philosophical objections to ""first public IPv6"" being a supported config when we've only ever offered first available private IP binding for IPv4.

I know there are systemic differences between IPv6 and IPv4 that make public IPs more appropriate in IPv6, but this is enough of a difference that I'm not comfortable merging without one of the project owners weighing in.
",ryanbreen,ryanuber
1219,2015-11-09 17:02:56,"ping @armon, @ryanuber, @slackpad 
Any comments ?
",42wim,armon
1219,2015-11-09 17:02:56,"ping @armon, @ryanuber, @slackpad 
Any comments ?
",42wim,slackpad
1219,2015-11-09 17:02:56,"ping @armon, @ryanuber, @slackpad 
Any comments ?
",42wim,ryanuber
1217,2015-09-02 14:17:44,"Subtle bug, we found in production. dig works, but some applications fail.

We only need to send the SOA record when the answer is empty, not NXDOMAIN (because the resource exists, it only doesn't have the required type), otherwise no other records will be asked.

@ryanbreen could you merge this ?
",42wim,ryanbreen
1212,2016-03-11 04:22:52,"Hi @cleung2010 we did work and extensive testing to make sure a mix of 0.5.2 and 0.6.x would work well together, though the newly-added TCP fallback ping for 0.6.x won't apply if it's talking to a 0.5.2 node on the other end (and vice-versa) so if you are experiencing heavy packet loss you won't get the benefit of that new feature.

We are working on some improvements for flapping in the upcoming 0.7 release at the Serf level, so we should have more details to share here soon.
",slackpad,cleung2010
1196,2015-08-25 22:16:44,"Hi @armon 

Assuming we have a Redis service defined as `redis.json` in consul directory:



Now assuming there is a check `redis_check.json`:



This example does not make sense in itself, but it's just to clear up the doc.

What happen in that case in Consul ? Should checks be tied to services or vice versa (or doesn't really matter) ?

Thanks in advance!
",scalp42,armon
1193,2015-08-28 04:08:08,"Hi @ahmetalpbalkan I think you might want to try the `-retry-join` option, as `-join` is a one-shot thing that won't try again. Take a look at this for more details - https://www.consul.io/docs/agent/options.html.

> -retry-join - Similar to -join but allows retrying a join if the first attempt fails. This is useful for cases where we know the address will become available eventually.
",slackpad,ahmetalpbalkan
1191,2015-08-31 21:53:31,"Hi @split3 - not sure what's going on with this one - will have to take a deeper look with a test configuration. Is forwarding not possible with your setup?
",slackpad,split3
1188,2015-08-20 20:14:01,"I brought this to the attention of the mailing list [here](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!topic/consul-tool/1wEHSx3Qp-Y). @slackpad asked me to go ahead and file a bug. Below summary of the issue from the discussion thread.

We have services that are being orphaned and we cannot deregister them. The orphans show up under one or more of the master nodes. In our configuration the master nodes are `dev-consul`, `dev-consul-s1`, and `dev-broker`.

The health check of the orphaned node looks something like the following:



I attempted to deregister via:



The node was removed but then reappears within 30-60s. As @slackpad's recommended, I tried deregistering with:



Both commands returned status `200 OK`. But that also failed. You can see the output in this [gist](https://gist.github.com/drsnyder/3016efb02efebc6afbe6) as well as the debug logs from consul.

From the debug logs in consul we see:



The annotation is from @slackpad. 

It's also noteworthy that the orphans are always associated with one of the master nodes (e.g. `dev-consul`) and not the node (`dev-mesos`) that's running the service that was registered. I should also mention (it could be a coincidence) that the service (`discussion`) is also flapping though from what I can tell from the debug logs for consul on `dev-mesos` everything is fine.

Our consul version:



Thanks!
",drsnyder,slackpad
1187,2015-09-10 21:32:37,"@slackpad @ryanuber - Thanks for the review, guys.

@slackpad - I have added a couple test cases in TestAgentAntiEntropy_EnableTagDrift.  But perhaps you can see in this conversation that the Travis failing with errors that don't appear to be related to my updates.  I'm not sure why they are failing - they seems to be complaining that an interface is being used. (in code that I did not modify)  Perhaps you guys have seen these errors before?  Known issue?

Travis errors:
command/maint_test.go:48: not enough arguments in call to a1.agent.EnableServiceMaintenance
command/maint_test.go:53: not enough arguments in call to a1.agent.EnableNodeMaintenance
",sfncook,ryanuber
1186,2015-08-19 00:46:27,"@cleung2010 The ACL data is not replicated between datacenters so this is a very difficult transition. You'd want to export all the ACL tokens from DC1, switch `acl_datacenter` to DC2 and then restore all the tokens.

Otherwise, once you do the switch, DC2 will be a ""blank slate"" from the ACL perspective.
",armon,cleung2010
1186,2015-08-19 01:23:17,"@cleung2010 You'd need to use the APIs to export/import unfortunately. The file storage is a bit opaque to manipulate. With the KVs there is nothing to do if you've already replicated across. 

That is about it, just the KV and ACL data to move. Catalog is auto-managed anyways, Serf is gossiped around.
",armon,cleung2010
1186,2015-09-11 18:35:51,"@cleung2010 Services will not disappear, that is correct. If ACLs are disabled then the `?token` parameter is just ignored as well. You can do that as well, simply disable ACLs, do the migration, re-enable and import the old tokens. The only window of time with an issue is between enabling ACLs and importing the old tokens.
",armon,cleung2010
1182,2015-08-17 18:14:55,"From #1181: We are linking to a 404 page in Atlas from our public Consul documentation.

/cc @pearkes @sethvargo
",ryanuber,pearkes
1182,2015-08-17 18:14:55,"From #1181: We are linking to a 404 page in Atlas from our public Consul documentation.

/cc @pearkes @sethvargo
",ryanuber,sethvargo
1182,2015-08-17 18:26:01,"/cc @justincampbell
",ryanuber,justincampbell
1171,2016-02-17 05:22:23,"Hi @youngking and @kamaradclimber you are correct, the current key goes to both WAN and LAN. We will take a look at making this more flexible.
",slackpad,youngking
1165,2015-08-11 01:46:09,"Talked about this with @armon - we probably want to lock per-address rather than one big lock for the pool. Otherwise, a slow connect to a remote DC could hold up a connection to a local server.
",slackpad,armon
1157,2015-08-11 07:59:32,"Hey @split3,

You could accomplish what you need by registering a health check with your service and passing the `critical` health state. The service and its health check should be registered together, so there shouldn't be any need to do anything else until you are ready to bring the service into the pool, at which point you would simply deregister the failing health check.

Maintenance mode could be used to do something like this, and in fact you can ""trick"" consul into the exact functionality you want by naming your initial failing health check `_service_maintenance`. You could then use `consul maint -disable` to remove it, though this is a hack. I'll leave this ticket open for now to see if there is more interest in the additional flag.
",ryanuber,split3
1157,2015-08-11 17:30:42,"@split3 I see, I guess the agent endpoints currently don't cater to this use case. I was thinking about it from a config file perspective, which should allow services and checks to be registered at once. Let's leave this open to track the request. Thanks for the follow-up.
",ryanuber,split3
1157,2015-08-11 19:33:03,"Yes doing this via the config files would work, sorry I wasn't clear about it being the HTTP API, but we will have a continuous delivery pipeline that deploys multiple services on various hosts (i.e. docker) so ideally we just want to use the API to register/deregister the services are part of the deployment pipeline instead of writing out the configs.

@james147 Yes indeed this would help for sure as it was initially what I tried to do.  I suppose if #740 was implemented then this issue could be closed to just use that approach instead of introducing a new mechanic to the configuration.
",hopperd,james147
1154,2015-08-05 22:15:31,"@darron Hmm this is odd. I haven't seen that before. @slackpad is looking into this.
",armon,slackpad
1150,2015-08-11 17:47:36,"@evanccnyc Hmm, so this looks like about ~35 services queries, and sounds like a few hundred nodes were involved.

My guess is this is similar to the issue #1154 #1165 and the other is the repro case @darron provided us. We are tracking those separately, but this seems like a related issue. We are working to address some of the read pressure issues CT causes in Consul 0.6 to increase the stability of the cluster under that kind of load.

A big improvement to his is the approach of running CT on a single node (or a few under `consul lock`) and storing the result template in a KV entry. Then the 100+ nodes only need to watch a single key for updates instead of 35+ endpoints. This dramatically reduces the load on the servers and helps with overall performance and stability.
",armon,darron
1130,2015-07-23 20:41:32,"This is interesting. I think it's worth probably just reducing the scope to tcp only. A UDP health check doesn't really make much sense in any case. 

/cc: @ryanuber @slackpad 
",armon,slackpad
1130,2015-07-23 20:41:32,"This is interesting. I think it's worth probably just reducing the scope to tcp only. A UDP health check doesn't really make much sense in any case. 

/cc: @ryanuber @slackpad 
",armon,ryanuber
1130,2015-07-24 00:10:30,"@ryanbreen of course you're correct on UDP, I wasn't thinking.  We could send a packet with no payload though.  WRT IPv6/IPv4, there's no way to check explicitly for one or the other if you also want to check via hostname, without specifying the protocol..
",pdf,ryanbreen
1118,2015-07-17 16:54:44,"Hi @bancore,

Consul allows this because it exposes the toggles for various settings through its HTTP API or over the RPC interface, so naturally if a client can connect to those interfaces and there is no authentication or ACL's set up, then anyone can perform these actions. This is why Consul binds to the loopback interface by default.

Because Consul is compatible across a wide variety of platforms, we can't lean on UNIX users and groups to do this kind of authorization. I would suggest looking into using Consul's [ACL system](https://consul.io/docs/internals/acl.html) to secure different aspects of the server. Service registrations can already be locked down using the ACL's, which also covers the `maint` command, and the next release of Consul will introduce many enhancements to the ACL system, which includes the keyring commands (these changes are already in the master branch).

Hope that helps!
",ryanuber,bancore
1108,2015-07-14 01:25:59,"@bancore This is not currently possible, as it requires tuning the low-level parameters of Serf which are not exposed. We want to expose them eventually, but tuning them down increases the rate of false positives.
",armon,bancore
1108,2015-07-14 11:38:05,"@bancore The TTL check is a different mechanism and can be set to a much lower value. The difference  is that the TTL check is managed by a running agent, while detecting if a different agent has failed requires the gossip protocol
",armon,bancore
1107,2015-09-28 19:49:45,"@slackpad This is the issue I was talking about. It's related to https://github.com/hashicorp/consul/issues/697.

There are also a couple of issues on it on registrator: https://github.com/gliderlabs/registrator/issues/52 / https://github.com/gliderlabs/registrator/pull/242
",amochtar,slackpad
1104,2015-07-17 17:13:32,"@omribahumi I think there may be a misunderstanding here. The cap is the maximum amount you may _extend_ the life of a session at a time, and not the total time a session may be valid for. It is the responsibility of the client to ""renew"" the session before this time period expires using the [renew api](https://consul.io/docs/agent/http/session.html#session_renew). More info on session internals can be found [here](https://consul.io/docs/internals/sessions.html).

I _think_ the 1h cap is in place to prevent dead client sessions from lingering around as a security practice. It seems reasonable to require clients to renew their session liveness each hour at least, but I'll let @armon comment here in case there are other reasons we cap it there.
",ryanuber,armon
1081,2015-07-13 16:37:29,"@bung87 thanks for the PR. Some before / after screenshots might be helpful to see the difference here. 

/cc @pearkes
",ryanuber,pearkes
1080,2015-07-16 22:40:00,"@armon or others, can I get a review on this, time permitting?
",babbottscott,armon
1072,2015-07-01 19:22:32,"Hi @ketzacoatl - you are right, we should beef up the documentation to make this more clear. I found this thread which gives some info about the format of the token from @armon:

https://groups.google.com/forum/#!topic/consul-tool/lN3jZRbS2-g

> If the `acl_master_token` is not supplied, then the servers do not create a master token. If they did,
> there would be no way to programmatically provide it safely. When you provide a value, it can be
> any string value. Using a UUID would ensure that it looks the same as the other tokens, but isnâ€™t
> strictly necessary.
",slackpad,armon
1071,2016-01-05 20:03:55,"Hi @split3 we are working on a release that should go out this week and contain the fix. You can get the latest Consul master and run the build process to generate the UI files without any manual edits.
",slackpad,split3
1071,2016-01-19 16:40:04,"@split3 this made it into the released web_ui files for 0.6.1+ (https://releases.hashicorp.com/consul/0.6.3/consul_0.6.3_web_ui.zip). If you use `-ui-dir` and point to that release all should be good.

Unfortunately, right after the 0.6.3 release we discovered that the internal `-ui` assets were missing this fix (https://github.com/hashicorp/consul/issues/1467), so you won't be able to use that until the next release. This comment should provide awareness of that issue, but since it's already fixed in master I'll close this.
",slackpad,split3
1071,2016-01-19 16:55:31,"@split3 can you share the patch you are applying?
",slackpad,split3
1071,2016-01-19 17:15:28,"@split3 awesome - thanks for the update!
",slackpad,split3
1057,2016-04-23 01:52:10,"Need to re-open this one. This seems to still be an issue:
1. TTL check gets registered after a service is created (output will default to empty).
2. External process starts hitting the TTL check with non-empty output at a 5 second interval.
3. Check output doesn't update unless the state changes (remains blank).

Doing some tracing it looks like the check always has a deferred timer active, even well after it should have expired.

Also, if the output _always_ changes there may be an issue where it _never_ syncs, need to double check this case as well.

/cc @sean- 
",slackpad,sean-
1049,2015-06-22 17:45:45,"Makes sense to me, marking as an enhancement! /cc @pearkes
",ryanuber,pearkes
1029,2015-06-13 00:04:53,"I don't think we use `the INTEG_TESTS` env var anywhere during the tests. This change will just use the `test` target for CI so that we can run the API tests there as well (we build the binary to a temp path in `scripts/test.sh`).

Also removed flowdock because I'm not sure what that is. If we need it I can add it back in.

/cc @armon
",ryanuber,armon
1019,2015-06-17 04:58:19,"@ryanbreen Thank you very much. I get it.
",feiyang21687,ryanbreen
1014,2015-06-08 14:16:25,"/cc @ryanuber 
",sethvargo,ryanuber
1003,2015-06-04 19:02:31,"The `consul lock` command is great (and can be used in tandem with `consul exec`), but it would be great if `consul exec` accepted a `-n` parameter and handled all the locking automatically:



This would be really great for rolling deploys or even Kernel upgrades:



/cc @armon @ryanuber @phinze 
",sethvargo,armon
1003,2015-06-04 19:02:31,"The `consul lock` command is great (and can be used in tandem with `consul exec`), but it would be great if `consul exec` accepted a `-n` parameter and handled all the locking automatically:



This would be really great for rolling deploys or even Kernel upgrades:



/cc @armon @ryanuber @phinze 
",sethvargo,phinze
1003,2015-06-04 19:02:31,"The `consul lock` command is great (and can be used in tandem with `consul exec`), but it would be great if `consul exec` accepted a `-n` parameter and handled all the locking automatically:



This would be really great for rolling deploys or even Kernel upgrades:



/cc @armon @ryanuber @phinze 
",sethvargo,ryanuber
1002,2015-06-05 05:13:50,"@phinze , the build seems to have failed, I hope it's nothing to do with this pull, please check
",sathiyas,phinze
993,2015-06-10 00:25:30,"@reversefold - After digging more I think you are seeing the same thing as is being discussed on #750 and #454.

I was able to reproduce your situation locally and verify that the consul.data/raft/peers.json file ends up with `null` inside on all three servers. That's why a `TERM` sig doesn't lead to this because it doesn't formally leave the set of peers (see [leave_on_terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate), which defaults to false).

I'll let @armon and/or @ryanuber weigh in on the best practice to follow to get into a working state. Maybe we should add a new ""Failure of all Servers in a Multi-Server Cluster"" section in the outage recovery docs since this seems to be confusing to people. I think it will end up being something similar to the manual bootstrapping procedure, picking one of the servers as the lead. In my local testing I was able to get them going again by manually editing the peers.json file, but I'm not sure if that's a safe thing to do.
",slackpad,armon
993,2015-06-10 00:25:30,"@reversefold - After digging more I think you are seeing the same thing as is being discussed on #750 and #454.

I was able to reproduce your situation locally and verify that the consul.data/raft/peers.json file ends up with `null` inside on all three servers. That's why a `TERM` sig doesn't lead to this because it doesn't formally leave the set of peers (see [leave_on_terminate](https://www.consul.io/docs/agent/options.html#leave_on_terminate), which defaults to false).

I'll let @armon and/or @ryanuber weigh in on the best practice to follow to get into a working state. Maybe we should add a new ""Failure of all Servers in a Multi-Server Cluster"" section in the outage recovery docs since this seems to be confusing to people. I think it will end up being something similar to the manual bootstrapping procedure, picking one of the servers as the lead. In my local testing I was able to get them going again by manually editing the peers.json file, but I'm not sure if that's a safe thing to do.
",slackpad,ryanuber
993,2016-02-06 22:25:54,"@sean, thanks for the explanation
It appears I simply restarted nodes out of the order
I maintain my configuration by ansible and it executes tasks in parallel on all hosts...
Same thing applies to nomad I guess(stop follower, wait for leader election, do what you need, bring back)
It would be super nice to have this all documented somewhere for both consul and nomad
",let4be,sean
988,2015-06-01 20:39:15,"@rafikk we generally recommend against using any non-DNS compatible characters in service names. That said, as long as it's allowed in Consul, the UI should support it too. @pearkes any thoughts on this?
",ryanuber,pearkes
985,2015-06-25 03:30:28,"Okay, so this is very interesting and behaves super differently in a variety of scenarios:
1. I set up 3 servers, got them into a cluster.
2. I set up 1 agent, joined it to the cluster.
3. I then did `consul lock test ""sleep 60""`

Now, this is where it varies (TL;DR scroll to the end to watch the lock be violated):

Scenario 1: Cleanly exiting the leader with leave_on_terminate at its default value of `true`, which means it shuts itself down and sends a message to remove itself from Raft, which isn't the same as a partition, but can easily happen.

I got the following result:



I immediately tried running the same command and got the following error until the election finished:



I can see not being able to create a lock during an election, so I'm actually fine with this except the error is a bit unclear.

---

Scenario 2:

I ran `pkill -9 consul` on the leader box after starting a new round of ""sleep 60"".

Results:

Serf immediately detected the failure in the server, but there were 0 errors from the agent and the 60 seconds finished cleanly. However, because of what you'll see in scenario 3, the agent was clearly not connected with the leader, but some other server. The output was as follows:



---

Scenario 3 (The one you're interested in):

I started a new consul lock sleep test and started running `sudo iptables -I INPUT -s 192.168.33.10 -j DROP` on boxes until I figured out which one the agent was talking to.

This is some strange behavior that I think @armon or someone else that wrote this needs to comment on.

Here's what happened, with consul communicating with `serverB`:



There are 2 problems here:
1. Consul lock hangs, and there's a chance depending on which server died to actually not even show the ""Error running handler: signal: terminated"" message. It doesn't respond to SIGTERM at all until the **_child process exits**_, it needs to be killed with `kill -9`. I'm suspecting a deadlock waiting on a channel somewhere.


1. The agent does not try to reconnect with another server and re-establish the session renewal. This wouldn't be a big deal except that if it can't renew the session, the session is destroyed due to the TTL, _and also_ due to problem 1, the child process is _still running_. This seems problematic.

I also replicated it on a single server/single agent - same problem, but this time it seemed to detect the failure a bit better due to the complete lack of consul servers. It still left the child process running though!
",highlyunavailable,armon
971,2015-06-08 17:01:35,"@miekg suggests to set the compress flag in consul, not wait for him to change this upstream.
@armon Can we get this merged soon? Even if it's not fixing the issue for all, it's definitely a pretty clear bug which breaks everyone using docker and consul as recursor.
",discordianfish,miekg
971,2015-06-25 04:46:01,"@ryanuber awesome, it looks like you reviewed and posted literally right as we were discovering that issue. 
",epipho,ryanuber
964,2015-05-20 19:29:26,"@phinze Thoughts?
",armon,phinze
956,2015-05-19 22:28:56,"@sean- Can you tell if its hung or just migrating? Our own servers took like 90 seconds to finish the migration. Or did they just sit there forever?

/cc: @ryanuber any ideas why it would be hanging?
",armon,ryanuber
955,2015-05-19 00:44:38,"I'd like to add the gradle-consul-plugin to the community tools page. @armon requested that I'd do that using a pull request.
",amirkibbar,armon
938,2015-05-29 17:27:14,"Thanks for reporting this, marking as a bug! /cc @pearkes @markupboy 
",ryanuber,pearkes
938,2015-05-29 17:27:14,"Thanks for reporting this, marking as a bug! /cc @pearkes @markupboy 
",ryanuber,markupboy
938,2015-05-29 17:29:08,"@ryanbreen fwiw, this happens similarly as well for Lock Sessions:

![image](https://cloud.githubusercontent.com/assets/375744/7888426/7e2c43f6-05ed-11e5-94c0-2ddefe6c61d7.png)
",mattrobenolt,ryanbreen
938,2015-10-26 21:05:49,"Kicking over to @meirish who's been looking into some UI bugs.
",slackpad,meirish
936,2015-05-14 08:17:09,"Clarify that the user is assured that Consul will listen to a
specific address when specifying a `bind` address, rather than
providing some kind of insurance policy.

/cc @ryanbreen 
",ceh,ryanbreen
930,2015-05-29 17:36:44,"Makes sense to me, preserving the values might be the way to go since flags are not such a commonly used feature, so I'm not sure if we want to expose it in the UI. I'll defer to @pearkes on that. Thanks for reporting!
",ryanuber,pearkes
924,2015-06-03 23:43:12,"@mainframe thanks for reporting this. This is happening in the gossip layer. After reading the code, it appears this is intentional. The gossip layer uses logical time only in its state which makes it more resilient to clock differences between the agents. My best guess at why the timers aren't restored is to avoid writing the local system time into the agent state to make this behavior more predictable. @armon can probably clarify here for us.

As for the peers.json file, that is intentionally left populated. You can read more about these types of failure scenarios in [this guide](https://consul.io/docs/guides/outage.html). Of particular interest here is the section on failed servers, which explains how this scenario may be recovered from.

I think the TL;DR is that this is working as intended, but I'll leave this open for now in case I missed something.
",ryanuber,armon
916,2015-05-07 17:17:14,"The main problem we're seeing is we have KV data associated with a lock, and hence a session, and the agents associated with those sessions ""frequently"" lose membership briefly, invalidating the associated KV data.  By ""frequently"", I mean that in a cluster consisting of 3 consul servers and 50-100 other nodes running consul agents, we see individual isolated incidents of agent membership lost every 3-4 hours, roughly (sometimes ~30 mins apart, sometimes 7-8 hours apart, but generally seems to be randomly distributed with an ""average"" of 3-4).

We have a heterogeneous cluster configured as a LAN, deployed across 3 AZs in EC2.  It appears that there is no correlation between the type of node and the loss of membership (e.g. if we have 10 instances of service A, and 50 of service B, we will see roughly 2 membership losses of A instances, and 10 instances of B losses in a period of a few days).  It also appears to be independent of stress on the system, i.e. we see roughly the same distribution of membership loss when the system is idle as we do when it's under heavy load.

We use consul for service discovery/DNS as well as a KV store.  We use the KV store specifically for the purpose of:
- maintaining presence -- certain nodes maintain the presence of a key with a TTL on it to indicate they are up and running, and when those disappear another node can react and re-schedule the workload that was being performed by that node, and
- locks -- for multiple instances of the same service to determine which one actually provides the service, in the case where the service needs to be a singleton

In addition to the occasional member loss, we also have the issue that when we roll the consul server cluster, which triggers a leader election, the KV store is temporarily unavailable. This potentially prevents a presence maintainer from bumping its lock before the TTL expires.

**Questions**:
1. Are there ways to configure things so that membership is more robust/more forgiving?  We've seen that WAN has more conservative parameters, e.g. a larger SuspicionMult(iplicationFactor), but switching to WAN feels like it would just be papering over an issue, and would only reduce the frequency of this issue.
2. Is there any advice for a better way to implement ""presence maintenance""?  Because we use locks, and hence sessions, we're sensitive to the lossiness of UDP and probabilistic nature of Gossip, even though the running application maintaining its presence in the KV stores is running fine.  E.g. is there a way to establish a lock but side-step the coupling to the membership of its agent?
3. What information would help diagnose this problem?  We have plenty of server and agent configuration, consul server logs, consul agent logs, and application logs from services running alongside consul agents, all spanning several days.

Thanks,
Amit + @matt-royal
",Amit-PivotalLabs,matt-royal
916,2015-07-22 22:49:50,"Thanks @armon.

/cc @fraenkel @ematpl @luan see above comment from @armon re UDP routing issues.
",Amit-PivotalLabs,luan
916,2015-07-22 22:49:50,"Thanks @armon.

/cc @fraenkel @ematpl @luan see above comment from @armon re UDP routing issues.
",Amit-PivotalLabs,ematpl
916,2015-07-22 22:49:50,"Thanks @armon.

/cc @fraenkel @ematpl @luan see above comment from @armon re UDP routing issues.
",Amit-PivotalLabs,fraenkel
916,2015-09-04 23:16:43,"@aj-jester: Everything we (myself, @ematpl, @fraenkel, @luan) have done has been in a VPC.
",Amit-PivotalLabs,luan
916,2015-09-04 23:16:43,"@aj-jester: Everything we (myself, @ematpl, @fraenkel, @luan) have done has been in a VPC.
",Amit-PivotalLabs,fraenkel
916,2016-01-26 11:08:33,"Thanks @amon for the information regarding configuration. I have now upgraded all my AWS instance sizes to m3.large and still see the occasional serf health check problems. 
Or perhaps I am misinterpreting the consul logs? On the consul server (running only 1 server but that should not affect serf, right?) I can see the following in the logs:



Does this imply that the server 10.7.1.190 is not available for service discovery during the problem period?
",draxly,amon
899,2015-05-04 21:28:08,"@rhelmer, yeah, I thought this might be a good fit for you because it seems our usage is pretty similar.  We have a bunch of configuration files we want to splat out onto the filesystem of remote hosts, so we use git2consul because we want to manage / version those in git and distribute them using Consul.  We then use http://github.com/cimpress-mcp/fsconsul to write them to disk on remote systems.  It makes a nice complement to git2consul.

If that seems like a good fit for you, it might make sense to close this ticket.  It's up to @armon and @ryanuber, of course, but IMHO it seems unnecessary to modify Consul itself if the constellation of tools around Consul can provide the desired functionality.
",ryanbreen,armon
899,2015-05-04 21:28:08,"@rhelmer, yeah, I thought this might be a good fit for you because it seems our usage is pretty similar.  We have a bunch of configuration files we want to splat out onto the filesystem of remote hosts, so we use git2consul because we want to manage / version those in git and distribute them using Consul.  We then use http://github.com/cimpress-mcp/fsconsul to write them to disk on remote systems.  It makes a nice complement to git2consul.

If that seems like a good fit for you, it might make sense to close this ticket.  It's up to @armon and @ryanuber, of course, but IMHO it seems unnecessary to modify Consul itself if the constellation of tools around Consul can provide the desired functionality.
",ryanbreen,ryanuber
893,2015-04-29 09:22:27,"[This comment](https://chocolatey.org/packages/consul#comment-1660768280) indicates that some enhancements have been submitted to the chocolatey package for consul.
- Use [NSSM](https://nssm.cc/) instead of WinSXW for service wrapper
- Support for -ia flag (whatever that is!)

I think because the repo isn't in a network connected to chocolatey, it might have been missed (?). The repo is at https://github.com/sitano/chocolatey-packages.

Where is the repo for the hashicorp-supported package? Perhaps @sitano or I can merge & re-PR.
",petemounce,sitano
893,2015-05-03 23:21:25,"Hi @ryanuber 
- [this is the link to the chocolatey package](https://chocolatey.org/packages/consul)
  - the comments (scroll down) are what I'm talking about.
- I _think_ the package source is https://github.com/sitano/chocolatey-packages, and I would guess community-provided.
  - this is the maintainer: https://chocolatey.org/profiles/mirthy

However, the chocolatey package lists @mitchellh and @armon as authors, so I assumed it was owned by Hashicorp.

I've used the package to bootstrap my use on Windows nodes - it saved me needing to figure out a service wrapper and so forth.
",petemounce,armon
893,2015-05-03 23:21:25,"Hi @ryanuber 
- [this is the link to the chocolatey package](https://chocolatey.org/packages/consul)
  - the comments (scroll down) are what I'm talking about.
- I _think_ the package source is https://github.com/sitano/chocolatey-packages, and I would guess community-provided.
  - this is the maintainer: https://chocolatey.org/profiles/mirthy

However, the chocolatey package lists @mitchellh and @armon as authors, so I assumed it was owned by Hashicorp.

I've used the package to bootstrap my use on Windows nodes - it saved me needing to figure out a service wrapper and so forth.
",petemounce,mitchellh
893,2015-05-04 00:01:07,"That makes sense, thanks for clarifying. Mitchell, Armon, and HashiCorp are listed under Authors, and the Maintainers section I think is what indicates who is maintaining the package. Perhaps you can get in touch with @sitano directly about the changes?

BTW, it's great to see this kind of community initiative!
",ryanuber,sitano
892,2015-04-28 22:12:22,"Since the ACL tokens are currently not passed as part of the URL's in the UI, a page refresh can cause the user to need to re-enter their ACL token. It also prevents sharing a URL with a team, which could be useful if you wanted to pass around a read-only token in a direct link.

Original report is here: https://groups.google.com/forum/#!topic/consul-tool/4XItKG8jO4M
/cc @pearkes
",ryanuber,pearkes
892,2015-05-07 18:56:44,"I think this is on purpose, to avoid leaking them. The token is saved in a cookie or local storage though. I'll let @pearkes comment.
",armon,pearkes
890,2015-05-18 22:47:38,"@mitchellh You did the `godep` integration on Vault, any thoughts?
",armon,mitchellh
884,2015-04-23 22:05:16,"Also, not sure how @ryanuber and @armon feel about this, but I'm not convinced this needs to be configurable.  A little bit of stagger by default seems like the right approach.
",ryanbreen,armon
884,2015-04-23 22:05:16,"Also, not sure how @ryanuber and @armon feel about this, but I'm not convinced this needs to be configurable.  A little bit of stagger by default seems like the right approach.
",ryanbreen,ryanuber
884,2015-04-23 22:10:16,"Hah, yeah, I actually pulled the logic from that function but for some reason though it was in a different package. Updated that.

@ryanuber and @armon, let me know what you think about it being configurable. I added it so that the behavior doesn't change for existing users unexpectedly but it may be a small change that would actually help everyone.
",artushin,armon
884,2015-04-23 22:10:16,"Hah, yeah, I actually pulled the logic from that function but for some reason though it was in a different package. Updated that.

@ryanuber and @armon, let me know what you think about it being configurable. I added it so that the behavior doesn't change for existing users unexpectedly but it may be a small change that would actually help everyone.
",artushin,ryanuber
883,2015-04-23 20:50:57,"I am trying to setup our DNS server hosted on windows in order to target our consuls instances when a client requests something within the 'consul' zone.
As far as I understand, we need to setup either a Forward Lookup zone or a Stub Zone on our master DNS.

**Setup**
Our master DNS: 192.168.1.130
Our consul instances: 192.168.1.190, 200, 210

All our clients have 192.168.1.130 as primary DNS.
They need to be able to resolve **.consul. In another hand, everything ending with '.consul' needs to be forwarded to consul.



Windows does not seem to recognize consul as an Authoritative zone.
Do you know if what i am trying to achieve is supported ?

PS: For some reason, it worked once for few minutes(despite error message saying that its not an Authoritative zone), and then went down. I never managed to make it work again.

**Error message on windows:**
https://www.dropbox.com/s/ql32tic5du8on9j/dns-1.jpg?dl=0
https://www.dropbox.com/s/yrxwvoxoewul5lk/dns-2.jpg?dl=0

Any feedback would be greatly appreciated

@mfischer-zd, @ryanuber and @armon you might have an idea
",florentvaldelievre,armon
883,2015-04-23 20:50:57,"I am trying to setup our DNS server hosted on windows in order to target our consuls instances when a client requests something within the 'consul' zone.
As far as I understand, we need to setup either a Forward Lookup zone or a Stub Zone on our master DNS.

**Setup**
Our master DNS: 192.168.1.130
Our consul instances: 192.168.1.190, 200, 210

All our clients have 192.168.1.130 as primary DNS.
They need to be able to resolve **.consul. In another hand, everything ending with '.consul' needs to be forwarded to consul.



Windows does not seem to recognize consul as an Authoritative zone.
Do you know if what i am trying to achieve is supported ?

PS: For some reason, it worked once for few minutes(despite error message saying that its not an Authoritative zone), and then went down. I never managed to make it work again.

**Error message on windows:**
https://www.dropbox.com/s/ql32tic5du8on9j/dns-1.jpg?dl=0
https://www.dropbox.com/s/yrxwvoxoewul5lk/dns-2.jpg?dl=0

Any feedback would be greatly appreciated

@mfischer-zd, @ryanuber and @armon you might have an idea
",florentvaldelievre,mfischer-zd
883,2015-04-23 20:50:57,"I am trying to setup our DNS server hosted on windows in order to target our consuls instances when a client requests something within the 'consul' zone.
As far as I understand, we need to setup either a Forward Lookup zone or a Stub Zone on our master DNS.

**Setup**
Our master DNS: 192.168.1.130
Our consul instances: 192.168.1.190, 200, 210

All our clients have 192.168.1.130 as primary DNS.
They need to be able to resolve **.consul. In another hand, everything ending with '.consul' needs to be forwarded to consul.



Windows does not seem to recognize consul as an Authoritative zone.
Do you know if what i am trying to achieve is supported ?

PS: For some reason, it worked once for few minutes(despite error message saying that its not an Authoritative zone), and then went down. I never managed to make it work again.

**Error message on windows:**
https://www.dropbox.com/s/ql32tic5du8on9j/dns-1.jpg?dl=0
https://www.dropbox.com/s/yrxwvoxoewul5lk/dns-2.jpg?dl=0

Any feedback would be greatly appreciated

@mfischer-zd, @ryanuber and @armon you might have an idea
",florentvaldelievre,ryanuber
882,2015-06-25 14:41:23,"Please include me (@armon), @ryanuber and @slackpad. 
",armon,slackpad
875,2016-02-02 03:47:37,"Hi @nathan7 I don't think it would be safe to pull the value inside the kvs_endpoint - you'd probably need to do that down in the state store to make sure there are no race conditions. I think you could add a new `KVSOp` for this new behavior and then plumb it down, probably as a parameter to `KVSLock` that changes its behavior. Let me know if you need any help getting this together!
",slackpad,nathan7
873,2015-04-21 00:19:28,"I'm seeing consul-replicate processes piling up in my servers: 
### Log output:



![](https://cldup.com/x4dbXIbt_N.png)
### Upstart script



CONSUL_REPLICATE_FLAGS=""-ssl -ssl-verify -syslog -log-level=debug -prefix=@us-east-1a""
",c4milo,us-east-1a
872,2015-04-20 23:31:07,"cc @armon 
",KFishner,armon
862,2015-04-14 02:42:08,"Fixes #321. This adds all of the CNAME's in the resolution chain to the result when a service's `Address` field contains a name which chains DNS CNAME's. An example is RDS. Simple change, hard test.

Thanks to @alouche and @cwstrommer for the repro and example fix.
",ryanuber,alouche
862,2015-04-14 02:42:08,"Fixes #321. This adds all of the CNAME's in the resolution chain to the result when a service's `Address` field contains a name which chains DNS CNAME's. An example is RDS. Simple change, hard test.

Thanks to @alouche and @cwstrommer for the repro and example fix.
",ryanuber,cwstrommer
850,2015-04-08 19:38:19,"Fixes #839
/cc @armon
",ryanuber,armon
848,2015-04-08 19:54:46,"Thanks for reporting this. The `undefined` makes me think maybe this is a javascript problem in the UI. @pearkes any ideas here?
",ryanuber,pearkes
831,2015-03-31 17:59:55,"From https://groups.google.com/forum/#!topic/consul-tool/JOGcE2o1GK0:

> the docs don't specify that you need to (or even that you can) set the 'https' address in the config. 
> If you don't do that it silently fails to set up the https server. Bit of a head-scratcher for a while.

/cc @ryanbreen
",ryanuber,ryanbreen
816,2015-04-01 09:42:42,"@armon would you mind please checking this to let us know whether we are on the right track or not?
",pepov,armon
813,2015-03-24 17:28:36,"Reference: #811 
/cc @pearkes
",ryanuber,pearkes
803,2015-03-24 22:38:58,"@Amit-PivotalLabs sorry about the delay, I've been gone for a few days. The agent configuration should be automatically copied into the server config at start time, so there shouldn't be any disconnect there.

I think it's probably fine to remove the validation from the agent, since the server does the same exact check during the next RPC call, and returns the same error. Invalid requests shouldn't be repeated, so I think this is sane.

Really it seems like this should be checked in one place (the session create code path). I'm not entirely sure why it is re-checked in the state store, and what the implications of removing that would be if servers are configured with different values. @armon any ideas on this?
",ryanuber,armon
802,2015-03-19 16:37:00,"Since this has come up a few times in different projects, I'm going to raise an issue for discussion. When determining a node's, service's, or logical service's status, one must do something like:



TL;DR - iterate over each check and `&` them together to get the ""best"" status for the node/service/logical service. 

I would like to propose that Consul does this calculation itself and exposes that result via the API and struct fields. It would be great if Consul could aggregate those checks into a single status. This would reduce a lot of duplication in our tooling and I think it would provide a better experience.

Thoughts @armon @ryanuber?
",sethvargo,armon
802,2015-03-19 16:37:00,"Since this has come up a few times in different projects, I'm going to raise an issue for discussion. When determining a node's, service's, or logical service's status, one must do something like:



TL;DR - iterate over each check and `&` them together to get the ""best"" status for the node/service/logical service. 

I would like to propose that Consul does this calculation itself and exposes that result via the API and struct fields. It would be great if Consul could aggregate those checks into a single status. This would reduce a lot of duplication in our tooling and I think it would provide a better experience.

Thoughts @armon @ryanuber?
",sethvargo,ryanuber
802,2016-09-15 08:46:27,"Ping @slackpad
",sethvargo,slackpad
796,2015-03-18 19:03:39,"We would like to be able to configure the minimum Session TTL rather than have it be hardcoded to 10s (although it could default to 10s if a minimum value isn't explicitly passed in).  This would be a command line flag as well as a config file option.  Specifically, we have several automated tests where we spin up a local consul cluster and test behaviour around locks being acquired and released, and don't want to have to wait for things to happen on a 10s time scale.

Would you all support a pull request for this feature?

For symmetry the maximum TTL could also be made configurable if that's desirable.

Thanks,
Amit + @ematpl
",Amit-PivotalLabs,ematpl
794,2015-03-18 14:41:08,"/cc @ryanuber 
",sethvargo,ryanuber
758,2016-06-16 22:14:56,"Hi

We were having a similar conversation in one of the InfluxData Telegraf Github issues (https://github.com/influxdata/telegraf/issues/860) and @StianOvrevage mentioned  https://godoc.org/bosun.org/cmd/scollector has a -winsvc flag which makes the binary register correctly as a Windows Service. 

https://github.com/bosun-monitor/bosun/blob/master/cmd/scollector/service_windows.go seems to do the magic. 

@slackpad @mitchellh Would you consider adding something similar to make running the Consul agent a bit easier in Windows machines? NSSM works great but it certainly seems a bit of a hack
",ricardclau,mitchellh
758,2016-06-16 22:14:56,"Hi

We were having a similar conversation in one of the InfluxData Telegraf Github issues (https://github.com/influxdata/telegraf/issues/860) and @StianOvrevage mentioned  https://godoc.org/bosun.org/cmd/scollector has a -winsvc flag which makes the binary register correctly as a Windows Service. 

https://github.com/bosun-monitor/bosun/blob/master/cmd/scollector/service_windows.go seems to do the magic. 

@slackpad @mitchellh Would you consider adding something similar to make running the Consul agent a bit easier in Windows machines? NSSM works great but it certainly seems a bit of a hack
",ricardclau,slackpad
758,2016-06-16 22:14:56,"Hi

We were having a similar conversation in one of the InfluxData Telegraf Github issues (https://github.com/influxdata/telegraf/issues/860) and @StianOvrevage mentioned  https://godoc.org/bosun.org/cmd/scollector has a -winsvc flag which makes the binary register correctly as a Windows Service. 

https://github.com/bosun-monitor/bosun/blob/master/cmd/scollector/service_windows.go seems to do the magic. 

@slackpad @mitchellh Would you consider adding something similar to make running the Consul agent a bit easier in Windows machines? NSSM works great but it certainly seems a bit of a hack
",ricardclau,StianOvrevage
751,2015-03-03 22:19:24,"This is a rough pass at documenting the anti-entropy internals to help users better understand the mechanics of it. @armon if you could take a quick look and make sure everything is accurate that would be good. This is sort of hard to document in an easy-to-understand way so all suggestions are welcome.

/cc @ryanbreen if you want to take a look and adjust some language, move things around, or anything else that would be great!
",ryanuber,armon
751,2015-03-03 22:19:24,"This is a rough pass at documenting the anti-entropy internals to help users better understand the mechanics of it. @armon if you could take a quick look and make sure everything is accurate that would be good. This is sort of hard to document in an easy-to-understand way so all suggestions are welcome.

/cc @ryanbreen if you want to take a look and adjust some language, move things around, or anything else that would be great!
",ryanuber,ryanbreen
744,2015-03-02 00:16:24,"This suggested language covers cases where manual removal of failed nodes from peers.json isn't the most expedient path to resolution.  Since this doc is so critical for operators working in tense situations, I would love to get some feedback from @armon and @ryanuber about whether these changes are accurate and appropriate.
",ryanbreen,armon
744,2015-03-02 00:16:24,"This suggested language covers cases where manual removal of failed nodes from peers.json isn't the most expedient path to resolution.  Since this doc is so critical for operators working in tense situations, I would love to get some feedback from @armon and @ryanuber about whether these changes are accurate and appropriate.
",ryanbreen,ryanuber
742,2015-06-04 04:28:38,"The TCP ping change is in and should help with flapping in bad UDP connectivity scenarios, providing a clear log message when this occurs. This should make it into the next release of Consul.

@ashish235 please re-open this or create a new issue if your investigation leads you to think this wouldn't help what you were seeing.

@marc this should help prevent these nodes from getting marked bad in the first place since there's an alternate TCP ping mechanism, so I think we should be covered.
",slackpad,marc
730,2015-02-23 19:07:16,"Seth, totally agreed about the need for more granularity, but @ryanuber already cracked the HTTP API monolith prior to 0.5: https://consul.io/docs/agent/http.html.  Does that cover the specific example you cited?
",ryanbreen,ryanuber
723,2015-02-21 03:59:05,"Fixes #231 by blocking the HTTP API responses until a sync has been _attempted_. This is still a ""best-effort"" mechanism in that the call to `syncChanges()` can fail. In this case, the service or check actually **is** registered with the agent, so it doesn't make sense for the caller to retry. Thus, if we fail a `syncChanges()`, we only log a warning, but still return the 200-range response to the client. Consul's built-in anti-entropy will take care of syncing the services and checks to the catalog once it is able. This seems like the best we can do.

@armon thoughts on this?
",ryanuber,armon
721,2015-02-20 19:11:04,"As @ryanuber and I were discussing in #consul, after upgrading from 0.4.1 to 0.5.0 my single-node cluster (operating necessarily in bootstrap mode) has no leader.  It does self-elect but then steps down.  Starting up a _new_ single node cluster with an empty data-dir does not exhibit this problem.

config:



log:


",blalor,ryanuber
713,2015-02-19 22:25:53,"This looks good, but we should talk about ""data center"" versus ""datacenter"". We are very inconsistent in what we use and we should just standardize on one /cc @KFishner @armon @mitchellh 
",sethvargo,armon
713,2015-02-19 22:25:53,"This looks good, but we should talk about ""data center"" versus ""datacenter"". We are very inconsistent in what we use and we should just standardize on one /cc @KFishner @armon @mitchellh 
",sethvargo,mitchellh
713,2015-02-19 22:25:53,"This looks good, but we should talk about ""data center"" versus ""datacenter"". We are very inconsistent in what we use and we should just standardize on one /cc @KFishner @armon @mitchellh 
",sethvargo,KFishner
711,2015-02-18 23:17:09,"This PR adds support for the [SCADA service](http://scada.hashicorp.com) which is used to integrate into [Atlas](https://atlas.hashicorp.com). It makes use of the `scads-client` library to do most of the work. The only capability that is enabled via SCADA is the HTTP API, which required some minor changes to allow a dedicated listener.

/cc: @ryanuber 
",armon,ryanuber
710,2015-02-18 23:10:00,"@ryanbreen Fixed in ee51530
",armon,ryanbreen
707,2015-02-17 20:01:49,"/cc @ryanuber 
",armon,ryanuber
695,2015-02-13 01:03:06,"@ryanbreen So the code for it is here:
https://github.com/hashicorp/consul/blob/master/command/agent/session_endpoint.go#L105

But @sethvargo recently showed me that Golang time.ParseDuration does not allow a value without a suffix, so this may be a non-issue.
",armon,sethvargo
679,2016-08-17 08:05:08,"Great work @slackpad, thanks.
",j0hnsmith,slackpad
657,2015-01-29 21:36:54,"I'm trying to set up consul in AWS, so that Route53 delegates to consul for entries that consul serves. Because Windows doesn't have an equivalent to dnsmasq, it strikes me as a bit risky to add `127.0.0.1` as a DNS server on each of my nodes (I don't know how Windows chooses which DNS server to use, and so on).

So, I have [set up bind on my consul servers to forward requests on port 53 to consul on port 8600](https://consul.io/docs/guides/forwarding.html) - that works when I `dig` locally - I can do `dig @localhost consul.service.consul` and get back the correct response. 

(I would love to know how to do that by just adding an iptables port-forward, to avoid needing to run bind, but that can wait).

Now what I want to do is create a hosted zone in Route53, linked to my VPC, so that I can get [Route53's plus-2 DNS server](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html) to delegate to consul.

I have set up my internal hosted zone `foowibble`; AWS Route53 automatically creates NS and SOA records for me, and I have left these untouched.

I've then created an NS record, `consul.tenant1.foowibble` whose value is



(I'm aiming at a multi-tenant setup, with one consul cluster per tenant.)

I've then launched my cluster, and for now, manually created 1 A record per server in my 3-node cluster.

My server nodes are configured to use `consul.tenant1.foowibble` as the `domain` via `consul.json` - but now, on any of them (and after `consul reload`), I cannot get 



to respond, and so I certainly won't be able to get responses from the Route53 ""plus 2"" DNS.

Should I _expect_ consul to work with a domain with periods in it...?

If not, could it be made to? If it couldn't, what alternatives might I have to make this work...?
",petemounce,localhost
622,2015-01-21 03:00:34,"As yet another follow-up on #587 and #612, this re-introduces the ability to set ownership and permission bits as you please on the UNIX domain sockets.
- Delete socket if it exists on agent startup, and recreate during bind.
- Set ownership of socket file including user name/id, group id, and permissions e.g. `0755` via the new `unix_sockets` config construct. This makes setting any of these optional and keeps the address fields clean and concise.

The function which handles file permissions now takes an interface, and the `unix_sockets` construct implements it. This will make it very easy to introduce separate, nested config structures in the future if we want to support setting per-interface domain socket permissions.

This functionality is new to Consul, however, it was originally implemented in #587 by @jefferai. This is merely an iteration on the design.

@jefferai @armon @sethvargo any questions/suggestions/concerns more than welcome.
",ryanuber,armon
622,2015-01-21 03:00:34,"As yet another follow-up on #587 and #612, this re-introduces the ability to set ownership and permission bits as you please on the UNIX domain sockets.
- Delete socket if it exists on agent startup, and recreate during bind.
- Set ownership of socket file including user name/id, group id, and permissions e.g. `0755` via the new `unix_sockets` config construct. This makes setting any of these optional and keeps the address fields clean and concise.

The function which handles file permissions now takes an interface, and the `unix_sockets` construct implements it. This will make it very easy to introduce separate, nested config structures in the future if we want to support setting per-interface domain socket permissions.

This functionality is new to Consul, however, it was originally implemented in #587 by @jefferai. This is merely an iteration on the design.

@jefferai @armon @sethvargo any questions/suggestions/concerns more than welcome.
",ryanuber,jefferai
622,2015-01-21 03:00:34,"As yet another follow-up on #587 and #612, this re-introduces the ability to set ownership and permission bits as you please on the UNIX domain sockets.
- Delete socket if it exists on agent startup, and recreate during bind.
- Set ownership of socket file including user name/id, group id, and permissions e.g. `0755` via the new `unix_sockets` config construct. This makes setting any of these optional and keeps the address fields clean and concise.

The function which handles file permissions now takes an interface, and the `unix_sockets` construct implements it. This will make it very easy to introduce separate, nested config structures in the future if we want to support setting per-interface domain socket permissions.

This functionality is new to Consul, however, it was originally implemented in #587 by @jefferai. This is merely an iteration on the design.

@jefferai @armon @sethvargo any questions/suggestions/concerns more than welcome.
",ryanuber,sethvargo
617,2015-01-18 00:55:31,"The HTTP API documentation page has gotten fairly large over time. This splits the page into one page per ""section"", meaning K/V is a page, Health Checks are a page, etc., and gives each page a sub-nav link on the left hand nav pane:

![httpdocs](https://cloud.githubusercontent.com/assets/1642288/5790988/6efbdaae-9e69-11e4-8a5b-996421dccead.gif)

/cc @pearkes because I'm rather terrible at SCSS and may have made some mistake(s).
/cc @sethvargo because I'm sure this will affect SEO in some way.
",ryanuber,pearkes
617,2015-01-18 00:55:31,"The HTTP API documentation page has gotten fairly large over time. This splits the page into one page per ""section"", meaning K/V is a page, Health Checks are a page, etc., and gives each page a sub-nav link on the left hand nav pane:

![httpdocs](https://cloud.githubusercontent.com/assets/1642288/5790988/6efbdaae-9e69-11e4-8a5b-996421dccead.gif)

/cc @pearkes because I'm rather terrible at SCSS and may have made some mistake(s).
/cc @sethvargo because I'm sure this will affect SEO in some way.
",ryanuber,sethvargo
617,2015-01-18 00:58:27,"@pearkes @sethvargo Feel free to pull/update the branch as well if you need to.
",ryanuber,pearkes
617,2015-01-18 00:58:27,"@pearkes @sethvargo Feel free to pull/update the branch as well if you need to.
",ryanuber,sethvargo
617,2015-01-21 06:56:08,"ping @pearkes @sethvargo, any input? just a :+1: if you think its ok as-is would be fine.
",ryanuber,pearkes
617,2015-01-21 06:56:08,"ping @pearkes @sethvargo, any input? just a :+1: if you think its ok as-is would be fine.
",ryanuber,sethvargo
616,2015-01-18 04:35:26,"@ryanbreen No, thanks for noticing. Rebased, fixup and forced push.
",ceh,ryanbreen
612,2015-01-20 15:04:10,"@ryanuber @armon  I wish you guys had included me in the discussions before unilaterally changing this around. Both of these are bad changes. I would appreciate if you reverted these and included me in the discussion.
",jefferai,armon
612,2015-01-20 16:54:50,"Hi @sethvargo @ryanuber @armon 

First off, I want to point out that this is an example of being a _terrible_ upstream. The syntax was proposed on the mailing list. Nobody, including Consul team members, objected. Ryan asked about it on the previous pull request, then after I explained my rationale, he thanked me for it and expressed no reservation.

You guys could have had a further discussion with me on the previous PR. You could have expressed concern and asked for community input on the mailing list. You could have poked me in email or on IRC. You could even have gotten me to make needed changes prior to you merging them so that my time wasn't wasted coding them in and writing tests for them only for you guys to waste your time reverting them less than 24 hours later.

That sucks.

So let's go over the problems with these changes.

1) nginx is not the only game in town. Many other services -- for instance, dovecot, clamav, _and_ your own later example of postgres -- allow you to specify the (usually) user and (definitely) group and mode you want to use, to make it easier and -- crucially -- more secure for other services to interoperate. That way you don't need to have the primary group you are running consul under be the group that everyone else uses to communicate with it. Removing that capability reduces both flexibility and security.

2) You can't simply get around this by making a directory and creating the socket in that directory and having it inherit permissions. I don't know what man page you're looking at, but `man 7 unix` on my Ubuntu 14.04 system says nothing of the sort. And I just verified that using netcat -- permissions of the parent directory have nothing to do with anything, so the workaround you guys suggest isn't actually a workaround. Proof:



3) Rather than removing the user/group/mode altogether, you could have simply expanded the configuration language, as Ryan and I discussed in the previous PR. As I said there, nobody expressed any issue with the configuration language since the original RFC, and if people didn't like the coalesced syntax the right thing to do would be to modify configuration to support sockets properly. You guys picked the nuclear (and time-wasting) option instead.

4) Leaving aside the point of what a user would do with a dead socket if Consul died in an unclean fashion, I don't know where you got your intel about removing sockets and postgres, but it's wrong. If postgres dies and you restart it, something in postgres wipes the socket and recreates it. I don't know what does it, but I _can_ tell you that it's not Ubuntu's init script. It's one of the pg tools, or it's the daemon itself. I just tested this -- on unclean shutdown the socket remains, and upon restarting the socket is removed and recreated, which I can tell because the inode changes:



Here's another example, using everyone's favorite netcat:



As a contrast, let's see the workflow with nginx:



I don't know where you guys got your intel, but it's wrong. You care about principle of least surprise...so do I. The least surprise solution is not to leave a dead socket lying around that the user can't do anything with anyways and then fail to start because of it. That will just leave users pissed off when a simple restart of consul fails to work. The least surprise solution is to do what everyone else is doing, and remove the socket and then re-create it.
",jefferai,armon
610,2015-01-17 00:39:15,"OK @ryanuber - ready for your second pass.
",dave-tucker,ryanuber
606,2015-01-16 23:58:57,"I'm going to merge this in. @armon if you want to change the endpoints or anything else feel free, or let me know!
",ryanuber,armon
606,2015-01-20 22:22:13,"Looks really good. Minor feedback, could we also add the API client updates for this too? One thing worth discussing is a potential CLI command to easily toggle the node/services. It seems like it would be useful.

@sethvargo @mitchellh thoughts?
",armon,mitchellh
605,2015-01-15 10:48:59,"I have a 3 server cluster in AWS, managed by a 3/3/3 ASG.

I start the servers with `-bootstrap-expect 3` via an upstart job. How should I handle the case where an instance dies unexpectedly? As in, without manual intervention?

Should I have logic in the upstart job that only adds the -bootstrap-expect flag if the instance is a replacement for a failed instance? I guess I could detect that by querying the launch-time of the instances in the cluster, and if the existing instances are older by, say, an hour or more, assume the current instance is a new one and it shouldn't be bootstrapping?

Or, should I start the servers _without_ `-bootstrap-expect`, and instead issue `consul info` queries to other servers to peek to see whether there's a bootstrapped cluster?

I found [auto-consul](https://github.com/ethanrowe/auto-consul) but have not yet done more than glance at it. (cc @ethanrowe for interest).

One upstart job to run consul like 



and one upstart job to join the other servers in the cluster:



and a consul.json like:



I also have an upstart job to set an EC2 tag on the server instances once the output of `consul info` locally shows `bootstrap = false`. I hope that's the best thing to use to indicate that a cluster has been bootstrapped...?
",petemounce,ethanrowe
605,2015-09-23 17:42:09,"@cleung2010 Yes, if you do not `leave` or `force-leave` old server nodes while quorum is maintained.

Take the following scenario:

You have an ASG with the following servers (the raft topology matches this):



Your quorum is 2, because the total server count is 3.

If you lose `i-6789ab` and `i-234567` is created to replace it, then you will have the following raft topology:



If `i-cdef01` then fails and `i-89abcd` is created to replace it, the raft topology will now be:



So, to answer your question, yes, adding new servers does increase the quorum.
",highlyunavailable,cleung2010
587,2015-01-08 20:13:32,"We strive for as high of test coverage as possible, and I think there are lots of testable areas with this patch. All of the tests are currently passing for us, and I believe @ryanuber changed the tests that were failing for you so that they should be passing more reliably as well.
",armon,ryanuber
576,2015-01-05 20:33:32,"This helps by rejecting configurations with invalid keys. Mapstructure supports this already, but the way we parse services and checks doesn't use straight mapstructure decoding, so there are a few discarded fields in the config struct. AFAIK there wasn't a better way to allow this.

/cc @armon @mitchellh
",ryanuber,armon
576,2015-01-05 20:33:32,"This helps by rejecting configurations with invalid keys. Mapstructure supports this already, but the way we parse services and checks doesn't use straight mapstructure decoding, so there are a few discarded fields in the config struct. AFAIK there wasn't a better way to allow this.

/cc @armon @mitchellh
",ryanuber,mitchellh
573,2015-01-05 19:17:03,"Good catch! @ryanuber maybe we can canonicalize somehow? I think windows has some characters it doesn't like either. Simplest may be to just MD5(ServiceID) or something.
",armon,ryanuber
563,2014-12-30 18:18:52,"/cc @KFishner 
",sethvargo,KFishner
557,2014-12-27 20:51:42,"While experimenting with consul on ceph based VMs, which were hanging due to ceph i/o (deep scrub), the VM becomes very slow/hangs for some time (time > 60 seconds). When tihs happens, consul-0.4.1 crashed with the following traceback.

I hope this helps do diagnose the problem.

@sethvargo edit, moved to Gist: https://gist.github.com/sethvargo/5b9f38e1693f414241a3
",telmich,sethvargo
555,2015-01-02 16:35:41,"@blalor Thanks for tackling this! The Apiary docs do look really good. I bet we can get pretty close to that by improving the docs generation we have now, instead of needing to link in an external service.

@sethvargo Thoughts? Any extensions to middleman we can use to make it more like Apiary and make the API doc experience nicer?
",armon,sethvargo
551,2014-12-19 11:57:50,"Ah, just noticed that @ryanuber already were assigned to #387.

This might even be considered a breaking change and should not go into /v1?
",ceh,ryanuber
550,2015-01-05 13:20:30,"@armon @ryanuber do you have any thoughts about that?
",i0rek,armon
550,2015-01-05 13:20:30,"@armon @ryanuber do you have any thoughts about that?
",i0rek,ryanuber
544,2016-04-11 07:17:12,"While implementing #1935 which makes this configurable, and reviewing it with @sean- we realized that lowering this too much can be fairly dangerous for the case of Consul servers. If there's a partition that isolates a server and this is set low, the server could get kicked prematurely and would need to be re-joined or restarted in order to work again, whereas with the current default setting you'd have to have 72 hours elapse before that's a problem.

Are people mostly worried about clutter in `consul members`, or is there some other problem people are hoping will be fixed by making this configurable?
",slackpad,sean-
539,2014-12-14 18:36:48,"Hey @Scorpiion it looks like we have [special cases for building BSD packages](https://github.com/hashicorp/consul/blob/0953efd5a0044756857860ca76c45f6690c5a423/scripts/build.sh#L30-L32) in the build script, but it doesn't look like we are uploading them to [the Bintray repo](http://dl.bintray.com/mitchellh/consul). I'll let @armon chime in, because I suspect there is a history/reason why we don't.
",sethvargo,armon
509,2014-12-03 19:12:22,"@lyrixx thanks for the report. Just looking over the MDB source I'm not exactly sure how this happens.

[This comment](https://github.com/armon/gomdb/blob/master/mdb.c#L6465) suggests that this should not happen, so perhaps this could be an upstream bug. Again, not sure though.

@armon thoughts?
",ryanuber,armon
504,2014-11-30 18:44:27,"@ryanuber thoughts? This may also be an issue for the API persisted services
",armon,ryanuber
497,2014-11-24 19:07:38,"Writes local services and checks to JSON files in the data directory, and loads them on agent start. The files are removed as services and checks are deregistered. Files seemed like the way to go since clients don't use MDB.

When checks are loaded, their health status is marked critical to avoid placing potentially unhealthy services into the service pool.

Fixes #464.

/cc @armon, let me know if I am missing anything here.
",ryanuber,armon
478,2014-11-17 23:11:18,"Sounds good, let me go through the comments and will update tomorrow.

On Nov 17, 2014 6:08 PM, Ryan Uber notifications@github.com wrote:

@amalaviyhttps://github.com/amalaviy This is looking good. I've left a few minor comments above. Other than that, if we can get some tests and comment all the methods in here, we will be in good shape!

â€”
Reply to this email directly or view it on GitHubhttps://github.com/hashicorp/consul/pull/478#issuecomment-63394055.
",amalaviy,amalaviyhttps
472,2014-11-25 19:34:00,"/cc @pearkes
",ryanuber,pearkes
467,2014-11-12 21:19:42,"This issue wants to explore the viability of the Agent functionalities used as a library in a new binary by using it as a golang pkg. For some context we (SoundCloud) are currently rebuilding our Service Discovery and have already well established dimensions in our SD schemas. In order to keep those stable we have to wrap consul in one way or another. As we are convinced that the general consul architecture is the way to go forward we like to want to deploy an agent per host. Our own Agent would have an HTTP as well as a DNS interface enforcing our dimensions and translate those into Consul services with appropriate set of tags.

The idea being instead of having our agent and the Consul agent running side-by-side on each host we want to wrap the Agent codebase to let our agent act as a participant in the gossiping, forward requests, etc. How viable is such approach in terms of:
- readiness of the Agent code to be used as library
- security implications
- other showstoppers

Happy to discuss and/or contribute in order to make this possible.

---

/cc @grobie @peterbourgon
",xla,grobie
467,2014-11-12 21:19:42,"This issue wants to explore the viability of the Agent functionalities used as a library in a new binary by using it as a golang pkg. For some context we (SoundCloud) are currently rebuilding our Service Discovery and have already well established dimensions in our SD schemas. In order to keep those stable we have to wrap consul in one way or another. As we are convinced that the general consul architecture is the way to go forward we like to want to deploy an agent per host. Our own Agent would have an HTTP as well as a DNS interface enforcing our dimensions and translate those into Consul services with appropriate set of tags.

The idea being instead of having our agent and the Consul agent running side-by-side on each host we want to wrap the Agent codebase to let our agent act as a participant in the gossiping, forward requests, etc. How viable is such approach in terms of:
- readiness of the Agent code to be used as library
- security implications
- other showstoppers

Happy to discuss and/or contribute in order to make this possible.

---

/cc @grobie @peterbourgon
",xla,peterbourgon
452,2014-11-04 19:46:38,"This is definitely an odd situation. If you really are sealed off from all outside network activity, then I'm not sure how this could be happening. You might want to check your agent's configuration files to make sure you don't have any ""left-over"" start-join's for nodes that you no longer own.

I would strongly recommend enabling gossip-layer encryption to avoid this kind of thing in the future. If all of the gossip messages were encrypted, the only way for an outsider to access the cluster would be to guess the encryption key, which is really not likely to happen.

@armon any other thoughts on this one?
",ryanuber,armon
441,2014-10-28 04:54:12,"Web UI download link is on /downloads.html not /downloads_tools.html.

Reported by @damomurf on IRC.
",tomlanyon,damomurf
436,2014-10-27 02:23:21,"There are currently a number of sites on the Internet that link to the old
downloads_web_ui.html page, including some popular blog posts. Since the WebUI
has been moved onto the Consul page itself, these links are now broken.

This commit adds a 301 (to preserve SEO) redirect from the old page to the new
one.

/cc @armon @ryanuber 

If this looks good, we should merge it ASAP so we don't loose the existing SEO.
",sethvargo,armon
436,2014-10-27 02:23:21,"There are currently a number of sites on the Internet that link to the old
downloads_web_ui.html page, including some popular blog posts. Since the WebUI
has been moved onto the Consul page itself, these links are now broken.

This commit adds a 301 (to preserve SEO) redirect from the old page to the new
one.

/cc @armon @ryanuber 

If this looks good, we should merge it ASAP so we don't loose the existing SEO.
",sethvargo,ryanuber
435,2014-10-27 02:16:20,"The word ""Jespen"" is one of our top keywords because it appears so many times
in the Jespen Testing page. This commit adds a comment to disable Google
indexing in that code block so we can better target keywords.

/cc @armon 
",sethvargo,armon
435,2014-10-27 02:32:14,"@ryanuber want to take a quick look at this one too please :smile:? If it's good, I can deploy now
",sethvargo,ryanuber
417,2014-10-21 21:25:27,"## HashiCorp:
- [Envconsul](https://github.com/hashicorp/envconsul)
- [Consul Template](https://github.com/hashicorp/consul-template)
- [Consul Replicate](https://github.com/hashicorp/consul-replicate)
- [Consul Web UI](https://github.com/hashicorp/consul/tree/master/ui)
## Community
- [Confd](https://github.com/kelseyhightower/confd)
- [Consulate](https://github.com/gmr/consulate)
- [Crypt](http://xordataexchange.github.io/crypt/)
- [git2consul](https://github.com/ryanbreen/git2consul)
- [docker-consul](https://github.com/progrium/docker-consul)
- [fsconsul](https://github.com/ryanbreen/fsconsul)
- [registrator](https://github.com/progrium/registrator)

/cc @armon @mitchellh 
",sethvargo,armon
417,2014-10-21 21:25:27,"## HashiCorp:
- [Envconsul](https://github.com/hashicorp/envconsul)
- [Consul Template](https://github.com/hashicorp/consul-template)
- [Consul Replicate](https://github.com/hashicorp/consul-replicate)
- [Consul Web UI](https://github.com/hashicorp/consul/tree/master/ui)
## Community
- [Confd](https://github.com/kelseyhightower/confd)
- [Consulate](https://github.com/gmr/consulate)
- [Crypt](http://xordataexchange.github.io/crypt/)
- [git2consul](https://github.com/ryanbreen/git2consul)
- [docker-consul](https://github.com/progrium/docker-consul)
- [fsconsul](https://github.com/ryanbreen/fsconsul)
- [registrator](https://github.com/progrium/registrator)

/cc @armon @mitchellh 
",sethvargo,mitchellh
406,2014-10-17 18:58:29,"@fidian I was just talking with @armon about this. The main issue is that just straight replacing the value of configuration variables doesn't necessarily mean they will immediately take effect. This is because at agent start, various goroutines, port binding, and other setup takes place, which we would have to replace on config reloads to effectively change the configuration. It might eliminate the point of the config reload in the first place, which is to reload configuration without disrupting the agent.

The things that can be safely reloaded on the fly include:
- Log level
- Services
- Checks
- Watch Plans

For now, we don't have any plans to try supporting a live reload of the entire consul agent, since the disruptiveness becomes close to the same as just restarting.
",ryanuber,armon
393,2014-10-11 19:05:25,"I think this might be possible if mDNS was added to Consul. The gossip layer below actually does support mDNS discovery, which could possibly be enabled on both LAN and WAN gossip pools, allowing them to join each other in a zero-touch way. This, combined with the `-bootstrap-expect` flag, could allow a cluster of servers to find eachother and auto-bootstrap once the expected number of servers had joined. Raft should be able to figure out who the leader is from that point.

@armon do you think something like this would work?
",ryanuber,armon
392,2014-10-16 20:44:01,"@kiryam Are you talking about the same use case as @erfane, where `consul exec` is run on very short intervals (< 3 seconds) for an extended period of time? Please clarify, and if you can provide any traces or logs from the machines when this happens that would be helpful!
",ryanuber,erfane
386,2014-10-06 23:20:32,"/cc @pearkes @mitchellh can you take a :eyes: please? This is the first step in unifying all the middleman projects in a single engine for consistency.
",sethvargo,pearkes
386,2014-10-06 23:20:32,"/cc @pearkes @mitchellh can you take a :eyes: please? This is the first step in unifying all the middleman projects in a single engine for consistency.
",sethvargo,mitchellh
384,2014-10-15 22:31:31,"@armon to my understanding we can't guarantee the service ID to be correct, as we initially included this but ended up removing it. Is that accurate?
",pearkes,armon
384,2016-05-03 08:48:59,"@armon any improvement on this issue?
",jsvisa,armon
336,2014-10-09 21:24:03,"Awesome! I'll give it another look over soon. I just discussed 1 with @mitchellh, and he had a good idea. Lets only use the `-encrypt` flag if there is no keyring to install the primary key. Once the key ring is in place, we should ignore the flag, and WARN the user that we are ignoring because of the keyring. This way a user can delete the keyring file if they want to reset it, but it removes this complex user interaction.

With 2, it just is the WAN timing is much slower. Gossip just takes longer, so I think that is fine.

With 3, that sounds great. Makes sense.
",armon,mitchellh
317,2014-09-02 17:54:41,"I feel bad making an Issue for the CI failures. But its just in case literally @armon doesn't know about it. Sorry if you do already.
",drnic,armon
276,2014-08-08 21:11:56,"#225 has an answer from @mitchellh on this. I think it probably came down to `.zip` being the most universal format in terms of out-of-the-box support in most operating systems.
",ryanuber,mitchellh
274,2014-08-06 21:21:08,"Aha... plain old ""bootstrap"" on a single node in 0.3.1 works as I'd expect. I guess I have @robxu9 to thank :-)
",kshep,robxu9
271,2014-11-04 18:26:58,"TCP:8300-8301 and UDP:8301 should be enough in your restricted case.

But it sounds fishy that your infrastructure won't let you add security groups easily. IMO you should fix this 1st (having an easy to maintain infra) as you might want to open more in the future to use more Consul stuff.

You should try and iterate if you see connection errors.

Say hello to @funkymed ;)
",lra,funkymed
271,2014-11-04 20:09:46,"Thanks for your quick response ;)

Actually, it's not possible to attach new SG in AWS to existing server. It's a PITA, but I was able to fix it this afternoon. We will add a common SG for the next servers, but it takes time to ""refactor"" the infrastructure. If you have good tips about that, I will carefully listen ;)

And I will say hello to @funkymed  tomorrow ;) The word is small :p
",lyrixx,funkymed
268,2014-08-01 21:52:32,"Hi, 

I renamed the ""MaxServiceResponses"" constant to ""MaxUDPResponses"" because is usable only for UDP network responses and I made it configurable using ""max_udp_responses"" in ""dns_config"".

[]s
@rogerlz
",rogerlz,rogerlz
263,2014-07-30 15:17:14,"Regarding `consul info`, I agree. It would have to be thought out a bit as it applies to each consul node and has quite a bit to just shove into the UI. Mostly it would be nice to know the `consul:`, `raft:` and maybe `serf_lan/wan:` sections from that output.

@pearkes Any thoughts on where some of the member info can fit in? My initial thought was on the node detail when opened. There doesn't seem to be a whole lot of room to add detail to the node in the node list on the left if you want it there too. But here's a rough idea on what the open node view could be:

![screen shot 2014-07-30 at 7 54 23 am](https://cloud.githubusercontent.com/assets/44689/3750910/1cea1d0c-17fa-11e4-81b6-f8bfc6ab6746.png)
",mtchavez,pearkes
257,2014-07-22 19:29:31,"I've found myself wanting to deregister services from within the UI more than a few times, especially while debugging a new setup. @pearkes pointed out that an ""action bar"" would be a good way to fit these sorts of actions so I've mocked up the simplest possible version of what that could look like:
![2014-07-22-122231_517x391_scrot](https://cloud.githubusercontent.com/assets/211613/3663708/c0fb873a-11d5-11e4-8682-599aff34dc90.png)

Is this something you want? If so, what actions should be supported? Here's what I'm thinking so far:

Nodes:
- Deregister
- Register _?_

Services:
- Deregister
- Register _?_

Checks:
- Mark passing
- Mark warning
- Mark critical
- Register _?_
",spro,pearkes
254,2014-07-22 15:22:47,"Are you using docker? This is an issue we've seen that is related to Docker for some reason. I know @progrium ran into this as well.

If you are using `-bootstrap-expect` there is no reason to restart the servers! It is handled automatically. However, if you _are_ using Docker, we've seen this issue resolve itself after about 5 minutes. Has something to do with cached routing tables or something...
",armon,progrium
248,2014-07-15 22:20:58,"I had a discussion with @armon today regarding the upcoming ACL support. It looks great, but I am in an enterprise setting and concerned about integration with existing SSO/auth mechanisms. Apparently you are thinking of LDAP; we use a combination of PubCookie/SAML...and the same thing everyone uses, SSH.

SSH is so ubiquitous that it's essentially in every enterprise large and small, every startup, and every nerd's set of home tools.

So, I thought I'd post my idea here for a bit broader input. My proposal is this: allow RPC authentication via SSH, by communicating with ssh-agent to verify ownership of private keys matching SSH public keys associated with tokens in Consul's database. Once authenticated, a Consul token could be provisioned to them for some period of time -- potentially storing the value in an environment variable, where it will disappear upon logout (unless the user specifically stores it somewhere).

The same mechanism could be used to get a token for the web UI; the generated token could be plugged into a web session to authenticate the user, without requiring SSH agent communication.

I'm sure the devil is in the details, but I like the idea of using an existing, widely deployed, and secure mechanism as the basis for (at least one method of) token management.
",jefferai,armon
246,2014-07-15 16:54:27,"I thought about doing this recently, actually. I helped with the Serf key rotation feature, but admittedly haven't done a whole lot of experimentation with Consul. If there is interest then I'd definitely be up for taking a stab at it. Perhaps @armon could shed some light on potential caveats (if any) of hooking into this from Consul.
",ryanuber,armon
233,2014-06-28 20:34:59,"cc @armon -- I'd probably like to write more tests before merging this, but can you ACK that this looks like the right track to you before I do so?

---

Namely, don't check the DNS names in TLS certificates when connecting to
other servers.

As of golang 1.3, crypto/tls no longer natively supports doing partial
verification (verifying the cert issuer but not the hostname), so we
have to disable verification entirely and then do the issuer
verification ourselves. Fortunately, crypto/x509 makes this relatively
straightforward.

If the ""server_name"" configuration option is passed, we preserve the
existing behavior of checking that server name everywhere.

No option is provided to retain the current behavior of checking the
remote certificate against the local node name, since that behavior
seems clearly buggy and unintentional, and I have difficulty imagining
it is actually being used anywhere. It would be relatively
straightforward to restore if desired, however.
",nelhage,armon
224,2014-07-16 10:27:35,"This should now cover the DNS interface, I'm not sure if we need to change any other interface. @armon any input?
",tiwilliam,armon
223,2014-06-18 23:20:23,"@armon and I talked about this privately, but we need to rename `-expect` to `-bootstrap-expect`. Although it isn't obvious even in the latter case what it exactly does, it is obvious and clear that it is related to bootstrapping and should therefore probably only apply to servers. We concluded that `-expect` is too vague for something we'll need to support forever.

This must happen prior to 0.4
",mitchellh,armon
214,2014-07-02 20:29:37,"Fixed by @nelhage in #233 
",armon,nelhage
208,2014-07-16 19:55:22,"@andrewwatson mentioned the possibility of named groups of data centers. e.g. ""EU"" -> [""UK"", ""GE"", ""FR""]
",armon,andrewwatson
208,2015-08-05 21:59:58,"@split3 Correct! You will be able to query multiple DCs at the same time.
",armon,split3
202,2016-12-20 04:17:35,/cc @kyhavlov - this may get picked up if we do any HIL interpolation as part of node tag support,slackpad,kyhavlov
197,2014-06-08 20:18:20,"@andrewwatson UI is not tested via Travis no worries. I will let @pearkes review and merge this since he is owning the UI.
",armon,pearkes
180,2014-06-02 04:25:44,"In my opinion, no, there should not be an option for a normal user to list these entries. The idea is that they are hidden from enumeration and by using one that is random and long, you can store entries in consul that are undiscoverable by others.

@armon An administrator, though, should have a way to do that. Adding such an ability is tricky because there isn't currently an admin mode. Is a configured token that can be presented by an admin be enough?

This (as well as this evenings BBQ with @mitchellh) has made me realize perhaps we should put energy into a ACL/capabilities system instead, since dealing with all of the side effects of hidden entries may result in more changes that a proper ACL system.

@armon Love to chat about that on Tuesday!
",evanphx,mitchellh
180,2014-06-02 21:47:46,"In prep for tomorrows discussion, here are some of my thoughts on on ACL system.

# ACL vs Capabilities

Typically, ACLs are seen as permission style bits. Elements are tagged with owners and bits that indicate what the owner and everyone else can do. Classic unix style. This introduces a whole bunch of concepts (users, perm bits, secure tokens (passwords), etc).

A slightly simpler approach is a capabilities style system (thanks @tarcieri). Instead entries can be tagged with a list of capabilities which are generated when requested. The capability PKI to carry along with it a secure payload that indicates what the capability is for. To access an entry, the client presents this capability token, which is verified and checked to see if this token can access this entry.

Capabilities are a bit easier in terms of server side implementation because they act as just a key to a lock that the client must hold to open the entry. But they can be more cumbersome because a client may have to hold many capability tokens to access different things, providing each one at different times. From a security standpoint this is good because it limits the footprint available to a stolen/lost token but users may find their management difficult.

For further reading: http://en.wikipedia.org/wiki/Capability-based_security
",evanphx,tarcieri
177,2014-05-28 18:03:14,"Oh yikes! I will try to get a new binary uploaded today. I'll bug @mitchellh since he has a windows machine.
",armon,mitchellh
174,2014-05-26 21:05:27,"LGTM! Will let @armon have a second opinion before merge.

OT: Saw your talk live at DEFCON 2011, impressive work!
",tiwilliam,armon
172,2014-10-06 17:51:33,"@naelyn Yes exactly.
",armon,naelyn
166,2015-11-20 22:40:35,"Hi @cleung2010 - there's no difference in the client vs. server code path that I can see for the server. If you do a `curl http://localhost:8500/v1/agent/self?pretty` does your `UiDir` look correctly configured in there? Is it possible you've got another JSON file that's stomping on the one above?
",slackpad,cleung2010
166,2015-12-17 14:57:26,"@cleung2010 
it is not working for me . i am running consul in local box and trying to access in same box.

> > docker run test -bootstrap -ui-dir /ui
> > ==> WARNING: Bootstrap mode enabled! Do not enable unless necessary
> > ==> WARNING: It is highly recommended to set GOMAXPROCS higher than 1
> > ==> Starting Consul agent...
> > ==> Starting Consul agent RPC...
> > ==> Consul agent running!
> >          Node name: '200d4ea560f4'
> >         Datacenter: 'dc1'
> >             Server: true (bootstrap: true)
> >        Client Addr: 0.0.0.0 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
> >       Cluster Addr: 172.17.0.12 (LAN: 8301, WAN: 8302)
> >     Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
> >              Atlas: <disabled>

  Log data will now stream in as it occurs:



my config file 

> > 
> > 
> > }

and i am using setup from >>https://github.com/gliderlabs/docker-consul/tree/master/0.6/consul-server

in local box outside the container 

> > curl -v -L 172.17.0.12:8500
> > - Rebuilt URL to: 172.17.0.12:8500/
> > - Hostname was NOT found in DNS cache
> > -   Trying 172.17.0.12...

but inside the container, i am able to get page using curl -v -L localhost:8500
",hridyeshpant,cleung2010
166,2015-12-17 20:26:55," @cleung2010 
docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                  NAMES
b3459a09f0bd        test                ""/bin/consul agent -s""   5 hours ago         Up About a minute   8300-8302/tcp, 8400/tcp, 8500/tcp, 8301-8302/udp, 8600/tcp, 8600/udp   admiring_curie
the git hub repo is our internal repo, you create a image from https://github.com/gliderlabs/docker-consul/tree/master/0.6/consul-server with the changed in  server.json 
""addresses"": {
    ""http"": ""0.0.0.0""
    }
i tried running command like docker run -p 8500:8500 test -bootstrap -ui-dir /ui , but no success.
",hridyeshpant,cleung2010
165,2014-06-02 14:31:37,"It's my understanding that tags aren't necessarily consistent at the service level. That is, a service on 2 different nodes may have different tags, thus the Web UI would need to ""resolve"" this conflict, which isn't really ideal.

@armon may have thoughts on a solution for this.
",pearkes,armon
159,2014-05-18 20:54:46,"Well that is interesting. /cc @armon 

Reopening.
",mitchellh,armon
159,2015-12-06 23:59:48,"That'd be great! @jperkin would be the best person to talk to regarding
this. But I'm not sure how ""ethical"" the patches are that I'm using.

On Sat, 5 Dec 2015 at 17:15, Charles Phillips notifications@github.com
wrote:

> @cmacrae https://github.com/cmacrae thanks for this, very helpful.
> 
> I would like to get Consul into pkgsrc
> https://pkgsrc.joyent.com/docs/creating/, I see hashicorp/vault
> https://github.com/hashicorp/vault is already present
> http://ftp.netbsd.org/pub/pkgsrc/current/pkgsrc/devel/hs-vault/README.html.
> Is there anyone here who can help fasttrack the process?
> 
> â€”
> Reply to this email directly or view it on GitHub
> https://github.com/hashicorp/consul/issues/159#issuecomment-162224344.
",cmacrae,jperkin
159,2016-01-05 19:20:10,"Hey all - it looks like @jen20 got a CLI change merged yesterday that fixes the syscall issue:

https://github.com/mitchellh/cli/pull/25

And the Docker client must have gotten fixed upstream:

https://twitter.com/jen20/status/684450871606939648

I'll take this and add solaris to the list of built flavors.
",slackpad,jen20
159,2016-01-06 10:14:32,"Awesome! Thanks @slackpad & @jen20 :+1: 
",cmacrae,jen20
126,2016-06-02 19:43:21,"@armon @slackpad 
Before I try to dig into the code, would you like to accept pull requests? May be I have some time in two or three month.

EDIT: my proposal fixes #215. It's not really broken, but it gives @darron ability to work around his problem.
",Bessonov,darron
112,2014-05-03 09:05:05,"<3! But is it reasonable to have a plugin system that's less than turing complete? I'm a acme/vi snob so I'd prefer these happen in a separate process, which requires an IPC (ideally STDIN/STDOUT). In-process is much more complicated, we (and [heka](https://github.com/mozilla-services/heka)) ended up using lua for an extension language.

Alternatively, @armon added consul support to [confd](https://github.com/kelseyhightower/confd) which supports a `reload_cmd` to trigger config updates. I have a feeling that this will handle 90% of the integration most folks need.
",josephholsten,armon
110,2014-12-16 10:47:03,"Wow, I was just thinking about this problem

Brian, could this same technique be used as part of the startup of an 
individual consul server?

I am currently using Hashicorp's consul-join.conf upstart script found 
here: 
https://github.com/hashicorp/consul/blob/master/terraform/aws/scripts/upstart-join.conf

I was thinking to replace the hardcoded host IP to join a cluster with a 
query for the SRV record. Do you see any immediate problems w/ this?

I am using ansible to start up the cluster. As part of the start up, I will 
check for the existence of the SRV record. Should it not exist, i will 
write the value of the first provisioned consul server.

On Sunday, May 4, 2014 11:31:39 PM UTC+2, Brian Lalor wrote:

> [Trying to bring threads in two mediums together]
> 
> On May 4, 2014, at 4:57 PM, XavM <notifi...@github.com <javascript:>> 
> wrote:
> 
> Regarding the consul join command with a DNS host name, you have to know 
> which host is up, is running consul (and on which port) and is member in 
> the desired cluster, meaning you still have to maintain a hard-coded list 
> of hosts:ports to join on startup
> 
> This is it exactly.  Itâ€™s a chicken/egg problem.  I think a -srv-domain 
> option would be ideal.  â€œ-srv-domainâ€ with no domain could default to the 
> hostâ€™s DNS domain name, or one could be provided.  The actual record that 
> would be queried would be _consul._tcp.$DOMAIN.  Then consul would just 
> join using all of the entries in that record.  Consul itself canâ€™t be 
> queried because it hasnâ€™t joined the cluster, yet!  Iâ€™ve got a work-around 
> for not having -srv-domain; Iâ€™m using Chef to run the following:
> 
> 
> 
> ; then
>         dig +search +noall +answer _consul._tcp SRV | awk '{print $NF}' | 
> xargs --no-run-if-empty consul join
>     fi
> 
> /v1/status/leader returns 500 if there is no leader (and therefore the 
> agentâ€™s not part of the cluster).  If that query fails, then dig is used to 
> search for the SRV record, and all entries in that record are passed to 
> â€œconsul join""
> 
> That just leaves the problem of how to update that record in DNS, which is 
> part of the discussion of agent bootstrapping.  If youâ€™ve got a cluster 
> with 3 servers, you donâ€™t want all three updating Route53 (for example) 
> when a server is added or removed; that should only happen from the leader. 
>  So the remaining issue is that I need a clean way to identify if a 
> particular node is the leader, and ideally there would be a blocking query 
> that would return the current set of servers.
> 
> A rejoin using old cached member information could fail due to a stale 
> cache (Depending on how long the node has been down, the topology could 
> have change)
> 
> With a definitive way to determine the servers for a datacenter 
> (_consul._tcp.$DOMAIN SRV record), re-joining just becomes a performance 
> optimization.  I think the real solution is having a well-defined way to 
> join a cluster on initial boot.
",blalor,github
108,2014-05-02 17:35:36,"@mitchellh 

How do we change the bind address for the web ui, its only accepting connections from localhost.
",bscott,mitchellh
105,2014-05-02 03:21:30,"Originally reported by @blalor

We need to provide better options for logging that isn't geared towards humans. I think this should probably entail both syslog and a file option.
",mitchellh,blalor
98,2014-05-01 17:23:53,"Awesome work by @pearkes. This brings in the web UI.
",armon,pearkes
88,2014-04-29 16:26:09,"Yo Chavez. Actually, I was hoping we could persist this problem from the servers into the agents, so that any agents can see if any servers are running GOMAXPROCS == 1.

I'll let @armon decide.
",mitchellh,armon
75,2014-04-24 05:56:09,"I believe Synapse supports plugins. I think doing a Consul Synapse plugin would be ideal here, rather than building this into Consul itself. This gives you the freedom to modify the HAProxy configurations as you want. @armon?
",mitchellh,armon
74,2014-04-24 00:14:18,"Yeah I attempted cross compilation and noted that @davecheney had done some work in this area but I don't think `cgo` is fully supported yet?

Just a note, I have spun up a few Raspberry pi's running consul and they are working fine, as you say the main thing to note is the build current does need to be done on a pi, then pushed to the other devices.

Process was:
1. Install `build-essential`
2. Grab one of @davecheney's unofficial golang tar balls and install that
3. Run the make

Overall it performs great and memory use is pretty stable.

Thanks
",wolfeidau,davecheney
74,2014-07-03 20:09:44,"OK I dug up my Raspberry pi and managed to build a working binary using golang 1.2. Need to chase up @davecheney on how to best solve the cross compile issue.

This version is packaged as `0.3.0_consul_linux_armpi.zip`.
",wolfeidau,davecheney
74,2014-07-03 20:34:24,"Works like a charm, thank you! And I'll throw in my vote for having @davecheney figure out how to streamline this :)
",spro,davecheney
73,2014-04-23 05:30:17,"@Tarrant Hmm. It is hard to tell exactly what is happening from the logs. If you can reproduce this the output of `consul info` would be useful, as well as the logs of the other servers. As far as I can tell, Raft does seem to be working as intended. The node seems to have been the leader previously and had a bunch of pending writes, so it's log is longer, and it is reject votes for other nodes. The ODD part is that this node is not entering the candidate state, or that the other two nodes are not able to win either. Do you have their logs?
",armon,Tarrant
73,2014-04-23 06:02:56,"@Tarrant I just pushed some changes to Raft to provide more debugging info for this as well: https://github.com/hashicorp/raft/commit/a98ae57c589de765a7004ac222b1a3d31f2e46d5
",armon,Tarrant
71,2014-04-22 06:03:11,"The way Ubuntu standardizes on this sort of thing is having a ""defaults"" file such as `/etc/defaults/consul` that just exports raw flags to run. For example, a defaults file for Consul might look like:



Then in your service you can do



That is the approach I prefer to take with ops. Its also just as easy to template the service file to have the proper configuration directory.

I think having both a config-file and config-dir might be confusing for users since one would only be able to contain the directory. I think the above approach is better, but we'll defer to @armon.
",mitchellh,armon
65,2014-05-01 16:55:54,"@nkts Should be fixed today. We are pushing out 0.2 shortly.
",armon,nkts
58,2014-04-18 15:55:48,"I think keeping ""consul."" as the default makes sense, but I also think it would make sense to make this configurable. Thoughts, @armon?
",mitchellh,armon
55,2014-04-18 06:53:31,"@Tarrant Please try to specify the `-bind` flag. Consul attempts to use the first private IP it finds, but that may not be suitable in all cases.
",armon,Tarrant
54,2014-04-18 03:04:15,"/cc: @aphyr @jpfuentes2

We demand that all reads and writes are serialized through a leader. All writes naturally go through the Raft log, but we do reads directly from the leader state. The leader ""leases"" it's position for a configurable time, and checks that it is still leader each LeaderLeaseTimeout interval. However, if the leader is partitioned, a new leader could be elected and new writes processed. A read from the old leader could return a stale value in this situation.

This situation is hard to trigger, since by default a leader leases for 300msec, and a node only starts an election if it hasn't heard from the leader in 300msec - 600msec. This means generally the new election only happens after the old leader has already stepped down.
",armon,jpfuentes2
54,2014-04-18 03:04:15,"/cc: @aphyr @jpfuentes2

We demand that all reads and writes are serialized through a leader. All writes naturally go through the Raft log, but we do reads directly from the leader state. The leader ""leases"" it's position for a configurable time, and checks that it is still leader each LeaderLeaseTimeout interval. However, if the leader is partitioned, a new leader could be elected and new writes processed. A read from the old leader could return a stale value in this situation.

This situation is hard to trigger, since by default a leader leases for 300msec, and a node only starts an election if it hasn't heard from the leader in 300msec - 600msec. This means generally the new election only happens after the old leader has already stepped down.
",armon,aphyr
40,2014-04-24 13:48:23,"I installed with the installer. I'll try to build from source today and see
if I'm able to.

Thanks!

On Wednesday, April 23, 2014, Armon Dadgar notifications@github.com wrote:

> @drnic https://github.com/drnic @mbrevoorthttps://github.com/mbrevoortHmm. I'm on Mavericks and it works without any issues for me. This is
> really bizarre, since it looks like its an open issue with the Golang
> toolchain. How did you guys get go? Build from source?
> 
> â€”
> Reply to this email directly or view it on GitHubhttps://github.com/hashicorp/consul/issues/40#issuecomment-41242614
> .
",mbrevoort,mbrevoorthttps
38,2014-04-16 05:21:57,"Adding a Docker Consul cluster inside of Vagrant. The `README` will also inform users they can bypass Vagrant if they have Docker running on their host.

This is a WIP so please don't merge or analyze too critically yet. This work will hopefully be used in upcoming Jepsen tests!

/cc @armon 
",jpfuentes2,armon
23,2014-04-04 20:11:36,"@mitchellh I was more thinking, once a service had been discovered, a node could then register its use of that service. This could be a one-time operation using a Serf event or query, which could contain the node's name/address/whatever else in the event payload.

This would require the endpoint doing the discovery using Consul to take on responsibility of registering utilization once a suitable service had been found. There would also need to be a reliable way of deregistering if a node died/got reaped.

This could help with transparency on who is talking to who in the cluster, which sounds like part of what @andrewwatson needs in #22, and wouldn't rely on DNS query frequency as @armon pointed out. 

Since automatic service discovery moves the source of truth for network topology into runtime, I could see using this to build a topology graph if the data were exposed over say, the HTTP interface.

Anyways, it might not be the immediate goal of Consul to handle stuff like this, and #22 points back here so its cool if we close this out. Thanks for your comments!
",ryanuber,armon
23,2014-04-04 20:11:36,"@mitchellh I was more thinking, once a service had been discovered, a node could then register its use of that service. This could be a one-time operation using a Serf event or query, which could contain the node's name/address/whatever else in the event payload.

This would require the endpoint doing the discovery using Consul to take on responsibility of registering utilization once a suitable service had been found. There would also need to be a reliable way of deregistering if a node died/got reaped.

This could help with transparency on who is talking to who in the cluster, which sounds like part of what @andrewwatson needs in #22, and wouldn't rely on DNS query frequency as @armon pointed out. 

Since automatic service discovery moves the source of truth for network topology into runtime, I could see using this to build a topology graph if the data were exposed over say, the HTTP interface.

Anyways, it might not be the immediate goal of Consul to handle stuff like this, and #22 points back here so its cool if we close this out. Thanks for your comments!
",ryanuber,andrewwatson
11,2014-05-02 03:31:46,"@armon I'm guessing this should be easier now since we had to write the Go API client for confd, no?
",mitchellh,armon
